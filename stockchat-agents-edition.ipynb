{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"datasetId":7122584,"sourceId":11376588,"sourceType":"datasetVersion"}],"dockerImageVersionId":31192,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/oswind/stockchat-agents-edition?scriptVersionId=280262633\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Environment Setup","metadata":{}},{"cell_type":"code","source":"# Setup the notebook based on running environment.\nimport os\n# Optional: Enable telemetry in browser_use and chromadb.\nos.environ[\"ANONYMIZED_TELEMETRY\"] = \"false\"\n# Check for kaggle environment.\nif os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"):\n    # Kaggle Run: update the system.\n    !pip uninstall -qqy google-ai-generativelanguage pydrive2 tensorflow tensorflow-decision-forests cryptography pyOpenSSL langchain langchain-core nltk ray click google-generativeai google-cloud-translate datasets cesium bigframes plotnine mlxtend fastai spacy thinc google-colab gcsfs jupyter-kernel-gateway\n    !pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n    !pip install -qU langchain-community langchain-text-splitters wikipedia lmnr[all] google-adk google-cloud-translate\n    from kaggle_secrets import UserSecretsClient # type: ignore\n    from jupyter_server.serverapp import list_running_servers # type: ignore\nelse:\n    # Mock the kaggle secrets client.\n    class UserSecretsClient:\n        @classmethod\n        def set_secret(cls, id: str, value: str):\n            os.environ[id] = value\n        @classmethod\n        def get_secret(cls, id: str):\n            try:\n                return os.environ[id]\n            except KeyError as e:\n                print(f\"KeyError: authentication token for {id} is undefined\")\n    # Local Run: update the venv.\n    %pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n    %pip install -qU langchain-community langchain-text-splitters wikipedia pandas google-api-core \"lmnr[all]\" browser-use ollama google-adk\n    from browser_use import Agent as BrowserAgent\n\nimport ast, chromadb, json, logging, pandas, platform, pytz, re, requests, threading, time, warnings, wikipedia\nfrom bs4 import Tag\nfrom chromadb import Documents, Embeddings\nfrom datetime import datetime, timedelta\nfrom dateutil.parser import parse\nfrom enum import Enum\nfrom google.adk.runners import InMemoryRunner\nfrom google import genai\nfrom google.api_core import retry, exceptions\nfrom google.genai.models import Models\nfrom google.genai import types, errors\nfrom IPython.display import Markdown, display, HTML\nfrom langchain_community.document_loaders.csv_loader import CSVLoader\nfrom langchain_text_splitters.html import HTMLSemanticPreservingSplitter\nfrom langchain_text_splitters.json import RecursiveJsonSplitter\nfrom lmnr import Laminar\nfrom math import inf\nfrom pydantic import BaseModel, field_validator\nfrom threading import Timer\nfrom tqdm import tqdm\nfrom typing import Optional, Callable, NewType, NamedTuple\nfrom wikipedia.exceptions import DisambiguationError, PageError","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-11-19T23:39:24.05827Z","iopub.execute_input":"2025-11-19T23:39:24.059373Z","iopub.status.idle":"2025-11-19T23:42:51.880398Z","shell.execute_reply.started":"2025-11-19T23:39:24.059309Z","shell.execute_reply":"2025-11-19T23:42:51.879307Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.3/257.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.6/456.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.1/456.1 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.9/205.9 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.0/473.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.4/270.4 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.5/371.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Prepare the Gemini api for use.\n# Setup a retry helper for generation not run through the below api-helper.\nis_retriable = lambda e: (isinstance(e, errors.APIError) and e.code in {429, 503, 500})\nModels.generate_content = retry.Retry(predicate=is_retriable)(Models.generate_content)\nModels.embed_content = retry.Retry(predicate=is_retriable)(Models.embed_content)\n\n# Activate Laminar auto-instrumentation.\ntry:\n    Laminar.initialize(project_api_key=UserSecretsClient().get_secret(\"LMNR_PROJECT_API_KEY\"))\nexcept:\n    print(\"Skipping Laminar.initialize()\")\n\nclass GeminiModel:\n    def __init__(self, rpm: list, tpm: list, rpd: list):\n        self.rpm = rpm # requests per minute\n        self.tpm = tpm # tokens per minute in millions\n        self.rpd = rpd # requests per day\n        self.err = [0,0] # validation, api_related\n\n# A python api-helper with model fail-over/chaining/retry support.\nGeminiEmbedFunction = NewType(\"GeminiEmbedFunction\", None) # forward-decl\nclass Api:\n    gen_limit_in = 1048576\n    emb_limit_in = 2048\n    gen_model = {\n        \"gemini-2.0-flash\": GeminiModel([15,2000,10000,30000],[1,4,10,30],[200,inf,inf,inf]), # stable wo/thinking: 15 RPM/1M TPM/200 RPD\n        \"gemini-2.0-flash-exp\": GeminiModel([15,2000,10000,30000],[1,4,10,30],[200,inf,inf,inf]), # latest w/thinking: 15 RPM/1M TPM/200 RPD\n        \"gemini-2.5-flash\": GeminiModel([10,1000,2000,10000],[.25,1,3,8],[250,10000,100000,inf]), # stable: 10 RPM/250K TPM/250 RPD\n        \"gemini-2.5-flash-preview-09-2025\": GeminiModel([10,1000,2000,10000],[.25,1,3,8],[250,10000,100000,inf]), # exp: 10 RPM/250K TPM/250 RPD\n        \"gemini-2.5-flash-lite\": GeminiModel([15,4000,10000,30000],[.25,4,10,30],[1000,inf,inf,inf]), # stable: 15 RPM/250K TPM/1K RPD\n        \"gemini-2.5-flash-lite-preview-09-2025\": GeminiModel([15,4000,10000,30000],[.25,4,10,30],[1000,inf,inf,inf]), # exp: 15 RPM/250K TPM/1K RPD\n        \"gemini-2.5-pro\": GeminiModel([5,150,1000,2000],[.25,2,5,8],[100,10000,50000,inf]), # stable: 5 RPM/250K TPM/100 RPD\n    }\n    gen_local = [\"gemma3n:e4b\",\"gemma3:12b-it-qat\"]\n    default_local = 0\n    default_model = []\n    embed_model = \"gemini-embedding-001\", GeminiModel([100,3000,5000,10000],[.03,1,5,10],[1000,inf,inf,inf]) # stable: 100 RPM/30K TPM/1000 RPD/100 per batch\n    embed_local = False\n    error_total = 0\n    min_rpm = 3\n    dt_between = 2.0\n    errored = False\n    running = False\n    dt_err = 60.0\n    dt_rpm = 60.0\n\n    @classmethod\n    def get(cls, url: str):\n        # Create a header matching the OS' tcp-stack fingerprint.\n        system_ua = None\n        match platform.system():\n            case 'Linux':\n                system_ua = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'\n            case 'Darwin':\n                system_ua = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 15_7_2) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/26.0 Safari/605.1.15'\n            case 'Windows':\n                system_ua = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'\n        try:\n            request = requests.get(url, headers={'User-Agent': system_ua})\n            if request.status_code != requests.codes.ok:\n                print(f\"Api.get() returned status {request.status_code}\")\n            return request.text\n        except Exception as e:\n            raise e\n\n    class Limit(Enum):\n        FREE = 0\n        TIER_1 = 1\n        TIER_2 = 2\n        TIER_3 = 3\n    \n    class Model(Enum):\n        GEN = 1\n        EMB = 2\n        LOC = 3\n\n    class Const(Enum):\n        STOP = \"I don't know.\"\n        METRIC_BATCH = 20\n        SERIES_BATCH = 40\n        EMBED_BATCH = 100\n        CHUNK_MAX = 1500\n\n        @classmethod\n        def Stop(cls):\n            return cls.STOP.value\n\n        @classmethod\n        def MetricBatch(cls):\n            return cls.METRIC_BATCH.value\n\n        @classmethod\n        def SeriesBatch(cls):\n            return cls.SERIES_BATCH.value\n\n        @classmethod\n        def EmbedBatch(cls):\n            return cls.EMBED_BATCH.value\n\n        @classmethod\n        def ChunkMax(cls):\n            return cls.CHUNK_MAX.value\n    \n    class Env(NamedTuple): # Make init args immutable.\n        CLIENT: genai.Client\n        API_LIMIT: int\n        GEN_DEFAULT: str\n\n    def __init__(self, with_limit: Limit, default_model: str):\n        if default_model in self.gen_model.keys():\n            self.write_lock = threading.RLock()\n            self.args = Api.Env(\n                genai.Client(api_key=UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")),\n                with_limit.value,\n                default_model)\n            self.m_id = list(self.gen_model.keys()).index(default_model)\n            self.default_model.append(default_model)\n            self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.args.API_LIMIT]\n            self.s_embed = GeminiEmbedFunction(self.args.CLIENT, semantic_mode = True) # type: ignore\n            logging.getLogger(\"google_genai\").setLevel(logging.WARNING) # suppress info on generate\n        else:\n            print(f\"{default_model} not found in gen_model.keys()\")\n        \n\n    def __call__(self, model: Model) -> str:\n        if model == self.Model.GEN:\n            return \"models/\" + list(self.gen_model.keys())[self.m_id]\n        elif model == self.Model.LOC:\n            return self.gen_local[self.default_local]\n        else:\n            return \"models/\" + self.embed_model[0] if not self.embed_local else \"embeddinggemma:latest\"\n\n    def push_default_model(self, model_id: str):\n        if model_id in self.gen_model.keys():\n            self.write_lock.acquire()\n            self.stop_running()\n            self.default_model.append(model_id)\n            self.m_id = list(self.gen_model.keys()).index(model_id)\n            self.write_lock.release()\n        else:\n            print(f\"{model_id} not found in gen_model.keys()\")\n\n    def pop_default_model(self):\n        if len(self.default_model) > 1:\n            self.write_lock.acquire()\n            self.stop_running()\n            self.default_model.pop(-1)\n            self.m_id = list(self.gen_model.keys()).index(self.default_model[-1])\n            self.write_lock.release()\n\n    def retriable(self, retry_fn: Callable, *args, **kwargs):\n        for attempt in range(len(self.gen_model.keys())):\n            try:\n                self.write_lock.acquire()\n                if self.gen_rpm > self.min_rpm:\n                    self.gen_rpm -= 1\n                else:\n                    self.on_error(kwargs)\n                if not self.running and not self.errored:\n                    self.rpm_timer = Timer(self.dt_rpm, self.refill_rpm)\n                    self.rpm_timer.start()\n                    self.running = True\n                return retry_fn(*args, **kwargs)\n            except (errors.APIError, exceptions.RetryError) as api_error:\n                if isinstance(api_error, errors.APIError):\n                    is_retry = api_error.code in {429, 503, 500, 400} # code 400 when TPM exceeded\n                    if not is_retry or attempt == 3*len(self.gen_model.keys())-1:\n                        raise api_error\n                self.on_error(kwargs)\n            except Exception as e:\n                self.on_error(kwargs) # raise e\n            finally:\n                self.write_lock.release()\n\n    def on_error(self, kwargs):\n        self.generation_fail()\n        kwargs[\"model\"] = self(Api.Model.GEN)\n        time.sleep(self.dt_between)\n\n    def stop_running(self):\n        if self.running:\n            self.rpm_timer.cancel()\n            self.running = False\n\n    def validation_fail(self):\n        list(self.gen_model.values())[self.m_id].err[0] += 1\n        self.error_total += 1\n\n    def generation_fail(self):\n        self.stop_running()\n        self.save_error()\n        self.next_model()\n        print(\"api.generation_fail.next_model: model is now \", list(self.gen_model.keys())[self.m_id])\n        if not self.errored:\n            self.error_timer = Timer(self.dt_err, self.zero_error)\n            self.error_timer.start()\n            self.errored = True\n\n    def save_error(self):\n        list(self.gen_model.values())[self.m_id].err[1] += 1\n        self.error_total += 1\n\n    def next_model(self):\n        self.m_id = (self.m_id+1)%len(self.gen_model.keys())\n        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.args.API_LIMIT]\n\n    def refill_rpm(self):\n        self.running = False\n        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.args.API_LIMIT]\n        print(\"api.refill_rpm \", self.gen_rpm)\n\n    def zero_error(self):\n        self.errored = False\n        self.m_id = list(self.gen_model.keys()).index(self.default_model[-1])\n        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.args.API_LIMIT]\n        print(\"api.zero_error: model is now \", list(self.gen_model.keys())[self.m_id])\n\n    def token_count(self, expr: str):\n        count = self.args.CLIENT.models.count_tokens(\n            model=self(Api.Model.GEN),\n            contents=json.dumps(expr))\n        return count.total_tokens\n\n    def errors(self):\n        errors = {\"total\": self.error_total, \"by_model\": {}}\n        for m_code, m in self.gen_model.items():\n            errors[\"by_model\"].update({\n                m_code: {\n                    \"api_related\": m.err[1],\n                    \"validation\": m.err[0]\n                }})\n        return errors\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def similarity(self, content: list):\n        return self.s_embed.sts(content) # type: ignore","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:42:51.882323Z","iopub.execute_input":"2025-11-19T23:42:51.88306Z","iopub.status.idle":"2025-11-19T23:42:52.03362Z","shell.execute_reply.started":"2025-11-19T23:42:51.883027Z","shell.execute_reply":"2025-11-19T23:42:52.032314Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","text":"Skipping Laminar.initialize()\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Define the embedding function.\napi = NewType(\"api\", Api) # type: ignore (forward-decl)\nclass GeminiEmbedFunction:\n    document_mode = True  # Generate embeddings for documents (T,F), or queries (F,F).\n    semantic_mode = False # Semantic text similarity mode is exclusive (F,T).\n    \n    def __init__(self, genai_client, semantic_mode: bool = False):\n        self.client = genai_client\n        if semantic_mode:\n            self.document_mode = False\n            self.semantic_mode = True\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def __embed__(self, input: Documents) -> Embeddings:\n        if self.document_mode:\n            embedding_task = \"retrieval_document\"\n        elif not self.document_mode and not self.semantic_mode:\n            embedding_task = \"retrieval_query\"\n        elif not self.document_mode and self.semantic_mode:\n            embedding_task = \"semantic_similarity\"\n        partial = self.client.models.embed_content(\n            model=api(Api.Model.EMB),\n            contents=input,\n            config=types.EmbedContentConfig(task_type=embedding_task)) # type: ignore\n        return [e.values for e in partial.embeddings]\n    \n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def __call__(self, input: Documents) -> Embeddings:\n        try:\n            response = []\n            for i in range(0, len(input), Api.Const.EmbedBatch()):  # Gemini max-batch-size is 100.\n                response += self.__embed__(input[i:i + Api.Const.EmbedBatch()])\n            return response\n        except Exception as e:\n            print(f\"caught exception of type {type(e)}\\n{e}\")\n            raise e\n\n    def sts(self, content: list) -> float:\n        df = pandas.DataFrame(self(content), index=content)\n        score = df @ df.T\n        return score.iloc[0].iloc[1]","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:42:52.034641Z","iopub.execute_input":"2025-11-19T23:42:52.034907Z","iopub.status.idle":"2025-11-19T23:42:52.046553Z","shell.execute_reply.started":"2025-11-19T23:42:52.034885Z","shell.execute_reply":"2025-11-19T23:42:52.04555Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Set Gemini API Limit","metadata":{}},{"cell_type":"code","source":"# Instantiate the api-helper with usage limit => FREE.\n# Optional: Set limit here to one of [FREE,TIER_1,TIER_2,TIER_3]\napi = Api(with_limit=Api.Limit.TIER_1, default_model=\"gemini-2.0-flash-exp\")\n# Export api environment for agent.\nos.environ[\"API_LIMIT\"]=str(api.args.API_LIMIT)\nos.environ[\"GEN_DEFAULT\"]=api.args.GEN_DEFAULT","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:42:52.048567Z","iopub.execute_input":"2025-11-19T23:42:52.048876Z","iopub.status.idle":"2025-11-19T23:42:52.421526Z","shell.execute_reply.started":"2025-11-19T23:42:52.048853Z","shell.execute_reply":"2025-11-19T23:42:52.420529Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Gemini Baseline Check","metadata":{}},{"cell_type":"code","source":"# This is an accurate retelling of events. \nconfig_with_search = types.GenerateContentConfig(\n    tools=[types.Tool(google_search=types.GoogleSearch())],\n    temperature=0.0\n)\n\nchat = api.args.CLIENT.chats.create(\n    model=api(Api.Model.GEN),\n    config=config_with_search,\n    history=[]) # Ignoring the part about dark elves, and tengwar.\n\nresponse = chat.send_message('Do you know anything about the stock market?')\nMarkdown(response.text)","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:42:52.422466Z","iopub.execute_input":"2025-11-19T23:42:52.423565Z","iopub.status.idle":"2025-11-19T23:42:57.536036Z","shell.execute_reply.started":"2025-11-19T23:42:52.423532Z","shell.execute_reply":"2025-11-19T23:42:57.534998Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Yes, I do. Here's some information about the stock market:\n\n**What it is:**\n\n*   The stock market is where investors buy and sell shares of stock, which represent ownership in public companies.\n*   It can refer to a specific exchange (like the New York Stock Exchange) or to the overall marketplace where stocks and other securities are traded.\n*   The stock market allows companies to raise capital by issuing shares to the public through an initial public offering (IPO).\n\n**How it works:**\n\n*   Stocks are listed on exchanges, and investors buy and sell these stocks among themselves.\n*   The price of a stock is determined by supply and demand.\n*   Trades can happen electronically through online stockbrokers.\n*   The U.S. Securities and Exchange Commission (SEC) regulates the stock market to protect investors and maintain fair markets.\n\n**Key components:**\n\n*   **Stock exchanges:** These are central locations (physical or virtual) where stocks are bought and sold. Examples include the New York Stock Exchange (NYSE) and the Nasdaq.\n*   **Stock market indices:** These are used to measure the performance of a stock market or a subset of it. Examples include the S&P 500, Dow Jones Industrial Average (DJIA), and Nasdaq Composite.\n*   **Market capitalization:** This is the total value of a company's outstanding shares of stock. Stock market indices are often weighted by market capitalization.\n\n**Important concepts:**\n\n*   **Bulls and Bears:** \"Bull market\" signifies a market on the rise, while a \"bear market\" indicates a declining market.\n*   **Trading:** Stocks can be traded \"over the counter\" (OTC), which means trading directly between parties without using an exchange.\n*   **Leveraged Strategies:** Strategies like short selling (betting that a stock price will fall) and margin buying (borrowing money to buy stocks) can amplify both gains and losses.\n\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"response = chat.send_message('I have an interest in AMZN stock')\nMarkdown(response.text)","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:42:57.537229Z","iopub.execute_input":"2025-11-19T23:42:57.537792Z","iopub.status.idle":"2025-11-19T23:43:03.424906Z","shell.execute_reply.started":"2025-11-19T23:42:57.537754Z","shell.execute_reply":"2025-11-19T23:43:03.423866Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Okay, here's some information regarding AMZN (Amazon) stock as of November 19, 2025:\n\n**Current Price and Market Sentiment:**\n\n*   As of today, November 19, 2025, Amazon (AMZN) is trading around \\$221.48 to \\$235.52.\n*   The consensus rating from analysts is \"Moderate Buy\" to \"Strong Buy\".\n*   However, one source indicates a \"Bearish\" sentiment based on technical indicators.\n\n**Price Targets and Forecasts:**\n\n*   The average 12-month price target from analysts ranges from \\$294.70 to \\$296.64.\n*   Some analysts have targets as high as \\$340 to \\$360.\n*   However, there are also lower price targets, with the lowest around \\$235 to \\$255.\n*   One analysis suggests the stock is poised for a move to around \\$310.\n*   For the end of 2025, forecasts vary, with some predicting around \\$210 to \\$250.\n\n**Recent News and Factors Influencing the Stock:**\n\n*   **AWS Growth:** Amazon Web Services (AWS) is experiencing accelerated growth, contributing significantly to Amazon's revenue and profitability.\n*   **Advertising:** Amazon's advertising revenue is also growing rapidly.\n*   **AI Investments:** Amazon is investing heavily in AI, including a partnership with Anthropic.\n*   **Regulatory Scrutiny:** Amazon, along with other large tech companies, faces increasing regulatory scrutiny, particularly in Europe.\n*   **Analyst Downgrade:** One analyst recently downgraded their recommendation on Amazon stock, citing concerns about the capital intensity of AI development.\n\n**Key Statistics:**\n\n*   **Market Cap:** Around \\$2.38 trillion.\n*   **Price-to-Earnings Ratio:** Approximately 31.44.\n*   **52-Week Range:** \\$161.38 to \\$258.60.\n\n**In summary:** Analyst sentiment is generally positive, with many predicting significant upside for AMZN stock. The company's strong growth in AWS and advertising, as well as its investments in AI, are seen as positive drivers. However, regulatory concerns and the potential impact of AI investments on margins are factors to watch.\n"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"response = chat.send_message('''Tell me about AMZN current share price, short-term trends, and bullish versus bearish predictions''')\nMarkdown(response.text)","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:03.42603Z","iopub.execute_input":"2025-11-19T23:43:03.426436Z","iopub.status.idle":"2025-11-19T23:43:08.846988Z","shell.execute_reply.started":"2025-11-19T23:43:03.426403Z","shell.execute_reply":"2025-11-19T23:43:08.845956Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's an overview of AMZN's current share price, short-term trends, and bullish/bearish predictions as of November 19, 2025:\n\n**Current Share Price:**\n\n*   AMZN is currently trading around \\$221.61 to \\$235.52.\n*   Recent trading has seen fluctuations between \\$218.53 and \\$226.13.\n\n**Short-Term Trends:**\n\n*   Mixed signals are present. Some sources indicate a recent decline over the past week or five trading sessions.\n*   Other analyses suggest potential for a slight increase in the immediate short term (next few days).\n*   One source suggests the stock is in a \"wide and weak rising trend,\" which could present a buying opportunity unless the trendline is broken.\n*   Another source indicates the stock has fallen for five consecutive days.\n\n**Bullish Predictions:**\n\n*   Many analysts have a \"Strong Buy\" or \"Moderate Buy\" consensus rating on AMZN.\n*   The average 12-month price target among analysts ranges from \\$294.40 to \\$297.80, implying a significant upside. Some have targets as high as \\$340 to \\$360.\n*   Bullish analysts point to Amazon's strong growth in AWS and advertising, as well as its investments in AI, as positive drivers.\n*   Some analysts believe the stock is poised to move toward \\$310.\n\n**Bearish Predictions:**\n\n*   Some sources indicate a \"Bearish\" sentiment based on technical indicators.\n*   One analysis predicts the stock could drop to around \\$209.99 by December 17, 2025.\n*   A few analysts have lower price targets, with the lowest around \\$230 to \\$255.\n*   Concerns exist regarding the capital intensity of AI development and potential regulatory scrutiny.\n*   One source suggests a potential tough correction is coming.\n\n**Important Considerations:**\n\n*   Analyst price targets are just estimates and not guarantees.\n*   The stock market is inherently volatile, and predictions can be wrong.\n*   Consider your own risk tolerance and investment goals before making any decisions.\n"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"response = chat.send_message('''What is mgm studio's stock ticker symbol?''')\nMarkdown(response.text)","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:08.848503Z","iopub.execute_input":"2025-11-19T23:43:08.848889Z","iopub.status.idle":"2025-11-19T23:43:11.343781Z","shell.execute_reply.started":"2025-11-19T23:43:08.848855Z","shell.execute_reply":"2025-11-19T23:43:11.342848Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"It's important to distinguish between **Metro-Goldwyn-Mayer (MGM)** studios and **MGM Resorts International**.\n\n*   **MGM Resorts International** is a hospitality and entertainment company. Its stock ticker symbol is **MGM** and it is listed on the NYSE (New York Stock Exchange).\n*   **Metro-Goldwyn-Mayer (MGM) Studios** was acquired by Amazon in 2022 and is now a subsidiary of Amazon MGM Studios. Therefore, it is no longer a publicly traded company with its own separate stock ticker.\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"response = chat.send_message('''What was the last open,close,high,low data for AMZN again?''')\nMarkdown(response.text)","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:11.344736Z","iopub.execute_input":"2025-11-19T23:43:11.345054Z","iopub.status.idle":"2025-11-19T23:43:13.436777Z","shell.execute_reply.started":"2025-11-19T23:43:11.345024Z","shell.execute_reply":"2025-11-19T23:43:13.435551Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's the data for AMZN (Amazon) stock from the most recent trading day, November 18, 2025:\n\n*   **Open:** \\$228.10\n*   **Close:** \\$222.55\n*   **High:** \\$230.20\n*   **Low:** \\$222.42"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"response = chat.send_message('''What is AMZN open,close,high,low data for the past month? \nPresent the data with multiple columns for display in markdown.''')\nMarkdown(response.text)","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:13.440479Z","iopub.execute_input":"2025-11-19T23:43:13.44106Z","iopub.status.idle":"2025-11-19T23:43:20.657662Z","shell.execute_reply.started":"2025-11-19T23:43:13.441036Z","shell.execute_reply":"2025-11-19T23:43:20.656807Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's the AMZN (Amazon) stock data for the past month (October 20, 2025 - November 18, 2025).\n\n| Date       | Open    | High    | Low     | Close   |\n| ---------- | ------- | ------- | ------- | ------- |\n| Nov 18, 2025 | $228.10 | $230.20 | $222.42 | $222.55 |\n| Nov 17, 2025 | $233.25 | $234.60 | $229.19 | $232.87 |\n| Nov 14, 2025 | $235.06 | $238.73 | $232.89 | $234.69 |\n| Nov 13, 2025 | $243.05 | $243.75 | $236.50 | $237.58 |\n| Nov 12, 2025 | $250.24 | $250.37 | $243.75 | $244.20 |\n| Nov 11, 2025 | $248.41 | $249.75 | $247.23 | $249.10 |\n| Nov 10, 2025 | $248.34 | $251.75 | $245.59 | $248.40 |\n| Nov 07, 2025 | $242.90 | $244.90 | $238.49 | $244.41 |\n| Nov 06, 2025 | $249.16 | $250.38 | $242.17 | $243.04 |\n| Nov 05, 2025 | $249.03 | $251.00 | $246.16 | $250.20 |\n| Nov 04, 2025 | $250.38 | $257.01 | $248.66 | $249.32 |\n| Nov 03, 2025 | $255.36 | $258.60 | $252.90 | $254.00 |\n| Oct 31, 2025 | $250.10 | $250.50 | $243.98 | $244.22 |\n| Oct 30, 2025 | $227.06 | $228.44 | $222.75 | $222.86 |\n| Oct 29, 2025 | $231.67 | $232.82 | $227.76 | $230.30 |\n| Oct 28, 2025 | $228.22 | $231.49 | $226.21 | $229.25 |\n| Oct 27, 2025 | $227.66 | $228.40 | $225.54 | $226.97 |\n| Oct 24, 2025 | $221.97 | $225.40 | $221.90 | $224.21 |\n| Oct 23, 2025 | $219.00 | $221.30 | $218.18 | $221.09 |\n| Oct 22, 2025 | $219.30 | $220.00 | $216.52 | $217.95 |\n| Oct 21, 2025 | $218.43 | $223.32 | $217.99 | $222.03 |\n| Oct 20, 2025 | $213.88 | $217.71 | $211.03 | $216.48 |\n\n**Disclaimer:**\n\n*   This data is based on available information as of November 19, 2025.\n*   Stock market data is subject to change.\n"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# Previously on Kaggle: StockChat 1.0","metadata":{}},{"cell_type":"markdown","source":"## Validation BaseModels","metadata":{}},{"cell_type":"code","source":"# Validation BaseModels in pydantic schema.\nclass RestStatus(Enum):\n    OK = \"OK\"\n    DELAY = \"DELAYED\"\n    NONE = \"NOT_FOUND\"\n    AUTH = \"NOT_AUTHORIZED\"\n\nclass StopGeneration(BaseModel):\n    result: str = Api.Const.Stop()\n\nclass RestResultPoly(BaseModel):\n    request_id: Optional[str] = None\n    count: Optional[int] = None\n    next_url: Optional[str] = None\n    status: RestStatus  \n\nclass MarketSession(Enum):\n    PRE = \"pre-market\"\n    REG = \"regular\"\n    POST = \"post-market\"\n    CLOSED = \"closed\"\n    NA = \"not applicable\"\n\nclass MarketEvent(Enum):\n    PRE_OPEN = 0\n    REG_OPEN = 1\n    REG_CLOSE = 2\n    POST_CLOSE = 3\n    LAST_CLOSE = 4\n\nclass AssetClass(Enum):\n    STOCKS = \"stocks\"\n    OPTION = \"options\"\n    CRYPTO = \"crypto\"\n    FOREX = \"fx\"\n    INDEX = \"indices\"\n    OTC = \"otc\"\n\nclass SymbolType(Enum):\n    COMMON = \"Common Stock\"\n    ETP = \"ETP\"\n    ADR = \"ADR\"\n    REIT = \"REIT\"\n    DELISTED = \"\"\n    CEF = \"Closed-End Fund\"\n    UNIT = \"Unit\"\n    RIGHT = \"Right\"\n    EQUITY = \"Equity WRT\"\n    GDR = \"GDR\"\n    PREF = \"Preference\"\n    CDI = \"CDI\"\n    NVDR = \"NVDR\"\n    REG = \"NY Reg Shrs\"\n    MLP = \"MLP\"\n    MUTUAL = \"Mutual Fund\"\n\nclass Locale(Enum):\n    US = \"us\"\n    GLOBAL = \"global\"\n\nclass Sentiment(Enum):\n    V_POS = \"very positive\"\n    POSITIVE = \"positive\"\n    NEUTRAL_P = \"neutral/positive\"\n    NEUTRAL_SP = \"neutral/slightly positive\"\n    NEUTRAL = \"neutral\"\n    NEUTRAL_SN = \"neutral/slightly negative\"\n    NEUTRAL_N = \"neutral/negative\"\n    MIXED = \"mixed\"\n    NEGATIVE = \"negative\"\n    V_NEG = \"very negative\"\n\nclass Trend(Enum):\n    S_BUY = \"strong-buy\"\n    BUY = \"buy\"\n    HOLD = \"hold\"\n    SELL = \"sell\"\n    S_SELL = \"strong-sell\"\n\nclass MarketCondition(Enum):\n    BULL = \"bullish\"\n    BULLN = \"cautiously bullish\"\n    HOLD = \"hold\"\n    BEARN = \"cautiously bearish\"\n    BEAR = \"bearish\"\n\nclass GeneratedEvent(BaseModel):\n    last_close: str\n    pre_open: str\n    reg_open: str\n    reg_close: str\n    post_close: str\n    timestamp: Optional[str] = None\n    is_holiday: Optional[bool] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        if self.timestamp is None:\n            self.timestamp = datetime.now(self.tz()).strftime('%c')\n        if self.is_holiday is None:\n            self.is_holiday = False\n\n    def session(self, with_date: Optional[str] = None) -> MarketSession:\n        if with_date is None:\n            with_date = datetime.now(self.tz()).strftime('%c')\n        compare = parse(with_date)\n        if self.is_holiday or compare.weekday() > 4: # weekend\n            return MarketSession.CLOSED\n        events = [parse(event).time() for event in [self.pre_open,self.reg_open,self.reg_close,self.post_close]]\n        if compare.time() < events[0]:\n            return MarketSession.CLOSED\n        else:\n            session = MarketSession.NA\n            if compare.time() >= events[0]:\n                session = MarketSession.PRE\n            if compare.time() >= events[1]:\n                session = MarketSession.REG\n            if compare.time() >= events[2]:\n                session = MarketSession.POST\n            if compare.time() >= events[3]:\n                session = MarketSession.CLOSED\n        return session\n\n    def is_open(self) -> bool:\n        return self.session() != MarketSession.CLOSED\n\n    def has_update(self) -> bool:\n        datetime_now = datetime.now(self.tz())\n        self_ts = parse(self.timestamp)\n        # Re-generate events for a new day.\n        if datetime_now.day > self_ts.day:\n            return True\n        # No updates on holidays or when generated after post_close.\n        if self.is_holiday or self_ts.time() >= parse(self.post_close).time():\n            return False\n        # Compare current time to generated event times.\n        for event in [self.pre_open,self.reg_open,self.reg_close]:\n            if datetime_now.time() > parse(event).time():\n                return True\n        # Current time is before pre_open.\n        return False\n\n    @classmethod\n    def tz(cls):\n        return pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\n    \n    @classmethod\n    def apply_fix(cls, value, fix: datetime) -> tuple[str, datetime]:\n        api.validation_fail()\n        value = fix.strftime('%c')\n        return value, fix\n    \n    @field_validator(\"last_close\")\n    def valid_close(cls, value):\n        date_gen = parse(value) # Generated close is in eastern time and tzinfo naive.\n        date_now = parse(datetime.now(cls.tz()).strftime('%c')) # Need now in same format as generated.\n        # Soft-pass: when actual session is closed after post-market\n        if date_now.day == date_gen.day+1 and date_now.weekday() <= 4:\n            date_fix = date_gen.replace(day=date_now.day)\n            if date_fix.timestamp() < date_now.timestamp():\n                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use today's close\n        # Soft-pass: when actual session is open post-market\n        if date_now.day == date_gen.day and date_now.timestamp() < date_gen.timestamp():\n            if date_now.weekday() > 0:\n                date_fix = date_gen.replace(day=date_now.day-1)\n            else:\n                date_fix = date_gen.replace(day=date_now.day-3)\n            if date_now.timestamp() > date_fix.timestamp():\n                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use previous close\n        if date_now.weekday() == 0 or date_now.weekday() == 1 and date_gen.weekday() <= 4: # 0=monday, 4=friday\n            return value # pass: generated thurs/friday on a monday/tues\n        elif date_now.weekday() > 0 and date_now.weekday() <= 4 and date_gen.weekday() <= date_now.weekday()-1:\n            return value # pass: generated yesterday/prior on a tues-fri\n        elif date_now.weekday() > 4 and date_gen.weekday() <= 4:\n            return value # pass: generated thurs/friday on a weekend\n        elif date_now.day == date_gen.day and date_now.timestamp() > date_gen.timestamp():\n            return value # pass: generated today after closed\n        elif date_now.timestamp() < date_gen.timestamp():\n            raise ValueError(\"last close cannot be a future value\")\n        else:\n            raise ValueError(\"generated invalid last close\")\n        api.validation_fail()\n\nclass VectorStoreResult(BaseModel):\n    docs: str\n    dist: Optional[float] # requires query\n    meta: Optional[dict]  # requires get or query\n    store_id: str\n\nclass Aggregate(RestResultPoly):\n    symbol: str\n    open: float\n    high: float\n    low: float\n    close: float\n    volume: int\n    otc: Optional[bool] = None\n    preMarket: Optional[float] = None\n    afterHours: Optional[float] = None\n\nclass DailyCandle(Aggregate):\n    from_date: str\n\nclass AggregateWindow(BaseModel):\n    o: float\n    h: float\n    l: float\n    c: float\n    v: int # traded volume\n    n: Optional[int] = None # transaction count\n    vw: Optional[float] = None # volume weighted average price\n    otc: Optional[bool] = None\n    t: int\n\n    @field_validator(\"t\")\n    def valid_t(cls, value):\n        if not value > 0:\n            raise ValueError(\"invalid timestamp\")\n        if len(str(value)) == 13:\n            return int(value/1000)\n        return value\n\nclass CustomCandle(RestResultPoly): \n    ticker: str\n    adjusted: bool\n    queryCount: int\n    resultsCount: int\n    results: list[AggregateWindow]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[AggregateWindow]:\n        return self.results\n    \nclass MarketStatus(BaseModel):\n    exchange: str\n    holiday: Optional[str] = None\n    isOpen: bool\n    session: Optional[MarketSession] = None\n    t: int\n    timezone: str\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        if self.session is None:\n            self.session = MarketSession.CLOSED\n        if self.holiday is None:\n            self.holiday = MarketSession.NA.value\n\nclass MarketStatusResult(BaseModel):\n    results: MarketStatus\n\n    def get(self) -> MarketStatus:\n        return self.results\n\nclass Symbol(BaseModel):\n    description: str\n    displaySymbol: str\n    symbol: str\n    type: SymbolType\n\nclass SymbolResult(BaseModel):\n    count: int\n    result: list[Symbol]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.result)\n\n    def get(self) -> list[Symbol]:\n        return self.result\n\nclass Quote(BaseModel):\n    c: float\n    d: float\n    dp: float\n    h: float\n    l: float\n    o: float\n    pc: float\n    t: int\n\n    @field_validator(\"t\")\n    def valid_t(cls, value):\n        if not value > 0:\n            raise ValueError(\"invalid timestamp\")\n        return value\n\nclass PeersResult(BaseModel):\n    results: list[str]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[str]:\n        return self.results\n\nclass BasicFinancials(BaseModel):\n    metric: dict\n    metricType: str\n    series: dict\n    symbol: str\n\nclass Insight(BaseModel):\n    sentiment: Sentiment|MarketCondition\n    sentiment_reasoning: str\n    ticker: str\n\nclass Publisher(BaseModel):\n    favicon_url: Optional[str]\n    homepage_url: str\n    logo_url: str\n    name: str\n\nclass NewsSummary(BaseModel):\n    title: str\n    summary: Optional[str]\n    insights: Optional[list[Insight]]\n    published_utc: str\n\nclass NewsTypePoly(BaseModel):\n    amp_url: Optional[str] = None\n    article_url: str\n    title: str\n    author: str\n    description: Optional[str] = None\n    id: str\n    image_url: Optional[str] = None\n    insights: Optional[list[Insight]] = None\n    keywords: Optional[list[str]] = None\n    published_utc: str\n    publisher: Publisher\n    tickers: list[str]\n\n    def summary(self):\n        return NewsSummary(title=self.title,\n                           summary=self.description,\n                           insights=self.insights,\n                           published_utc=self.published_utc)\n\nclass NewsResultPoly(RestResultPoly):\n    results: list[NewsTypePoly]\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[NewsTypePoly]:\n        return self.results\n\nclass NewsTypeFinn(BaseModel):\n    category: str\n    datetime: int\n    headline: str\n    id: int\n    image: str\n    related: str # symbol\n    source: str\n    summary: str\n    url: str\n\n    def summary(self):\n        return NewsSummary(title=self.headline,\n                           summary=self.summary,\n                           insights=None,\n                           published_utc=self.datetime)\n\nclass NewsResultFinn(BaseModel):\n    results: list[NewsTypeFinn]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[NewsTypeFinn]:\n        return self.results\n\nclass NewsTypeGenerated(BaseModel):\n    title: str\n    summary: str\n    insights: list[Insight]\n    keywords: list[str]\n    source: Publisher\n    published_utc: str\n    tickers: list[str]\n    url: str\n\n    def summary(self):\n        return NewsSummary(title=self.title,\n                           summary=self.summary,\n                           insights=self.insights,\n                           published_utc=self.published_utc)\n\nclass TickerOverview(BaseModel):\n    ticker: str\n    name: str\n    market: AssetClass\n    locale: Locale\n    primary_exchange: Optional[str] = None\n    active: bool\n    currency_name: str\n    cik: Optional[str] = None\n    composite_figi: Optional[str] = None\n    share_class_figi: Optional[str] = None\n    market_cap: Optional[int|float] = None\n    phone_number: Optional[str] = None\n    address: Optional[dict] = None\n    description: Optional[str] = None\n    sic_code: Optional[str] = None\n    sic_description: Optional[str] = None\n    ticker_root: Optional[str] = None\n    homepage_url: Optional[str] = None\n    total_employees: Optional[int] = None\n    list_date: Optional[str] = None\n    branding: Optional[dict] = None\n    share_class_shares_outstanding: Optional[int] = None\n    weighted_shares_outstanding: Optional[int] = None\n    round_lot: Optional[int] = None\n\nclass OverviewResult(RestResultPoly):\n    results: TickerOverview\n\n    def get(self) -> TickerOverview:\n        return self.results\n\nclass RecommendationTrend(BaseModel):\n    buy: int\n    hold: int\n    period: str\n    sell: int\n    strongBuy: int\n    strongSell: int\n    symbol: str\n\nclass TrendsResult(BaseModel):\n    results: list[RecommendationTrend]\n    count: Optional[int] = None\n\n    def model_post_init(self, *args, **kwargs) -> None:\n        self.count = len(self.results)\n\n    def get(self) -> list[RecommendationTrend]:\n        return self.results","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:20.658883Z","iopub.execute_input":"2025-11-19T23:43:20.659287Z","iopub.status.idle":"2025-11-19T23:43:20.744976Z","shell.execute_reply.started":"2025-11-19T23:43:20.659185Z","shell.execute_reply":"2025-11-19T23:43:20.744045Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Contents Memory","metadata":{}},{"cell_type":"code","source":"# A contents-memory object.\nclass Memory:\n    def __init__(self):\n        self.system = f\"\"\"Give a concise, and detailed summary. Use information that you learn from the API responses.\n        Use your tools and function calls according to the rules. Convert any all-upper case identifiers\n        to proper case in your response. Convert any abbreviated or shortened identifiers to their full forms.\n        Convert timestamps according to the rules before including them. Think step by step.\n        \"\"\"\n        self.revery = {}\n        self.contents = []\n        self.prompt = None\n        self.summary = None\n    \n    def set_prompt(self, prompt):\n        self.prompt = f\"\"\"\n        The current date and time is: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n        \n        {prompt}\n        \"\"\"\n        self.contents = [types.Content(role=\"user\", parts=[types.Part(text=self.prompt)])]\n\n    def set_reason(self, step):\n        # Append the model's reasoning part.\n        self.contents.append(types.Content(role=\"model\", parts=[types.Part(thought=True,text=step)]))\n\n    def append_code(self, prompt, code_response_parts):\n        subroutine_content = [types.Content(role=\"user\", parts=[types.Part(text=prompt)]),\n                              types.Content(role=\"model\", parts=code_response_parts)]\n        # Append the model's generated code and execution result.\n        self.revery[datetime.now(GeneratedEvent.tz()).strftime('%c')] = { \n            \"contents\": subroutine_content\n        }\n\n    def update_contents(self, function_call, api_response_part):\n        # Append the model's function call part.\n        self.contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=function_call)])) \n        # Append the api response part.\n        self.contents.append(types.Content(role=\"user\", parts=[api_response_part]))\n\n    def set_summary(self, summary):\n        self.summary = summary\n        self.contents.append(types.Content(role=\"model\", parts=[types.Part(text=summary)]))\n        self.revery[datetime.now(GeneratedEvent.tz()).strftime('%c')] = {\n            \"prompt\": self.prompt, \n            \"summary\": self.summary, \n            \"contents\": self.contents\n        }\n        self.contents = []\n\nmemory = Memory()","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:20.746013Z","iopub.execute_input":"2025-11-19T23:43:20.746376Z","iopub.status.idle":"2025-11-19T23:43:20.75713Z","shell.execute_reply.started":"2025-11-19T23:43:20.746322Z","shell.execute_reply":"2025-11-19T23:43:20.756171Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Retrieval-Augmented Generation","metadata":{}},{"cell_type":"code","source":"# Define tool: retrieval-augmented generation.\n# - using Chroma and text-embedding-004 for storage and retrieval\n# - using gemini-2.0-flash for augmented generation\nclass RetrievalAugmentedGenerator:\n    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n    config_temp = types.GenerateContentConfig(temperature=0.0)\n    exchange_codes: Optional[dict] = None\n    exchange_lists: dict = {}\n    events: dict = {}\n    holidays: dict = {}\n\n    def __init__(self, genai_client, collection_name):\n        self.client = genai_client\n        self.embed_fn = GeminiEmbedFunction(genai_client)\n        self.db = self.chroma_client.get_or_create_collection(\n            name=collection_name, \n            embedding_function=self.embed_fn,  # type: ignore\n            metadata={\"hnsw:space\": \"cosine\"})\n        logging.getLogger(\"chromadb\").setLevel(logging.ERROR) # suppress warning on existing id\n        self.set_holidays(\"US\", [\"09-01-2025\",\"10-13-2025\",\"11-11-2025\",\"11-27-2025\",\"12-25-2025\"])\n        #self.generated_events(\"US\")\n\n    def set_holidays(self, exchange_code: str, holidays: list):\n        self.holidays[exchange_code] = [datetime.strptime(h, \"%m-%d-%Y\").date() for h in holidays]\n\n    def get_exchange_codes(self, with_query: Optional[str] = None):\n        gen = None\n        if with_query and with_query not in self.exchange_lists.keys():\n            gen = tqdm(total=1, desc=\"Generate exchange codes with_query\")\n            data = self.get_exchanges_csv(\n                f\"\"\"What is the {with_query} exchange code? Return only the exchange codes \n                as a list in string form. Just the list string. \n                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n            self.exchange_lists[with_query] = ast.literal_eval(data.parts[-1].text)\n        elif with_query is None and self.exchange_codes is None:\n            gen = tqdm(total=1, desc=\"Generate exchange codes\")\n            data = self.get_exchanges_csv(\n                \"\"\"Give me a dictionary in string form. It must contain key:value pairs \n                mapping exchange code to name. Just the dictionary string. \n                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n            self.exchange_codes = ast.literal_eval(data.parts[-1].text.strip(\"\\\\`\"))\n        if gen:\n            gen.update(1)\n        return self.exchange_lists[with_query] if with_query else self.exchange_codes\n\n    def get_event_date(self, event_t: str, exchange_code: str, event: MarketEvent):\n        current_dt_str = datetime.now(GeneratedEvent.tz()).strftime('%c')\n        current_dt = datetime.strptime(current_dt_str, \"%a %b %d %H:%M:%S %Y\")\n        current_t_str = datetime.now(GeneratedEvent.tz()).strftime('%H:%M:%S')\n        current_t = datetime.strptime(current_t_str, \"%H:%M:%S\").time()\n        event_time = parse(event_t).time()\n        gen_datetime = None\n        if event is MarketEvent.LAST_CLOSE:\n            last_close_day = current_dt.date() - timedelta(days=0 if current_t > event_time else 1)\n            # Loop backwards to find the last valid trading day (not a weekend or holiday).\n            while last_close_day.weekday() >= 5 or last_close_day in self.holidays[exchange_code]: # 5 = Sat, 6 = Sun\n                last_close_day -= timedelta(days=1)\n            # Combine the date and time.\n            gen_datetime = datetime.combine(last_close_day, event_time)\n        else:\n            next_event_day = current_dt.date() + timedelta(days=0 if current_t < event_time else 1)\n            # Loop forward to find the next valid trading day (not a weekend or holiday).\n            while next_event_day.weekday() >= 5 or next_event_day in self.holidays[exchange_code]: # 5 = Sat, 6 = Sun\n                next_event_day += timedelta(days=1)\n            # Combine date and time.\n            gen_datetime = datetime.combine(next_event_day, event_time)\n        # Format the result as requested.\n        return gen_datetime.strftime('%a %b %d %X %Y')\n\n    def generate_event(self, exchange_code: str, event: MarketEvent):\n        if event is MarketEvent.LAST_CLOSE or event is MarketEvent.POST_CLOSE:\n            prompt = f\"\"\"What is the closing time including post_market hours.\"\"\"\n        elif event is MarketEvent.PRE_OPEN or event is MarketEvent.REG_OPEN:\n            is_pre = \"including\" if event is MarketEvent.PRE_OPEN else \"excluding\"\n            prompt = f\"\"\"What is the opening time {is_pre} pre_market hours.\"\"\"\n        elif event is MarketEvent.REG_CLOSE:\n            prompt = f\"\"\"What is the closing time excluding post_market hours.\"\"\"\n        prompt = f\"\"\"Answer based on your knowledge of exchange operating hours.\n            Do not answer in full sentences. Omit all chat and provide the answer only.\n            The fields pre_market and post_market both represent extended operating hours.\n\n            The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n            \n            Consider the {exchange_code} exchange's operating hours.\n            {prompt}\n            \n            Answer with the time in this format: '%H:%M:%S'.\n            Omit all other chat and details. Do not use sentences.\"\"\"\n        progress = tqdm(total=1, desc=f\"Generate {exchange_code}->{event}\")\n        response = self.get_exchanges_csv(prompt).candidates[0].content\n        if api.Const.Stop() in f\"{response.parts[-1].text}\":\n            progress.close()\n            api.generation_fail()\n            time.sleep(api.dt_between)\n            return self.generate_event(exchange_code, event)\n        else:\n            response = self.get_event_date(response.parts[-1].text, exchange_code, event)\n            progress.update(1)\n            return response\n\n    def generated_events(self, exchange_code: str) -> GeneratedEvent:\n        # Check for an existing GeneratedEvent object having updates.\n        if exchange_code in self.events.keys() and self.events[exchange_code].has_update():\n            event_obj = self.events[exchange_code]\n            event_state = [(event_obj.pre_open, MarketEvent.PRE_OPEN),\n                           (event_obj.reg_open, MarketEvent.REG_OPEN),\n                           (event_obj.reg_close, MarketEvent.REG_CLOSE),\n                           (event_obj.post_close, MarketEvent.POST_CLOSE)]\n            # Need now in same format as generated.\n            datetime_now = parse(datetime.now(event_obj.tz()).strftime('%c'))\n            gen_ts = parse(event_obj.timestamp)\n            # Re-generate events when day changes.\n            if datetime_now.day > gen_ts.day:\n                del self.events[exchange_code]\n                return self.generated_events(exchange_code)\n            # Update changed events on trading days.\n            for e in event_state:\n                if datetime_now > parse(e[0]):\n                    event_dt = self.generate_event(exchange_code, e[1])\n                    match e[1]:\n                        case MarketEvent.PRE_OPEN:\n                            event_obj.pre_open = event_dt\n                        case MarketEvent.REG_OPEN:\n                            event_obj.reg_open = event_dt\n                        case MarketEvent.REG_CLOSE:\n                            event_obj.reg_close = event_dt\n                        case MarketEvent.POST_CLOSE:\n                            event_obj.post_close = event_dt\n            event_obj.timestamp = datetime.now(event_obj.tz()).strftime('%c')\n            self.events[exchange_code] = event_obj\n        # Generate events for an exchange code not in cache.\n        elif exchange_code not in self.events.keys():\n            self.events[exchange_code] = GeneratedEvent(\n                last_close=self.generate_event(exchange_code, MarketEvent.LAST_CLOSE),\n                pre_open=self.generate_event(exchange_code, MarketEvent.PRE_OPEN),\n                reg_open=self.generate_event(exchange_code, MarketEvent.REG_OPEN),\n                reg_close=self.generate_event(exchange_code, MarketEvent.REG_CLOSE),\n                post_close=self.generate_event(exchange_code, MarketEvent.POST_CLOSE),\n                is_holiday=datetime.now().date() in self.holidays[exchange_code])\n        return self.events[exchange_code]\n\n    def set_holiday_event(self, exchange_code: str):\n        self.generated_events(exchange_code).is_holiday = True\n\n    def last_market_close(self, exchange_code: str):\n        return self.generated_events(exchange_code).last_close\n\n    def add_documents_list(self, docs: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        metas=[{\"source\": doc.metadata[\"source\"]} for doc in docs]\n        content=[doc.page_content for doc in docs]\n        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate document embedding\")\n\n    def add_api_document(self, query: str, api_response: str, topic: str, source: str = \"add_api_document\"):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        splitter = RecursiveJsonSplitter(max_chunk_size=Api.Const.ChunkMax())\n        docs = splitter.create_documents(texts=[api_response], convert_lists=True)\n        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n        content = [json.dumps(doc.page_content) for doc in docs]\n        metas = [{\"source\": source, \"topic\": topic}]*len(docs)\n        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate api embedding\")\n\n    def add_peers_document(self, query: str, names: list, topic: str, source: str, group: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        peers = {\"symbol\": topic, \"peers\": names}\n        tqdm(self.db.add(ids=str(self.db.count()),\n                         documents=[json.dumps(peers)],\n                         metadatas=[{\"source\": source, \"topic\": topic, \"group\": group}]),\n             desc=\"Generate peers embedding\")\n\n    def get_peers_document(self, query: str, topic: str, group: str):\n        return self.get_documents_list(query, where={\"$and\": [{\"group\": group}, {\"topic\": topic}]})\n\n    def add_rest_chunks(self, chunks: list, topic: str, source: str, ids: Optional[list[str]] = None,\n                        meta_opt: Optional[list[dict]] = None, is_update: bool = True):\n        self.embed_fn.document_mode = True # Switch to document mode\n        if ids is None:\n            ids = list(map(str, range(self.db.count(), self.db.count()+len(chunks))))\n        if isinstance(chunks[0], BaseModel):\n            docs = [model.model_dump_json() for model in chunks]\n        else:\n            docs = [json.dumps(obj) for obj in chunks]\n        meta_base = {\"source\": source, \"topic\": topic}\n        if meta_opt is not None:\n            for m in meta_opt:\n                m.update(meta_base)\n        metas = [meta_base]*len(chunks) if meta_opt is None else meta_opt\n        if is_update:\n            tqdm(self.db.upsert(ids=ids, documents=docs, metadatas=metas), desc=\"Upsert chunks embedding\")\n        else:\n            tqdm(self.db.add(ids=ids, documents=docs, metadatas=metas), desc=\"Add chunks embedding\")\n\n    def get_market_status(self, exchange_code: str) -> tuple[list[VectorStoreResult], bool]: # result, has rest update\n        self.embed_fn.document_mode = False # Switch to query mode.\n        stored = self.stored_result(self.db.get(where={\n            \"$and\": [{\"exchange\": exchange_code}, {\"topic\": \"market_status\"}]}))\n        if len(stored) == 0:\n            return stored, True\n        # Check for a daily market status update.\n        status = json.loads(stored[0].docs)\n        gen_day = parse(self.generated_events(exchange_code).timestamp).day\n        store_day = parse(stored[0].meta['timestamp']).day\n        if status[\"holiday\"] != MarketSession.NA.value and gen_day == store_day:\n            return stored, False\n        elif gen_day > store_day:\n            return stored, True\n        # Update with generated events to avoid rest api requests.\n        status[\"session\"] = self.generated_events(exchange_code).session().value\n        status[\"isOpen\"] = self.generated_events(exchange_code).is_open()\n        stored[0].docs = json.dumps(status)\n        return stored, False\n\n    def get_basic_financials(self, query: str, topic: str, source: str = \"get_financials_1\"):\n        return self.get_documents_list(\n            query, max_sources=200, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def add_quote_document(self, query: str, quote: str, topic: str, timestamp: int, source: str):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        tqdm(self.db.add(ids=str(self.db.count()), \n                             documents=[quote], \n                             metadatas=[{\"source\": source, \"topic\": topic, \"timestamp\": timestamp}]), \n             desc=\"Generate quote embedding\")\n\n    def get_api_documents(self, query: str, topic: str, source: str = \"add_api_document\", \n                          meta_opt: Optional[list[dict]] = None):\n        where = [{\"source\": source}, {\"topic\": topic}]\n        if meta_opt is None:\n            return self.get_documents_list(query, where={\"$and\": where})\n        else:\n            for meta in meta_opt:\n                for k,v in meta.items():\n                    where.append({k: v})\n            return self.get_documents_list(query, where={\"$and\": where})\n\n    def query_api_documents(self, query: str, topic: str, source: str = \"add_api_document\"):\n        return self.generate_answer(query, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n\n    def add_grounded_document(self, query: str, topic: str, result):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        chunks = result.candidates[0].grounding_metadata.grounding_chunks\n        supports = result.candidates[0].grounding_metadata.grounding_supports\n        if supports is not None: # Only add grounded documents which have supports\n            grounded_text = [f\"{s.segment.text}\" for s in supports]\n            source = [f\"{c.web.title}\" for c in chunks]\n            score = [f\"{s.confidence_scores}\" for s in supports]\n            tqdm(self.db.add(ids=str(self.db.count()),\n                             documents=json.dumps(grounded_text),\n                             metadatas=[{\"source\": \", \".join(source),\n                                         \"confidence_score\": \", \".join(score),\n                                         \"topic\": topic,\n                                         \"question\": query}]),\n                 desc=\"Generate grounding embedding\")\n\n    def get_grounding_documents(self, query: str, topic: str):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.stored_result(self.db.get(where={\"$and\": [{\"question\": query}, {\"topic\": topic}]}))\n            \n    def add_wiki_documents(self, title: str, wiki_chunks: list):\n        self.embed_fn.document_mode = True # Switch to document mode.\n        result = self.get_wiki_documents(title)\n        if len(result) == 0:\n            ids = list(map(str, range(self.db.count(), self.db.count()+len(wiki_chunks))))\n            metas=[{\"title\": title, \"source\": \"add_wiki_documents\"}]*len(wiki_chunks)\n            tqdm(self.db.add(ids=ids, documents=wiki_chunks, metadatas=metas), desc=\"Generate wiki embeddings\")\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def generate_with_wiki_passages(self, query: str, title: str, passages: list[str]):\n        return self.generate_answer(query, where={\"title\": title}, passages=passages)\n    \n    def get_wiki_documents(self, title: Optional[str] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        if title is None:\n            return self.stored_result(self.db.get(where={\"source\": \"add_wiki_document\"}))\n        else:\n            return self.stored_result(self.db.get(where={\"title\": title}))\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_documents_list(self, query: str, max_sources: int = 5000, where: Optional[dict] = None):\n        self.embed_fn.document_mode = False # Switch to query mode.\n        return self.stored_result(\n            self.db.query(query_texts=[query], \n                          n_results=max_sources, \n                          where=where), \n            is_query = True)\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_exchanges_csv(self, query: str):\n        return self.generate_answer(query, max_sources=100, where={\"source\": \"exchanges.csv\"})\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def generate_answer(self, query: str, max_sources: int = 10, \n                        where: Optional[dict] = None, passages: Optional[list[str]] = None):\n        stored = self.get_documents_list(query, max_sources, where)\n        query_oneline = query.replace(\"\\n\", \" \")\n        prompt = f\"\"\"You're an expert writer. You understand how to interpret html and markdown. You will accept the\n        question below and answer based only on the passages. Never mention the passages in your answers. Be sure to \n        respond in concise sentences. Include all relevant background information when possible. If a passage is not \n        relevant to the answer you must ignore it. If no passage answers the question respond with: I don't know.\n\n        QUESTION: {query_oneline}\n        \n        \"\"\"\n        # Add the retrieved documents to the prompt.\n        stored_docs = [passage.docs for passage in stored]\n        for passage in stored_docs if passages is None else stored_docs + passages:\n            passage_oneline = passage.replace(\"\\n\", \" \")\n            prompt += f\"PASSAGE: {passage_oneline}\\n\"\n        # Generate the response.\n        response = api.retriable(\n            self.client.models.generate_content,\n            model=api(Api.Model.GEN),\n            config=self.config_temp,\n            contents=prompt)\n        # Check for generated code and store in memory.\n        content = response.candidates[0].content\n        if len(content.parts) > 1 and content.parts[0].executable_code:\n            memory.append_code(prompt, content.parts)\n        return response\n\n    def stored_result(self, result, is_query: bool = False) -> list[VectorStoreResult]:\n        try:\n            results = []\n            if len(result[\"documents\"]) == 0:\n                return results\n            if isinstance(result[\"documents\"][0], list):\n                for i in range(len(result[\"documents\"][0])):\n                    obj = VectorStoreResult(docs=result[\"documents\"][0][i],\n                                            dist=result[\"distances\"][0][i] if is_query else None,\n                                            meta=result[\"metadatas\"][0][i],\n                                            store_id=result[\"ids\"][0][i])\n                    results.append(obj)\n            else:\n                results.append(\n                    VectorStoreResult(docs=result[\"documents\"][0],\n                                      dist=result[\"distances\"][0] if is_query else None,\n                                      meta=result[\"metadatas\"][0],\n                                      store_id=result[\"ids\"][0]))\n            return results\n        except Exception as e:\n            raise e","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:20.75832Z","iopub.execute_input":"2025-11-19T23:43:20.758835Z","iopub.status.idle":"2025-11-19T23:43:21.791084Z","shell.execute_reply.started":"2025-11-19T23:43:20.758804Z","shell.execute_reply":"2025-11-19T23:43:21.790099Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## Wiki Grounding","metadata":{}},{"cell_type":"code","source":"# Define tool: wiki-grounding generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by similarity to topic\n# - retrieve existing groundings by similarity to topic\nclass WikiGroundingGenerator:   \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\") # suppress beta-warning\n            self.splitter = HTMLSemanticPreservingSplitter(\n                headers_to_split_on=[(\"h2\", \"Main Topic\"), (\"h3\", \"Sub Topic\")],\n                separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \"],\n                max_chunk_size=Api.Const.ChunkMax(),\n                chunk_overlap=50,\n                preserve_links=True,\n                preserve_images=True,\n                preserve_videos=True,\n                preserve_audio=True,\n                elements_to_preserve=[\"table\", \"ul\", \"ol\", \"code\"],\n                denylist_tags=[\"script\", \"style\", \"head\"],\n                custom_handlers={\"code\": self.code_handler},\n            )\n\n    def generate_answer(self, query: str, topic: str):\n        stored = self.rag.get_wiki_documents(topic)\n        if len(stored) > 0:\n            return self.rag.generate_with_wiki_passages(query, topic, [chunk.docs for chunk in stored]).text\n        else:\n            pages = wikipedia.search(topic + \" company\")\n            if len(pages) > 0:\n                p_topic_match = 0.80\n                for i in range(len(pages)):\n                    if tqdm(api.similarity([topic + \" company\", pages[i]]) > p_topic_match, \n                            desc= \"Score wiki search by similarity to topic\"):\n                        page_html = Api.get(f\"https://en.wikipedia.org/wiki/{pages[i]}\")\n                        chunks = [chunk.page_content for chunk in self.splitter.split_text(page_html)]\n                        self.rag.add_wiki_documents(topic, chunks)\n                        return self.rag.generate_with_wiki_passages(query, topic, chunks).text\n            return Api.Const.Stop()\n\n    def code_handler(self, element: Tag) -> str:\n        data_lang = element.get(\"data-lang\")\n        code_format = f\"<code:{data_lang}>{element.get_text()}</code>\"\n        return code_format","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:21.792155Z","iopub.execute_input":"2025-11-19T23:43:21.792719Z","iopub.status.idle":"2025-11-19T23:43:21.803665Z","shell.execute_reply.started":"2025-11-19T23:43:21.792685Z","shell.execute_reply":"2025-11-19T23:43:21.802391Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Search Grounding","metadata":{}},{"cell_type":"code","source":"# Define tool: search-grounding generation.\n# - using gemini-2.0-flash with GoogleSearch tool for response generation\n# - using a RAG-implementation to store groundings\n# - create new groundings by exact match to topic\n# - retrieve existing groundings by similarity to topic\nclass SearchGroundingGenerator:\n    config_ground = types.GenerateContentConfig(\n        tools=[types.Tool(google_search=types.GoogleSearch())],\n        temperature=0.0\n    )\n    \n    def __init__(self, genai_client, rag_impl):\n        self.client = genai_client\n        self.rag = rag_impl\n\n    def generate_answer(self, query: str, topic: str):\n        stored = self.rag.get_grounding_documents(query, topic)\n        if len(stored) > 0:\n            for i in range(len(stored)):\n                meta_q = stored[i].meta[\"question\"]\n                p_ground_match = 0.95 # This can be really high ~ 95-97%\n                if tqdm(api.similarity([query, meta_q]) > p_ground_match,\n                        desc=\"Score similarity to stored grounding\"):\n                    return ast.literal_eval(stored[i].docs)\n        return self.get_grounding(query, topic)\n\n    @retry.Retry(\n        predicate=is_retriable,\n        initial=2.0,\n        maximum=64.0,\n        multiplier=2.0,\n        timeout=600,\n    )\n    def get_grounding(self, query: str, topic: str):\n        contents = [types.Content(role=\"user\", parts=[types.Part(text=query)])]\n        contents += f\"\"\"\n        You're a search assistant that provides grounded answers to questions about {topic}. You will provide only \n        results that discuss {topic}. Be brief and specific in answering and omit extra details.\n        If an answer is not possible respond with: I don't know.\"\"\"\n        response = api.retriable(self.client.models.generate_content, \n                                 model=api(Api.Model.GEN), \n                                 config=self.config_ground, \n                                 contents=contents)\n        if response.candidates[0].grounding_metadata.grounding_supports is not None:\n            if self.is_consistent(query, topic, response.text):\n                self.rag.add_grounded_document(query, topic, response)\n                return response.text \n        return Api.Const.Stop() # Empty grounding supports or not consistent in response\n\n    def is_consistent(self, query: str, topic: str, model_response: str) -> bool:\n        topic = topic.replace(\"'\", \"\")\n        id_strs = topic.split()\n        if len(id_strs) == 1:\n            matches = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", query)\n            if len(matches) > 0:\n                topic = matches[0]\n        compound_match = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", model_response)\n        model_response = model_response.replace(\"'\", \"\")\n        if len(compound_match) == 0 and topic in model_response:\n            return True # not a compound topic id and exact topic match\n        for match in compound_match:\n            if topic not in match:\n                return False\n        return True # all prefix matches contained topic","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:21.804732Z","iopub.execute_input":"2025-11-19T23:43:21.805067Z","iopub.status.idle":"2025-11-19T23:43:21.833081Z","shell.execute_reply.started":"2025-11-19T23:43:21.805037Z","shell.execute_reply":"2025-11-19T23:43:21.831945Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Rest Grounding","metadata":{}},{"cell_type":"code","source":"# Rest api-helpers to manage request-per-minute limits.\n# - define an entry for each endpoint limit\n# - init rest tool with limits to create blocking queues\n# - apply a limit to requests with rest_tool.try_url\nclass ApiLimit(Enum):\n    FINN = \"finnhub.io\",50\n    POLY = \"polygon.io\",4 # (id_url,rpm)\n\nclass BlockingUrlQueue:\n    on_cooldown = False\n    cooldown = None\n    cooldown_start = None\n    \n    def __init__(self, rest_fn: Callable, per_minute: int):\n        self.per_minute_max = per_minute\n        self.quota = per_minute\n        self.rest_fn = rest_fn\n\n    def push(self, rest_url: str):\n        if not self.on_cooldown:\n            self.cooldown = Timer(60, self.reset_quota)\n            self.cooldown.start()\n            self.cooldown_start = time.time()\n            self.on_cooldown = True\n        if self.quota > 0:\n            self.quota -= 1\n            time.sleep(0.034) # ~30 requests per second\n            return self.rest_fn(rest_url)\n        else:\n            print(f\"limited {self.per_minute_max}/min, waiting {self.limit_expiry()}s\")\n            time.sleep(max(self.limit_expiry(),0.5))\n            return self.push(rest_url)\n\n    def reset_quota(self):\n        self.quota = self.per_minute_max\n        self.on_cooldown = False\n        self.cooldown_start = None\n\n    def limit_expiry(self):\n        if self.cooldown_start:\n            return max(60-(time.time()-self.cooldown_start),0)\n        return 0","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:21.834226Z","iopub.execute_input":"2025-11-19T23:43:21.834553Z","iopub.status.idle":"2025-11-19T23:43:21.858598Z","shell.execute_reply.started":"2025-11-19T23:43:21.834532Z","shell.execute_reply":"2025-11-19T23:43:21.857598Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Define tool: rest-grounding generation.\n# - using gemini-2.0-flash for response generation\n# - using a RAG-implementation to store groundings\n# - reduce long-context by chunked pre-processing\nclass RestGroundingGenerator:    \n    limits = None\n\n    def __init__(self, rag_impl, with_limits: bool):\n        self.rag = rag_impl\n        if with_limits:\n            self.limits = {}\n            for rest_api in ApiLimit:\n                self.limits[rest_api.value[0]] = BlockingUrlQueue(Api.get, rest_api.value[1])\n\n    def get_limit(self, rest_api: ApiLimit) -> Optional[BlockingUrlQueue]:\n        return self.limits[rest_api.value[0]] if self.limits else None\n\n    def basemodel(self, data: str, schema: BaseModel, from_lambda: bool = False) -> Optional[BaseModel]:\n        try:\n            if from_lambda:\n                return schema(results=json.loads(data))\n            return schema.model_validate_json(data)\n        except Exception as e:\n            raise e\n\n    def dailycandle(self, data: str) -> Optional[DailyCandle]:\n        try:\n            candle = json.loads(data)\n            if \"from\" not in candle:\n                raise ValueError(\"not a dailycandle / missing value for date\")\n            agg = self.basemodel(data, Aggregate)\n            return DailyCandle(from_date=candle[\"from\"], \n                               status=agg.status.value, \n                               symbol=agg.symbol, \n                               open=agg.open, \n                               high=agg.high, \n                               low=agg.low, \n                               close=agg.close, \n                               volume=agg.volume, \n                               otc=agg.otc, \n                               preMarket=agg.preMarket, \n                               afterHours=agg.afterHours)\n        except Exception as e:\n            raise e\n\n    @retry.Retry(timeout=600)\n    def try_url(self, url: str, schema: BaseModel, as_lambda: bool, with_limit: Optional[BlockingUrlQueue],\n                success_fn: Callable, *args, **kwargs):\n        try:\n            if self.limits is None:\n                data = Api.get(url)\n            elif with_limit:\n                data = with_limit.push(url)\n            if schema is DailyCandle:\n                model = self.dailycandle(data)\n            else:\n                model = self.basemodel(data, schema, as_lambda)\n        except Exception as e:\n            try:\n                print(f\"try_url exception: {e}\")\n                if issubclass(schema, RestResultPoly):\n                    return success_fn(*args, **kwargs, result=self.basemodel(data, RestResultPoly))\n            except Exception as not_a_result:\n                print(not_a_result)\n            return StopGeneration()\n        else:\n            return success_fn(*args, **kwargs, model=model)\n\n    def get_symbol_matches(self, with_content, by_name: bool, model: SymbolResult):\n        matches = []\n        max_failed_match = model.count if not by_name else 3\n        p_desc_match = 0.92\n        p_symb_match = 0.95\n        if model.count > 0:\n            for obj in tqdm(model.get(), desc=\"Score similarity to query\"):\n                if max_failed_match > 0:\n                    desc = [with_content[\"q\"].upper(), obj.description.split(\"-\", -1)[0]]\n                    symb = [with_content[\"q\"].upper(), obj.symbol]\n                    if by_name and api.similarity(desc) > p_desc_match: \n                        matches.append(obj.symbol)\n                    elif not by_name and api.similarity(symb) > p_symb_match:\n                        matches.append(obj.description)\n                        max_failed_match = 0\n                    else:\n                        max_failed_match -= 1\n        if len(matches) > 0:\n            self.rag.add_api_document(with_content[\"query\"], matches, with_content[\"q\"], \"get_symbol_1\")\n            return matches\n        return Api.Const.Stop()\n\n    def get_quote(self, with_content, model: Quote):\n        quote = model.model_dump_json()\n        self.rag.add_quote_document(with_content[\"query\"], quote, with_content[\"symbol\"], model.t, \"get_quote_1\")\n        return quote\n\n    def parse_financials(self, with_content, model: BasicFinancials):\n        metric = list(model.metric.items())\n        chunks = []\n        # Chunk the metric data.\n        for i in range(0, len(metric), Api.Const.MetricBatch()):\n            batch = metric[i:i + Api.Const.MetricBatch()]\n            chunks.append({\"question\": with_content[\"query\"], \"answer\": batch})\n        # Chunk the series data.\n        for key in model.series.keys():\n            series = list(model.series[key].items())\n            for s in series:\n                if api.token_count(s) <= Api.Const.ChunkMax():\n                    chunks.append({\"question\": with_content[\"query\"], \"answer\": s})\n                else:\n                    k = s[0]\n                    v = s[1]\n                    for i in range(0, len(v), Api.Const.SeriesBatch()):\n                        batch = v[i:i + Api.Const.SeriesBatch()]\n                        chunks.append({\"question\": with_content[\"query\"], \"answer\": {k: batch}})\n        self.rag.add_rest_chunks(chunks, topic=with_content[\"symbol\"], source=\"get_financials_1\")\n        return chunks\n\n    def parse_news(self, with_content, model: NewsResultFinn):\n        if model.count > 0:\n            metas = []\n            for digest in model.get():\n                pub_date = datetime.fromtimestamp(digest.datetime, tz=GeneratedEvent.tz()).strftime(\"%Y-%m-%d\")\n                metas.append({\"publisher\": digest.source,\n                              \"published_est\": parse(pub_date).timestamp(),\n                              \"news_id\": digest.id,\n                              \"related\": digest.related})\n            self.rag.add_rest_chunks(model.get(), topic=with_content[\"symbol\"], source=\"get_news_1\",\n                                     ids=[f\"{digest.id}+news\" for digest in model.get()],\n                                     meta_opt=metas, is_update=False)\n            return [digest.summary().model_dump_json() for digest in model.get()]\n        return Api.Const.Stop()\n\n    def parse_news(self, with_content, model: Optional[NewsResultPoly] = None,\n                   result: Optional[RestResultPoly] = None) -> tuple[list, str]: # list of summary, next list url\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            metas = []\n            for news in model.get():\n                pub_date = parse(news.published_utc).strftime(\"%Y-%m-%d\")\n                metas.append({\"publisher\": news.publisher.name,\n                              \"published_utc\": parse(pub_date).timestamp(),\n                              \"news_id\": news.id,\n                              \"related\": json.dumps(news.tickers),\n                              \"keywords\": json.dumps(news.keywords)})\n            self.rag.add_rest_chunks(model.get(), topic=with_content[\"ticker\"], source=\"get_news_2\",\n                                     ids=[news.id for news in model.get()],\n                                     meta_opt=metas, is_update=False)\n            return [news.summary().model_dump_json() for news in model.get()], model.next_url\n        elif result:\n            return result.model_dump_json()\n\n    def parse_daily_candle(self, with_content, model: Optional[DailyCandle] = None,\n                           result: Optional[RestResultPoly] = None):\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            self.rag.add_rest_chunks(\n                chunks=[model],\n                topic=with_content[\"stocksTicker\"],\n                source=\"daily_candle_2\",\n                meta_opt=[{\"from_date\": model.from_date, \"adjusted\": with_content[\"adjusted\"]}])\n            return model\n        elif result:\n            return result\n\n    def parse_custom_candle(self, with_content, model: Optional[CustomCandle] = None,\n                            result: Optional[RestResultPoly] = None):\n        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n            metas = [{\n                \"timespan\": with_content[\"timespan\"],\n                \"adjusted\": with_content[\"adjusted\"],\n                \"from\": with_content[\"from\"],\n                \"to\": with_content[\"to\"]}]*model.count\n            candles = [candle.model_dump_json() for candle in model.get()]\n            self.rag.add_rest_chunks(\n                chunks=candles,\n                topic=with_content[\"stocksTicker\"],\n                source=\"custom_candle_2\",\n                meta_opt=metas)\n            return candles\n        elif result:\n            return result.model_dump_json()\n\n    def parse_overview(self, with_content, model: OverviewResult):\n        overview = [model.get().model_dump_json()]\n        self.rag.add_rest_chunks(chunks=overview, topic=with_content[\"ticker\"], source=\"ticker_overview_2\")\n        return overview\n\n    def parse_trends(self, with_content, model: TrendsResult):\n        if model.count > 0:\n            metas = [{\"period\": trend.period} for trend in model.get()]\n            trends = [trend.model_dump_json() for trend in model.get()]\n            self.rag.add_rest_chunks(trends, topic=with_content[\"symbol\"], source=\"trends_1\", meta_opt=metas)\n            return trends\n        return Api.Const.Stop()\n\n    def augment_market_status(self, with_id: Optional[str], model: MarketStatusResult):\n        if model.get().holiday != MarketSession.NA.value:\n            self.rag.set_holiday_event(model.get().exchange)\n        events = self.rag.generated_events(model.get().exchange)\n        model.get().session = events.session()\n        model.get().isOpen = events.is_open()\n        meta = {\"exchange\": model.get().exchange,\n                \"last_close\": events.last_close,\n                \"pre_open\": events.pre_open,\n                \"reg_open\": events.reg_open,\n                \"reg_close\": events.reg_close,\n                \"post_close\": events.post_close,\n                \"timestamp\": events.timestamp }\n        self.rag.add_rest_chunks([model.get()],\n                                 topic=\"market_status\",\n                                 source=\"get_market_status_1\",\n                                 ids=[with_id] if with_id else None,\n                                 meta_opt=[meta])\n        return model.get().model_dump_json()\n\n    def get_symbol(self, content, by_name: bool = True):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/search?q={content['q']}&exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n            schema=SymbolResult,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.get_symbol_matches,\n            with_content=content,\n            by_name=by_name)\n\n    def get_current_price(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/quote?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n            schema=Quote,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.get_quote,\n            with_content=content)\n\n    def get_market_status(self, content, store_id: Optional[str] = None):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/market-status?exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n            schema=MarketStatusResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.augment_market_status,\n            with_id=store_id)\n\n    def get_peers(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/peers?symbol={content['symbol']}&grouping={content['grouping']}&token={FINNHUB_API_KEY}\",\n            schema=PeersResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=lambda model: model)\n\n    def get_basic_financials(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/metric?symbol={content['symbol']}&metric={content['metric']}&token={FINNHUB_API_KEY}\",\n            schema=BasicFinancials,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_financials,\n            with_content=content)\n\n    def get_news_simple(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/company-news?symbol={content['symbol']}&from={content['from']}&to={content['to']}&token={FINNHUB_API_KEY}\",\n            schema=NewsResultFinn,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_news,\n            with_content=content)\n\n    def get_news_tagged(self, content):\n        next_url = f\"https://api.polygon.io/v2/reference/news?ticker={content['ticker']}&published_utc.gte={content['published_utc.gte']}&published_utc.lte={content['published_utc.lte']}&order={content['order']}&limit={content['limit']}&sort={content['sort']}&apiKey={POLYGON_API_KEY}\"\n        news = []\n        while True:\n            news_list, next_url = self.try_url(\n                next_url,\n                schema=NewsResultPoly,\n                as_lambda=False,\n                with_limit=self.get_limit(ApiLimit.POLY),\n                success_fn=self.parse_news,\n                with_content=content)\n            news += news_list\n            if next_url is None:\n                break\n            next_url += f\"&apiKey={POLYGON_API_KEY}\"\n        return news\n\n    def get_daily_candle(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v1/open-close/{content['stocksTicker']}/{content['date']}?adjusted={content['adjusted']}&apiKey={POLYGON_API_KEY}\",\n            schema=DailyCandle,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_daily_candle,\n            with_content=content)\n\n    def get_custom_candle(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v2/aggs/ticker/{content['stocksTicker']}/range/{content['multiplier']}/{content['timespan']}/{content['from']}/{content['to']}?adjusted={content['adjusted']}&sort={content['sort']}&limit={content['limit']}&apiKey={POLYGON_API_KEY}\",\n            schema=CustomCandle,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_custom_candle,\n            with_content=content)\n\n    def get_overview(self, content):\n        return self.try_url(\n            f\"https://api.polygon.io/v3/reference/tickers/{content['ticker']}?apiKey={POLYGON_API_KEY}\",\n            schema=OverviewResult,\n            as_lambda=False,\n            with_limit=self.get_limit(ApiLimit.POLY),\n            success_fn=self.parse_overview,\n            with_content=content)\n\n    def get_trends_simple(self, content):\n        return self.try_url(\n            f\"https://finnhub.io/api/v1/stock/recommendation?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n            schema=TrendsResult,\n            as_lambda=True,\n            with_limit=self.get_limit(ApiLimit.FINN),\n            success_fn=self.parse_trends,\n            with_content=content)","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:21.859928Z","iopub.execute_input":"2025-11-19T23:43:21.860245Z","iopub.status.idle":"2025-11-19T23:43:21.909192Z","shell.execute_reply.started":"2025-11-19T23:43:21.860219Z","shell.execute_reply":"2025-11-19T23:43:21.908386Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## Callable Functions","metadata":{}},{"cell_type":"code","source":"# Callable functions in openapi schema.\ndecl_get_symbol_1 = types.FunctionDeclaration(\n    name=\"get_symbol_1\",\n    description=\"\"\"Search for the stock ticker symbol of a given company, security, isin or cusip. Each ticker\n                   entry provides a description, symbol, and asset type. If this doesn't help you should try \n                   calling get_wiki_tool_response next.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The company, security, isin or cusip to search for a symbol.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\"]\n    }\n)\n\ndecl_get_symbols_1 = types.FunctionDeclaration(\n    name=\"get_symbols_1\",\n    description=\"\"\"List all supported symbols and tickers. The results are filtered by exchange code.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter the results.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"exchange\", \"query\"]\n    }\n)\n\ndecl_get_name_1 = types.FunctionDeclaration(\n    name=\"get_name_1\",\n    description=\"\"\"Search for the name associated with a stock ticker or symbol's company, security, isin or cusip. \n    Each ticker entry provides a description, matching symbol, and asset type.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The symbol or ticker to search for.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"company\": {\n                \"type\": \"string\",\n                \"description\": \"The company you're searching for.\"\n            }\n        },\n        \"required\": [\"q\", \"exchange\", \"query\", \"company\"]\n    }\n)\n\ndecl_get_symbol_quote_1 = types.FunctionDeclaration(\n    name=\"get_symbol_quote_1\",\n    description=\"\"\"Search for the current price or quote of a stock ticker or symbol. The response is\n                   provided in json format. Each response contains the following key-value pairs:\n                   \n                   c: Current price,\n                   d: Change,\n                  dp: Percent change,\n                   h: High price of the day,\n                   l: Low price of the day,\n                   o: Open price of the day,\n                  pc: Previous close price,\n                   t: Epoch timestamp of price in seconds.\n\n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol for a company, security, isin, or cusip.\" \n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"The exchange code used to filter quotes. This must always be 'US'.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\", \"exchange\"]\n    }\n)\n\ndecl_get_local_datetime = types.FunctionDeclaration(\n    name=\"get_local_datetime\",\n    description=\"\"\"Converts an array of timestamps from epoch time to the local timezone format. The result is an array\n                   of date and time in locale appropriate format. Suitable for use in a locale appropriate response.\n                   Treat this function as a vector function. Always prefer to batch timestamps for conversion. Use this\n                   function to format date and time in your responses.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"t\": {\n                \"type\": \"array\",\n                \"description\": \"\"\"An array of timestamps in seconds since epoch to be converted. The order of\n                                  timestamps matches the order of conversion.\"\"\",\n                \"items\": {\n                    \"type\": \"integer\"\n                }\n            }\n        },\n        \"required\": [\"t\"]\n    }\n)\n\ndecl_get_market_status_1 = types.FunctionDeclaration(\n    name=\"get_market_status_1\",\n    description=\"\"\"Get the current market status of global exchanges. Includes whether exchanges are open or closed.  \n                   Also includes holiday details if applicable. The response is provided in json format. Each response \n                   contains the following key-value pairs:\n\n                   exchange: Exchange code,\n                   timezone: Timezone of the exchange,\n                    holiday: Holiday event name, or null if it's not a holiday,\n                     isOpen: Whether the market is open at the moment,\n                          t: Epoch timestamp of status in seconds (Eastern Time),\n                    session: The market session can be 1 of the following values: \n                    \n                    pre-market,regular,post-market when open, or null if closed.\n                    \n                    Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_market_session_1 = types.FunctionDeclaration(\n    name=\"get_market_session_1\",\n    description=\"Get the current market session of global exchanges.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_company_peers_1 = types.FunctionDeclaration(\n    name=\"get_company_peers_1\",\n    description=\"\"\"Search for a company's peers. Returns a list of peers operating in the same country and in the same\n                   sector, industry, or subIndustry. Each response contains the following key-value pairs: \n                   \n                   symbol: The company's stock ticker symbol, \n                   peers: A list containing the peers.\n                   \n                   Each peers entry contains the following key-value pairs:\n                   \n                   symbol: The peer company's stock ticker symbol, \n                   name: The peer company's name.\n                   \n                   Parse the response and respond according to this information.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to obtain peers.\"\n            },\n            \"grouping\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"This parameter may be one of the following values: sector, industry, subIndustry.\n                                  Always use subIndustry unless told otherwise.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"grouping\", \"exchange\", \"query\"]\n    }\n)\n\ndecl_get_exchange_codes_1 = types.FunctionDeclaration(\n    name=\"get_exchange_codes_1\",\n    description=\"\"\"Get a dictionary mapping all supported exchange codes to their names.\"\"\"\n)\n\ndecl_get_exchange_code_1 = types.FunctionDeclaration(\n    name=\"get_exchange_code_1\",\n    description=\"\"\"Search for the exchange code to use when filtering by exchange. The result will be one or\n                   more exchange codes provided as a comma-separated string value.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"Specifies which exchange code to search for.\"\n            }\n        },\n        \"required\": [\"q\"]\n    }\n)\n\ndecl_get_financials_1 = types.FunctionDeclaration(\n    name=\"get_financials_1\",\n    description=\"\"\"Get company basic financials such as margin, P/E ratio, 52-week high/low, etc. Parse the response for \n                   key-value pairs in json format and interpret their meaning as stock market financial indicators.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"metric\": {\n                \"type\": \"string\",\n                \"description\": \"It must always be declared as the value 'all'\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"metric\", \"query\"]\n    }\n)\n\ndecl_get_daily_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_daily_candlestick_2\",\n    description=\"\"\"Get a historical daily stock ticker candlestick / aggregate bar (OHLC). \n                   Includes historical daily open, high, low, and close prices. Also includes historical daily trade\n                   volume and pre-market/after-hours trade prices. It provides the last trading days' data after \n                   11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"date\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"The date of the requested candlestick in format YYYY-MM-DD.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n                                  Use true unless told otherwise.\"\"\"\n            },\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"date\", \"adjusted\", \"exchange\", \"query\"]\n    },\n)\n\ndecl_get_company_news_1 = types.FunctionDeclaration(\n    name=\"get_company_news_1\",\n    description=\"Retrieve the most recent news articles related to a specified ticker.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\",\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be older than the parameter 'to'.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be more recent than the parameter 'from'. The\n                                  default value is today's date.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"from\", \"to\", \"query\"]\n    },\n)\n\ndecl_get_custom_candlestick_2 = types.FunctionDeclaration(\n    name=\"get_custom_candlestick_2\",\n    description=\"\"\"Get a historical stock ticker candlestick / aggregate bar (OHLC) over a custom date range and \n                   time interval in Eastern Time. Includes historical open, high, low, and close prices. Also \n                   includes historical daily trade volume and pre-market/after-hours trade prices. It includes \n                   the last trading days' data after 11:59PM Eastern Time.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"stocksTicker\": {\n                \"type\": \"string\",\n                \"description\": \"The stock ticker symbol of a company to search for.\",\n            },\n            \"multiplier\": {\n                \"type\": \"integer\",\n                \"description\": \"This must be included and equal to 1 unless told otherwise.\"\n            },\n            \"timespan\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The size of the candlestick's time window. This is allowed to be one of the following:\n                                  second, minute, hour, day, week, month, quarter, or year. The default value is day.\"\"\"\n            },\n            \"from\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'to'.\"\"\"\n            },\n            \"to\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'from'. The \n                                  default is one weekday before get_last_market_close.\n                                  Replace more recent dates with the default.\"\"\"\n            },\n            \"adjusted\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n                                  Use true unless told otherwise.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"This must be included. May be one of asc or desc. asc will sort by timestmap in \n                                  ascending order. desc will sort by timestamp in descending order.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"Set the number of base aggregates used to create this candlestick. This must be 5000 \n                                  unless told to limit base aggregates to something else.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"stocksTicker\", \"multiplier\", \"timespan\", \"from\", \"to\", \"adjusted\", \"sort\", \"limit\", \"query\"]\n    },\n)\n\ndecl_get_last_market_close = types.FunctionDeclaration(\n    name=\"get_last_market_close\",\n    description=\"\"\"Get the last market close of the specified exchange in Eastern Time. The response has already\n                   been converted by get_local_datetime so this step should be skipped.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"exchange\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n                                  exchange code to search for.\"\"\"\n            }\n        },\n        \"required\": [\"exchange\"]\n    }\n)\n\ndecl_get_ticker_overview_2 = types.FunctionDeclaration(\n    name=\"get_ticker_overview_2\",\n    description=\"\"\"Retrieve comprehensive details for a single ticker symbol. It's a deep look into a company’s \n    fundamental attributes, including its primary exchange, standardized identifiers (CIK, composite FIGI, \n    share class FIGI), market capitalization, industry classification, and key dates. Also includes branding assets in\n    the form of icons and logos.\n    \"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol of a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"ticker\", \"query\"]\n    }\n)\n\ndecl_get_recommendation_trends_1 = types.FunctionDeclaration(\n    name=\"get_recommendation_trends_1\",\n    description=\"\"\"Get the latest analyst recommendation trends for a company.\n                The data includes the latest recommendations as well as historical\n                recommendation data for each month. The data is classified according\n                to these categories: strongBuy, buy, hold, sell, and strongSell.\n                The date of a recommendation indicated by the value of 'period'.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"symbol\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"symbol\", \"query\"]\n    }\n)\n\ndecl_get_news_with_sentiment_2 = types.FunctionDeclaration(\n    name=\"get_news_with_sentiment_2\",\n    description=\"\"\"Retrieve the most recent news articles related to a specified ticker. Each article includes \n                   comprehensive coverage. Including a summary, publisher information, article metadata, \n                   and sentiment analysis.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"ticker\": {\n                \"type\": \"string\",\n                \"description\": \"Stock ticker symbol for a company.\"\n            },\n            \"published_utc.gte\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'published_utc.lte'. \n                                  The default value is one-month ago from today's date.\"\"\"\n            },\n            \"published_utc.lte\": {\n                \"type\": \"string\",\n                \"format\": \"date-time\",\n                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'published_utc.gte'.\n                                  The default is one weekday prior to get_last_market_close (excluding weekends).\n                                  Replace more recent dates with the default.\"\"\"\n            },\n            \"order\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"Must be desc for descending order, or asc for ascending order.\n                                  When order is not specified the default is descending order.\n                                  Ordering will be based on the parameter 'sort'.\"\"\"\n            },\n            \"limit\": {\n                \"type\": \"integer\",\n                \"description\": \"\"\"This must be included and equal to 1000 unless told otherwise.\"\"\"\n            },\n            \"sort\": {\n                \"type\": \"string\",\n                \"description\": \"\"\"The sort field used for ordering. This value must\n                                  always be published_utc.\"\"\"\n            },\n            \"query\": {\n                \"type\": \"string\",\n                \"description\": \"The question you're attempting to answer.\"\n            }\n        },\n        \"required\": [\"limit\", \"ticker\", \"published_utc.gte\", \"published_utc.lte\", \"order\", \"sort\", \"query\"]\n    }\n)\n\ndecl_get_rag_tool_response = types.FunctionDeclaration(\n    name=\"get_rag_tool_response\",\n    description=\"\"\"A database containing useful financial information. Always check here for answers first.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"question\": {\n                \"type\": \"string\",\n                \"description\": \"A question needing an answer. Asked as a simple string.\"\n            }\n        }\n    }\n)\n\ndecl_get_wiki_tool_response = types.FunctionDeclaration(\n    name=\"get_wiki_tool_response\",\n    description=\"\"\"Answers questions that still have unknown answers. Retrieve a wiki page related to a company, \n                   product, or service. Each web page includes detailed company information, financial indicators, \n                   tickers, symbols, history, and products and services.\"\"\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. Just the name and no other details.\"\n            },\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The complete, unaltered, query string.\"\n            }\n        },\n        \"required\": [\"id\", \"q\"]\n    }\n)\n\ndecl_get_search_tool_response = types.FunctionDeclaration(\n    name=\"get_search_tool_response\",\n    description=\"Answers questions that still have unknown answers. Use it after checking all your other tools.\",\n    parameters={\n        \"type\": \"object\",\n        \"properties\": {\n            \"q\": {\n                \"type\": \"string\",\n                \"description\": \"The question needing an answer. Asked as a simple string.\"\n            },\n            \"id\": {\n                \"type\": \"string\",\n                \"description\": \"The question's company or product. In one word. Just the name and no other details.\"\n            }\n        },\n        \"required\": [\"q\", \"id\"]\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:21.910445Z","iopub.execute_input":"2025-11-19T23:43:21.91071Z","iopub.status.idle":"2025-11-19T23:43:21.947937Z","shell.execute_reply.started":"2025-11-19T23:43:21.91069Z","shell.execute_reply":"2025-11-19T23:43:21.946821Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Define the system prompt.\n\ninstruction = f\"\"\"You are a helpful and informative bot that answers finance and stock market questions. \nOnly answer the question asked and do not change topic. While the answer is still\nunknown you must follow these rules for predicting function call order:\n\nRULE#1: Always consult your other functions before get_search_tool_response.\nRULE#2: Always consult get_wiki_tool_response before get_search_tool_response.\nRULE#3: Always consult get_search_tool_response last.\nRULE#4: Always convert timestamps with get_local_datetime and use the converted date/time in your response.\nRULE#5: Always incorporate as much useful information from tools and functions in your response.\"\"\"","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:21.949016Z","iopub.execute_input":"2025-11-19T23:43:21.949309Z","iopub.status.idle":"2025-11-19T23:43:21.969692Z","shell.execute_reply.started":"2025-11-19T23:43:21.94928Z","shell.execute_reply":"2025-11-19T23:43:21.968489Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Import the finance api secret keys.\n\nPOLYGON_API_KEY = UserSecretsClient().get_secret(\"POLYGON_API_KEY\")\nFINNHUB_API_KEY = UserSecretsClient().get_secret(\"FINNHUB_API_KEY\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:21.97075Z","iopub.execute_input":"2025-11-19T23:43:21.971017Z","iopub.status.idle":"2025-11-19T23:43:22.295715Z","shell.execute_reply.started":"2025-11-19T23:43:21.970996Z","shell.execute_reply":"2025-11-19T23:43:22.294686Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Instantiate tools and load the exchange data from source csv.\n# - Identifies exchanges by a 1-2 letter code which can be used to filter response data.\n# - Also maps the exchange code to exchange details.\ntry:\n    df = pandas.read_csv(\"/kaggle/input/exchanges/exchanges_src.csv\")\nexcept FileNotFoundError as e:\n    df = pandas.read_csv(\"exchanges_src.csv\") # local run\ndf = df.drop([\"close_date\"], axis=1).fillna(\"\")\ndf.to_csv(\"exchanges.csv\", index=False)\nexchanges = CSVLoader(file_path=\"exchanges.csv\", encoding=\"utf-8\", csv_args={\"delimiter\": \",\"}).load()\n\n# Prepare a RAG tool for use and add the exchange data.\ntool_rag = RetrievalAugmentedGenerator(api.args.CLIENT, \"finance\")\ntool_rag.add_documents_list(exchanges)\n\n# Prepare a the grounding tools for use.\ntool_wiki = WikiGroundingGenerator(api.args.CLIENT, tool_rag)\ntool_ground = SearchGroundingGenerator(api.args.CLIENT, tool_rag)\ntool_rest = RestGroundingGenerator(tool_rag, with_limits=True)","metadata":{"jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T23:43:22.296741Z","iopub.execute_input":"2025-11-19T23:43:22.297052Z","iopub.status.idle":"2025-11-19T23:43:23.215269Z","shell.execute_reply.started":"2025-11-19T23:43:22.297029Z","shell.execute_reply":"2025-11-19T23:43:23.21378Z"}},"outputs":[{"name":"stderr","text":"Generate document embedding: 0it [00:00, ?it/s]\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## Function Calling Expert","metadata":{}},{"cell_type":"code","source":"# Implement the callable functions and function handler.\n\ndef ask_rag_tool(content):\n    return tool_rag.generate_answer(content[\"question\"]).text\n\ndef ask_wiki_tool(content):\n    return tool_wiki.generate_answer(content[\"q\"], content[\"id\"])\n\ndef ask_search_tool(content):\n    return tool_ground.generate_answer(content[\"q\"], content[\"id\"])\n\ndef get_exchange_codes_1(content):\n    return tool_rag.get_exchange_codes()\n\ndef get_exchange_code_1(content):\n    return tool_rag.get_exchange_codes(with_query=content)\n    \ndef last_market_close(content):\n    return tool_rag.last_market_close(content[\"exchange\"])\n    \ndef get_symbol_1(content, by_name: bool = True):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"q\"], \"get_symbol_1\")\n    if len(stored) == 0:\n        return tool_rest.get_symbol(content, by_name)\n    return json.loads(stored[0].docs)\n\ndef get_symbols_1(content):\n    return None # todo\n\ndef get_name_1(content):\n    return get_symbol_1(content, by_name = False)\n\ndef get_quote_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_quote_1\")\n    if tool_rag.generated_events(content[\"exchange\"]).is_open():\n        return get_current_price_1(content)\n    elif len(stored) > 0:\n        last_close = parse(tool_rag.last_market_close(content[\"exchange\"])).timestamp()\n        for quote in stored:\n            if quote.meta[\"timestamp\"] >= last_close:\n                return [quote.docs for quote in stored]\n    return get_current_price_1(content)\n\ndef get_current_price_1(content):\n    return tool_rest.get_current_price(content)\n\ndef get_market_status_1(content):\n    stored, has_update = tool_rag.get_market_status(content['exchange'])\n    if has_update:\n        with_id = stored[0].store_id if len(stored) > 0 else None\n        return tool_rest.get_market_status(content, with_id)\n    return stored[0].docs\n\ndef get_session_1(content):\n    return json.loads(get_market_status_1(content))[\"session\"]\n\ndef get_peers_1(content):\n    stored = tool_rag.get_peers_document(content[\"query\"], content[\"symbol\"], content['grouping'])\n    if len(stored) == 0:\n        peers = tool_rest.get_peers(content)\n        if peers.count > 0:\n            names = []\n            for peer in peers.get():\n                if peer == content[\"symbol\"]:\n                    continue # skip including the query symbol in peers\n                name = get_name_1(dict(q=peer, exchange=content[\"exchange\"], query=content[\"query\"]))\n                if name != Api.Const.Stop():\n                    data = {\"symbol\": peer, \"name\": name}\n                    names.append(data)\n            tool_rag.add_peers_document(content[\"query\"], names, content[\"symbol\"], \"get_peers_1\", content['grouping'])\n            return names\n        return Api.Const.Stop()\n    return json.loads(stored[0].docs)[\"peers\"]\n\ndef local_datetime(content):\n    local_t = []\n    for timestamp in content[\"t\"]:\n        local_t.append(local_date_from_epoch(timestamp))\n    return local_t\n\ndef local_date_from_epoch(timestamp):\n    if len(str(timestamp)) == 13:\n        return datetime.fromtimestamp(timestamp/1000, tz=GeneratedEvent.tz()).strftime('%c')\n    else:\n        return datetime.fromtimestamp(timestamp, tz=GeneratedEvent.tz()).strftime('%c')\n\ndef get_financials_1(content):\n    stored = tool_rag.get_basic_financials(content[\"query\"], content[\"symbol\"], \"get_financials_1\")\n    if len(stored) == 0:\n        return tool_rest.get_basic_financials(content)\n    return [chunk.docs for chunk in stored]\n\ndef get_news_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_news_1\")\n    if len(stored) == 0:\n        return tool_rest.get_news_simple(content)\n    return [NewsTypeFinn.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n\ndef get_daily_candle_2(content):\n    stored = tool_rag.get_api_documents(\n        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"daily_candle_2\", \n        meta_opt=[{\"from_date\": content[\"date\"], \"adjusted\": content[\"adjusted\"]}])\n    if len(stored) == 0:\n        candle = tool_rest.get_daily_candle(content)\n        # Attempt to recover from choosing a holiday.\n        candle_date = parse(content[\"date\"])\n        if candle.status is RestStatus.NONE and candle_date.weekday() == 0 or candle_date.weekday() == 4:\n            if candle_date.weekday() == 0: # index 0 is monday, index 4 is friday\n                content[\"date\"] = candle_date.replace(day=candle_date.day-3).strftime(\"%Y-%m-%d\")\n            else:\n                content[\"date\"] = candle_date.replace(day=candle_date.day-1).strftime(\"%Y-%m-%d\")\n            return get_daily_candle_2(content)\n        return candle.model_dump_json()\n    return [json.loads(candle.docs) for candle in stored]\n\ndef get_custom_candle_2(content):\n    stored = tool_rag.get_api_documents(\n        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"custom_candle_2\", \n        meta_opt=[{\n            \"timespan\": content[\"timespan\"],\n            \"adjusted\": content[\"adjusted\"],\n            \"from\": content[\"from\"],\n            \"to\": content[\"to\"]}])\n    if len(stored) == 0:\n        return tool_rest.get_custom_candle(content)\n    return [json.loads(candle.docs) for candle in stored]\n\ndef get_overview_2(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"ticker\"], \"ticker_overview_2\")\n    if len(stored) == 0:\n        return tool_rest.get_overview(content)\n    return json.loads(stored[0].docs)\n\ndef get_trends_1(content):\n    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"trends_1\")\n    if len(stored) == 0:\n        return tool_rest.get_trends_simple(content)\n    return [json.loads(trend.docs) for trend in stored]\n\ndef get_news_2(content):\n    timestamp_from = parse(content[\"published_utc.gte\"]).timestamp()\n    timestamp_to = parse(content[\"published_utc.lte\"]).timestamp()\n    news_from = tool_rag.get_api_documents(\n        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_from}])\n    news_to = tool_rag.get_api_documents(\n        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_to}])\n    if len(news_from) > 0 and len(news_to) > 0:\n        stored = tool_rag.get_api_documents(\n            content[\"query\"], content[\"ticker\"], \"get_news_2\",\n            [{\"published_utc\": {\"$gte\": timestamp_from}},\n             {\"published_utc\": {\"$lte\": timestamp_to}}])\n        return [NewsTypePoly.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n    return tool_rest.get_news_tagged(content)\n        \nfinance_tool = types.Tool(\n    function_declarations=[\n        decl_get_symbol_1,\n        decl_get_symbols_1,\n        decl_get_name_1,\n        decl_get_symbol_quote_1,\n        decl_get_market_status_1,\n        decl_get_market_session_1,\n        decl_get_company_peers_1,\n        decl_get_local_datetime,\n        decl_get_last_market_close,\n        decl_get_exchange_codes_1,\n        decl_get_exchange_code_1,\n        decl_get_financials_1,\n        decl_get_daily_candlestick_2,\n        decl_get_custom_candlestick_2,\n        decl_get_ticker_overview_2,\n        decl_get_recommendation_trends_1,\n        decl_get_news_with_sentiment_2,\n        decl_get_rag_tool_response,\n        decl_get_wiki_tool_response,\n        decl_get_search_tool_response\n    ]\n)\n\nfunction_handler = {\n    \"get_symbol_1\": get_symbol_1,\n    \"get_symbols_1\": get_symbols_1,\n    \"get_name_1\": get_name_1,\n    \"get_symbol_quote_1\": get_quote_1,\n    \"get_market_status_1\": get_market_status_1,\n    \"get_market_session_1\": get_session_1,\n    \"get_company_peers_1\": get_peers_1,\n    \"get_local_datetime\": local_datetime,\n    \"get_last_market_close\": last_market_close,\n    \"get_exchange_codes_1\": get_exchange_codes_1,\n    \"get_exchange_code_1\": get_exchange_code_1,\n    \"get_financials_1\": get_financials_1,\n    \"get_daily_candlestick_2\": get_daily_candle_2,\n    \"get_custom_candlestick_2\": get_custom_candle_2,\n    \"get_ticker_overview_2\": get_overview_2,\n    \"get_recommendation_trends_1\": get_trends_1,\n    \"get_news_with_sentiment_2\": get_news_2,\n    \"get_rag_tool_response\": ask_rag_tool,\n    \"get_wiki_tool_response\": ask_wiki_tool,\n    \"get_search_tool_response\": ask_search_tool\n}","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:23.216222Z","iopub.execute_input":"2025-11-19T23:43:23.216506Z","iopub.status.idle":"2025-11-19T23:43:23.249197Z","shell.execute_reply.started":"2025-11-19T23:43:23.216486Z","shell.execute_reply":"2025-11-19T23:43:23.248158Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Implement the function calling expert.\n\n@retry.Retry(\n    predicate=is_retriable,\n    initial=2.0,\n    maximum=64.0,\n    multiplier=2.0,\n    timeout=600,\n)\ndef send_message(prompt):\n    #display(Markdown(\"#### Prompt\"))\n    #print(prompt, \"\\n\")\n    memory.set_prompt(prompt)\n    # Enable system prompt, function calling and minimum-randomness.\n    config_fncall = types.GenerateContentConfig(\n        system_instruction=instruction,\n        tools=[finance_tool],\n        temperature=0.0\n    )\n    # Handle cases with multiple chained function calls.\n    function_calling_in_process = True\n    # Send the initial user prompt and function declarations.\n    response = api.retriable(api.args.CLIENT.models.generate_content,\n                             model=api(Api.Model.GEN),\n                             config=config_fncall,\n                             contents=memory.contents)\n    while function_calling_in_process:\n        # A part can be a function call or natural language response.\n        for part in response.candidates[0].content.parts:\n            if function_call := part.function_call:\n                # Extract the function call.\n                fn_name = function_call.name\n                #display(Markdown(\"#### Predicted function name\"))\n                #print(fn_name, \"\\n\")\n                # Extract the function call arguments.\n                fn_args = {key: value for key, value in function_call.args.items()}\n                #display(Markdown(\"#### Predicted function arguments\"))\n                #print(fn_args, \"\\n\")\n                # Call the predicted function.\n                try:\n                    api_response = function_handler[fn_name](fn_args)[:20000] # Stay within the input token limit\n                except KeyError as e: # Gemini sometimes omits required fn_args\n                    api.generation_fail()\n                    time.sleep(api.dt_between)\n                    send_message(prompt)\n                #display(Markdown(\"#### API response\"))\n                #print(api_response[:500], \"...\", \"\\n\")\n                # Create an API response part.\n                api_response_part = types.Part.from_function_response(\n                    name=fn_name,\n                    response={\"content\": api_response},\n                )\n                memory.update_contents(function_call, api_response_part)\n                # Send the updated prompt.\n                response = api.retriable(api.args.CLIENT.models.generate_content,\n                                         model=api(Api.Model.GEN),\n                                         config=config_fncall,\n                                         contents=memory.contents)\n            else:\n                # Response may be a summary or reasoning step.\n                if len(response.candidates[0].content.parts) == 1:\n                    function_calling_in_process = False\n                    memory.set_summary(response.text.replace(\"$\", \"\\\\$\"))\n                    break # No more parts in response.\n                else:\n                    #display(Markdown(\"#### Natural language reasoning step\"))\n                    #print(response)\n                    memory.set_reason(response.candidates[0].content.parts[0].text)\n                    continue # Next part contains a function call.\n        if not function_calling_in_process:\n            break # The function calling chain is complete.\n            \n    # Show the final natural language summary.\n    display(Markdown(\"#### Natural language response\"))\n    display(Markdown(memory.summary))","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:23.250224Z","iopub.execute_input":"2025-11-19T23:43:23.250554Z","iopub.status.idle":"2025-11-19T23:43:23.290473Z","shell.execute_reply.started":"2025-11-19T23:43:23.250529Z","shell.execute_reply":"2025-11-19T23:43:23.289219Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# RAG Baseline Check","metadata":{}},{"cell_type":"code","source":"response = tool_rag.get_exchanges_csv(\n    \"\"\"Give me a dictionary in string form. It must contain key:value pairs mapping \n    exchange code to name. Just the dictionary string in pretty form.\"\"\")\nprint(response.candidates[0].content.parts[-1].text)\n\nresponse = tool_rag.get_exchanges_csv(\n    \"\"\"What is the Germany exchange code? Return only the exchange codes as a simple \n    comma separated value that I can copy.\"\"\")\nprint(response.candidates[0].content.parts[-1].text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\"What are the Germany exchanges and thier corresponding exchange codes?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.generate_answer(\"What are Google's stock ticker symbols?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.generate_answer(\"What is Facebook's stock ticker symbol?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\"What are the US exchange operating hours?\")\nprint(response.text, \"\\n\")\n\nresponse = tool_rag.get_exchanges_csv(\n    f\"\"\"Answer based on your knowledge of exchange operating hours.\n    Do not answer in full sentences. Omit all chat and provide the answer only.\n    The fields pre_market and post_market both represent extended operating hours.\n\n    The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n\n    Weekdays are: Mon, Tue, Wed, Thu, Fri.\n    On weekdays all exchanges open after pre-market and regular hours.\n    On weekdays all exchanges close after regular and post-market hours.\n    \n    Weekends are: Sat, Sun.\n    Always exclude weekends from exchange operating hours.\n    A list of holidays in date format mm-dd-yyyy: {tool_rag.holidays[\"US\"]}\n    Always exclude holidays from exchange operating hours.\n    When the answer is a holiday use the prior weekday for close.\n    When the answer is a holiday use the next weekday for open.\n    \n    Consider the US exchange's operating hours.\n    Provide the most recent weekday's close including post_market hours.\n    \n    Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\")\nprint(response.candidates[0].content.parts[-1].text)","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:23.291474Z","iopub.execute_input":"2025-11-19T23:43:23.291733Z","iopub.status.idle":"2025-11-19T23:43:53.619912Z","shell.execute_reply.started":"2025-11-19T23:43:23.291712Z","shell.execute_reply":"2025-11-19T23:43:53.618967Z"},"trusted":true},"outputs":[{"name":"stdout","text":"```\n{\n    \"VN\": \"Vietnam exchanges including HOSE, HNX and UPCOM\",\n    \"AD\": \"ABU DHABI SECURITIES EXCHANGE\",\n    \"US\": \"US exchanges (NYSE, Nasdaq)\",\n    \"CO\": \"OMX NORDIC EXCHANGE COPENHAGEN A/S\",\n    \"QA\": \"QATAR EXCHANGE\",\n    \"BA\": \"BOLSA DE COMERCIO DE BUENOS AIRES\",\n    \"MX\": \"BOLSA MEXICANA DE VALORES (MEXICAN STOCK EXCHANGE)\",\n    \"PR\": \"PRAGUE STOCK EXCHANGE\",\n    \"HK\": \"HONG KONG EXCHANGES AND CLEARING LTD\",\n    \"CA\": \"Egyptian Stock Exchange\",\n    \"AX\": \"ASX - ALL MARKETS\",\n    \"SX\": \"DEUTSCHE BOERSE Stoxx\",\n    \"KQ\": \"KOREA EXCHANGE (KOSDAQ)\",\n    \"DB\": \"DUBAI FINANCIAL MARKET\",\n    \"PM\": \"Philippine Stock Exchange\",\n    \"KS\": \"KOREA EXCHANGE (STOCK MARKET)\",\n    \"ST\": \"NASDAQ OMX NORDIC STOCKHOLM\",\n    \"DU\": \"BOERSE DUESSELDORF\",\n    \"TL\": \"NASDAQ OMX TALLINN\",\n    \"AT\": \"ATHENS EXCHANGE S.A. CASH MARKET\",\n    \"SW\": \"SWISS EXCHANGE\",\n    \"LS\": \"NYSE EURONEXT - EURONEXT LISBON\",\n    \"SI\": \"SINGAPORE EXCHANGE\",\n    \"RG\": \"NASDAQ OMX RIGA\",\n    \"CR\": \"CARACAS STOCK EXCHANGE\",\n    \"SA\": \"Brazil Bolsa - Sao Paolo\",\n    \"BH\": \"BAHRAIN BOURSE\",\n    \"NZ\": \"NEW ZEALAND EXCHANGE LTD\",\n    \"L\": \"LONDON STOCK EXCHANGE\",\n    \"SZ\": \"SHENZHEN STOCK EXCHANGE\",\n    \"IC\": \"NASDAQ OMX ICELAND\",\n    \"KW\": \"Kuwait Stock Exchange\",\n    \"JK\": \"INDONESIA STOCK EXCHANGE\",\n    \"BE\": \"BOERSE BERLIN\",\n    \"TA\": \"TEL AVIV STOCK EXCHANGE\",\n    \"PA\": \"NYSE EURONEXT - MARCHE LIBRE PARIS\",\n    \"V\": \"TSX VENTURE EXCHANGE - NEX\",\n    \"SN\": \"SANTIAGO STOCK EXCHANGE\",\n    \"BD\": \"BUDAPEST STOCK EXCHANGE\",\n    \"KL\": \"BURSA MALAYSIA\",\n    \"CN\": \"CANADIAN NATIONAL STOCK EXCHANGE\",\n    \"VS\": \"NASDAQ OMX VILNIUS\",\n    \"ME\": \"MOSCOW EXCHANGE\",\n    \"CS\": \"CASABLANCA STOCK EXCHANGE\",\n    \"NL\": \"Nigerian Stock Exchange\",\n    \"BR\": \"NYSE EURONEXT - EURONEXT BRUSSELS\",\n    \"NS\": \"NATIONAL STOCK EXCHANGE OF INDIA\",\n    \"DE\": \"XETRA\",\n    \"WA\": \"WARSAW STOCK EXCHANGE/EQUITIES/MAIN MARKET\",\n    \"AS\": \"NYSE EURONEXT - EURONEXT AMSTERDAM\",\n    \"TG\": \"DEUTSCHE BOERSE TradeGate\",\n    \"IR\": \"IRISH STOCK EXCHANGE - ALL MARKET\",\n    \"OL\": \"OSLO BORS ASA\",\n    \"BO\": \"BSE LTD\",\n    \"MT\": \"MALTA STOCK EXCHANGE\",\n    \"BC\": \"BOLSA DE VALORES DE COLOMBIA\",\n    \"F\": \"DEUTSCHE BOERSE AG\",\n    \"HE\": \"NASDAQ OMX HELSINKI LTD\",\n    \"MU\": \"BOERSE MUENCHEN\",\n    \"IS\": \"BORSA ISTANBUL\",\n    \"SR\": \"SAUDI STOCK EXCHANGE\",\n    \"NE\": \"AEQUITAS NEO EXCHANGE\",\n    \"MI\": \"Italian Stock Exchange\",\n    \"SS\": \"SHANGHAI STOCK EXCHANGE\",\n    \"MC\": \"BOLSA DE MADRID\",\n    \"HA\": \"Hanover Stock Exchange\",\n    \"VI\": \"Vienna Stock Exchange\",\n    \"TWO\": \"TPEx\",\n    \"HM\": \"HANSEATISCHE WERTPAPIERBOERSE HAMBURG\",\n    \"TW\": \"TAIWAN STOCK EXCHANGE\",\n    \"TO\": \"TORONTO STOCK EXCHANGE\",\n    \"SC\": \"BOERSE_FRANKFURT_ZERTIFIKATE\",\n    \"JO\": \"JOHANNESBURG STOCK EXCHANGE\",\n    \"SG\": \"BOERSE STUTTGART\",\n    \"RO\": \"BUCHAREST STOCK EXCHANGE\",\n    \"T\": \"TOKYO STOCK EXCHANGE-TOKYO PRO MARKET\",\n    \"BK\": \"STOCK EXCHANGE OF THAILAND\"\n}\n```\nDE, F, TG, SX, BE, DU, HA, HM, MU, SC, SG\n \n\nThe Germany exchanges and their corresponding codes are: XETRA (DE), DEUTSCHE BOERSE AG (F), Hanover Stock Exchange (HA), DEUTSCHE BOERSE TradeGate (TG), BOERSE BERLIN (BE), BOERSE DUESSELDORF (DU), HANSEATISCHE WERTPAPIERBOERSE HAMBURG (HM), BOERSE MUENCHEN (MU), DEUTSCHE BOERSE Stoxx (SX), BOERSE_FRANKFURT_ZERTIFIKATE (SC), and BOERSE STUTTGART (SG).\n \n\nI don't know.\n \n\nI don't know.\n \n\nIn the U.S., pre-market trading hours are from 04:00-09:30, regular trading hours are from 09:30-16:00, and post-market hours are from 16:00-20:00, America/New_York time. These hours apply to exchanges such as NYSE and Nasdaq.\n \n\nWed Nov 19 20:00:00 2025\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# SC1 Baseline Check","metadata":{}},{"cell_type":"code","source":"# Wait 59s for rate-limits to reset on FREE-tier.\nif api.args.API_LIMIT is Api.Limit.FREE.value:\n    print(\"Gemini API limit is FREE. Waiting 59s...\")\n    time.sleep(59)","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:53.620865Z","iopub.execute_input":"2025-11-19T23:43:53.6211Z","iopub.status.idle":"2025-11-19T23:43:53.62607Z","shell.execute_reply.started":"2025-11-19T23:43:53.621081Z","shell.execute_reply":"2025-11-19T23:43:53.625087Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"send_message(\"What is the current session for US exchanges?\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:43:53.627006Z","iopub.execute_input":"2025-11-19T23:43:53.627277Z","iopub.status.idle":"2025-11-19T23:43:57.897838Z","shell.execute_reply.started":"2025-11-19T23:43:53.627249Z","shell.execute_reply":"2025-11-19T23:43:57.896821Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Generate US->MarketEvent.LAST_CLOSE: 100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\nGenerate US->MarketEvent.PRE_OPEN: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\nGenerate US->MarketEvent.REG_OPEN: 100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\nGenerate US->MarketEvent.REG_CLOSE: 100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\nGenerate US->MarketEvent.POST_CLOSE: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The current session for US exchanges is post-market.\n"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"send_message(\"What is the US market status?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T23:43:57.898807Z","iopub.execute_input":"2025-11-19T23:43:57.899139Z","iopub.status.idle":"2025-11-19T23:45:20.984594Z","shell.execute_reply.started":"2025-11-19T23:43:57.899111Z","shell.execute_reply":"2025-11-19T23:45:20.983431Z"}},"outputs":[{"name":"stdout","text":"api.refill_rpm  2000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The US market is currently open for the post-market session. The current time is Wed Nov 19 18:44:01 2025 America/New_York. There is no holiday today.\n"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"send_message(\"When was the last US market close?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T23:45:20.989214Z","iopub.execute_input":"2025-11-19T23:45:20.989621Z","iopub.status.idle":"2025-11-19T23:45:22.073828Z","shell.execute_reply.started":"2025-11-19T23:45:20.989598Z","shell.execute_reply":"2025-11-19T23:45:22.072571Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The last US market close was on Tue Nov 18 20:00:00 2025.\n"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"send_message(\"What is Apple's stock ticker?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T23:45:22.074931Z","iopub.execute_input":"2025-11-19T23:45:22.07529Z","iopub.status.idle":"2025-11-19T23:45:24.284101Z","shell.execute_reply.started":"2025-11-19T23:45:22.075259Z","shell.execute_reply":"2025-11-19T23:45:24.283124Z"}},"outputs":[{"name":"stderr","text":"Score similarity to query: 100%|██████████| 10/10 [00:00<00:00, 16.66it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple's stock ticker is AAPL.\n"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"send_message(\"What is the current price of Amazon stock? Display the result as a json object.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:45:24.285148Z","iopub.execute_input":"2025-11-19T23:45:24.285685Z","iopub.status.idle":"2025-11-19T23:45:27.728386Z","shell.execute_reply.started":"2025-11-19T23:45:24.285654Z","shell.execute_reply":"2025-11-19T23:45:27.727423Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Generate quote embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is the current price of Amazon stock:\n```json\n{\n\"c\": 222.69,\n\"d\": 0.14,\n\"dp\": 0.0629,\n\"h\": 223.735,\n\"l\": 218.52,\n\"o\": 223.735,\n\"pc\": 222.55,\n\"t\": 1763586000\n}\n```\nThe current price is 222.69. The price changed by 0.14, which is a 0.0629 percent change. The high price of the day is 223.735, and the low price of the day is 218.52. The open price of the day was 223.735, and the previous close price was 222.55. The timestamp is Wed Nov 19 16:00:00 2025.\n"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"send_message(\"\"\"Show me Apple's basic financials and help me understand key performance metrics. \nHow has the stock performed?\"\"\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:45:27.729369Z","iopub.execute_input":"2025-11-19T23:45:27.72976Z","iopub.status.idle":"2025-11-19T23:45:36.675943Z","shell.execute_reply.started":"2025-11-19T23:45:27.729732Z","shell.execute_reply":"2025-11-19T23:45:36.674849Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's an overview of Apple's financial performance based on the data from 2025-09-27:\n\n**Key Financial Metrics:**\n*   **Current Ratio:** 0.8933 - This indicates Apple may have difficulty meeting its short-term obligations with its current assets.\n*   **Quick Ratio:** 0.8588 - Similar to the current ratio, this suggests potential short-term liquidity issues.\n*   **Gross Margin:** 46.91% - A strong gross margin indicates efficient production and pricing strategies.\n*   **Operating Margin:** 31.97% - This reflects Apple's profitability from its core operations after accounting for operating expenses.\n*   **Net Profit Margin:** 26.92% - Shows the percentage of revenue that translates into profit after all expenses.\n*   **Return on Assets (ROA):** 31.18% - Indicates how effectively Apple is using its assets to generate earnings.\n*   **Return on Equity (ROE):** 151.91% - A very high ROE suggests Apple is generating substantial profits relative to shareholder equity.\n*   **Debt-to-Equity Ratio:** 1.338 - This indicates Apple has a significant amount of debt compared to its equity.\n*   **Price-to-Earnings Ratio (P/E):** 33.7099 - This suggests investors are willing to pay a premium for Apple's earnings, possibly due to growth expectations.\n*   **52-Week Performance:**\n    *   52 Week High: 277.32\n    *   52 Week Low: 169.2101\n    *   52 Week Price Return Daily: 18.8622%\n\n**Stock Performance:**\n*   The stock's price has fluctuated significantly over the past 52 weeks, with a high of 277.32 and a low of 169.2101.\n*   The 52 Week Price Return Daily is 18.8622%, indicating positive stock performance over the past year.\n*   The beta is 1.0898864, suggesting the stock is slightly more volatile than the market.\n\n**Additional Considerations:**\n*   The data includes various financial ratios and growth rates, offering a comprehensive view of Apple's financial health.\n*   It's important to compare these metrics to industry averages and historical data to gain a deeper understanding of Apple's performance.\n"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"send_message(\"I need Apple's daily candlestick from 2025-05-05\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:45:36.67684Z","iopub.execute_input":"2025-11-19T23:45:36.677125Z","iopub.status.idle":"2025-11-19T23:45:47.254163Z","shell.execute_reply.started":"2025-11-19T23:45:36.677104Z","shell.execute_reply":"2025-11-19T23:45:47.252527Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"On 2025-05-05, Apple's stock (AAPL) had the following daily candlestick data:\nOpen: 203.1, High: 204.1, Low: 198.21, Close: 198.89, Volume: 69018452, PreMarket: 205.0, AfterHours: 198.6."},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"send_message(\"Tell me who are Apple's peers?\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:45:47.255772Z","iopub.execute_input":"2025-11-19T23:45:47.256619Z","iopub.status.idle":"2025-11-19T23:45:55.850973Z","shell.execute_reply.started":"2025-11-19T23:45:47.256588Z","shell.execute_reply":"2025-11-19T23:45:55.850046Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Score similarity to query: 100%|██████████| 5/5 [00:00<00:00, 33.99it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  6.52it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  6.51it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 5/5 [00:00<00:00, 39.14it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.10it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 2/2 [00:00<00:00, 15.66it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.16it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 2/2 [00:00<00:00, 14.41it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.35it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nGenerate peers embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple's peers include: DELL, WDC, SNDK, HPE, PSTG, NTAP, HPQ, SMCI, IONQ, QUBT, and CMPO.\n"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"send_message(\"Tell me who are Amazon's peers?\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:45:55.851747Z","iopub.execute_input":"2025-11-19T23:45:55.851987Z","iopub.status.idle":"2025-11-19T23:46:03.737136Z","shell.execute_reply.started":"2025-11-19T23:45:55.851966Z","shell.execute_reply":"2025-11-19T23:46:03.736179Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.61it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 2/2 [00:00<00:00, 15.60it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  8.08it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 5/5 [00:00<00:00, 36.28it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 2/2 [00:00<00:00, 14.07it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 11/11 [00:00<00:00, 82.51it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.62it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.20it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nScore similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.31it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\nGenerate peers embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Amazon's peers include COUPANG INC (CPNG), EBAY INC (EBAY), DILLARDS INC-CL A (DDS), OLLIE'S BARGAIN OUTLET HOLDI (OLLI), ETSY INC (ETSY), MACY'S INC (M), PATTERN GROUP INC-CL A (PTRN), KOHLS CORP (KSS), SAVERS VALUE VILLAGE INC (SVV), and GROUPON INC (GRPN).\n"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"send_message(\"\"\"Locate Apple's stock ticker, then download recommendation trends of all Apple's peers by sub-industry, \nand then finally compare them.\"\"\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:46:03.738094Z","iopub.execute_input":"2025-11-19T23:46:03.738335Z","iopub.status.idle":"2025-11-19T23:46:42.009443Z","shell.execute_reply.started":"2025-11-19T23:46:03.738306Z","shell.execute_reply":"2025-11-19T23:46:42.008535Z"},"trusted":true},"outputs":[{"name":"stdout","text":"api.generation_fail.next_model: model is now  gemini-2.5-flash\n","output_type":"stream"},{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple's stock ticker is AAPL. Here's a comparison of the latest recommendation trends (as of November 1, 2025) for Apple's peers by sub-industry:\n\n*   **DELL TECHNOLOGIES -C (DELL):** 8 Strong Buy, 18 Buy, 6 Hold, 0 Sell, 0 Strong Sell\n*   **WESTERN DIGITAL CORP (WDC):** 6 Strong Buy, 19 Buy, 7 Hold, 0 Sell, 0 Strong Sell\n*   **SANDISK CORP (SNDK):** 7 Strong Buy, 10 Buy, 8 Hold, 0 Sell, 0 Strong Sell\n*   **HEWLETT PACKARD ENTERPRISE (HPE):** 6 Strong Buy, 8 Buy, 12 Hold, 0 Sell, 0 Strong Sell\n*   **PURE STORAGE INC - CLASS A (PSTG):** 6 Strong Buy, 13 Buy, 7 Hold, 1 Sell, 0 Strong Sell\n*   **NETAPP INC (NTAP):** 3 Strong Buy, 9 Buy, 15 Hold, 0 Sell, 0 Strong Sell\n*   **HP INC (HPQ):** 2 Strong Buy, 3 Buy, 16 Hold, 1 Sell, 0 Strong Sell\n*   **SUPER MICRO COMPUTER INC (SMCI):** 2 Strong Buy, 10 Buy, 11 Hold, 3 Sell, 0 Strong Sell\n*   **IONQ INC (IONQ):** 2 Strong Buy, 10 Buy, 3 Hold, 0 Sell, 0 Strong Sell\n*   **QUANTUM COMPUTING INC (QUBT):** 2 Strong Buy, 5 Buy, 2 Hold, 0 Sell, 0 Strong Sell\n*   **COMPOSECURE INC-A (CMPO):** 2 Strong Buy, 8 Buy, 1 Hold, 1 Sell, 0 Strong Sell"},"metadata":{}},{"name":"stdout","text":"api.generation_fail.next_model: model is now  gemini-2.5-flash-preview-09-2025\napi.generation_fail.next_model: model is now  gemini-2.5-flash-lite\napi.generation_fail.next_model: model is now  gemini-2.5-flash-lite-preview-09-2025\napi.generation_fail.next_model: model is now  gemini-2.5-pro\napi.generation_fail.next_model: model is now  gemini-2.0-flash\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I am sorry, I cannot fulfill this request. The available tools do not allow to download recommendation trends of all Apple's peers. I can only get a list of the peers.\n"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"send_message(\"\"\"Tell me Amazon's current share price and provide candlestick data for the past month. \nSort the data in descending order by date. Format the prices consistently as currency. \nRound prices to two decimal places. \nPresent the data with multiple columns for display in markdown. \nDiscuss and provide details about any patterns you notice in the price data. \nCorrelate recent patterns with news over the same date range.\"\"\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:46:42.0103Z","iopub.execute_input":"2025-11-19T23:46:42.010608Z","iopub.status.idle":"2025-11-19T23:47:03.413597Z","shell.execute_reply.started":"2025-11-19T23:46:42.010586Z","shell.execute_reply":"2025-11-19T23:47:03.412415Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Generate quote embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nUpsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here's the requested information about Amazon's stock (AMZN):\n\n**Current Share Price:**\n\n*   As of November 19, 2025, at 16:00:00 (local time), the current price is \\$222.69.\n*   The change from the previous close is \\$0.14, which represents a 0.0629% increase.\n*   Today's high is \\$223.735, and today's low is \\$218.52.\n*   The opening price for today was \\$223.735.\n*   The previous close price was \\$222.55.\n\n**Candlestick Data for the Past Month (October 19, 2025 - November 19, 2025):**\n\nI'm including the candlestick data in markdown format below.\n\n| Date        | Open    | High    | Low     | Close   | Volume     |\n| :---------- | :------ | :------ | :------ | :------ | :--------- |\n| 2025-11-19  | \\$228.10 | \\$230.20 | \\$222.42 | \\$222.55 | 60,608,442 |\n| 2025-11-18  | \\$233.25 | \\$234.60 | \\$229.19 | \\$232.87 | 59,918,908 |\n| 2025-11-17  | \\$235.06 | \\$238.73 | \\$232.89 | \\$234.69 | 38,956,619 |\n| 2025-11-14  | \\$243.05 | \\$243.75 | \\$236.50 | \\$237.58 | 41,401,638 |\n| 2025-11-13  | \\$250.24 | \\$250.37 | \\$243.75 | \\$244.20 | 31,190,063 |\n| 2025-11-12  | \\$248.41 | \\$249.75 | \\$247.23 | \\$249.10 | 23,563,960 |\n| 2025-11-11  | \\$248.34 | \\$251.75 | \\$245.59 | \\$248.40 | 36,476,474 |\n| 2025-11-07  | \\$242.90 | \\$244.90 | \\$238.49 | \\$244.41 | 46,374,294 |\n| 2025-11-06  | \\$249.16 | \\$250.38 | \\$242.17 | \\$243.04 | 46,004,201 |\n| 2025-11-05  | \\$249.03 | \\$251.00 | \\$246.16 | \\$250.20 | 40,610,602 |\n| 2025-11-04  | \\$250.38 | \\$257.01 | \\$248.66 | \\$249.32 | 51,546,311 |\n| 2025-11-03  | \\$255.36 | \\$258.60 | \\$252.90 | \\$254.00 | 95,997,714 |\n| 2025-10-31  | \\$250.10 | \\$250.50 | \\$243.98 | \\$244.22 | 166,340,683|\n| 2025-10-30  | \\$227.06 | \\$228.44 | \\$222.75 | \\$222.86 | 102,252,888|\n| 2025-10-29  | \\$231.67 | \\$232.82 | \\$227.76 | \\$230.30 | 52,035,936 |\n| 2025-10-28  | \\$228.22 | \\$231.49 | \\$226.21 | \\$229.25 | 47,099,924 |\n| 2025-10-27  | \\$227.66 | \\$228.40 | \\$225.54 | \\$226.97 | 38,266,995 |\n| 2025-10-24  | \\$221.97 | \\$225.40 | \\$221.90 | \\$224.21 | 38,684,853 |\n| 2025-10-23  | \\$219.00 | \\$221.30 | \\$218.18 | \\$221.09 | 31,539,699 |\n| 2025-10-22  | \\$219.30 | \\$220.01 | \\$216.52 | \\$217.95 | 44,308,538 |\n| 2025-10-21  | \\$218.43 | \\$223.32 | \\$217.99 | \\$222.03 | 50,494,565 |\n| 2025-10-20  | \\$213.88 | \\$216.69 | \\$213.59 | \\$216.48 | 38,882,819 |\n\n**Price Data Analysis and Recent News Correlation:**\n\n*   **Overall Trend:** The stock experienced a volatile month. It began around \\$213, peaked near \\$258 in early November, and then declined to approximately \\$222 by November 19, 2025.\n*   **Early November Peak:** The period between November 3rd and November 7th saw high prices and high trading volumes. News from this period suggests a strong market sentiment driven by AI optimism. For example, articles highlighted Amazon's AI cloud race, commitment to Nvidia chips, and potential for long-term wealth generation.\n*   **Mid-November Decline:** A significant drop occurred around November 14th and continued through November 19th. News from this period reveals concerns about AI investments, potential market corrections, and broader tech stock selloffs. For instance, articles discussed Amazon selling shares of AI-related companies, a projected dip in free cash flow due to AI investments, and a general shift to a bearish market sentiment.\n*   **Recent Stability:** The price appears to have stabilized somewhat in the last few days, hovering around the \\$222-\\$230 range. Recent news indicates a mix of positive and negative factors, including Amazon's involvement in AI infrastructure, analyst views on its valuation, and broader market trends affecting tech stocks.\n\n**In summary:** Amazon's stock price fluctuations in the past month appear closely tied to overall market sentiment regarding AI, broader economic factors, and company-specific news related to its investments and financial health.\n"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"send_message(\"What is Apple's ticker overview\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:47:03.414621Z","iopub.execute_input":"2025-11-19T23:47:03.414881Z","iopub.status.idle":"2025-11-19T23:47:07.995477Z","shell.execute_reply.started":"2025-11-19T23:47:03.414862Z","shell.execute_reply":"2025-11-19T23:47:07.994434Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.zero_error: model is now  gemini-2.0-flash-exp\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Apple Inc. (AAPL) is a US-based stock in the stocks market, primarily exchanged on XNAS. It is active and its currency is USD. The company's CIK is 0000320193, composite FIGI is BBG000B9XRY4, and share class FIGI is BBG001S5N8V8. As of November 19, 2025, its market cap is 3951787846320.0. Apple's phone number is (408) 996-1010, and its address is ONE APPLE PARK WAY, CUPERTINO, CA 95014.\n\nApple is among the largest companies in the world, with a broad portfolio of hardware and software products targeted at consumers and businesses. Apple's iPhone makes up a majority of the firm sales, and Apple's other products like Mac, iPad, and Watch are designed around the iPhone as the focal point of an expansive software ecosystem. Apple has progressively worked to add new applications, like streaming video, subscription bundles, and augmented reality. The firm designs its own software and semiconductors while working with subcontractors like Foxconn and TSMC to build its products and chips. Slightly less than half of Apple's sales come directly through its flagship stores, with a majority of sales coming indirectly through partnerships and distribution.\n\nThe SIC code is 3571, describing ELECTRONIC COMPUTERS. The ticker root is AAPL, and the homepage URL is https://www.apple.com. Apple has 166000 employees. It was listed on 1980-12-12. The logo URL is https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04_logo.svg and the icon URL is https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04_icon.png. The share class shares outstanding is 848612359, and the weighted shares outstanding is 14776353000, with a round lot of 100.\n"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"send_message(\"What is Google's stock ticker symbol?\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:47:07.996376Z","iopub.execute_input":"2025-11-19T23:47:07.996647Z","iopub.status.idle":"2025-11-19T23:47:16.85626Z","shell.execute_reply.started":"2025-11-19T23:47:07.996626Z","shell.execute_reply":"2025-11-19T23:47:16.855005Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Score wiki search by similarity to topic: 0it [00:00, ?it/s]\nGenerate wiki embeddings: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Google's stock ticker symbols on the NASDAQ are GOOGL and GOOG. It is also listed on the Frankfurt Stock Exchange under the ticker symbol GGQ1. These symbols refer to Alphabet Inc., Google's holding company.\n"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"send_message(\"What is MGM Studio's stock symbol?\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:47:16.857428Z","iopub.execute_input":"2025-11-19T23:47:16.857757Z","iopub.status.idle":"2025-11-19T23:47:23.704254Z","shell.execute_reply.started":"2025-11-19T23:47:16.857732Z","shell.execute_reply":"2025-11-19T23:47:23.703265Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Score wiki search by similarity to topic: 0it [00:00, ?it/s]\nGenerate wiki embeddings: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"I am sorry, I cannot fulfill this request. I do not have the answer to what MGM Studio's stock symbol is.\n"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"send_message(\"What is MGM Studio's owner company stock symbol?\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:47:23.705212Z","iopub.execute_input":"2025-11-19T23:47:23.705533Z","iopub.status.idle":"2025-11-19T23:48:30.445987Z","shell.execute_reply.started":"2025-11-19T23:47:23.705511Z","shell.execute_reply":"2025-11-19T23:48:30.44485Z"},"trusted":true},"outputs":[{"name":"stdout","text":"api.refill_rpm  2000\n","output_type":"stream"},{"name":"stderr","text":"Score similarity to query: 100%|██████████| 2/2 [00:00<00:00,  7.18it/s]\nGenerate api embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"MGM Studios is owned by Amazon. Amazon's stock symbol is AMZN.\n"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"send_message(\"What is Facebook's stock ticker symbol?\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:48:30.447235Z","iopub.execute_input":"2025-11-19T23:48:30.447751Z","iopub.status.idle":"2025-11-19T23:48:37.072153Z","shell.execute_reply.started":"2025-11-19T23:48:30.447724Z","shell.execute_reply":"2025-11-19T23:48:37.070991Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Score wiki search by similarity to topic: 0it [00:00, ?it/s]\nGenerate wiki embeddings: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"The stock ticker symbol for Facebook, now known as Meta Platforms, Inc., is META and it is traded on the NASDAQ stock exchange.\n"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"send_message(\"\"\"Compare Amazon's bullish versus bearish predictions from Oct 01 2025 until today. \nInclude a discussion of recommendation trends, and sentiment analysis of news from the same dates. \nDiscuss any patterns or correlations you find.\"\"\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:48:37.073187Z","iopub.execute_input":"2025-11-19T23:48:37.073493Z","iopub.status.idle":"2025-11-19T23:48:50.934716Z","shell.execute_reply.started":"2025-11-19T23:48:37.07347Z","shell.execute_reply":"2025-11-19T23:48:50.933417Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Between October 1, 2025, and November 19, 2025, here's an analysis of Amazon's (AMZN) stock based on recommendation trends and news sentiment:\n\n**Recommendation Trends:**\n\n*   The recommendation trends from October 1, 2025, to November 1, 2025, show a slight increase in \"buy\" ratings (from 52 to 54) and a decrease in \"hold\" ratings (from 3 to 2). The \"strongBuy,\" \"sell,\" and \"strongSell\" ratings remained constant. This indicates a generally positive or stable outlook from analysts.\n\n**Sentiment Analysis of News:**\n\n*   The news articles from October 1, 2025, to November 19, 2025, present a mixed sentiment regarding Amazon.\n*   Many articles discuss Amazon's investments in AI and cloud computing, particularly AWS, and its partnerships with companies like OpenAI and Anthropic. These are generally viewed positively.\n*   However, there are also concerns about increasing capital expenditures, potential market corrections, and competition in the AI and e-commerce spaces. Some articles note that Amazon is reducing its workforce in certain areas, which could be seen as a cost-cutting measure or a sign of restructuring.\n*   Several articles mention Amazon's involvement in the AI sector, with analysts suggesting that Amazon is well-positioned to benefit from the AI boom. However, some articles also caution about a potential AI bubble and the sustainability of current valuations.\n*   There are also articles discussing Amazon's performance in comparison to other tech companies, such as Microsoft, Google, and Nvidia, with varying sentiments depending on the specific context.\n\n**Patterns and Correlations:**\n\n*   The recommendation trends suggest a generally positive outlook from analysts, which aligns with the positive sentiment in some news articles regarding Amazon's AI and cloud computing investments.\n*   However, the mixed sentiment in news articles indicates that there are also concerns and uncertainties surrounding Amazon's stock, such as potential market corrections and competition.\n*   It's important to note that sentiment analysis is based on the tone and content of news articles, which may not always accurately reflect the actual performance or future prospects of a company.\n\nIn summary, the analysis suggests that Amazon's stock has a generally positive outlook, driven by its AI and cloud computing investments. However, there are also concerns and uncertainties that investors should consider.\n"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"send_message(\"\"\"Compare Google's bullish versus bearish predictions from Oct 01 2025 until today. \nInclude a discussion of recommendation trends, and sentiment analysis of news from the same dates. \nDiscuss any patterns or correlations you find.\"\"\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:48:50.935937Z","iopub.execute_input":"2025-11-19T23:48:50.936302Z","iopub.status.idle":"2025-11-19T23:50:07.369887Z","shell.execute_reply.started":"2025-11-19T23:48:50.936271Z","shell.execute_reply":"2025-11-19T23:50:07.36886Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Upsert chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.refill_rpm  2000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"From October 1, 2025, to November 19, 2025, here's a comparison of Google's bullish versus bearish predictions, including a discussion of recommendation trends and sentiment analysis of news:\n\n**Recommendation Trends:**\n\n*   The recommendation trends for Google (GOOGL) show a consistently positive outlook from analysts. In October 2025, there were 39 buy, 13 hold, 21 strong buy, and 0 sell recommendations. In November 2025, the recommendations remained largely the same with 41 buy, 12 hold, 21 strong buy, and 0 sell recommendations. This indicates a stable and bullish sentiment from analysts regarding Google's stock.\n\n**Sentiment Analysis of News:**\n\n*   The news articles from October 1, 2025, to November 19, 2025, present a mixed sentiment towards Google.\n*   Many articles highlight Google's strong position in AI, cloud computing, and search, with positive mentions of its Gemini AI model, cloud revenue growth, and strategic partnerships.\n*   Several articles indicate that Berkshire Hathaway made a massive investment in Google.\n*   Some articles suggest potential challenges, such as increased competition in the online travel agency market, concerns about AI spending efficiency, and potential regulatory pressures.\n*   There are also neutral sentiments, with Google being mentioned as part of the \"Magnificent Seven\" stocks or in the context of general AI infrastructure investments.\n\n**Patterns and Correlations:**\n\n*   **AI Focus:** A dominant theme is Google's involvement in AI, with many articles discussing its AI capabilities, investments, and partnerships. This aligns with the strong buy recommendations, suggesting that analysts view Google's AI initiatives positively.\n*   **Cloud Computing:** Google's cloud computing growth is frequently mentioned, indicating its importance as a revenue driver and growth area.\n*   **Mixed Sentiments:** While there's a general bullish sentiment, some articles point out potential risks and challenges, such as competition and regulatory concerns. This suggests that while Google is seen as a strong player, it's not without potential headwinds.\n*   **Market Influence:** News of Warren Buffett's Berkshire Hathaway investing in Google had a positive impact on the stock, indicating the influence of major investors on market sentiment.\n\nIn summary, the analysis reveals a generally bullish outlook for Google, driven by its strong position in AI and cloud computing. While there are some concerns and challenges, the overall sentiment is positive, supported by analyst recommendations and key investments.\n"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"api.push_default_model(\"gemini-2.5-flash\")\nsend_message(\"\"\"How is the outlook for Apple based on trends and news sentiment from July 01 2025 until today? \nPerform the same analysis on all peers by sub-industry. Then compare Apple result to it's peers.\"\"\")","metadata":{"execution":{"iopub.status.busy":"2025-11-20T00:05:29.675036Z","iopub.execute_input":"2025-11-20T00:05:29.675402Z","iopub.status.idle":"2025-11-20T00:11:48.646262Z","shell.execute_reply.started":"2025-11-20T00:05:29.675366Z","shell.execute_reply":"2025-11-20T00:11:48.645392Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.refill_rpm  1000\nlimited 4/min, waiting 5.281108140945435s\n","output_type":"stream"},{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"name":"stdout","text":"api.refill_rpm  1000\n","output_type":"stream"},{"name":"stderr","text":"Add chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\nAdd chunks embedding: 0it [00:00, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"#### Natural language response"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Based on news sentiment from July 01, 2025, until today (November 19, 2025), here's an outlook for Apple and its peers by sub-industry:\n\n**Apple (AAPL) Outlook:**\n\nApple's outlook is **mixed to cautiously positive**.\n\n*   **Positive aspects:** Strong iPhone 17 sales, robust growth in its services segment, strategic investments in US manufacturing and AI, and FDA approval for new Apple Watch features. Analysts generally maintain a positive long-term view due to Apple's strong brand loyalty, extensive ecosystem, and significant cash generation.\n*   **Negative aspects:** Concerns persist about Apple's pace of AI innovation compared to some competitors, ongoing regulatory pressures (antitrust lawsuits, GDPR-K violations), and potential impacts from tariffs. Several class-action lawsuits regarding alleged misrepresentation of AI features have also been noted. Warren Buffett's Berkshire Hathaway has been reducing its stake in Apple, citing high valuation and slower growth.\n*   **Neutral aspects:** The company's AI strategy is viewed with a mix of cautious patience and concerns about falling behind. Stock valuation is a recurring theme, with some analysts questioning if the current price is justified.\n\n**Peers by Sub-Industry Outlook:**\n\nApple's peers in the \"Computer Hardware\" sub-industry generally show a **stronger and more unequivocally positive outlook**, largely driven by the booming demand for AI infrastructure.\n\n*   **Dell Technologies (DELL):** **Strongly positive.** Dell is experiencing significant growth in AI servers (44% Q2 revenue increase, \\$20 billion projected sales) and is seen as undervalued. Strategic partnerships and increased dividend commitments further bolster its positive outlook, despite a recent downgrade by Morgan Stanley due to rising memory costs.\n*   **Western Digital Corp (WDC):** **Very positive.** WDC is a top S&P 500 performer (263% total return) with a 27% revenue increase and a 25% dividend hike. Strong demand for data storage from AI companies and expansion of its AI-focused labs are key drivers.\n*   **SanDisk Corp (SNDK):** **Highly positive.** SanDisk's stock has rocketed over 300% this year, benefiting from an improving NAND flash market and growing AI-related demand for storage. Cloud storage growth is also a significant positive.\n*   **Hewlett Packard Enterprise (HPE):** **Positive.** HPE successfully completed its \\$14 billion acquisition of Juniper Networks, which is expected to double its networking business and provide AI networking solutions. Strategic partnerships in 5G and AI infrastructure are also positive indicators, despite some short-term margin pressures from restructuring.\n*   **Pure Storage Inc (PSTG):** **Positive.** PSTG is up 46% year-to-date with 18% annual recurring revenue growth. Its subscription-based model and key clients like Meta and Nvidia contribute to a strong outlook driven by AI demand.\n*   **NetApp Inc (NTAP):** **Neutral to positive.** NetApp is aligning with security-focused innovations through a Broadcom partnership and is mentioned in sustainability discussions, indicating a stable and forward-looking approach.\n*   **HP Inc (HPQ):** **Cautiously positive.** HP has seen its fifth consecutive quarter of revenue growth and is focusing on AI-powered devices and sustainable practices. However, it faces margin pressures despite these strategic initiatives.\n*   **Super Micro Computer Inc (SMCI):** **Mixed to cautiously negative.** While SMCI has a strong AI order backlog (\\$13 billion+) and is shipping Nvidia-powered AI systems, it missed Q1 FY2026 revenue expectations, faces declining margins, negative cash flow, and is a heavily shorted stock.\n*   **IonQ Inc (IONQ):** **Highly speculative.** IonQ shows promising technological advancements in quantum computing with strong revenue growth (222% year-over-year) and strategic acquisitions. However, it carries significant risks due to high valuation (147-303x sales), substantial operating losses, and the unproven commercial viability of quantum computing. Amazon recently sold its entire stake.\n*   **Quantum Computing Inc (QUBT):** **Highly speculative.** QUBT reported strong Q3 revenue growth (280% year-over-year) and secured its first commercial quantum cybersecurity sale. However, it has minimal sales, high operating expenses, an inflated stock price, and significant cash burn, making it a very high-risk investment.\n*   **CompoSecure Inc-A (CMPO):** **Neutral to cautiously positive.** CMPO is planning a business combination with Husky Technologies and shows ongoing management fee generation. Its outlook is stable, but its parent company recently reported a net loss.\n\n**Comparison of Apple to its Peers:**\n\n*   **AI Leadership:** Many of Apple's peers, particularly Nvidia, Microsoft, Google, Amazon, AMD, Broadcom, and TSMC (as mentioned in the news for their AI contributions), are highlighted as leaders or aggressive investors in AI infrastructure and solutions. Apple, while investing in AI, is often perceived as lagging in this critical area.\n*   **Financial Performance & Valuation:** While Apple demonstrates strong financial health and consistent cash flow, some peers like Dell, Western Digital, and SanDisk are showing more explosive growth and stock appreciation directly tied to the AI boom. Apple's valuation is a point of caution for some investors, including Warren Buffett, who has been reducing his holdings.\n*   **Market Focus:** Apple's core business remains consumer electronics and services. Its peers are more diversified in their direct contributions to the underlying AI infrastructure (e.g., servers, storage, chips), which is currently experiencing immense demand.\n*   **Risk Profile:** Apple faces regulatory and tariff-related risks. Quantum computing peers (IonQ, QUBT) represent extremely high-risk, high-reward investments due to their early-stage technology and weak financial fundamentals.\n\n**Conclusion:**\n\nWhile Apple remains a robust and profitable company with a strong brand, its outlook is tempered by concerns about its AI strategy and regulatory challenges. In contrast, many of its peers, especially those deeply embedded in the AI infrastructure supply chain, are experiencing more rapid growth and a more unequivocally positive sentiment, directly benefiting from the massive investments in artificial intelligence. Investors seeking direct exposure to the AI revolution might find more aggressive growth opportunities among Apple's peers in the \"Computer Hardware\" sub-industry."},"metadata":{}},{"name":"stdout","text":"api.refill_rpm  1000\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"send_message(\"\"\"What does the recent news say about Apple and the impact of tariffs? From 2025-09-01 up to today. \nAlso locate candlestick data for the same dates. \nDiscuss in detail any correlations in patterns between the candlestick and news data. Ignore duplicate news entry.\"\"\")","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:55:30.600237Z","iopub.status.idle":"2025-11-19T23:55:30.600859Z","shell.execute_reply.started":"2025-11-19T23:55:30.600634Z","shell.execute_reply":"2025-11-19T23:55:30.600653Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# StockChat: Agents Edition","metadata":{}},{"cell_type":"markdown","source":"## Run ADK Web UI","metadata":{}},{"cell_type":"code","source":"# Get the proxied URL in the Kaggle Notebooks environment.\ndef get_adk_proxy_url():\n    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n    ADK_PORT = \"8000\"\n\n    servers = list(list_running_servers())\n    if not servers:\n        raise Exception(\"No running Jupyter servers found.\")\n\n    baseURL = servers[0]['base_url']\n\n    try:\n        path_parts = baseURL.split('/')\n        kernel = path_parts[2]\n        token = path_parts[3]\n    except IndexError:\n        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n\n    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n    url = f\"{PROXY_HOST}{url_prefix}\"\n\n    styled_html = f\"\"\"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            <strong>⚠️ IMPORTANT:</strong> The ADK web UI is <strong>not started yet</strong>. You must wait for that to appear below.\n        </div>\n        <a href='{url}' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Open ADK Web UI (after started appears below) ↗\n        </a>\n    </div>\n    \"\"\"\n\n    display(HTML(styled_html))\n\n    return url_prefix","metadata":{"execution":{"iopub.status.busy":"2025-11-19T23:55:30.602507Z","iopub.status.idle":"2025-11-19T23:55:30.602887Z","shell.execute_reply.started":"2025-11-19T23:55:30.602726Z","shell.execute_reply":"2025-11-19T23:55:30.602742Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Launch the ADK Web UI.\nif not os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"):\n    !adk web\nelse:\n    if not os.path.isdir(\"sc2/\"):\n        !git init -b main\n        !git remote add origin https://github.com/lol-dungeonmaster/kaggle-agents-2025.git\n        !git config core.sparseCheckout true\n        !echo \"sc2/\" >> .git/info/sparse-checkout\n        !git pull origin main\n        env_key = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n        !echo \"GOOGLE_API_KEY=$env_key\" >> sc2/.env # from .venv on local runs\n    url_prefix = get_adk_proxy_url()\n    !adk web --url_prefix {url_prefix}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T23:55:30.604374Z","iopub.status.idle":"2025-11-19T23:55:30.604814Z","shell.execute_reply.started":"2025-11-19T23:55:30.604562Z","shell.execute_reply":"2025-11-19T23:55:30.60458Z"}},"outputs":[],"execution_count":null}]}