{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/oswind/stockchat-agents-edition?scriptVersionId=281526760\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-24T21:22:17.529394Z",
     "iopub.status.busy": "2025-11-24T21:22:17.528426Z",
     "iopub.status.idle": "2025-11-24T21:25:16.092285Z",
     "shell.execute_reply": "2025-11-24T21:25:16.091267Z",
     "shell.execute_reply.started": "2025-11-24T21:22:17.529355Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.3/257.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.3/108.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.6/456.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.1/456.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.9/205.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.4/270.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Setup the notebook based on running environment.\n",
    "import os\n",
    "# Optional: Enable telemetry in browser_use and chromadb.\n",
    "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"false\"\n",
    "# Check for kaggle environment.\n",
    "if os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
    "    # Kaggle Run: update the system.\n",
    "    !pip uninstall -qqy google-ai-generativelanguage pydrive2 tensorflow tensorflow-decision-forests cryptography pyOpenSSL langchain langchain-core nltk ray click google-generativeai google-cloud-translate datasets cesium bigframes plotnine mlxtend fastai spacy thinc google-colab gcsfs jupyter-kernel-gateway\n",
    "    !pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n",
    "    !pip install -qU langchain-community langchain-text-splitters wikipedia lmnr[all] google-adk google-cloud-translate\n",
    "    from kaggle_secrets import UserSecretsClient # type: ignore\n",
    "    from jupyter_server.serverapp import list_running_servers # type: ignore\n",
    "else:\n",
    "    # Mock the kaggle secrets client.\n",
    "    class UserSecretsClient:\n",
    "        @classmethod\n",
    "        def set_secret(cls, id: str, value: str):\n",
    "            os.environ[id] = value\n",
    "        @classmethod\n",
    "        def get_secret(cls, id: str):\n",
    "            try:\n",
    "                return os.environ[id]\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError: authentication token for {id} is undefined\")\n",
    "    # Local Run: update the venv.\n",
    "    %pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n",
    "    %pip install -qU langchain-community langchain-text-splitters wikipedia pandas google-api-core \"lmnr[all]\" browser-use ollama google-adk\n",
    "    from browser_use import Agent as BrowserAgent\n",
    "\n",
    "import ast, chromadb, json, logging, pandas, platform, pytz, re, requests, threading, time, warnings, wikipedia\n",
    "from bs4 import Tag\n",
    "from chromadb import Documents, Embeddings\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from enum import Enum\n",
    "from google.adk.apps.app import App\n",
    "from google.adk.sessions import InMemorySessionService, BaseSessionService as SessionService\n",
    "from google.adk.runners import Runner, Event\n",
    "from google import genai\n",
    "from google.api_core import retry, exceptions\n",
    "from google.genai.models import Models\n",
    "from google.genai import types, errors\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_text_splitters.html import HTMLSemanticPreservingSplitter\n",
    "from langchain_text_splitters.json import RecursiveJsonSplitter\n",
    "from lmnr import Laminar\n",
    "from math import inf\n",
    "from pydantic import BaseModel, field_validator\n",
    "from threading import Timer\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Callable, NewType, NamedTuple\n",
    "from wikipedia.exceptions import DisambiguationError, PageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:16.095114Z",
     "iopub.status.busy": "2025-11-24T21:25:16.094175Z",
     "iopub.status.idle": "2025-11-24T21:25:16.218247Z",
     "shell.execute_reply": "2025-11-24T21:25:16.217212Z",
     "shell.execute_reply.started": "2025-11-24T21:25:16.095081Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Laminar.initialize()\n"
     ]
    }
   ],
   "source": [
    "# Prepare the Gemini api for use.\n",
    "# Setup a retry helper for generation not run through the below api-helper.\n",
    "is_retriable = lambda e: (isinstance(e, errors.APIError) and e.code in {429, 503, 500})\n",
    "Models.generate_content = retry.Retry(predicate=is_retriable)(Models.generate_content)\n",
    "Models.embed_content = retry.Retry(predicate=is_retriable)(Models.embed_content)\n",
    "\n",
    "# Activate Laminar auto-instrumentation.\n",
    "try:\n",
    "    Laminar.initialize(project_api_key=UserSecretsClient().get_secret(\"LMNR_PROJECT_API_KEY\"))\n",
    "except:\n",
    "    print(\"Skipping Laminar.initialize()\")\n",
    "\n",
    "class GeminiModel:\n",
    "    def __init__(self, rpm: list, tpm: list, rpd: list):\n",
    "        self.rpm = rpm # requests per minute\n",
    "        self.tpm = tpm # tokens per minute in millions\n",
    "        self.rpd = rpd # requests per day\n",
    "        self.err = [0,0] # validation, api_related\n",
    "\n",
    "# A python api-helper with model fail-over/chaining/retry support.\n",
    "GeminiEmbedFunction = NewType(\"GeminiEmbedFunction\", None) # forward-decl\n",
    "class Api:\n",
    "    gen_limit_in = 1048576\n",
    "    emb_limit_in = 2048\n",
    "    gen_model = {\n",
    "        \"gemini-2.5-flash\": GeminiModel([10,1000,2000,10000],[.25,1,3,8],[250,10000,100000,inf]), # stable: 10 RPM/250K TPM/250 RPD\n",
    "        \"gemini-2.5-flash-preview-09-2025\": GeminiModel([10,1000,2000,10000],[.25,1,3,8],[250,10000,100000,inf]), # exp: 10 RPM/250K TPM/250 RPD\n",
    "        \"gemini-2.0-flash-exp\": GeminiModel([10,10,10,10],[.25,.25,.25,.25],[200,500,500,500]), # latest w/thinking: 10 RPM/250K TPM/200 RPD\n",
    "        \"gemini-2.0-flash\": GeminiModel([15,2000,10000,30000],[1,4,10,30],[200,inf,inf,inf]), # stable wo/thinking: 15 RPM/1M TPM/200 RPD\n",
    "        \"gemini-2.5-flash-lite\": GeminiModel([15,4000,10000,30000],[.25,4,10,30],[1000,inf,inf,inf]), # stable: 15 RPM/250K TPM/1K RPD\n",
    "        \"gemini-2.5-flash-lite-preview-09-2025\": GeminiModel([15,4000,10000,30000],[.25,4,10,30],[1000,inf,inf,inf]), # exp: 15 RPM/250K TPM/1K RPD\n",
    "        \"gemini-2.5-pro\": GeminiModel([5,150,1000,2000],[.125,2,5,8],[100,10000,50000,inf]), # stable: 5 RPM/250K TPM/100 RPD\n",
    "    }\n",
    "    gen_local = [\"gemma3n:e4b\",\"gemma3:12b-it-qat\"]\n",
    "    default_local = 0\n",
    "    default_model = []\n",
    "    embed_model = \"gemini-embedding-001\", GeminiModel([100,3000,5000,10000],[.03,1,5,10],[1000,inf,inf,inf]) # stable: 100 RPM/30K TPM/1000 RPD/100 per batch\n",
    "    embed_local = False\n",
    "    error_total = 0\n",
    "    min_rpm = 3\n",
    "    min_tpm = 40000\n",
    "    dt_between = 2.0\n",
    "    errored = False\n",
    "    running = False\n",
    "    dt_err = 45.0\n",
    "    dt_rpm = 60.0\n",
    "\n",
    "    @classmethod\n",
    "    def get(cls, url: str):\n",
    "        # Create a header matching the OS' tcp-stack fingerprint.\n",
    "        system_ua = None\n",
    "        match platform.system():\n",
    "            case 'Linux':\n",
    "                system_ua = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'\n",
    "            case 'Darwin':\n",
    "                system_ua = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 15_7_2) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/26.0 Safari/605.1.15'\n",
    "            case 'Windows':\n",
    "                system_ua = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'\n",
    "        try:\n",
    "            request = requests.get(url, headers={'User-Agent': system_ua})\n",
    "            if request.status_code != requests.codes.ok:\n",
    "                print(f\"Api.get() returned status {request.status_code}\")\n",
    "            return request.text\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    class Limit(Enum):\n",
    "        FREE = 0\n",
    "        TIER_1 = 1\n",
    "        TIER_2 = 2\n",
    "        TIER_3 = 3\n",
    "    \n",
    "    class Model(Enum):\n",
    "        GEN = 1\n",
    "        EMB = 2\n",
    "        LOC = 3\n",
    "\n",
    "    class Const(Enum):\n",
    "        STOP = \"I don't know.\"\n",
    "        METRIC_BATCH = 20\n",
    "        SERIES_BATCH = 40\n",
    "        EMBED_BATCH = 100\n",
    "        CHUNK_MAX = 1500\n",
    "\n",
    "        @classmethod\n",
    "        def Stop(cls):\n",
    "            return cls.STOP.value\n",
    "\n",
    "        @classmethod\n",
    "        def MetricBatch(cls):\n",
    "            return cls.METRIC_BATCH.value\n",
    "\n",
    "        @classmethod\n",
    "        def SeriesBatch(cls):\n",
    "            return cls.SERIES_BATCH.value\n",
    "\n",
    "        @classmethod\n",
    "        def EmbedBatch(cls):\n",
    "            return cls.EMBED_BATCH.value\n",
    "\n",
    "        @classmethod\n",
    "        def ChunkMax(cls):\n",
    "            return cls.CHUNK_MAX.value\n",
    "    \n",
    "    class Env(NamedTuple): # Make init args immutable.\n",
    "        CLIENT: genai.Client\n",
    "        API_LIMIT: int\n",
    "        GEN_DEFAULT: str\n",
    "\n",
    "    def __init__(self, with_limit: Limit | int, default_model: str):\n",
    "        if default_model in self.gen_model.keys():\n",
    "            self.write_lock = threading.RLock()\n",
    "            try:\n",
    "                if isinstance(with_limit, int) and with_limit in [id.value for id in Api.Limit]:\n",
    "                    limit = with_limit\n",
    "                else:\n",
    "                    limit = with_limit.value\n",
    "            except Exception as e:\n",
    "                print(f\"Api.__init__: {with_limit} is not a valid limit\")\n",
    "            else:\n",
    "                self.args = Api.Env(\n",
    "                    genai.Client(api_key=UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")),\n",
    "                    limit, default_model)\n",
    "            self.m_id = list(self.gen_model.keys()).index(default_model)\n",
    "            self.default_model.append(default_model)\n",
    "            self.update_quota()\n",
    "            self.s_embed = GeminiEmbedFunction(self.args.CLIENT, semantic_mode = True) # type: ignore\n",
    "            logging.getLogger(\"google_genai\").setLevel(logging.WARNING) # suppress info on generate\n",
    "        else:\n",
    "            print(f\"Api.__init__: {default_model} not found in gen_model.keys()\")\n",
    "        \n",
    "\n",
    "    def __call__(self, model: Model) -> str:\n",
    "        if model == self.Model.GEN:\n",
    "            return \"models/\" + list(self.gen_model.keys())[self.m_id]\n",
    "        elif model == self.Model.LOC:\n",
    "            return self.gen_local[self.default_local]\n",
    "        else:\n",
    "            return \"models/\" + self.embed_model[0] if not self.embed_local else \"embeddinggemma:latest\"\n",
    "\n",
    "    def push_default_model(self, model_id: str):\n",
    "        if model_id in self.gen_model.keys():\n",
    "            self.write_lock.acquire()\n",
    "            self.stop_running()\n",
    "            self.default_model.append(model_id)\n",
    "            self.m_id = list(self.gen_model.keys()).index(model_id)\n",
    "            self.write_lock.release()\n",
    "        else:\n",
    "            print(f\"{model_id} not found in gen_model.keys()\")\n",
    "\n",
    "    def pop_default_model(self):\n",
    "        if len(self.default_model) > 1:\n",
    "            self.write_lock.acquire()\n",
    "            self.stop_running()\n",
    "            self.default_model.pop(-1)\n",
    "            self.m_id = list(self.gen_model.keys()).index(self.default_model[-1])\n",
    "            self.write_lock.release()\n",
    "\n",
    "    def retriable(self, retry_fn: Callable, *args, **kwargs):\n",
    "        tries = 3*len(self.gen_model.keys())\n",
    "        for attempt in range(tries):\n",
    "            try:\n",
    "                self.write_lock.acquire()\n",
    "                token_use = self.token_count(kwargs[\"contents\"])\n",
    "                if self.gen_rpm > self.min_rpm and token_use <= self.token_quota and self.token_quota > self.min_tpm:\n",
    "                    self.token_quota -= token_use\n",
    "                    self.gen_rpm -= 1\n",
    "                else:\n",
    "                    self.on_error(kwargs)\n",
    "                if not self.running and not self.errored:\n",
    "                    self.rpm_timer = Timer(self.dt_rpm, self.refill_rpm)\n",
    "                    self.rpm_timer.start()\n",
    "                    self.running = True\n",
    "                return retry_fn(*args, **kwargs)\n",
    "            except (errors.APIError, exceptions.RetryError) as api_error:\n",
    "                if isinstance(api_error, errors.APIError):\n",
    "                    is_retry = api_error.code in {429, 503, 500, 400} # code 400 when TPM exceeded\n",
    "                    if api_error.code == 400:\n",
    "                        print(f\"retriable.api_error: token limit exceeded ({token_use})\")\n",
    "                    else:\n",
    "                        print(f\"retriable.api_error({api_error.code}): {str(api_error)}\")\n",
    "                    if not is_retry or attempt == tries:\n",
    "                        raise api_error\n",
    "                self.on_error(kwargs)\n",
    "            except Exception as e:\n",
    "                print(f\"retriable.exception: {str(e)}\")\n",
    "                self.on_error(kwargs)\n",
    "            finally:\n",
    "                self.write_lock.release()\n",
    "\n",
    "    def on_error(self, kwargs):\n",
    "        self.generation_fail()\n",
    "        kwargs[\"model\"] = self(Api.Model.GEN)\n",
    "        time.sleep(self.dt_between)\n",
    "\n",
    "    def stop_running(self):\n",
    "        if self.running:\n",
    "            self.rpm_timer.cancel()\n",
    "            self.running = False\n",
    "\n",
    "    def validation_fail(self):\n",
    "        list(self.gen_model.values())[self.m_id].err[0] += 1\n",
    "        self.error_total += 1\n",
    "\n",
    "    def generation_fail(self):\n",
    "        self.stop_running()\n",
    "        self.save_error()\n",
    "        self.next_model()\n",
    "        print(\"Api.generation_fail.next_model: model is now\", list(self.gen_model.keys())[self.m_id])\n",
    "        if not self.errored:\n",
    "            self.error_timer = Timer(self.dt_err, self.zero_error)\n",
    "            self.error_timer.start()\n",
    "            self.errored = True\n",
    "\n",
    "    def save_error(self):\n",
    "        list(self.gen_model.values())[self.m_id].err[1] += 1\n",
    "        self.error_total += 1\n",
    "\n",
    "    def next_model(self):\n",
    "        self.m_id = (self.m_id+1)%len(self.gen_model.keys())\n",
    "        self.update_quota()\n",
    "\n",
    "    def refill_rpm(self):\n",
    "        self.running = False\n",
    "        self.update_quota()\n",
    "        print(\"Api.refill_rpm\", self.gen_rpm)\n",
    "\n",
    "    def zero_error(self):\n",
    "        self.errored = False\n",
    "        self.m_id = list(self.gen_model.keys()).index(self.default_model[-1])\n",
    "        self.update_quota()\n",
    "        print(\"Api.zero_error: model is now\", list(self.gen_model.keys())[self.m_id])\n",
    "\n",
    "    def update_quota(self):\n",
    "        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.args.API_LIMIT]\n",
    "        self.token_quota = list(self.gen_model.values())[self.m_id].tpm[self.args.API_LIMIT]*1_000_000\n",
    "\n",
    "    def token_count(self, expr: str | list):\n",
    "        count = self.args.CLIENT.models.count_tokens(\n",
    "            model=self(Api.Model.GEN),\n",
    "            contents=json.dumps(expr) if isinstance(expr, str) else str(expr))\n",
    "        return count.total_tokens\n",
    "\n",
    "    def errors(self):\n",
    "        errors = {\"total\": self.error_total, \"by_model\": {}}\n",
    "        for m_code, m in self.gen_model.items():\n",
    "            errors[\"by_model\"].update({\n",
    "                m_code: {\n",
    "                    \"api_related\": m.err[1],\n",
    "                    \"validation\": m.err[0]\n",
    "                }})\n",
    "        return errors\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def similarity(self, content: list):\n",
    "        return self.s_embed.sts(content) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:16.219527Z",
     "iopub.status.busy": "2025-11-24T21:25:16.219235Z",
     "iopub.status.idle": "2025-11-24T21:25:16.229378Z",
     "shell.execute_reply": "2025-11-24T21:25:16.228469Z",
     "shell.execute_reply.started": "2025-11-24T21:25:16.219502Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the embedding function.\n",
    "api = NewType(\"api\", Api) # type: ignore (forward-decl)\n",
    "class GeminiEmbedFunction:\n",
    "    document_mode = True  # Generate embeddings for documents (T,F), or queries (F,F).\n",
    "    semantic_mode = False # Semantic text similarity mode is exclusive (F,T).\n",
    "    \n",
    "    def __init__(self, genai_client, semantic_mode: bool = False):\n",
    "        self.client = genai_client\n",
    "        if semantic_mode:\n",
    "            self.document_mode = False\n",
    "            self.semantic_mode = True\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def __embed__(self, input: Documents) -> Embeddings:\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\"\n",
    "        elif not self.document_mode and not self.semantic_mode:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "        elif not self.document_mode and self.semantic_mode:\n",
    "            embedding_task = \"semantic_similarity\"\n",
    "        partial = self.client.models.embed_content(\n",
    "            model=api(Api.Model.EMB),\n",
    "            contents=input,\n",
    "            config=types.EmbedContentConfig(task_type=embedding_task)) # type: ignore\n",
    "        return [e.values for e in partial.embeddings]\n",
    "    \n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        try:\n",
    "            response = []\n",
    "            for i in range(0, len(input), Api.Const.EmbedBatch()):  # Gemini max-batch-size is 100.\n",
    "                response += self.__embed__(input[i:i + Api.Const.EmbedBatch()])\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"caught exception of type {type(e)}\\n{e}\")\n",
    "            raise e\n",
    "\n",
    "    def sts(self, content: list) -> float:\n",
    "        df = pandas.DataFrame(self(content), index=content)\n",
    "        score = df @ df.T\n",
    "        return score.iloc[0].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Gemini API Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:16.231567Z",
     "iopub.status.busy": "2025-11-24T21:25:16.231237Z",
     "iopub.status.idle": "2025-11-24T21:25:16.677524Z",
     "shell.execute_reply": "2025-11-24T21:25:16.676184Z",
     "shell.execute_reply.started": "2025-11-24T21:25:16.231542Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the api-helper with usage limit => FREE.\n",
    "# Optional: Set limit here to one of [FREE,TIER_1,TIER_2,TIER_3]\n",
    "api = Api(with_limit=Api.Limit.FREE, default_model=\"gemini-2.5-flash\")\n",
    "# Export api environment for agent.\n",
    "os.environ[\"API_LIMIT\"]=str(api.args.API_LIMIT)\n",
    "os.environ[\"GEN_DEFAULT\"]=api.args.GEN_DEFAULT\n",
    "# Cleanup old vector_db instances.\n",
    "!rm -rf vector_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini Baseline Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:16.679105Z",
     "iopub.status.busy": "2025-11-24T21:25:16.678795Z",
     "iopub.status.idle": "2025-11-24T21:25:23.317384Z",
     "shell.execute_reply": "2025-11-24T21:25:23.316505Z",
     "shell.execute_reply.started": "2025-11-24T21:25:16.679075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The stock market is a global network of exchanges and over-the-counter (OTC) marketplaces where investors buy and sell shares of publicly traded companies. These shares, also known as equities, represent partial ownership in a company.\n",
       "\n",
       "**How the Stock Market Works**\n",
       "The stock market operates through a system of supply and demand, which determines the price of each security. When demand from buyers exceeds the supply from sellers, the price typically rises, and vice versa.\n",
       "\n",
       "The process generally involves two main markets:\n",
       "*   **Primary Market:** This is where companies initially issue new stocks to the public through a process called an Initial Public Offering (IPO) to raise capital for growth and expansion.\n",
       "*   **Secondary Market:** After the IPO, these shares are traded among investors on stock exchanges like the New York Stock Exchange (NYSE) or Nasdaq. The company is no longer directly involved in these subsequent transactions.\n",
       "\n",
       "**Purpose of the Stock Market**\n",
       "The stock market serves two crucial functions:\n",
       "1.  **Capital Raising for Companies:** It allows businesses to raise money from the public by selling shares of ownership, which they can then use to fund and expand their operations.\n",
       "2.  **Wealth Creation for Investors:** It provides individuals and institutions with an opportunity to invest in companies and potentially grow their wealth through capital gains (when stock prices increase) or dividends (a share of the company's profits).\n",
       "\n",
       "**Key Components and Participants**\n",
       "*   **Stock Exchanges:** These are organized platforms, often electronic, where stocks and other securities are bought and sold. They provide the infrastructure for trades, maintain orderly markets, and ensure compliance with regulations.\n",
       "*   **Brokers:** These intermediaries execute buy and sell orders on behalf of investors.\n",
       "*   **Investors:** Participants range from individual retail investors to large institutional investors like pension funds, mutual funds, insurance companies, and hedge funds.\n",
       "\n",
       "**Types of Investments**\n",
       "While \"stock market\" often refers to stocks, it encompasses various investment types:\n",
       "*   **Common Stock:** Represents partial ownership and typically grants voting rights on corporate decisions and the potential for dividends.\n",
       "*   **Preferred Stock:** Also represents ownership but usually doesn't come with voting rights. Preferred shareholders have a higher claim on dividends and assets in case of liquidation compared to common stockholders.\n",
       "*   **Exchange-Traded Funds (ETFs):** These trade like stocks but allow investors to own a basket of different stocks, commodities, or other assets.\n",
       "*   **Mutual Funds:** Professionally managed portfolios that pool money from multiple investors to invest in a diversified collection of securities.\n",
       "*   **Bonds:** While primarily debt instruments, they are often discussed alongside stocks as investment options. Investing in bonds means lending money to a government or corporation for regular interest payments.\n",
       "\n",
       "**Factors Influencing Stock Prices**\n",
       "Stock market movements are influenced by a variety of factors, including macroeconomic indicators (like interest rates, inflation, and GDP growth), company-specific news (such as earnings reports and product launches), political events, and geopolitical tensions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is an accurate retelling of events. \n",
    "config_with_search = types.GenerateContentConfig(\n",
    "    tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "chat = api.args.CLIENT.chats.create(\n",
    "    model=api(Api.Model.GEN),\n",
    "    config=config_with_search,\n",
    "    history=[]) # Ignoring the part about dark elves, and tengwar.\n",
    "\n",
    "response = chat.send_message('Do you know anything about the stock market?')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:23.318621Z",
     "iopub.status.busy": "2025-11-24T21:25:23.318338Z",
     "iopub.status.idle": "2025-11-24T21:25:29.427679Z",
     "shell.execute_reply": "2025-11-24T21:25:29.426468Z",
     "shell.execute_reply.started": "2025-11-24T21:25:23.318593Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Amazon.com Inc. (NASDAQ: AMZN) is a multinational technology company known for its extensive operations in e-commerce, cloud computing (Amazon Web Services - AWS), digital streaming, and artificial intelligence. Founded by Jeff Bezos in 1994 as an online bookstore, it has grown into one of the world's largest internet retail platforms and a significant player in the tech industry.\n",
       "\n",
       "As of November 24, 2025, Amazon's stock (AMZN) is trading around $221.44. The stock has fluctuated between $221.60 and $226.79 today, and its 52-week range has been between $161.38 and $258.60. The company's market capitalization stands at approximately $2.36 trillion, making it one of the most valuable companies globally.\n",
       "\n",
       "Amazon's business is diversified across several key segments:\n",
       "*   **North America and International:** These segments encompass its vast online retail operations, offering a wide range of products and services.\n",
       "*   **Amazon Web Services (AWS):** This cloud computing platform provides on-demand computing resources and is a significant driver of Amazon's profitability, often generating the majority of its operating income.\n",
       "*   **Other ventures:** Amazon also has a strong presence in digital streaming, online advertising, and artificial intelligence. The company recently announced plans to invest up to $50 billion to expand its AI and supercomputing infrastructure for U.S. government clients.\n",
       "\n",
       "In terms of recent performance, AMZN stock has seen a 1.73% rise over the last month and a 13.50% increase over the past year. The company's most recent stock split was a 20-for-1 split in June 2022, which aimed to make shares more accessible to retail investors.\n",
       "\n",
       "Analyst sentiment for AMZN stock is generally positive, with a consensus rating of \"Strong Buy\" from numerous analysts. The average analyst price target for Amazon stock ranges from approximately $280.47 to $297.64, suggesting a potential increase from its current price over the next year. The highest analyst price target is $340.00, while the lowest is $195.00."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message('I have an interest in AMZN stock')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:29.428993Z",
     "iopub.status.busy": "2025-11-24T21:25:29.428726Z",
     "iopub.status.idle": "2025-11-24T21:25:37.01998Z",
     "shell.execute_reply": "2025-11-24T21:25:37.019115Z",
     "shell.execute_reply.started": "2025-11-24T21:25:29.428967Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Amazon.com Inc. (NASDAQ: AMZN) is currently trading around **$225.01** as of November 24, 2025, reflecting a 2.32% increase in the past 24 hours.\n",
       "\n",
       "**Short-Term Trends:**\n",
       "In the short term, AMZN has experienced some fluctuations. While it has seen a 1.73% rise over the last month, the stock has fallen by -3.19% compared to the previous week. The stock's price has been moving between $222.27 and $227.27 today. From a technical perspective, Amazon is in a short-term downtrend on the daily chart, although it remains within a broader long-term uptrend. The price has been making lower highs and lower lows over the last two weeks, with momentum indicators showing some weakening. However, a buy signal was issued from a pivot bottom point on November 20, 2025, and the stock has risen 1.63% since then, with rising volume, which is considered a positive technical signal. The stock is currently below its 5, 20, and 50-day exponential moving averages, indicating a strongly bearish short-term trend, but it is also experiencing buying pressure.\n",
       "\n",
       "**Bullish Predictions:**\n",
       "*   **Analyst Consensus:** The overall sentiment from analysts is strongly bullish. Amazon has an average brokerage recommendation of \"Strong Buy\" from 58 brokerage firms, with 50 strong buy ratings and six buy ratings.\n",
       "*   **Price Targets:** The average analyst price target for AMZN ranges from approximately $280.47 to $297.64, suggesting a potential upside of 23.82% to 34.06% from its current price over the next year. The highest price target among analysts is $360.00.\n",
       "*   **Growth Drivers:** Bullish arguments are supported by the continued growth of Amazon Web Services (AWS), which remains a significant profit driver for the company. Amazon's dominance in e-commerce and its expanding advertising business also contribute to a positive outlook. The company's recent announcement to invest up to $50 billion to expand its AI and supercomputing infrastructure for U.S. government clients is also seen as a positive development.\n",
       "*   **Long-Term Potential:** Historically, AMZN has shown strong long-term performance, rising by an average of 55.1% over a 52-week period based on the past 28 years.\n",
       "\n",
       "**Bearish Predictions:**\n",
       "*   **Technical Indicators:** Some technical indicators suggest caution. The stock holds sell signals from both short and long-term Moving Averages, and there is a general sell signal from the relation where the long-term average is above the short-term average. Additionally, there is a sell signal from the 3-month Moving Average Convergence Divergence (MACD).\n",
       "*   **Valuation Concerns:** The price-to-earnings ratio of 33.10 may suggest that the stock is overvalued compared to its earnings, which could deter value-focused investors.\n",
       "*   **Competition and Macro Factors:** While AWS is strong, its growth has been slowing, leading to concerns about losing market share to competitors like Microsoft's Azure. Broader macroeconomic conditions, such as high inflation, changes in consumer spending, and interest rate hikes, could also influence Amazon's revenue growth and profitability, particularly in its retail operations.\n",
       "*   **Recent Pullback:** The stock has pulled back about 13% from its early-November peak of $258.60 to the current trading range, despite strong Q3 2025 results. This pullback reflects a repricing of risk rather than a failure of the business, but it highlights potential volatility."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message('''Tell me about AMZN current share price, short-term trends, and bullish versus bearish predictions''')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:37.021286Z",
     "iopub.status.busy": "2025-11-24T21:25:37.021043Z",
     "iopub.status.idle": "2025-11-24T21:25:39.798851Z",
     "shell.execute_reply": "2025-11-24T21:25:39.797812Z",
     "shell.execute_reply.started": "2025-11-24T21:25:37.021266Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The stock ticker symbol \"MGM\" on the New York Stock Exchange (NYSE) belongs to **MGM Resorts International**.\n",
       "\n",
       "It's important to note that MGM Resorts International is a hospitality and entertainment company known for its resorts and casinos. While \"Amazon MGM Studios\" is mentioned in the context of co-produced series, the \"MGM\" ticker symbol itself is for the resorts company, not directly for the film studio as a separate publicly traded entity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message('''What is mgm studio's stock ticker symbol?''')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:39.800043Z",
     "iopub.status.busy": "2025-11-24T21:25:39.799812Z",
     "iopub.status.idle": "2025-11-24T21:25:42.859992Z",
     "shell.execute_reply": "2025-11-24T21:25:42.858791Z",
     "shell.execute_reply.started": "2025-11-24T21:25:39.800025Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the last available open, close, high, and low data for AMZN as of November 21, 2025:\n",
       "\n",
       "*   **Open:** $216.34\n",
       "*   **Close:** $220.69\n",
       "*   **High:** $222.21\n",
       "*   **Low:** $215.18"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message('''What was the last open,close,high,low data for AMZN again?''')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:42.863431Z",
     "iopub.status.busy": "2025-11-24T21:25:42.863051Z",
     "iopub.status.idle": "2025-11-24T21:25:50.859766Z",
     "shell.execute_reply": "2025-11-24T21:25:50.858635Z",
     "shell.execute_reply.started": "2025-11-24T21:25:42.863405Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the open, close, high, and low data for AMZN stock for the past month, from approximately October 24, 2025, to November 21, 2025. Please note that stock markets are typically closed on weekends and holidays.\n",
       "\n",
       "| Date       | Open      | High      | Low       | Close     |\n",
       "| :--------- | :-------- | :-------- | :-------- | :-------- |\n",
       "| Nov 21, 2025 | $216.35   | $222.21   | $215.18   | $220.69   |\n",
       "| Nov 20, 2025 | $227.05   | $227.41   | $216.74   | $217.14   |\n",
       "| Nov 19, 2025 | $223.74   | $223.74   | $218.52   | $222.69   |\n",
       "| Nov 18, 2025 | $228.10   | $230.20   | $222.42   | $222.55   |\n",
       "| Nov 17, 2025 | $233.25   | $234.60   | $229.19   | $232.87   |\n",
       "| Nov 14, 2025 | $235.06   | $238.73   | $232.89   | $234.69   |\n",
       "| Nov 13, 2025 | $243.05   | $243.75   | $236.50   | $237.58   |\n",
       "| Nov 12, 2025 | $250.24   | $250.37   | $243.75   | $244.20   |\n",
       "| Nov 11, 2025 | $248.41   | $249.75   | $247.23   | $249.10   |\n",
       "| Nov 10, 2025 | $248.34   | $251.75   | $245.59   | $248.40   |\n",
       "| Nov 07, 2025 | $242.90   | $244.90   | $238.49   | $244.41   |\n",
       "| Nov 06, 2025 | $249.16   | $250.38   | $242.17   | $243.04   |\n",
       "| Nov 05, 2025 | $249.03   | $251.00   | $246.16   | $250.20   |\n",
       "| Nov 04, 2025 | $250.38   | $257.01   | $248.66   | $249.32   |\n",
       "| Nov 03, 2025 | $255.36   | $258.60   | $252.90   | $254.00   |\n",
       "| Oct 31, 2025 | $250.10   | $250.50   | $243.98   | $244.22   |\n",
       "| Oct 30, 2025 | $227.06   | $228.44   | $222.75   | $222.86   |\n",
       "| Oct 29, 2025 | $231.67   | $232.82   | $227.76   | $230.30   |\n",
       "| Oct 28, 2025 | $228.00   | $230.00   | $225.00   | $227.00   |\n",
       "| Oct 27, 2025 | $225.00   | $228.00   | $224.00   | $226.00   |\n",
       "| Oct 24, 2025 | $221.97   | $225.40   | $221.90   | $224.21   |\n",
       "| Oct 23, 2025 | $218.95   | $221.30   | $218.18   | $221.09   |\n",
       "| Oct 22, 2025 | $219.30   | $220.01   | $216.52   | $217.95   |\n",
       "| Oct 21, 2025 | $218.43   | $223.32   | $218.00   | $222.03   |\n",
       "| Oct 20, 2025 | $213.88   | $216.69   | $213.59   | $216.48   |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message('''What is AMZN open,close,high,low data for the past month? \n",
    "Present the data with multiple columns for display in markdown.''')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previously on Kaggle: StockChat 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation BaseModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:50.861363Z",
     "iopub.status.busy": "2025-11-24T21:25:50.861017Z",
     "iopub.status.idle": "2025-11-24T21:25:50.947307Z",
     "shell.execute_reply": "2025-11-24T21:25:50.946224Z",
     "shell.execute_reply.started": "2025-11-24T21:25:50.861337Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Validation BaseModels in pydantic schema.\n",
    "class RestStatus(Enum):\n",
    "    OK = \"OK\"\n",
    "    DELAY = \"DELAYED\"\n",
    "    NONE = \"NOT_FOUND\"\n",
    "    AUTH = \"NOT_AUTHORIZED\"\n",
    "\n",
    "class StopGeneration(BaseModel):\n",
    "    result: str = Api.Const.Stop()\n",
    "\n",
    "class RestResultPoly(BaseModel):\n",
    "    request_id: Optional[str] = None\n",
    "    count: Optional[int] = None\n",
    "    next_url: Optional[str] = None\n",
    "    status: RestStatus  \n",
    "\n",
    "class MarketSession(Enum):\n",
    "    PRE = \"pre-market\"\n",
    "    REG = \"regular\"\n",
    "    POST = \"post-market\"\n",
    "    CLOSED = \"closed\"\n",
    "    NA = \"not applicable\"\n",
    "\n",
    "class MarketEvent(Enum):\n",
    "    PRE_OPEN = 0\n",
    "    REG_OPEN = 1\n",
    "    REG_CLOSE = 2\n",
    "    POST_CLOSE = 3\n",
    "    LAST_CLOSE = 4\n",
    "\n",
    "class AssetClass(Enum):\n",
    "    STOCKS = \"stocks\"\n",
    "    OPTION = \"options\"\n",
    "    CRYPTO = \"crypto\"\n",
    "    FOREX = \"fx\"\n",
    "    INDEX = \"indices\"\n",
    "    OTC = \"otc\"\n",
    "\n",
    "class SymbolType(Enum):\n",
    "    COMMON = \"Common Stock\"\n",
    "    ETP = \"ETP\"\n",
    "    ADR = \"ADR\"\n",
    "    REIT = \"REIT\"\n",
    "    DELISTED = \"\"\n",
    "    CEF = \"Closed-End Fund\"\n",
    "    UNIT = \"Unit\"\n",
    "    RIGHT = \"Right\"\n",
    "    EQUITY = \"Equity WRT\"\n",
    "    GDR = \"GDR\"\n",
    "    PREF = \"Preference\"\n",
    "    CDI = \"CDI\"\n",
    "    NVDR = \"NVDR\"\n",
    "    REG = \"NY Reg Shrs\"\n",
    "    MLP = \"MLP\"\n",
    "    MUTUAL = \"Mutual Fund\"\n",
    "\n",
    "class Locale(Enum):\n",
    "    US = \"us\"\n",
    "    GLOBAL = \"global\"\n",
    "\n",
    "class Sentiment(Enum):\n",
    "    V_POS = \"very positive\"\n",
    "    POSITIVE = \"positive\"\n",
    "    NEUTRAL_P = \"neutral/positive\"\n",
    "    NEUTRAL_SP = \"neutral/slightly positive\"\n",
    "    NEUTRAL = \"neutral\"\n",
    "    NEUTRAL_SN = \"neutral/slightly negative\"\n",
    "    NEUTRAL_N = \"neutral/negative\"\n",
    "    MIXED = \"mixed\"\n",
    "    NEGATIVE = \"negative\"\n",
    "    V_NEG = \"very negative\"\n",
    "\n",
    "class Trend(Enum):\n",
    "    S_BUY = \"strong-buy\"\n",
    "    BUY = \"buy\"\n",
    "    HOLD = \"hold\"\n",
    "    SELL = \"sell\"\n",
    "    S_SELL = \"strong-sell\"\n",
    "\n",
    "class MarketCondition(Enum):\n",
    "    BULL = \"bullish\"\n",
    "    BULLN = \"cautiously bullish\"\n",
    "    HOLD = \"hold\"\n",
    "    BEARN = \"cautiously bearish\"\n",
    "    BEAR = \"bearish\"\n",
    "\n",
    "class GeneratedEvent(BaseModel):\n",
    "    last_close: str\n",
    "    pre_open: str\n",
    "    reg_open: str\n",
    "    reg_close: str\n",
    "    post_close: str\n",
    "    timestamp: Optional[str] = None\n",
    "    is_holiday: Optional[bool] = None\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        if self.timestamp is None:\n",
    "            self.timestamp = datetime.now(self.tz()).strftime('%c')\n",
    "        if self.is_holiday is None:\n",
    "            self.is_holiday = False\n",
    "\n",
    "    def session(self, with_date: Optional[str] = None) -> MarketSession:\n",
    "        if with_date is None:\n",
    "            with_date = datetime.now(self.tz()).strftime('%c')\n",
    "        compare = parse(with_date)\n",
    "        if self.is_holiday or compare.weekday() > 4: # weekend\n",
    "            return MarketSession.CLOSED\n",
    "        events = [parse(event).time() for event in [self.pre_open,self.reg_open,self.reg_close,self.post_close]]\n",
    "        if compare.time() < events[0]:\n",
    "            return MarketSession.CLOSED\n",
    "        else:\n",
    "            session = MarketSession.NA\n",
    "            if compare.time() >= events[0]:\n",
    "                session = MarketSession.PRE\n",
    "            if compare.time() >= events[1]:\n",
    "                session = MarketSession.REG\n",
    "            if compare.time() >= events[2]:\n",
    "                session = MarketSession.POST\n",
    "            if compare.time() >= events[3]:\n",
    "                session = MarketSession.CLOSED\n",
    "        return session\n",
    "\n",
    "    def is_open(self) -> bool:\n",
    "        return self.session() != MarketSession.CLOSED\n",
    "\n",
    "    def has_update(self) -> bool:\n",
    "        datetime_now = datetime.now(self.tz())\n",
    "        self_ts = parse(self.timestamp)\n",
    "        # Re-generate events for a new day.\n",
    "        if datetime_now.day > self_ts.day:\n",
    "            return True\n",
    "        # No updates on holidays or when generated after post_close.\n",
    "        if self.is_holiday or self_ts.time() >= parse(self.post_close).time():\n",
    "            return False\n",
    "        # Compare current time to generated event times.\n",
    "        for event in [self.pre_open,self.reg_open,self.reg_close]:\n",
    "            if datetime_now.time() > parse(event).time():\n",
    "                return True\n",
    "        # Current time is before pre_open.\n",
    "        return False\n",
    "\n",
    "    @classmethod\n",
    "    def tz(cls):\n",
    "        return pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\n",
    "    \n",
    "    @classmethod\n",
    "    def apply_fix(cls, value, fix: datetime) -> tuple[str, datetime]:\n",
    "        api.validation_fail()\n",
    "        value = fix.strftime('%c')\n",
    "        return value, fix\n",
    "    \n",
    "    @field_validator(\"last_close\")\n",
    "    def valid_close(cls, value):\n",
    "        date_gen = parse(value) # Generated close is in eastern time and tzinfo naive.\n",
    "        date_now = parse(datetime.now(cls.tz()).strftime('%c')) # Need now in same format as generated.\n",
    "        # Soft-pass: when actual session is closed after post-market\n",
    "        if date_now.day == date_gen.day+1 and date_now.weekday() <= 4:\n",
    "            date_fix = date_gen.replace(day=date_now.day)\n",
    "            if date_fix.timestamp() < date_now.timestamp():\n",
    "                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use today's close\n",
    "        # Soft-pass: when actual session is open post-market\n",
    "        if date_now.day == date_gen.day and date_now.timestamp() < date_gen.timestamp():\n",
    "            if date_now.weekday() > 0:\n",
    "                date_fix = date_gen.replace(day=date_now.day-1)\n",
    "            else:\n",
    "                date_fix = date_gen.replace(day=date_now.day-3)\n",
    "            if date_now.timestamp() > date_fix.timestamp():\n",
    "                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use previous close\n",
    "        if date_now.weekday() == 0 or date_now.weekday() == 1 and date_gen.weekday() <= 4: # 0=monday, 4=friday\n",
    "            return value # pass: generated thurs/friday on a monday/tues\n",
    "        elif date_now.weekday() > 0 and date_now.weekday() <= 4 and date_gen.weekday() <= date_now.weekday()-1:\n",
    "            return value # pass: generated yesterday/prior on a tues-fri\n",
    "        elif date_now.weekday() > 4 and date_gen.weekday() <= 4:\n",
    "            return value # pass: generated thurs/friday on a weekend\n",
    "        elif date_now.day == date_gen.day and date_now.timestamp() > date_gen.timestamp():\n",
    "            return value # pass: generated today after closed\n",
    "        elif date_now.timestamp() < date_gen.timestamp():\n",
    "            raise ValueError(\"last close cannot be a future value\")\n",
    "        else:\n",
    "            raise ValueError(\"generated invalid last close\")\n",
    "        api.validation_fail()\n",
    "\n",
    "class VectorStoreResult(BaseModel):\n",
    "    docs: str\n",
    "    dist: Optional[float] # requires query\n",
    "    meta: Optional[dict]  # requires get or query\n",
    "    store_id: str\n",
    "\n",
    "class Aggregate(RestResultPoly):\n",
    "    symbol: str\n",
    "    open: float\n",
    "    high: float\n",
    "    low: float\n",
    "    close: float\n",
    "    volume: int\n",
    "    otc: Optional[bool] = None\n",
    "    preMarket: Optional[float] = None\n",
    "    afterHours: Optional[float] = None\n",
    "\n",
    "class DailyCandle(Aggregate):\n",
    "    from_date: str\n",
    "\n",
    "class AggregateWindow(BaseModel):\n",
    "    o: float\n",
    "    h: float\n",
    "    l: float\n",
    "    c: float\n",
    "    v: int # traded volume\n",
    "    n: Optional[int] = None # transaction count\n",
    "    vw: Optional[float] = None # volume weighted average price\n",
    "    otc: Optional[bool] = None\n",
    "    t: int\n",
    "\n",
    "    @field_validator(\"t\")\n",
    "    def valid_t(cls, value):\n",
    "        if not value > 0:\n",
    "            raise ValueError(\"invalid timestamp\")\n",
    "        if len(str(value)) == 13:\n",
    "            return int(value/1000)\n",
    "        return value\n",
    "\n",
    "class CustomCandle(RestResultPoly): \n",
    "    ticker: str\n",
    "    adjusted: bool\n",
    "    queryCount: int\n",
    "    resultsCount: int\n",
    "    results: list[AggregateWindow]\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[AggregateWindow]:\n",
    "        return self.results\n",
    "    \n",
    "class MarketStatus(BaseModel):\n",
    "    exchange: str\n",
    "    holiday: Optional[str] = None\n",
    "    isOpen: bool\n",
    "    session: Optional[MarketSession] = None\n",
    "    t: int\n",
    "    timezone: str\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        if self.session is None:\n",
    "            self.session = MarketSession.CLOSED\n",
    "        if self.holiday is None:\n",
    "            self.holiday = MarketSession.NA.value\n",
    "\n",
    "class MarketStatusResult(BaseModel):\n",
    "    results: MarketStatus\n",
    "\n",
    "    def get(self) -> MarketStatus:\n",
    "        return self.results\n",
    "\n",
    "class Symbol(BaseModel):\n",
    "    description: str\n",
    "    displaySymbol: str\n",
    "    symbol: str\n",
    "    type: SymbolType\n",
    "\n",
    "class SymbolResult(BaseModel):\n",
    "    count: int\n",
    "    result: list[Symbol]\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.result)\n",
    "\n",
    "    def get(self) -> list[Symbol]:\n",
    "        return self.result\n",
    "\n",
    "class Quote(BaseModel):\n",
    "    c: float\n",
    "    d: float\n",
    "    dp: float\n",
    "    h: float\n",
    "    l: float\n",
    "    o: float\n",
    "    pc: float\n",
    "    t: int\n",
    "\n",
    "    @field_validator(\"t\")\n",
    "    def valid_t(cls, value):\n",
    "        if not value > 0:\n",
    "            raise ValueError(\"invalid timestamp\")\n",
    "        return value\n",
    "\n",
    "class PeersResult(BaseModel):\n",
    "    results: list[str]\n",
    "    count: Optional[int] = None\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[str]:\n",
    "        return self.results\n",
    "\n",
    "class BasicFinancials(BaseModel):\n",
    "    metric: dict\n",
    "    metricType: str\n",
    "    series: dict\n",
    "    symbol: str\n",
    "\n",
    "class Insight(BaseModel):\n",
    "    sentiment: Sentiment|MarketCondition\n",
    "    sentiment_reasoning: str\n",
    "    ticker: str\n",
    "\n",
    "class Publisher(BaseModel):\n",
    "    favicon_url: Optional[str]\n",
    "    homepage_url: str\n",
    "    logo_url: str\n",
    "    name: str\n",
    "\n",
    "class NewsSummary(BaseModel):\n",
    "    title: str\n",
    "    summary: Optional[str]\n",
    "    insights: Optional[list[Insight]]\n",
    "    published_utc: str\n",
    "\n",
    "class NewsTypePoly(BaseModel):\n",
    "    amp_url: Optional[str] = None\n",
    "    article_url: str\n",
    "    title: str\n",
    "    author: str\n",
    "    description: Optional[str] = None\n",
    "    id: str\n",
    "    image_url: Optional[str] = None\n",
    "    insights: Optional[list[Insight]] = None\n",
    "    keywords: Optional[list[str]] = None\n",
    "    published_utc: str\n",
    "    publisher: Publisher\n",
    "    tickers: list[str]\n",
    "\n",
    "    def summary(self):\n",
    "        return NewsSummary(title=self.title,\n",
    "                           summary=self.description,\n",
    "                           insights=self.insights,\n",
    "                           published_utc=self.published_utc)\n",
    "\n",
    "class NewsResultPoly(RestResultPoly):\n",
    "    results: list[NewsTypePoly]\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[NewsTypePoly]:\n",
    "        return self.results\n",
    "\n",
    "class NewsTypeFinn(BaseModel):\n",
    "    category: str\n",
    "    datetime: int\n",
    "    headline: str\n",
    "    id: int\n",
    "    image: str\n",
    "    related: str # symbol\n",
    "    source: str\n",
    "    summary: str\n",
    "    url: str\n",
    "\n",
    "    def summary(self):\n",
    "        return NewsSummary(title=self.headline,\n",
    "                           summary=self.summary,\n",
    "                           insights=None,\n",
    "                           published_utc=self.datetime)\n",
    "\n",
    "class NewsResultFinn(BaseModel):\n",
    "    results: list[NewsTypeFinn]\n",
    "    count: Optional[int] = None\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[NewsTypeFinn]:\n",
    "        return self.results\n",
    "\n",
    "class NewsTypeGenerated(BaseModel):\n",
    "    title: str\n",
    "    summary: str\n",
    "    insights: list[Insight]\n",
    "    keywords: list[str]\n",
    "    source: Publisher\n",
    "    published_utc: str\n",
    "    tickers: list[str]\n",
    "    url: str\n",
    "\n",
    "    def summary(self):\n",
    "        return NewsSummary(title=self.title,\n",
    "                           summary=self.summary,\n",
    "                           insights=self.insights,\n",
    "                           published_utc=self.published_utc)\n",
    "\n",
    "class TickerOverview(BaseModel):\n",
    "    ticker: str\n",
    "    name: str\n",
    "    market: AssetClass\n",
    "    locale: Locale\n",
    "    primary_exchange: Optional[str] = None\n",
    "    active: bool\n",
    "    currency_name: str\n",
    "    cik: Optional[str] = None\n",
    "    composite_figi: Optional[str] = None\n",
    "    share_class_figi: Optional[str] = None\n",
    "    market_cap: Optional[int|float] = None\n",
    "    phone_number: Optional[str] = None\n",
    "    address: Optional[dict] = None\n",
    "    description: Optional[str] = None\n",
    "    sic_code: Optional[str] = None\n",
    "    sic_description: Optional[str] = None\n",
    "    ticker_root: Optional[str] = None\n",
    "    homepage_url: Optional[str] = None\n",
    "    total_employees: Optional[int] = None\n",
    "    list_date: Optional[str] = None\n",
    "    branding: Optional[dict] = None\n",
    "    share_class_shares_outstanding: Optional[int] = None\n",
    "    weighted_shares_outstanding: Optional[int] = None\n",
    "    round_lot: Optional[int] = None\n",
    "\n",
    "class OverviewResult(RestResultPoly):\n",
    "    results: TickerOverview\n",
    "\n",
    "    def get(self) -> TickerOverview:\n",
    "        return self.results\n",
    "\n",
    "class RecommendationTrend(BaseModel):\n",
    "    buy: int\n",
    "    hold: int\n",
    "    period: str\n",
    "    sell: int\n",
    "    strongBuy: int\n",
    "    strongSell: int\n",
    "    symbol: str\n",
    "\n",
    "class TrendsResult(BaseModel):\n",
    "    results: list[RecommendationTrend]\n",
    "    count: Optional[int] = None\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[RecommendationTrend]:\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:50.948916Z",
     "iopub.status.busy": "2025-11-24T21:25:50.948537Z",
     "iopub.status.idle": "2025-11-24T21:25:50.958658Z",
     "shell.execute_reply": "2025-11-24T21:25:50.957716Z",
     "shell.execute_reply.started": "2025-11-24T21:25:50.948885Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# A contents-memory object.\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.system = f\"\"\"Give a concise, and detailed summary. Use information that you learn from the API responses.\n",
    "        Use your tools and function calls according to the rules. Convert any all-upper case identifiers\n",
    "        to proper case in your response. Convert any abbreviated or shortened identifiers to their full forms.\n",
    "        Convert timestamps according to the rules before including them. Think step by step.\n",
    "        \"\"\"\n",
    "        self.revery = {}\n",
    "        self.contents = []\n",
    "        self.prompt = None\n",
    "        self.summary = None\n",
    "        self.response = None\n",
    "    \n",
    "    def set_prompt(self, prompt):\n",
    "        self.prompt = f\"\"\"\n",
    "        The current date and time is: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n",
    "        \n",
    "        {prompt}\n",
    "        \"\"\"\n",
    "        self.contents = [types.Content(role=\"user\", parts=[types.Part(text=self.prompt)])]\n",
    "\n",
    "    def set_reason(self, step):\n",
    "        # Append the model's reasoning part.\n",
    "        self.contents.append(types.Content(role=\"model\", parts=[types.Part(thought=True,text=step)]))\n",
    "\n",
    "    def append_code(self, prompt, code_response_parts):\n",
    "        subroutine_content = [types.Content(role=\"user\", parts=[types.Part(text=prompt)]),\n",
    "                              types.Content(role=\"model\", parts=code_response_parts)]\n",
    "        # Append the model's generated code and execution result.\n",
    "        self.revery[datetime.now(GeneratedEvent.tz()).strftime('%c')] = { \n",
    "            \"contents\": subroutine_content\n",
    "        }\n",
    "\n",
    "    def update_contents(self, function_call, api_response_part):\n",
    "        # Append the model's function call part.\n",
    "        self.contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=function_call)])) \n",
    "        # Append the api response part.\n",
    "        self.contents.append(types.Content(role=\"user\", parts=[api_response_part]))\n",
    "\n",
    "    def set_summary(self, summary):\n",
    "        self.summary = summary\n",
    "        self.contents.append(types.Content(role=\"model\", parts=[types.Part(text=summary)]))\n",
    "        self.revery[datetime.now(GeneratedEvent.tz()).strftime('%c')] = {\n",
    "            \"prompt\": self.prompt, \n",
    "            \"summary\": self.summary, \n",
    "            \"contents\": self.contents\n",
    "        }\n",
    "        self.contents = []\n",
    "\n",
    "memory = Memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:50.960064Z",
     "iopub.status.busy": "2025-11-24T21:25:50.959823Z",
     "iopub.status.idle": "2025-11-24T21:25:51.974553Z",
     "shell.execute_reply": "2025-11-24T21:25:51.973085Z",
     "shell.execute_reply.started": "2025-11-24T21:25:50.960046Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: retrieval-augmented generation.\n",
    "# - using Chroma and text-embedding-004 for storage and retrieval\n",
    "# - using gemini-2.0-flash for augmented generation\n",
    "class RetrievalAugmentedGenerator:\n",
    "    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n",
    "    config_temp = types.GenerateContentConfig(temperature=0.0)\n",
    "    exchange_codes: Optional[dict] = None\n",
    "    exchange_lists: dict = {}\n",
    "    events: dict = {}\n",
    "    holidays: dict = {}\n",
    "\n",
    "    def __init__(self, genai_client, collection_name):\n",
    "        self.client = genai_client\n",
    "        self.embed_fn = GeminiEmbedFunction(genai_client)\n",
    "        self.db = self.chroma_client.get_or_create_collection(\n",
    "            name=collection_name, \n",
    "            embedding_function=self.embed_fn,  # type: ignore\n",
    "            metadata={\"hnsw:space\": \"cosine\"})\n",
    "        logging.getLogger(\"chromadb\").setLevel(logging.ERROR) # suppress warning on existing id\n",
    "        self.set_holidays(\"US\", [\"09-01-2025\",\"10-13-2025\",\"11-11-2025\",\"11-27-2025\",\"12-25-2025\"])\n",
    "        #self.generated_events(\"US\")\n",
    "\n",
    "    def set_holidays(self, exchange_code: str, holidays: list):\n",
    "        self.holidays[exchange_code] = [datetime.strptime(h, \"%m-%d-%Y\").date() for h in holidays]\n",
    "\n",
    "    def get_exchange_codes(self, with_query: Optional[str] = None):\n",
    "        gen = None\n",
    "        if with_query and with_query not in self.exchange_lists.keys():\n",
    "            gen = tqdm(total=1, desc=\"Generate exchange codes with_query\")\n",
    "            data = self.get_exchanges_csv(\n",
    "                f\"\"\"What is the {with_query} exchange code? Return only the exchange codes \n",
    "                as a list in string form. Just the list string. \n",
    "                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n",
    "            self.exchange_lists[with_query] = ast.literal_eval(data.parts[-1].text)\n",
    "        elif with_query is None and self.exchange_codes is None:\n",
    "            gen = tqdm(total=1, desc=\"Generate exchange codes\")\n",
    "            data = self.get_exchanges_csv(\n",
    "                \"\"\"Give me a dictionary in string form. It must contain key:value pairs \n",
    "                mapping exchange code to name. Just the dictionary string. \n",
    "                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n",
    "            self.exchange_codes = ast.literal_eval(data.parts[-1].text.strip(\"\\\\`\"))\n",
    "        if gen:\n",
    "            gen.update(1)\n",
    "        return self.exchange_lists[with_query] if with_query else self.exchange_codes\n",
    "\n",
    "    def get_event_date(self, event_t: str, exchange_code: str, event: MarketEvent):\n",
    "        current_dt_str = datetime.now(GeneratedEvent.tz()).strftime('%c')\n",
    "        current_dt = datetime.strptime(current_dt_str, \"%a %b %d %H:%M:%S %Y\")\n",
    "        current_t_str = datetime.now(GeneratedEvent.tz()).strftime('%H:%M:%S')\n",
    "        current_t = datetime.strptime(current_t_str, \"%H:%M:%S\").time()\n",
    "        event_time = parse(event_t).time()\n",
    "        gen_datetime = None\n",
    "        if event is MarketEvent.LAST_CLOSE:\n",
    "            last_close_day = current_dt.date() - timedelta(days=0 if current_t > event_time else 1)\n",
    "            # Loop backwards to find the last valid trading day (not a weekend or holiday).\n",
    "            while last_close_day.weekday() >= 5 or last_close_day in self.holidays[exchange_code]: # 5 = Sat, 6 = Sun\n",
    "                last_close_day -= timedelta(days=1)\n",
    "            # Combine the date and time.\n",
    "            gen_datetime = datetime.combine(last_close_day, event_time)\n",
    "        else:\n",
    "            next_event_day = current_dt.date() + timedelta(days=0 if current_t < event_time else 1)\n",
    "            # Loop forward to find the next valid trading day (not a weekend or holiday).\n",
    "            while next_event_day.weekday() >= 5 or next_event_day in self.holidays[exchange_code]: # 5 = Sat, 6 = Sun\n",
    "                next_event_day += timedelta(days=1)\n",
    "            # Combine date and time.\n",
    "            gen_datetime = datetime.combine(next_event_day, event_time)\n",
    "        # Format the result as requested.\n",
    "        return gen_datetime.strftime('%a %b %d %X %Y')\n",
    "\n",
    "    def generate_event(self, exchange_code: str, event: MarketEvent):\n",
    "        if event is MarketEvent.LAST_CLOSE or event is MarketEvent.POST_CLOSE:\n",
    "            prompt = f\"\"\"What is the closing time including post_market hours.\"\"\"\n",
    "        elif event is MarketEvent.PRE_OPEN or event is MarketEvent.REG_OPEN:\n",
    "            is_pre = \"including\" if event is MarketEvent.PRE_OPEN else \"excluding\"\n",
    "            prompt = f\"\"\"What is the opening time {is_pre} pre_market hours.\"\"\"\n",
    "        elif event is MarketEvent.REG_CLOSE:\n",
    "            prompt = f\"\"\"What is the closing time excluding post_market hours.\"\"\"\n",
    "        prompt = f\"\"\"Answer based on your knowledge of exchange operating hours.\n",
    "            Do not answer in full sentences. Omit all chat and provide the answer only.\n",
    "            The fields pre_market and post_market both represent extended operating hours.\n",
    "\n",
    "            The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n",
    "            \n",
    "            Consider the {exchange_code} exchange's operating hours.\n",
    "            {prompt}\n",
    "            \n",
    "            Answer with the time in this format: '%H:%M:%S'.\n",
    "            Omit all other chat and details. Do not use sentences.\"\"\"\n",
    "        progress = tqdm(total=1, desc=f\"Generate {exchange_code}->{event}\")\n",
    "        response = self.get_exchanges_csv(prompt).candidates[0].content\n",
    "        try:\n",
    "            if Api.Const.Stop() in f\"{response.parts[-1].text}\":\n",
    "                self.generate_event_failed(progress, exchange_code, event)\n",
    "            else:\n",
    "                response = self.get_event_date(response.parts[-1].text, exchange_code, event)\n",
    "                progress.update(1)\n",
    "                return response\n",
    "        except Exception as e:\n",
    "            self.generate_event_failed(progress, exchange_code, event)\n",
    "\n",
    "    def generate_event_failed(self, progress: tqdm, exchange_code: str, event: MarketEvent):\n",
    "        progress.close()\n",
    "        api.generation_fail()\n",
    "        time.sleep(api.dt_between)\n",
    "        return self.generate_event(exchange_code, event)\n",
    "\n",
    "    def generated_events(self, exchange_code: str) -> GeneratedEvent:\n",
    "        # Check for an existing GeneratedEvent object having updates.\n",
    "        if exchange_code in self.events.keys() and self.events[exchange_code].has_update():\n",
    "            event_obj = self.events[exchange_code]\n",
    "            event_state = [(event_obj.pre_open, MarketEvent.PRE_OPEN),\n",
    "                           (event_obj.reg_open, MarketEvent.REG_OPEN),\n",
    "                           (event_obj.reg_close, MarketEvent.REG_CLOSE),\n",
    "                           (event_obj.post_close, MarketEvent.POST_CLOSE)]\n",
    "            # Need now in same format as generated.\n",
    "            datetime_now = parse(datetime.now(event_obj.tz()).strftime('%c'))\n",
    "            gen_ts = parse(event_obj.timestamp)\n",
    "            # Re-generate events when day changes.\n",
    "            if datetime_now.day > gen_ts.day:\n",
    "                del self.events[exchange_code]\n",
    "                return self.generated_events(exchange_code)\n",
    "            # Update changed events on trading days.\n",
    "            for e in event_state:\n",
    "                if datetime_now > parse(e[0]):\n",
    "                    event_dt = self.generate_event(exchange_code, e[1])\n",
    "                    match e[1]:\n",
    "                        case MarketEvent.PRE_OPEN:\n",
    "                            event_obj.pre_open = event_dt\n",
    "                        case MarketEvent.REG_OPEN:\n",
    "                            event_obj.reg_open = event_dt\n",
    "                        case MarketEvent.REG_CLOSE:\n",
    "                            event_obj.reg_close = event_dt\n",
    "                        case MarketEvent.POST_CLOSE:\n",
    "                            event_obj.post_close = event_dt\n",
    "            event_obj.timestamp = datetime.now(event_obj.tz()).strftime('%c')\n",
    "            self.events[exchange_code] = event_obj\n",
    "        # Generate events for an exchange code not in cache.\n",
    "        elif exchange_code not in self.events.keys():\n",
    "            self.events[exchange_code] = GeneratedEvent(\n",
    "                last_close=self.generate_event(exchange_code, MarketEvent.LAST_CLOSE),\n",
    "                pre_open=self.generate_event(exchange_code, MarketEvent.PRE_OPEN),\n",
    "                reg_open=self.generate_event(exchange_code, MarketEvent.REG_OPEN),\n",
    "                reg_close=self.generate_event(exchange_code, MarketEvent.REG_CLOSE),\n",
    "                post_close=self.generate_event(exchange_code, MarketEvent.POST_CLOSE),\n",
    "                is_holiday=datetime.now().date() in self.holidays[exchange_code])\n",
    "        return self.events[exchange_code]\n",
    "\n",
    "    def set_holiday_event(self, exchange_code: str):\n",
    "        self.generated_events(exchange_code).is_holiday = True\n",
    "\n",
    "    def last_market_close(self, exchange_code: str):\n",
    "        return self.generated_events(exchange_code).last_close\n",
    "\n",
    "    def add_documents_list(self, docs: list):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n",
    "        metas=[{\"source\": doc.metadata[\"source\"]} for doc in docs]\n",
    "        content=[doc.page_content for doc in docs]\n",
    "        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate document embedding\")\n",
    "\n",
    "    def add_api_document(self, query: str, api_response: str, topic: str, source: str = \"add_api_document\"):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        splitter = RecursiveJsonSplitter(max_chunk_size=Api.Const.ChunkMax())\n",
    "        docs = splitter.create_documents(texts=[api_response], convert_lists=True)\n",
    "        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n",
    "        content = [json.dumps(doc.page_content) for doc in docs]\n",
    "        metas = [{\"source\": source, \"topic\": topic}]*len(docs)\n",
    "        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate api embedding\")\n",
    "\n",
    "    def add_peers_document(self, query: str, names: list, topic: str, source: str, group: str):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        peers = {\"symbol\": topic, \"peers\": names}\n",
    "        tqdm(self.db.add(ids=str(self.db.count()),\n",
    "                         documents=[json.dumps(peers)],\n",
    "                         metadatas=[{\"source\": source, \"topic\": topic, \"group\": group}]),\n",
    "             desc=\"Generate peers embedding\")\n",
    "\n",
    "    def get_peers_document(self, query: str, topic: str, group: str):\n",
    "        return self.get_documents_list(query, where={\"$and\": [{\"group\": group}, {\"topic\": topic}]})\n",
    "\n",
    "    def add_rest_chunks(self, chunks: list, topic: str, source: str, ids: Optional[list[str]] = None,\n",
    "                        meta_opt: Optional[list[dict]] = None, is_update: bool = True):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode\n",
    "        if ids is None:\n",
    "            ids = list(map(str, range(self.db.count(), self.db.count()+len(chunks))))\n",
    "        if isinstance(chunks[0], BaseModel):\n",
    "            docs = [model.model_dump_json() for model in chunks]\n",
    "        else:\n",
    "            docs = [json.dumps(obj) for obj in chunks]\n",
    "        meta_base = {\"source\": source, \"topic\": topic}\n",
    "        if meta_opt is not None:\n",
    "            for m in meta_opt:\n",
    "                m.update(meta_base)\n",
    "        metas = [meta_base]*len(chunks) if meta_opt is None else meta_opt\n",
    "        if is_update:\n",
    "            tqdm(self.db.upsert(ids=ids, documents=docs, metadatas=metas), desc=\"Upsert chunks embedding\")\n",
    "        else:\n",
    "            tqdm(self.db.add(ids=ids, documents=docs, metadatas=metas), desc=\"Add chunks embedding\")\n",
    "\n",
    "    def get_market_status(self, exchange_code: str) -> tuple[list[VectorStoreResult], bool]: # result, has rest update\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        stored = self.stored_result(self.db.get(where={\n",
    "            \"$and\": [{\"exchange\": exchange_code}, {\"topic\": \"market_status\"}]}))\n",
    "        if len(stored) == 0:\n",
    "            return stored, True\n",
    "        # Check for a daily market status update.\n",
    "        status = json.loads(stored[0].docs)\n",
    "        gen_day = parse(self.generated_events(exchange_code).timestamp).day\n",
    "        store_day = parse(stored[0].meta['timestamp']).day\n",
    "        if status[\"holiday\"] != MarketSession.NA.value and gen_day == store_day:\n",
    "            return stored, False\n",
    "        elif gen_day > store_day:\n",
    "            return stored, True\n",
    "        # Update with generated events to avoid rest api requests.\n",
    "        status[\"session\"] = self.generated_events(exchange_code).session().value\n",
    "        status[\"isOpen\"] = self.generated_events(exchange_code).is_open()\n",
    "        stored[0].docs = json.dumps(status)\n",
    "        return stored, False\n",
    "\n",
    "    def get_basic_financials(self, query: str, topic: str, source: str = \"get_financials_1\"):\n",
    "        return self.get_documents_list(\n",
    "            query, max_sources=200, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n",
    "\n",
    "    def add_quote_document(self, query: str, quote: str, topic: str, timestamp: int, source: str):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        tqdm(self.db.add(ids=str(self.db.count()), \n",
    "                             documents=[quote], \n",
    "                             metadatas=[{\"source\": source, \"topic\": topic, \"timestamp\": timestamp}]), \n",
    "             desc=\"Generate quote embedding\")\n",
    "\n",
    "    def get_api_documents(self, query: str, topic: str, source: str = \"add_api_document\", \n",
    "                          meta_opt: Optional[list[dict]] = None):\n",
    "        where = [{\"source\": source}, {\"topic\": topic}]\n",
    "        if meta_opt is None:\n",
    "            return self.get_documents_list(query, where={\"$and\": where})\n",
    "        else:\n",
    "            for meta in meta_opt:\n",
    "                for k,v in meta.items():\n",
    "                    where.append({k: v})\n",
    "            return self.get_documents_list(query, where={\"$and\": where})\n",
    "\n",
    "    def query_api_documents(self, query: str, topic: str, source: str = \"add_api_document\"):\n",
    "        return self.generate_answer(query, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n",
    "\n",
    "    def add_grounded_document(self, query: str, topic: str, result):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        chunks = result.candidates[0].grounding_metadata.grounding_chunks\n",
    "        supports = result.candidates[0].grounding_metadata.grounding_supports\n",
    "        if supports is not None: # Only add grounded documents which have supports\n",
    "            grounded_text = [f\"{s.segment.text}\" for s in supports]\n",
    "            source = [f\"{c.web.title}\" for c in chunks]\n",
    "            score = [f\"{s.confidence_scores}\" for s in supports]\n",
    "            tqdm(self.db.add(ids=str(self.db.count()),\n",
    "                             documents=json.dumps(grounded_text),\n",
    "                             metadatas=[{\"source\": \", \".join(source),\n",
    "                                         \"confidence_score\": \", \".join(score),\n",
    "                                         \"topic\": topic,\n",
    "                                         \"question\": query}]),\n",
    "                 desc=\"Generate grounding embedding\")\n",
    "\n",
    "    def get_grounding_documents(self, query: str, topic: str):\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        return self.stored_result(self.db.get(where={\"$and\": [{\"question\": query}, {\"topic\": topic}]}))\n",
    "            \n",
    "    def add_wiki_documents(self, title: str, wiki_chunks: list):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        result = self.get_wiki_documents(title)\n",
    "        if len(result) == 0:\n",
    "            ids = list(map(str, range(self.db.count(), self.db.count()+len(wiki_chunks))))\n",
    "            metas=[{\"title\": title, \"source\": \"add_wiki_documents\"}]*len(wiki_chunks)\n",
    "            tqdm(self.db.add(ids=ids, documents=wiki_chunks, metadatas=metas), desc=\"Generate wiki embeddings\")\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def generate_with_wiki_passages(self, query: str, title: str, passages: list[str]):\n",
    "        return self.generate_answer(query, where={\"title\": title}, passages=passages)\n",
    "    \n",
    "    def get_wiki_documents(self, title: Optional[str] = None):\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        if title is None:\n",
    "            return self.stored_result(self.db.get(where={\"source\": \"add_wiki_document\"}))\n",
    "        else:\n",
    "            return self.stored_result(self.db.get(where={\"title\": title}))\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def get_documents_list(self, query: str, max_sources: int = 5000, where: Optional[dict] = None):\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        return self.stored_result(\n",
    "            self.db.query(query_texts=[query], \n",
    "                          n_results=max_sources, \n",
    "                          where=where), \n",
    "            is_query = True)\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def get_exchanges_csv(self, query: str):\n",
    "        return self.generate_answer(query, max_sources=100, where={\"source\": \"exchanges.csv\"})\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def generate_answer(self, query: str, max_sources: int = 10, \n",
    "                        where: Optional[dict] = None, passages: Optional[list[str]] = None):\n",
    "        stored = self.get_documents_list(query, max_sources, where)\n",
    "        query_oneline = query.replace(\"\\n\", \" \")\n",
    "        prompt = f\"\"\"You're an expert writer. You understand how to interpret html and markdown. You will accept the\n",
    "        question below and answer based only on the passages. Never mention the passages in your answers. Be sure to \n",
    "        respond in concise sentences. Include all relevant background information when possible. If a passage is not \n",
    "        relevant to the answer you must ignore it. If no passage answers the question respond with: I don't know.\n",
    "\n",
    "        QUESTION: {query_oneline}\n",
    "        \n",
    "        \"\"\"\n",
    "        # Add the retrieved documents to the prompt.\n",
    "        stored_docs = [passage.docs for passage in stored]\n",
    "        for passage in stored_docs if passages is None else stored_docs + passages:\n",
    "            passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "            prompt += f\"PASSAGE: {passage_oneline}\\n\"\n",
    "        # Generate the response.\n",
    "        response = api.retriable(\n",
    "            self.client.models.generate_content,\n",
    "            model=api(Api.Model.GEN),\n",
    "            config=self.config_temp,\n",
    "            contents=prompt)\n",
    "        # Check for generated code and store in memory.\n",
    "        content = response.candidates[0].content\n",
    "        if len(content.parts) > 1 and content.parts[0].executable_code:\n",
    "            memory.append_code(prompt, content.parts)\n",
    "        return response\n",
    "\n",
    "    def stored_result(self, result, is_query: bool = False) -> list[VectorStoreResult]:\n",
    "        try:\n",
    "            results = []\n",
    "            if len(result[\"documents\"]) == 0:\n",
    "                return results\n",
    "            if isinstance(result[\"documents\"][0], list):\n",
    "                for i in range(len(result[\"documents\"][0])):\n",
    "                    obj = VectorStoreResult(docs=result[\"documents\"][0][i],\n",
    "                                            dist=result[\"distances\"][0][i] if is_query else None,\n",
    "                                            meta=result[\"metadatas\"][0][i],\n",
    "                                            store_id=result[\"ids\"][0][i])\n",
    "                    results.append(obj)\n",
    "            else:\n",
    "                results.append(\n",
    "                    VectorStoreResult(docs=result[\"documents\"][0],\n",
    "                                      dist=result[\"distances\"][0] if is_query else None,\n",
    "                                      meta=result[\"metadatas\"][0],\n",
    "                                      store_id=result[\"ids\"][0]))\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiki Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:51.976125Z",
     "iopub.status.busy": "2025-11-24T21:25:51.975769Z",
     "iopub.status.idle": "2025-11-24T21:25:51.987874Z",
     "shell.execute_reply": "2025-11-24T21:25:51.986521Z",
     "shell.execute_reply.started": "2025-11-24T21:25:51.976092Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: wiki-grounding generation.\n",
    "# - using gemini-2.0-flash for response generation\n",
    "# - using a RAG-implementation to store groundings\n",
    "# - create new groundings by similarity to topic\n",
    "# - retrieve existing groundings by similarity to topic\n",
    "class WikiGroundingGenerator:   \n",
    "    def __init__(self, genai_client, rag_impl):\n",
    "        self.client = genai_client\n",
    "        self.rag = rag_impl\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\") # suppress beta-warning\n",
    "            self.splitter = HTMLSemanticPreservingSplitter(\n",
    "                headers_to_split_on=[(\"h2\", \"Main Topic\"), (\"h3\", \"Sub Topic\")],\n",
    "                separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \"],\n",
    "                max_chunk_size=Api.Const.ChunkMax(),\n",
    "                chunk_overlap=50,\n",
    "                preserve_links=True,\n",
    "                preserve_images=True,\n",
    "                preserve_videos=True,\n",
    "                preserve_audio=True,\n",
    "                elements_to_preserve=[\"table\", \"ul\", \"ol\", \"code\"],\n",
    "                denylist_tags=[\"script\", \"style\", \"head\"],\n",
    "                custom_handlers={\"code\": self.code_handler},\n",
    "            )\n",
    "\n",
    "    def generate_answer(self, query: str, topic: str):\n",
    "        stored = self.rag.get_wiki_documents(topic)\n",
    "        if len(stored) > 0:\n",
    "            return self.rag.generate_with_wiki_passages(query, topic, [chunk.docs for chunk in stored]).text\n",
    "        else:\n",
    "            pages = wikipedia.search(topic + \" company\")\n",
    "            if len(pages) > 0:\n",
    "                p_topic_match = 0.80\n",
    "                for i in range(len(pages)):\n",
    "                    if tqdm(api.similarity([topic + \" company\", pages[i]]) > p_topic_match, \n",
    "                            desc= \"Score wiki search by similarity to topic\"):\n",
    "                        page_html = Api.get(f\"https://en.wikipedia.org/wiki/{pages[i]}\")\n",
    "                        chunks = [chunk.page_content for chunk in self.splitter.split_text(page_html)]\n",
    "                        self.rag.add_wiki_documents(topic, chunks)\n",
    "                        return self.rag.generate_with_wiki_passages(query, topic, chunks).text\n",
    "            return Api.Const.Stop()\n",
    "\n",
    "    def code_handler(self, element: Tag) -> str:\n",
    "        data_lang = element.get(\"data-lang\")\n",
    "        code_format = f\"<code:{data_lang}>{element.get_text()}</code>\"\n",
    "        return code_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:51.989657Z",
     "iopub.status.busy": "2025-11-24T21:25:51.989244Z",
     "iopub.status.idle": "2025-11-24T21:25:52.022288Z",
     "shell.execute_reply": "2025-11-24T21:25:52.021242Z",
     "shell.execute_reply.started": "2025-11-24T21:25:51.989629Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: search-grounding generation.\n",
    "# - using gemini-2.0-flash with GoogleSearch tool for response generation\n",
    "# - using a RAG-implementation to store groundings\n",
    "# - create new groundings by exact match to topic\n",
    "# - retrieve existing groundings by similarity to topic\n",
    "class SearchGroundingGenerator:\n",
    "    config_ground = types.GenerateContentConfig(\n",
    "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    \n",
    "    def __init__(self, genai_client, rag_impl):\n",
    "        self.client = genai_client\n",
    "        self.rag = rag_impl\n",
    "\n",
    "    def generate_answer(self, query: str, topic: str):\n",
    "        stored = self.rag.get_grounding_documents(query, topic)\n",
    "        if len(stored) > 0:\n",
    "            for i in range(len(stored)):\n",
    "                meta_q = stored[i].meta[\"question\"]\n",
    "                p_ground_match = 0.95 # This can be really high ~ 95-97%\n",
    "                if tqdm(api.similarity([query, meta_q]) > p_ground_match,\n",
    "                        desc=\"Score similarity to stored grounding\"):\n",
    "                    return ast.literal_eval(stored[i].docs)\n",
    "        return self.get_grounding(query, topic)\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def get_grounding(self, query: str, topic: str):\n",
    "        contents = [types.Content(role=\"user\", parts=[types.Part(text=query)])]\n",
    "        contents += f\"\"\"\n",
    "        You're a search assistant that provides answers to questions about {topic}.\n",
    "        Do not discuss alternative topics of interest. Do not discuss similar topics.\n",
    "        You will provide answers that discuss only {topic}. \n",
    "        You may discuss the owner or parent of {topic} when no other answer is possible.\n",
    "        Otherwise respond with: I don't know.\"\"\"\n",
    "        response = api.retriable(self.client.models.generate_content, \n",
    "                                 model=api(Api.Model.GEN), \n",
    "                                 config=self.config_ground, \n",
    "                                 contents=contents)\n",
    "        if response.candidates[0].grounding_metadata.grounding_supports is not None:\n",
    "            if self.is_consistent(query, topic, response.text):\n",
    "                self.rag.add_grounded_document(query, topic, response)\n",
    "                return response.text \n",
    "        return Api.Const.Stop() # Empty grounding supports or not consistent in response\n",
    "\n",
    "    def is_consistent(self, query: str, topic: str, model_response: str) -> bool:\n",
    "        topic = topic.replace(\"'\", \"\")\n",
    "        id_strs = topic.split()\n",
    "        if len(id_strs) == 1:\n",
    "            matches = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", query)\n",
    "            if len(matches) > 0:\n",
    "                topic = matches[0]\n",
    "        compound_match = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", model_response)\n",
    "        model_response = model_response.replace(\"'\", \"\")\n",
    "        if len(compound_match) == 0 and topic in model_response:\n",
    "            return True # not a compound topic id and exact topic match\n",
    "        for match in compound_match:\n",
    "            if topic not in match:\n",
    "                return False\n",
    "        return True # all prefix matches contained topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:52.023537Z",
     "iopub.status.busy": "2025-11-24T21:25:52.023271Z",
     "iopub.status.idle": "2025-11-24T21:25:52.050795Z",
     "shell.execute_reply": "2025-11-24T21:25:52.049654Z",
     "shell.execute_reply.started": "2025-11-24T21:25:52.023518Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Rest api-helpers to manage request-per-minute limits.\n",
    "# - define an entry for each endpoint limit\n",
    "# - init rest tool with limits to create blocking queues\n",
    "# - apply a limit to requests with rest_tool.try_url\n",
    "class ApiLimit(Enum):\n",
    "    FINN = \"finnhub.io\",50\n",
    "    POLY = \"polygon.io\",4 # (id_url,rpm)\n",
    "\n",
    "class BlockingUrlQueue:\n",
    "    on_cooldown = False\n",
    "    cooldown = None\n",
    "    cooldown_start = None\n",
    "    \n",
    "    def __init__(self, rest_fn: Callable, per_minute: int):\n",
    "        self.per_minute_max = per_minute\n",
    "        self.quota = per_minute\n",
    "        self.rest_fn = rest_fn\n",
    "\n",
    "    def push(self, rest_url: str):\n",
    "        if not self.on_cooldown:\n",
    "            self.cooldown = Timer(60, self.reset_quota)\n",
    "            self.cooldown.start()\n",
    "            self.cooldown_start = time.time()\n",
    "            self.on_cooldown = True\n",
    "        if self.quota > 0:\n",
    "            self.quota -= 1\n",
    "            time.sleep(0.034) # ~30 requests per second\n",
    "            return self.rest_fn(rest_url)\n",
    "        else:\n",
    "            print(f\"limited {self.per_minute_max}/min, waiting {self.limit_expiry()}s\")\n",
    "            time.sleep(max(self.limit_expiry(),0.5))\n",
    "            return self.push(rest_url)\n",
    "\n",
    "    def reset_quota(self):\n",
    "        self.quota = self.per_minute_max\n",
    "        self.on_cooldown = False\n",
    "        self.cooldown_start = None\n",
    "\n",
    "    def limit_expiry(self):\n",
    "        if self.cooldown_start:\n",
    "            return max(60-(time.time()-self.cooldown_start),0)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:52.052564Z",
     "iopub.status.busy": "2025-11-24T21:25:52.052067Z",
     "iopub.status.idle": "2025-11-24T21:25:52.099258Z",
     "shell.execute_reply": "2025-11-24T21:25:52.098213Z",
     "shell.execute_reply.started": "2025-11-24T21:25:52.052536Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: rest-grounding generation.\n",
    "# - using gemini-2.0-flash for response generation\n",
    "# - using a RAG-implementation to store groundings\n",
    "# - reduce long-context by chunked pre-processing\n",
    "class RestGroundingGenerator:    \n",
    "    limits = None\n",
    "\n",
    "    def __init__(self, rag_impl, with_limits: bool):\n",
    "        self.rag = rag_impl\n",
    "        if with_limits:\n",
    "            self.limits = {}\n",
    "            for rest_api in ApiLimit:\n",
    "                self.limits[rest_api.value[0]] = BlockingUrlQueue(Api.get, rest_api.value[1])\n",
    "\n",
    "    def get_limit(self, rest_api: ApiLimit) -> Optional[BlockingUrlQueue]:\n",
    "        return self.limits[rest_api.value[0]] if self.limits else None\n",
    "\n",
    "    def basemodel(self, data: str, schema: BaseModel, from_lambda: bool = False) -> Optional[BaseModel]:\n",
    "        try:\n",
    "            if from_lambda:\n",
    "                return schema(results=json.loads(data))\n",
    "            return schema.model_validate_json(data)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def dailycandle(self, data: str) -> Optional[DailyCandle]:\n",
    "        try:\n",
    "            candle = json.loads(data)\n",
    "            if \"from\" not in candle:\n",
    "                raise ValueError(\"not a dailycandle / missing value for date\")\n",
    "            agg = self.basemodel(data, Aggregate)\n",
    "            return DailyCandle(from_date=candle[\"from\"], \n",
    "                               status=agg.status.value, \n",
    "                               symbol=agg.symbol, \n",
    "                               open=agg.open, \n",
    "                               high=agg.high, \n",
    "                               low=agg.low, \n",
    "                               close=agg.close, \n",
    "                               volume=agg.volume, \n",
    "                               otc=agg.otc, \n",
    "                               preMarket=agg.preMarket, \n",
    "                               afterHours=agg.afterHours)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    @retry.Retry(timeout=600)\n",
    "    def try_url(self, url: str, schema: BaseModel, as_lambda: bool, with_limit: Optional[BlockingUrlQueue],\n",
    "                success_fn: Callable, *args, **kwargs):\n",
    "        try:\n",
    "            if self.limits is None:\n",
    "                data = Api.get(url)\n",
    "            elif with_limit:\n",
    "                data = with_limit.push(url)\n",
    "            if schema is DailyCandle:\n",
    "                model = self.dailycandle(data)\n",
    "            else:\n",
    "                model = self.basemodel(data, schema, as_lambda)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                print(f\"try_url exception: {e}\")\n",
    "                if issubclass(schema, RestResultPoly):\n",
    "                    return success_fn(*args, **kwargs, result=self.basemodel(data, RestResultPoly))\n",
    "            except Exception as not_a_result:\n",
    "                print(not_a_result)\n",
    "            return StopGeneration()\n",
    "        else:\n",
    "            return success_fn(*args, **kwargs, model=model)\n",
    "\n",
    "    def get_symbol_matches(self, with_content, by_name: bool, model: SymbolResult):\n",
    "        matches = []\n",
    "        max_failed_match = model.count if not by_name else 3\n",
    "        p_desc_match = 0.92\n",
    "        p_symb_match = 0.95\n",
    "        if model.count > 0:\n",
    "            for obj in tqdm(model.get(), desc=\"Score similarity to query\"):\n",
    "                if max_failed_match > 0:\n",
    "                    desc = [with_content[\"q\"].upper(), obj.description.split(\"-\", -1)[0]]\n",
    "                    symb = [with_content[\"q\"].upper(), obj.symbol]\n",
    "                    if by_name and api.similarity(desc) > p_desc_match: \n",
    "                        matches.append(obj.symbol)\n",
    "                    elif not by_name and api.similarity(symb) > p_symb_match:\n",
    "                        matches.append(obj.description)\n",
    "                        max_failed_match = 0\n",
    "                    else:\n",
    "                        max_failed_match -= 1\n",
    "        if len(matches) > 0:\n",
    "            self.rag.add_api_document(with_content[\"query\"], matches, with_content[\"q\"], \"get_symbol_1\")\n",
    "            return matches\n",
    "        return Api.Const.Stop()\n",
    "\n",
    "    def get_quote(self, with_content, model: Quote):\n",
    "        quote = model.model_dump_json()\n",
    "        self.rag.add_quote_document(with_content[\"query\"], quote, with_content[\"symbol\"], model.t, \"get_quote_1\")\n",
    "        return quote\n",
    "\n",
    "    def parse_financials(self, with_content, model: BasicFinancials):\n",
    "        metric = list(model.metric.items())\n",
    "        chunks = []\n",
    "        # Chunk the metric data.\n",
    "        for i in range(0, len(metric), Api.Const.MetricBatch()):\n",
    "            batch = metric[i:i + Api.Const.MetricBatch()]\n",
    "            chunks.append({\"question\": with_content[\"query\"], \"answer\": batch})\n",
    "        # Chunk the series data.\n",
    "        for key in model.series.keys():\n",
    "            series = list(model.series[key].items())\n",
    "            for s in series:\n",
    "                if api.token_count(s) <= Api.Const.ChunkMax():\n",
    "                    chunks.append({\"question\": with_content[\"query\"], \"answer\": s})\n",
    "                else:\n",
    "                    k = s[0]\n",
    "                    v = s[1]\n",
    "                    for i in range(0, len(v), Api.Const.SeriesBatch()):\n",
    "                        batch = v[i:i + Api.Const.SeriesBatch()]\n",
    "                        chunks.append({\"question\": with_content[\"query\"], \"answer\": {k: batch}})\n",
    "        self.rag.add_rest_chunks(chunks, topic=with_content[\"symbol\"], source=\"get_financials_1\")\n",
    "        return chunks\n",
    "\n",
    "    def parse_news(self, with_content, model: NewsResultFinn):\n",
    "        if model.count > 0:\n",
    "            metas = []\n",
    "            for digest in model.get():\n",
    "                pub_date = datetime.fromtimestamp(digest.datetime, tz=GeneratedEvent.tz()).strftime(\"%Y-%m-%d\")\n",
    "                metas.append({\"publisher\": digest.source,\n",
    "                              \"published_est\": parse(pub_date).timestamp(),\n",
    "                              \"news_id\": digest.id,\n",
    "                              \"related\": digest.related})\n",
    "            self.rag.add_rest_chunks(model.get(), topic=with_content[\"symbol\"], source=\"get_news_1\",\n",
    "                                     ids=[f\"{digest.id}+news\" for digest in model.get()],\n",
    "                                     meta_opt=metas, is_update=False)\n",
    "            return [digest.summary().model_dump_json() for digest in model.get()]\n",
    "        return Api.Const.Stop()\n",
    "\n",
    "    def parse_news(self, with_content, model: Optional[NewsResultPoly] = None,\n",
    "                   result: Optional[RestResultPoly] = None) -> tuple[list, str]: # list of summary, next list url\n",
    "        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n",
    "            metas = []\n",
    "            for news in model.get():\n",
    "                pub_date = parse(news.published_utc).strftime(\"%Y-%m-%d\")\n",
    "                metas.append({\"publisher\": news.publisher.name,\n",
    "                              \"published_utc\": parse(pub_date).timestamp(),\n",
    "                              \"news_id\": news.id,\n",
    "                              \"related\": json.dumps(news.tickers),\n",
    "                              \"keywords\": json.dumps(news.keywords)})\n",
    "            self.rag.add_rest_chunks(model.get(), topic=with_content[\"ticker\"], source=\"get_news_2\",\n",
    "                                     ids=[news.id for news in model.get()],\n",
    "                                     meta_opt=metas, is_update=False)\n",
    "            return [news.summary().model_dump_json() for news in model.get()], model.next_url\n",
    "        elif result:\n",
    "            return result.model_dump_json()\n",
    "\n",
    "    def parse_daily_candle(self, with_content, model: Optional[DailyCandle] = None,\n",
    "                           result: Optional[RestResultPoly] = None):\n",
    "        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n",
    "            self.rag.add_rest_chunks(\n",
    "                chunks=[model],\n",
    "                topic=with_content[\"stocksTicker\"],\n",
    "                source=\"daily_candle_2\",\n",
    "                meta_opt=[{\"from_date\": model.from_date, \"adjusted\": with_content[\"adjusted\"]}])\n",
    "            return model\n",
    "        elif result:\n",
    "            return result\n",
    "\n",
    "    def parse_custom_candle(self, with_content, model: Optional[CustomCandle] = None,\n",
    "                            result: Optional[RestResultPoly] = None):\n",
    "        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n",
    "            metas = [{\n",
    "                \"timespan\": with_content[\"timespan\"],\n",
    "                \"adjusted\": with_content[\"adjusted\"],\n",
    "                \"from\": with_content[\"from\"],\n",
    "                \"to\": with_content[\"to\"]}]*model.count\n",
    "            candles = [candle.model_dump_json() for candle in model.get()]\n",
    "            self.rag.add_rest_chunks(\n",
    "                chunks=candles,\n",
    "                topic=with_content[\"stocksTicker\"],\n",
    "                source=\"custom_candle_2\",\n",
    "                meta_opt=metas)\n",
    "            return candles\n",
    "        elif result:\n",
    "            return result.model_dump_json()\n",
    "\n",
    "    def parse_overview(self, with_content, model: OverviewResult):\n",
    "        overview = [model.get().model_dump_json()]\n",
    "        self.rag.add_rest_chunks(chunks=overview, topic=with_content[\"ticker\"], source=\"ticker_overview_2\")\n",
    "        return overview\n",
    "\n",
    "    def parse_trends(self, with_content, model: TrendsResult):\n",
    "        if model.count > 0:\n",
    "            metas = [{\"period\": trend.period} for trend in model.get()]\n",
    "            trends = [trend.model_dump_json() for trend in model.get()]\n",
    "            self.rag.add_rest_chunks(trends, topic=with_content[\"symbol\"], source=\"trends_1\", meta_opt=metas)\n",
    "            return trends\n",
    "        return Api.Const.Stop()\n",
    "\n",
    "    def augment_market_status(self, with_id: Optional[str], model: MarketStatusResult):\n",
    "        if model.get().holiday != MarketSession.NA.value:\n",
    "            self.rag.set_holiday_event(model.get().exchange)\n",
    "        events = self.rag.generated_events(model.get().exchange)\n",
    "        model.get().session = events.session()\n",
    "        model.get().isOpen = events.is_open()\n",
    "        meta = {\"exchange\": model.get().exchange,\n",
    "                \"last_close\": events.last_close,\n",
    "                \"pre_open\": events.pre_open,\n",
    "                \"reg_open\": events.reg_open,\n",
    "                \"reg_close\": events.reg_close,\n",
    "                \"post_close\": events.post_close,\n",
    "                \"timestamp\": events.timestamp }\n",
    "        self.rag.add_rest_chunks([model.get()],\n",
    "                                 topic=\"market_status\",\n",
    "                                 source=\"get_market_status_1\",\n",
    "                                 ids=[with_id] if with_id else None,\n",
    "                                 meta_opt=[meta])\n",
    "        return model.get().model_dump_json()\n",
    "\n",
    "    def get_symbol(self, content, by_name: bool = True):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/search?q={content['q']}&exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=SymbolResult,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.get_symbol_matches,\n",
    "            with_content=content,\n",
    "            by_name=by_name)\n",
    "\n",
    "    def get_current_price(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/quote?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=Quote,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.get_quote,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_market_status(self, content, store_id: Optional[str] = None):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/market-status?exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=MarketStatusResult,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.augment_market_status,\n",
    "            with_id=store_id)\n",
    "\n",
    "    def get_peers(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/peers?symbol={content['symbol']}&grouping={content['grouping']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=PeersResult,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=lambda model: model)\n",
    "\n",
    "    def get_basic_financials(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/metric?symbol={content['symbol']}&metric={content['metric']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=BasicFinancials,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.parse_financials,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_news_simple(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/company-news?symbol={content['symbol']}&from={content['from']}&to={content['to']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=NewsResultFinn,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.parse_news,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_news_tagged(self, content):\n",
    "        next_url = f\"https://api.polygon.io/v2/reference/news?ticker={content['ticker']}&published_utc.gte={content['published_utc.gte']}&published_utc.lte={content['published_utc.lte']}&order={content['order']}&limit={content['limit']}&sort={content['sort']}&apiKey={POLYGON_API_KEY}\"\n",
    "        news = []\n",
    "        while True:\n",
    "            news_list, next_url = self.try_url(\n",
    "                next_url,\n",
    "                schema=NewsResultPoly,\n",
    "                as_lambda=False,\n",
    "                with_limit=self.get_limit(ApiLimit.POLY),\n",
    "                success_fn=self.parse_news,\n",
    "                with_content=content)\n",
    "            news += news_list\n",
    "            if next_url is None:\n",
    "                break\n",
    "            next_url += f\"&apiKey={POLYGON_API_KEY}\"\n",
    "        return news\n",
    "\n",
    "    def get_daily_candle(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://api.polygon.io/v1/open-close/{content['stocksTicker']}/{content['date']}?adjusted={content['adjusted']}&apiKey={POLYGON_API_KEY}\",\n",
    "            schema=DailyCandle,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.POLY),\n",
    "            success_fn=self.parse_daily_candle,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_custom_candle(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://api.polygon.io/v2/aggs/ticker/{content['stocksTicker']}/range/{content['multiplier']}/{content['timespan']}/{content['from']}/{content['to']}?adjusted={content['adjusted']}&sort={content['sort']}&limit={content['limit']}&apiKey={POLYGON_API_KEY}\",\n",
    "            schema=CustomCandle,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.POLY),\n",
    "            success_fn=self.parse_custom_candle,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_overview(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://api.polygon.io/v3/reference/tickers/{content['ticker']}?apiKey={POLYGON_API_KEY}\",\n",
    "            schema=OverviewResult,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.POLY),\n",
    "            success_fn=self.parse_overview,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_trends_simple(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/recommendation?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=TrendsResult,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.parse_trends,\n",
    "            with_content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callable Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:52.100883Z",
     "iopub.status.busy": "2025-11-24T21:25:52.100514Z",
     "iopub.status.idle": "2025-11-24T21:25:52.135917Z",
     "shell.execute_reply": "2025-11-24T21:25:52.13482Z",
     "shell.execute_reply.started": "2025-11-24T21:25:52.100856Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Callable functions in openapi schema.\n",
    "decl_get_symbol_1 = types.FunctionDeclaration(\n",
    "    name=\"get_symbol_1\",\n",
    "    description=\"\"\"Search for the stock ticker symbol of a given company, security, isin or cusip. Each ticker\n",
    "                   entry provides a description, symbol, and asset type. If this doesn't help you should try \n",
    "                   calling get_wiki_tool_response next.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"A ticker symbol to search for.\"\"\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"q\", \"exchange\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_symbols_1 = types.FunctionDeclaration(\n",
    "    name=\"get_symbols_1\",\n",
    "    description=\"\"\"List all supported symbols and tickers. The results are filtered by exchange code.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter the results.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"exchange\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_name_1 = types.FunctionDeclaration(\n",
    "    name=\"get_name_1\",\n",
    "    description=\"\"\"Search for the name associated with a stock ticker or symbol's company, security, isin or cusip. \n",
    "    Each ticker entry provides a description, matching symbol, and asset type.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The symbol or ticker to search for.\"\"\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            },\n",
    "            \"company\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The company you're searching for.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"q\", \"exchange\", \"query\", \"company\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_symbol_quote_1 = types.FunctionDeclaration(\n",
    "    name=\"get_symbol_quote_1\",\n",
    "    description=\"\"\"Search for the current price or quote of a stock ticker or symbol. The response is\n",
    "                   provided in json format. Each response contains the following key-value pairs:\n",
    "                   \n",
    "                   c: Current price,\n",
    "                   d: Change,\n",
    "                  dp: Percent change,\n",
    "                   h: High price of the day,\n",
    "                   l: Low price of the day,\n",
    "                   o: Open price of the day,\n",
    "                  pc: Previous close price,\n",
    "                   t: Epoch timestamp of price in seconds.\n",
    "\n",
    "                   Parse the response and respond according to this information.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The stock ticker symbol for a company, security, isin, or cusip.\" \n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The exchange code used to filter quotes. This must always be 'US'.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"query\", \"exchange\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_local_datetime = types.FunctionDeclaration(\n",
    "    name=\"get_local_datetime\",\n",
    "    description=\"\"\"Converts an array of timestamps from epoch time to the local timezone format. The result is an array\n",
    "                   of date and time in locale appropriate format. Suitable for use in a locale appropriate response.\n",
    "                   Treat this function as a vector function. Always prefer to batch timestamps for conversion. Use this\n",
    "                   function to format date and time in your responses.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"t\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"\"\"An array of timestamps in seconds since epoch to be converted. The order of\n",
    "                                  timestamps matches the order of conversion.\"\"\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"integer\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"t\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_market_status_1 = types.FunctionDeclaration(\n",
    "    name=\"get_market_status_1\",\n",
    "    description=\"\"\"Get the current market status of global exchanges. Includes whether exchanges are open or closed.  \n",
    "                   Also includes holiday details if applicable. The response is provided in json format. Each response \n",
    "                   contains the following key-value pairs:\n",
    "\n",
    "                   exchange: Exchange code,\n",
    "                   timezone: Timezone of the exchange,\n",
    "                    holiday: Holiday event name, or null if it's not a holiday,\n",
    "                     isOpen: Whether the market is open at the moment,\n",
    "                          t: Epoch timestamp of status in seconds (Eastern Time),\n",
    "                    session: The market session can be 1 of the following values: \n",
    "                    \n",
    "                    pre-market,regular,post-market when open, or null if closed.\n",
    "                    \n",
    "                    Parse the response and respond according to this information.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"exchange\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_market_session_1 = types.FunctionDeclaration(\n",
    "    name=\"get_market_session_1\",\n",
    "    description=\"Get the current market session of global exchanges.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"exchange\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_company_peers_1 = types.FunctionDeclaration(\n",
    "    name=\"get_company_peers_1\",\n",
    "    description=\"\"\"Search for a company's peers. Returns a list of peers operating in the same country and in the same\n",
    "                   sector, industry, or subIndustry. Each response contains the following key-value pairs: \n",
    "                   \n",
    "                   symbol: The company's stock ticker symbol, \n",
    "                   peers: A list containing the peers.\n",
    "                   \n",
    "                   Each peers entry contains the following key-value pairs:\n",
    "                   \n",
    "                   symbol: The peer company's stock ticker symbol, \n",
    "                   name: The peer company's name.\n",
    "                   \n",
    "                   Parse the response and respond according to this information.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The stock ticker symbol of a company to obtain peers.\"\n",
    "            },\n",
    "            \"grouping\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"This parameter may be one of the following values: sector, industry, subIndustry.\n",
    "                                  Always use subIndustry unless told otherwise.\"\"\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"grouping\", \"exchange\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_exchange_codes_1 = types.FunctionDeclaration(\n",
    "    name=\"get_exchange_codes_1\",\n",
    "    description=\"\"\"Get a dictionary mapping all supported exchange codes to their names.\"\"\"\n",
    ")\n",
    "\n",
    "decl_get_exchange_code_1 = types.FunctionDeclaration(\n",
    "    name=\"get_exchange_code_1\",\n",
    "    description=\"\"\"Search for the exchange code to use when filtering by exchange. The result will be one or\n",
    "                   more exchange codes provided as a comma-separated string value.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Specifies which exchange code to search for.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"q\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_financials_1 = types.FunctionDeclaration(\n",
    "    name=\"get_financials_1\",\n",
    "    description=\"\"\"Get company basic financials such as margin, P/E ratio, 52-week high/low, etc. Parse the response for \n",
    "                   key-value pairs in json format and interpret their meaning as stock market financial indicators.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol for a company.\"\n",
    "            },\n",
    "            \"metric\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"It must always be declared as the value 'all'\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"metric\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_daily_candlestick_2 = types.FunctionDeclaration(\n",
    "    name=\"get_daily_candlestick_2\",\n",
    "    description=\"\"\"Get a historical daily stock ticker candlestick / aggregate bar (OHLC). \n",
    "                   Includes historical daily open, high, low, and close prices. Also includes historical daily trade\n",
    "                   volume and pre-market/after-hours trade prices. It provides the last trading days' data after \n",
    "                   11:59PM Eastern Time.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"stocksTicker\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The stock ticker symbol of a company to search for.\",\n",
    "            },\n",
    "            \"date\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"The date of the requested candlestick in format YYYY-MM-DD.\"\"\"\n",
    "            },\n",
    "            \"adjusted\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n",
    "                                  Use true unless told otherwise.\"\"\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"stocksTicker\", \"date\", \"adjusted\", \"exchange\", \"query\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "decl_get_company_news_1 = types.FunctionDeclaration(\n",
    "    name=\"get_company_news_1\",\n",
    "    description=\"Retrieve the most recent news articles related to a specified ticker.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol for a company.\",\n",
    "            },\n",
    "            \"from\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be older than the parameter 'to'.\"\"\"\n",
    "            },\n",
    "            \"to\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be more recent than the parameter 'from'. The\n",
    "                                  default value is today's date.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"from\", \"to\", \"query\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "decl_get_custom_candlestick_2 = types.FunctionDeclaration(\n",
    "    name=\"get_custom_candlestick_2\",\n",
    "    description=\"\"\"Get a historical stock ticker candlestick / aggregate bar (OHLC) over a custom date range and \n",
    "                   time interval in Eastern Time. Includes historical open, high, low, and close prices. Also \n",
    "                   includes historical daily trade volume and pre-market/after-hours trade prices. It includes \n",
    "                   the last trading days' data after 11:59PM Eastern Time.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"stocksTicker\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The stock ticker symbol of a company to search for.\",\n",
    "            },\n",
    "            \"multiplier\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"This must be included and equal to 1 unless told otherwise.\"\n",
    "            },\n",
    "            \"timespan\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The size of the candlestick's time window. This is allowed to be one of the following:\n",
    "                                  second, minute, hour, day, week, month, quarter, or year. The default value is day.\"\"\"\n",
    "            },\n",
    "            \"from\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'to'.\"\"\"\n",
    "            },\n",
    "            \"to\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'from'. The \n",
    "                                  default is one weekday before get_last_market_close.\n",
    "                                  Replace more recent dates with the default.\"\"\"\n",
    "            },\n",
    "            \"adjusted\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n",
    "                                  Use true unless told otherwise.\"\"\"\n",
    "            },\n",
    "            \"sort\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"This must be included. May be one of asc or desc. asc will sort by timestmap in \n",
    "                                  ascending order. desc will sort by timestamp in descending order.\"\"\"\n",
    "            },\n",
    "            \"limit\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"\"\"Set the number of base aggregates used to create this candlestick. This must be 5000 \n",
    "                                  unless told to limit base aggregates to something else.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"stocksTicker\", \"multiplier\", \"timespan\", \"from\", \"to\", \"adjusted\", \"sort\", \"limit\", \"query\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "decl_get_last_market_close = types.FunctionDeclaration(\n",
    "    name=\"get_last_market_close\",\n",
    "    description=\"\"\"Get the last market close of the specified exchange in Eastern Time. The response has already\n",
    "                   been converted by get_local_datetime so this step should be skipped.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"exchange\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_ticker_overview_2 = types.FunctionDeclaration(\n",
    "    name=\"get_ticker_overview_2\",\n",
    "    description=\"\"\"Retrieve comprehensive details for a single ticker symbol. It's a deep look into a company’s \n",
    "    fundamental attributes, including its primary exchange, standardized identifiers (CIK, composite FIGI, \n",
    "    share class FIGI), market capitalization, industry classification, and key dates. Also includes branding assets in\n",
    "    the form of icons and logos.\n",
    "    \"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"ticker\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol of a company.\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"ticker\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_recommendation_trends_1 = types.FunctionDeclaration(\n",
    "    name=\"get_recommendation_trends_1\",\n",
    "    description=\"\"\"Get the latest analyst recommendation trends for a company.\n",
    "                The data includes the latest recommendations as well as historical\n",
    "                recommendation data for each month. The data is classified according\n",
    "                to these categories: strongBuy, buy, hold, sell, and strongSell.\n",
    "                The date of a recommendation indicated by the value of 'period'.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol for a company.\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_news_with_sentiment_2 = types.FunctionDeclaration(\n",
    "    name=\"get_news_with_sentiment_2\",\n",
    "    description=\"\"\"Retrieve the most recent news articles related to a specified ticker. Each article includes \n",
    "                   comprehensive coverage. Including a summary, publisher information, article metadata, \n",
    "                   and sentiment analysis.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"ticker\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol for a company.\"\n",
    "            },\n",
    "            \"published_utc.gte\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'published_utc.lte'. \n",
    "                                  The default value is one-month ago from today's date.\"\"\"\n",
    "            },\n",
    "            \"published_utc.lte\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'published_utc.gte'.\n",
    "                                  The default is one weekday prior to get_last_market_close (excluding weekends).\n",
    "                                  Replace more recent dates with the default.\"\"\"\n",
    "            },\n",
    "            \"order\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"Must be desc for descending order, or asc for ascending order.\n",
    "                                  When order is not specified the default is descending order.\n",
    "                                  Ordering will be based on the parameter 'sort'.\"\"\"\n",
    "            },\n",
    "            \"limit\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"\"\"This must be included and equal to 1000 unless told otherwise.\"\"\"\n",
    "            },\n",
    "            \"sort\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The sort field used for ordering. This value must\n",
    "                                  always be published_utc.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"limit\", \"ticker\", \"published_utc.gte\", \"published_utc.lte\", \"order\", \"sort\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_rag_tool_response = types.FunctionDeclaration(\n",
    "    name=\"get_rag_tool_response\",\n",
    "    description=\"\"\"A database containing useful financial information. Always check here for answers first.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"A question needing an answer. Asked as a simple string.\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_wiki_tool_response = types.FunctionDeclaration(\n",
    "    name=\"get_wiki_tool_response\",\n",
    "    description=\"\"\"Answers questions that still have unknown answers. Retrieve a wiki page related to a company, \n",
    "                   product, or service. Each web page includes detailed company information, financial indicators, \n",
    "                   tickers, symbols, history, and products and services.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question's company or product. Just the name and no other details.\"\n",
    "            },\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The complete, unaltered, query string.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"id\", \"q\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_search_tool_response = types.FunctionDeclaration(\n",
    "    name=\"get_search_tool_response\",\n",
    "    description=\"Answers questions that still have unknown answers. Use it after checking all your other tools.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question needing an answer. Asked as a simple string.\"\n",
    "            },\n",
    "            \"id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question's company or product. In one word. Just the name and no other details.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"q\", \"id\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:52.137203Z",
     "iopub.status.busy": "2025-11-24T21:25:52.136939Z",
     "iopub.status.idle": "2025-11-24T21:25:52.334516Z",
     "shell.execute_reply": "2025-11-24T21:25:52.333601Z",
     "shell.execute_reply.started": "2025-11-24T21:25:52.13718Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import the finance api secret keys.\n",
    "\n",
    "POLYGON_API_KEY = UserSecretsClient().get_secret(\"POLYGON_API_KEY\")\n",
    "FINNHUB_API_KEY = UserSecretsClient().get_secret(\"FINNHUB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:52.335724Z",
     "iopub.status.busy": "2025-11-24T21:25:52.335436Z",
     "iopub.status.idle": "2025-11-24T21:25:53.339353Z",
     "shell.execute_reply": "2025-11-24T21:25:53.338494Z",
     "shell.execute_reply.started": "2025-11-24T21:25:52.335681Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate document embedding: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tools and load the exchange data from source csv.\n",
    "# - Identifies exchanges by a 1-2 letter code which can be used to filter response data.\n",
    "# - Also maps the exchange code to exchange details.\n",
    "try:\n",
    "    df = pandas.read_csv(\"/kaggle/input/exchanges/exchanges_src.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    df = pandas.read_csv(\"exchanges_src.csv\") # local run\n",
    "df = df.drop([\"close_date\"], axis=1).fillna(\"\")\n",
    "df.to_csv(\"exchanges.csv\", index=False)\n",
    "exchanges = CSVLoader(file_path=\"exchanges.csv\", encoding=\"utf-8\", csv_args={\"delimiter\": \",\"}).load()\n",
    "\n",
    "# Prepare a RAG tool for use and add the exchange data.\n",
    "tool_rag = RetrievalAugmentedGenerator(api.args.CLIENT, \"finance\")\n",
    "tool_rag.add_documents_list(exchanges)\n",
    "\n",
    "# Prepare a the grounding tools for use.\n",
    "tool_wiki = WikiGroundingGenerator(api.args.CLIENT, tool_rag)\n",
    "tool_ground = SearchGroundingGenerator(api.args.CLIENT, tool_rag)\n",
    "tool_rest = RestGroundingGenerator(tool_rag, with_limits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:53.341219Z",
     "iopub.status.busy": "2025-11-24T21:25:53.340768Z",
     "iopub.status.idle": "2025-11-24T21:25:53.37221Z",
     "shell.execute_reply": "2025-11-24T21:25:53.370999Z",
     "shell.execute_reply.started": "2025-11-24T21:25:53.341196Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Implement the callable functions and function handler.\n",
    "\n",
    "def ask_rag_tool(content):\n",
    "    return tool_rag.generate_answer(content[\"question\"]).text\n",
    "\n",
    "def ask_wiki_tool(content):\n",
    "    return tool_wiki.generate_answer(content[\"q\"], content[\"id\"])\n",
    "\n",
    "def ask_search_tool(content):\n",
    "    return tool_ground.generate_answer(content[\"q\"], content[\"id\"])\n",
    "\n",
    "def get_exchange_codes_1(content):\n",
    "    return tool_rag.get_exchange_codes()\n",
    "\n",
    "def get_exchange_code_1(content):\n",
    "    return tool_rag.get_exchange_codes(with_query=content)\n",
    "    \n",
    "def last_market_close(content):\n",
    "    return tool_rag.last_market_close(content[\"exchange\"])\n",
    "    \n",
    "def get_symbol_1(content, by_name: bool = True):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"q\"], \"get_symbol_1\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_symbol(content, by_name)\n",
    "    return json.loads(stored[0].docs)\n",
    "\n",
    "def get_symbols_1(content):\n",
    "    return None # todo\n",
    "\n",
    "def get_name_1(content):\n",
    "    return get_symbol_1(content, by_name = False)\n",
    "\n",
    "def get_quote_1(content):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_quote_1\")\n",
    "    if tool_rag.generated_events(content[\"exchange\"]).is_open():\n",
    "        return get_current_price_1(content)\n",
    "    elif len(stored) > 0:\n",
    "        last_close = parse(tool_rag.last_market_close(content[\"exchange\"])).timestamp()\n",
    "        for quote in stored:\n",
    "            if quote.meta[\"timestamp\"] >= last_close:\n",
    "                return [quote.docs for quote in stored]\n",
    "    return get_current_price_1(content)\n",
    "\n",
    "def get_current_price_1(content):\n",
    "    return tool_rest.get_current_price(content)\n",
    "\n",
    "def get_market_status_1(content):\n",
    "    stored, has_update = tool_rag.get_market_status(content['exchange'])\n",
    "    if has_update:\n",
    "        with_id = stored[0].store_id if len(stored) > 0 else None\n",
    "        return tool_rest.get_market_status(content, with_id)\n",
    "    return stored[0].docs\n",
    "\n",
    "def get_session_1(content):\n",
    "    return json.loads(get_market_status_1(content))[\"session\"]\n",
    "\n",
    "def get_peers_1(content):\n",
    "    stored = tool_rag.get_peers_document(content[\"query\"], content[\"symbol\"], content['grouping'])\n",
    "    if len(stored) == 0:\n",
    "        peers = tool_rest.get_peers(content)\n",
    "        if peers.count > 0:\n",
    "            names = []\n",
    "            for peer in peers.get():\n",
    "                if peer == content[\"symbol\"]:\n",
    "                    continue # skip including the query symbol in peers\n",
    "                name = get_name_1(dict(q=peer, exchange=content[\"exchange\"], query=content[\"query\"]))\n",
    "                if name != Api.Const.Stop():\n",
    "                    data = {\"symbol\": peer, \"name\": name}\n",
    "                    names.append(data)\n",
    "            tool_rag.add_peers_document(content[\"query\"], names, content[\"symbol\"], \"get_peers_1\", content['grouping'])\n",
    "            return names\n",
    "        return Api.Const.Stop()\n",
    "    return json.loads(stored[0].docs)[\"peers\"]\n",
    "\n",
    "def local_datetime(content):\n",
    "    local_t = []\n",
    "    for timestamp in content[\"t\"]:\n",
    "        local_t.append(local_date_from_epoch(timestamp))\n",
    "    return local_t\n",
    "\n",
    "def local_date_from_epoch(timestamp):\n",
    "    if len(str(timestamp)) == 13:\n",
    "        return datetime.fromtimestamp(timestamp/1000, tz=GeneratedEvent.tz()).strftime('%c')\n",
    "    else:\n",
    "        return datetime.fromtimestamp(timestamp, tz=GeneratedEvent.tz()).strftime('%c')\n",
    "\n",
    "def get_financials_1(content):\n",
    "    stored = tool_rag.get_basic_financials(content[\"query\"], content[\"symbol\"], \"get_financials_1\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_basic_financials(content)\n",
    "    return [chunk.docs for chunk in stored]\n",
    "\n",
    "def get_news_1(content):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_news_1\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_news_simple(content)\n",
    "    return [NewsTypeFinn.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n",
    "\n",
    "def get_daily_candle_2(content):\n",
    "    stored = tool_rag.get_api_documents(\n",
    "        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"daily_candle_2\", \n",
    "        meta_opt=[{\"from_date\": content[\"date\"], \"adjusted\": content[\"adjusted\"]}])\n",
    "    if len(stored) == 0:\n",
    "        candle = tool_rest.get_daily_candle(content)\n",
    "        # Attempt to recover from choosing a holiday.\n",
    "        candle_date = parse(content[\"date\"])\n",
    "        if candle.status is RestStatus.NONE and candle_date.weekday() == 0 or candle_date.weekday() == 4:\n",
    "            if candle_date.weekday() == 0: # index 0 is monday, index 4 is friday\n",
    "                content[\"date\"] = candle_date.replace(day=candle_date.day-3).strftime(\"%Y-%m-%d\")\n",
    "            else:\n",
    "                content[\"date\"] = candle_date.replace(day=candle_date.day-1).strftime(\"%Y-%m-%d\")\n",
    "            return get_daily_candle_2(content)\n",
    "        return candle.model_dump_json()\n",
    "    return [json.loads(candle.docs) for candle in stored]\n",
    "\n",
    "def get_custom_candle_2(content):\n",
    "    stored = tool_rag.get_api_documents(\n",
    "        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"custom_candle_2\", \n",
    "        meta_opt=[{\n",
    "            \"timespan\": content[\"timespan\"],\n",
    "            \"adjusted\": content[\"adjusted\"],\n",
    "            \"from\": content[\"from\"],\n",
    "            \"to\": content[\"to\"]}])\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_custom_candle(content)\n",
    "    return [json.loads(candle.docs) for candle in stored]\n",
    "\n",
    "def get_overview_2(content):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"ticker\"], \"ticker_overview_2\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_overview(content)\n",
    "    return json.loads(stored[0].docs)\n",
    "\n",
    "def get_trends_1(content):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"trends_1\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_trends_simple(content)\n",
    "    return [json.loads(trend.docs) for trend in stored]\n",
    "\n",
    "def get_news_2(content):\n",
    "    timestamp_from = parse(content[\"published_utc.gte\"]).timestamp()\n",
    "    timestamp_to = parse(content[\"published_utc.lte\"]).timestamp()\n",
    "    news_from = tool_rag.get_api_documents(\n",
    "        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_from}])\n",
    "    news_to = tool_rag.get_api_documents(\n",
    "        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_to}])\n",
    "    if len(news_from) > 0 and len(news_to) > 0:\n",
    "        stored = tool_rag.get_api_documents(\n",
    "            content[\"query\"], content[\"ticker\"], \"get_news_2\",\n",
    "            [{\"published_utc\": {\"$gte\": timestamp_from}},\n",
    "             {\"published_utc\": {\"$lte\": timestamp_to}}])\n",
    "        return [NewsTypePoly.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n",
    "    return tool_rest.get_news_tagged(content)\n",
    "        \n",
    "finance_tool = types.Tool(\n",
    "    function_declarations=[\n",
    "        decl_get_symbol_1,\n",
    "        decl_get_symbols_1,\n",
    "        decl_get_name_1,\n",
    "        decl_get_symbol_quote_1,\n",
    "        decl_get_market_status_1,\n",
    "        decl_get_market_session_1,\n",
    "        decl_get_company_peers_1,\n",
    "        decl_get_local_datetime,\n",
    "        decl_get_last_market_close,\n",
    "        decl_get_exchange_codes_1,\n",
    "        decl_get_exchange_code_1,\n",
    "        decl_get_financials_1,\n",
    "        decl_get_daily_candlestick_2,\n",
    "        decl_get_custom_candlestick_2,\n",
    "        decl_get_ticker_overview_2,\n",
    "        decl_get_recommendation_trends_1,\n",
    "        decl_get_news_with_sentiment_2,\n",
    "        decl_get_rag_tool_response,\n",
    "        decl_get_wiki_tool_response,\n",
    "        decl_get_search_tool_response\n",
    "    ]\n",
    ")\n",
    "\n",
    "function_handler = {\n",
    "    \"get_symbol_1\": get_symbol_1,\n",
    "    \"get_symbols_1\": get_symbols_1,\n",
    "    \"get_name_1\": get_name_1,\n",
    "    \"get_symbol_quote_1\": get_quote_1,\n",
    "    \"get_market_status_1\": get_market_status_1,\n",
    "    \"get_market_session_1\": get_session_1,\n",
    "    \"get_company_peers_1\": get_peers_1,\n",
    "    \"get_local_datetime\": local_datetime,\n",
    "    \"get_last_market_close\": last_market_close,\n",
    "    \"get_exchange_codes_1\": get_exchange_codes_1,\n",
    "    \"get_exchange_code_1\": get_exchange_code_1,\n",
    "    \"get_financials_1\": get_financials_1,\n",
    "    \"get_daily_candlestick_2\": get_daily_candle_2,\n",
    "    \"get_custom_candlestick_2\": get_custom_candle_2,\n",
    "    \"get_ticker_overview_2\": get_overview_2,\n",
    "    \"get_recommendation_trends_1\": get_trends_1,\n",
    "    \"get_news_with_sentiment_2\": get_news_2,\n",
    "    \"get_rag_tool_response\": ask_rag_tool,\n",
    "    \"get_wiki_tool_response\": ask_wiki_tool,\n",
    "    \"get_search_tool_response\": ask_search_tool\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:53.374139Z",
     "iopub.status.busy": "2025-11-24T21:25:53.373803Z",
     "iopub.status.idle": "2025-11-24T21:25:53.404482Z",
     "shell.execute_reply": "2025-11-24T21:25:53.403023Z",
     "shell.execute_reply.started": "2025-11-24T21:25:53.374107Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Implement the function calling expert.\n",
    "# Define the system prompt.\n",
    "instruction = f\"\"\"You are a helpful and informative bot that answers finance and stock market questions. \n",
    "Only answer the question asked and do not change topic. While the answer is still\n",
    "unknown you must follow these rules for predicting function call order:\n",
    "\n",
    "RULE#1: Always consult your other functions before get_search_tool_response.\n",
    "RULE#2: Always consult get_wiki_tool_response before get_search_tool_response.\n",
    "RULE#3: Always consult get_search_tool_response last.\n",
    "RULE#4: Always convert timestamps with get_local_datetime and use the converted date/time in your response.\n",
    "RULE#5: Always incorporate as much useful information from tools and functions in your response.\"\"\"\n",
    "\n",
    "def get_response():\n",
    "    # Enable system prompt, function calling and minimum-randomness.\n",
    "    config_fncall = types.GenerateContentConfig(\n",
    "        system_instruction=instruction,\n",
    "        tools=[finance_tool],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    memory.response = api.retriable(\n",
    "        api.args.CLIENT.models.generate_content,\n",
    "        model=api(Api.Model.GEN),\n",
    "        config=config_fncall,\n",
    "        contents=memory.contents)\n",
    "\n",
    "def retry_last_send():\n",
    "    api.generation_fail()\n",
    "    time.sleep(api.dt_between)\n",
    "    get_response()\n",
    "\n",
    "@retry.Retry(\n",
    "    predicate=is_retriable,\n",
    "    initial=2.0,\n",
    "    maximum=64.0,\n",
    "    multiplier=2.0,\n",
    "    timeout=600,\n",
    ")\n",
    "def send_message(prompt):\n",
    "    #display(Markdown(\"#### Prompt\"))\n",
    "    #print(prompt, \"\\n\")\n",
    "    memory.set_prompt(prompt)\n",
    "    # Handle cases with multiple chained function calls.\n",
    "    function_calling_in_process = True\n",
    "    # Send the initial user prompt and function declarations.\n",
    "    get_response()\n",
    "    while function_calling_in_process:\n",
    "        try:\n",
    "            response_parts = memory.response.candidates[0].content.parts\n",
    "            # A summary response never includes function calls.\n",
    "            if not any(part.function_call for part in response_parts):\n",
    "                memory.set_summary(\"\\n\".join(e.text for e in response_parts))\n",
    "                function_calling_in_process = False\n",
    "                break # The function calling chain is complete.\n",
    "            else:\n",
    "                # A part can be a function call or reasoning-step.\n",
    "                for part in response_parts:\n",
    "                    if function_call := part.function_call:\n",
    "                        # Extract the function call.\n",
    "                        fn_name = function_call.name\n",
    "                        #display(Markdown(\"#### Predicted function name\"))\n",
    "                        #print(fn_name, \"\\n\")\n",
    "                        # Extract the function call arguments.\n",
    "                        fn_args = {key: value for key, value in function_call.args.items()}\n",
    "                        #display(Markdown(\"#### Predicted function arguments\"))\n",
    "                        #print(fn_args, \"\\n\")\n",
    "                        # Call the predicted function.\n",
    "                        print(\"send_message: get function response\")\n",
    "                        api_response = function_handler[fn_name](fn_args)[:20000] # Stay within the input token limit\n",
    "                        #display(Markdown(\"#### API response\"))\n",
    "                        #print(api_response[:500], \"...\", \"\\n\")\n",
    "                        # Create an API response part.\n",
    "                        api_response_part = types.Part.from_function_response(\n",
    "                            name=fn_name,\n",
    "                            response={\"content\": api_response},\n",
    "                        )\n",
    "                        memory.update_contents(function_call, api_response_part)\n",
    "                    else:\n",
    "                        #display(Markdown(\"#### Natural language reasoning step\"))\n",
    "                        #print(part.text)\n",
    "                        memory.set_reason(part.text)\n",
    "                print(\"send_message: updating state\")\n",
    "                get_response() # Send the updated prompt.\n",
    "                print(\"send_message: got a response\")\n",
    "        except Exception as e:\n",
    "            if isinstance(response_parts, list):\n",
    "                print(\"send_message: generated wrong function arguments\")\n",
    "            retry_last_send()\n",
    "            \n",
    "    # Show the final natural language summary.\n",
    "    display(Markdown(\"#### Natural language response\"))\n",
    "    display(Markdown(memory.summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Baseline Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:25:53.406821Z",
     "iopub.status.busy": "2025-11-24T21:25:53.406191Z",
     "iopub.status.idle": "2025-11-24T21:26:13.903472Z",
     "shell.execute_reply": "2025-11-24T21:26:13.902555Z",
     "shell.execute_reply.started": "2025-11-24T21:25:53.406771Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "{\n",
      "    \"VN\": \"Vietnam exchanges including HOSE, HNX and UPCOM\",\n",
      "    \"AD\": \"ABU DHABI SECURITIES EXCHANGE\",\n",
      "    \"US\": \"US exchanges (NYSE, Nasdaq)\",\n",
      "    \"CO\": \"OMX NORDIC EXCHANGE COPENHAGEN A/S\",\n",
      "    \"QA\": \"QATAR EXCHANGE\",\n",
      "    \"BA\": \"BOLSA DE COMERCIO DE BUENOS AIRES\",\n",
      "    \"MX\": \"BOLSA MEXICANA DE VALORES (MEXICAN STOCK EXCHANGE)\",\n",
      "    \"PR\": \"PRAGUE STOCK EXCHANGE\",\n",
      "    \"HK\": \"HONG KONG EXCHANGES AND CLEARING LTD\",\n",
      "    \"CA\": \"Egyptian Stock Exchange\",\n",
      "    \"AX\": \"ASX - ALL MARKETS\",\n",
      "    \"SX\": \"DEUTSCHE BOERSE Stoxx\",\n",
      "    \"KQ\": \"KOREA EXCHANGE (KOSDAQ)\",\n",
      "    \"DB\": \"DUBAI FINANCIAL MARKET\",\n",
      "    \"PM\": \"Philippine Stock Exchange\",\n",
      "    \"KS\": \"KOREA EXCHANGE (STOCK MARKET)\",\n",
      "    \"ST\": \"NASDAQ OMX NORDIC STOCKHOLM\",\n",
      "    \"DU\": \"BOERSE DUESSELDORF\",\n",
      "    \"TL\": \"NASDAQ OMX TALLINN\",\n",
      "    \"AT\": \"ATHENS EXCHANGE S.A. CASH MARKET\",\n",
      "    \"SW\": \"SWISS EXCHANGE\",\n",
      "    \"LS\": \"NYSE EURONEXT - EURONEXT LISBON\",\n",
      "    \"SI\": \"SINGAPORE EXCHANGE\",\n",
      "    \"RG\": \"NASDAQ OMX RIGA\",\n",
      "    \"CR\": \"CARACAS STOCK EXCHANGE\",\n",
      "    \"SA\": \"Brazil Bolsa - Sao Paolo\",\n",
      "    \"BH\": \"BAHRAIN BOURSE\",\n",
      "    \"NZ\": \"NEW ZEALAND EXCHANGE LTD\",\n",
      "    \"L\": \"LONDON STOCK EXCHANGE\",\n",
      "    \"SZ\": \"SHENZHEN STOCK EXCHANGE\",\n",
      "    \"IC\": \"NASDAQ OMX ICELAND\",\n",
      "    \"KW\": \"Kuwait Stock Exchange\",\n",
      "    \"JK\": \"INDONESIA STOCK EXCHANGE\",\n",
      "    \"BE\": \"BOERSE BERLIN\",\n",
      "    \"TA\": \"TEL AVIV STOCK EXCHANGE\",\n",
      "    \"PA\": \"NYSE EURONEXT - MARCHE LIBRE PARIS\",\n",
      "    \"V\": \"TSX VENTURE EXCHANGE - NEX\",\n",
      "    \"SN\": \"SANTIAGO STOCK EXCHANGE\",\n",
      "    \"BD\": \"BUDAPEST STOCK EXCHANGE\",\n",
      "    \"KL\": \"BURSA MALAYSIA\",\n",
      "    \"CN\": \"CANADIAN NATIONAL STOCK EXCHANGE\",\n",
      "    \"VS\": \"NASDAQ OMX VILNIUS\",\n",
      "    \"ME\": \"MOSCOW EXCHANGE\",\n",
      "    \"CS\": \"CASABLANCA STOCK EXCHANGE\",\n",
      "    \"NL\": \"Nigerian Stock Exchange\",\n",
      "    \"BR\": \"NYSE EURONEXT - EURONEXT BRUSSELS\",\n",
      "    \"NS\": \"NATIONAL STOCK EXCHANGE OF INDIA\",\n",
      "    \"DE\": \"XETRA\",\n",
      "    \"WA\": \"WARSAW STOCK EXCHANGE/EQUITIES/MAIN MARKET\",\n",
      "    \"AS\": \"NYSE EURONEXT - EURONEXT AMSTERDAM\",\n",
      "    \"TG\": \"DEUTSCHE BOERSE TradeGate\",\n",
      "    \"IR\": \"IRISH STOCK EXCHANGE - ALL MARKET\",\n",
      "    \"OL\": \"OSLO BORS ASA\",\n",
      "    \"BO\": \"BSE LTD\",\n",
      "    \"MT\": \"MALTA STOCK EXCHANGE\",\n",
      "    \"BC\": \"BOLSA DE VALORES DE COLOMBIA\",\n",
      "    \"F\": \"DEUTSCHE BOERSE AG\",\n",
      "    \"HE\": \"NASDAQ OMX HELSINKI LTD\",\n",
      "    \"MU\": \"BOERSE MUENCHEN\",\n",
      "    \"IS\": \"BORSA ISTANBUL\",\n",
      "    \"SR\": \"SAUDI STOCK EXCHANGE\",\n",
      "    \"NE\": \"AEQUITAS NEO EXCHANGE\",\n",
      "    \"MI\": \"Italian Stock Exchange\",\n",
      "    \"SS\": \"SHANGHAI STOCK EXCHANGE\",\n",
      "    \"MC\": \"BOLSA DE MADRID\",\n",
      "    \"HA\": \"Hanover Stock Exchange\",\n",
      "    \"VI\": \"Vienna Stock Exchange\",\n",
      "    \"TWO\": \"TPEx\",\n",
      "    \"HM\": \"HANSEATISCHE WERTPAPIERBOERSE HAMBURG\",\n",
      "    \"TW\": \"TAIWAN STOCK EXCHANGE\",\n",
      "    \"TO\": \"TORONTO STOCK EXCHANGE\",\n",
      "    \"SC\": \"BOERSE_FRANKFURT_ZERTIFIKATE\",\n",
      "    \"JO\": \"JOHANNESBURG STOCK EXCHANGE\",\n",
      "    \"SG\": \"BOERSE STUTTGART\",\n",
      "    \"RO\": \"BUCHAREST STOCK EXCHANGE\",\n",
      "    \"T\": \"TOKYO STOCK EXCHANGE-TOKYO PRO MARKET\",\n",
      "    \"BK\": \"STOCK EXCHANGE OF THAILAND\"\n",
      "}\n",
      "```\n",
      "DE, F, TG, SX, BE, DU, HA, HM, MU, SC, SG \n",
      "\n",
      "The Germany exchanges and their corresponding exchange codes are: XETRA (DE), DEUTSCHE BOERSE AG (F), Hanover Stock Exchange (HA), DEUTSCHE BOERSE TradeGate (TG), BOERSE BERLIN (BE), BOERSE DUESSELDORF (DU), HANSEATISCHE WERTPAPIERBOERSE HAMBURG (HM), BOERSE MUENCHEN (MU), DEUTSCHE BOERSE Stoxx (SX), BOERSE_FRANKFURT_ZERTIFIKATE (SC), and BOERSE STUTTGART (SG). \n",
      "\n",
      "I don't know. \n",
      "\n",
      "I don't know. \n",
      "\n",
      "US exchanges, including NYSE and Nasdaq, operate from 09:30 to 16:00 in the America/New_York timezone. \n",
      "\n",
      "Fri Nov 21 20:00:00 2025\n"
     ]
    }
   ],
   "source": [
    "response = tool_rag.get_exchanges_csv(\n",
    "    \"\"\"Give me a dictionary in string form. It must contain key:value pairs mapping \n",
    "    exchange code to name. Just the dictionary string in pretty form.\"\"\")\n",
    "print(response.candidates[0].content.parts[-1].text)\n",
    "\n",
    "response = tool_rag.get_exchanges_csv(\n",
    "    \"\"\"What is the Germany exchange code? Return only the exchange codes as a simple \n",
    "    comma separated value that I can copy.\"\"\")\n",
    "print(response.candidates[0].content.parts[-1].text, \"\\n\")\n",
    "\n",
    "response = tool_rag.get_exchanges_csv(\"What are the Germany exchanges and thier corresponding exchange codes?\")\n",
    "print(response.text, \"\\n\")\n",
    "\n",
    "response = tool_rag.generate_answer(\"What are Google's stock ticker symbols?\")\n",
    "print(response.text, \"\\n\")\n",
    "\n",
    "response = tool_rag.generate_answer(\"What is Facebook's stock ticker symbol?\")\n",
    "print(response.text, \"\\n\")\n",
    "\n",
    "response = tool_rag.get_exchanges_csv(\"What are the US exchange operating hours?\")\n",
    "print(response.text, \"\\n\")\n",
    "\n",
    "response = tool_rag.get_exchanges_csv(\n",
    "    f\"\"\"Answer based on your knowledge of exchange operating hours.\n",
    "    Do not answer in full sentences. Omit all chat and provide the answer only.\n",
    "    The fields pre_market and post_market both represent extended operating hours.\n",
    "\n",
    "    The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n",
    "\n",
    "    Weekdays are: Mon, Tue, Wed, Thu, Fri.\n",
    "    On weekdays all exchanges open after pre-market and regular hours.\n",
    "    On weekdays all exchanges close after regular and post-market hours.\n",
    "    \n",
    "    Weekends are: Sat, Sun.\n",
    "    Always exclude weekends from exchange operating hours.\n",
    "    A list of holidays in date format mm-dd-yyyy: {tool_rag.holidays[\"US\"]}\n",
    "    Always exclude holidays from exchange operating hours.\n",
    "    When the answer is a holiday use the prior weekday for close.\n",
    "    When the answer is a holiday use the next weekday for open.\n",
    "    \n",
    "    Consider the US exchange's operating hours.\n",
    "    Provide the most recent weekday's close including post_market hours.\n",
    "    \n",
    "    Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\")\n",
    "print(response.candidates[0].content.parts[-1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SC1 Baseline Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:26:13.904679Z",
     "iopub.status.busy": "2025-11-24T21:26:13.90441Z",
     "iopub.status.idle": "2025-11-24T21:27:12.908922Z",
     "shell.execute_reply": "2025-11-24T21:27:12.907798Z",
     "shell.execute_reply.started": "2025-11-24T21:26:13.904658Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini API limit is FREE. Waiting 59s...\n",
      "Api.refill_rpm 10\n"
     ]
    }
   ],
   "source": [
    "# Wait 59s for rate-limits to reset on FREE-tier.\n",
    "if api.args.API_LIMIT is Api.Limit.FREE.value:\n",
    "    print(\"Gemini API limit is FREE. Waiting 59s...\")\n",
    "    time.sleep(59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:27:12.909993Z",
     "iopub.status.busy": "2025-11-24T21:27:12.909755Z",
     "iopub.status.idle": "2025-11-24T21:27:23.783741Z",
     "shell.execute_reply": "2025-11-24T21:27:23.782796Z",
     "shell.execute_reply.started": "2025-11-24T21:27:12.909974Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate US->MarketEvent.LAST_CLOSE: 100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "Generate US->MarketEvent.PRE_OPEN: 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "Generate US->MarketEvent.REG_OPEN: 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "Generate US->MarketEvent.REG_CLOSE: 100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "Generate US->MarketEvent.POST_CLOSE: 100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The current market session for US exchanges is post-market."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is the current session for US exchanges?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:27:23.785568Z",
     "iopub.status.busy": "2025-11-24T21:27:23.785119Z",
     "iopub.status.idle": "2025-11-24T21:27:29.873692Z",
     "shell.execute_reply": "2025-11-24T21:27:29.872756Z",
     "shell.execute_reply.started": "2025-11-24T21:27:23.785541Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Api.generation_fail.next_model: model is now gemini-2.5-flash-preview-09-2025\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The US market is currently **open** and in the **post-market** session as of Mon Nov 24 16:27:21 2025 (America/New_York timezone). It is not a holiday."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is the US market status?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:27:29.876136Z",
     "iopub.status.busy": "2025-11-24T21:27:29.875341Z",
     "iopub.status.idle": "2025-11-24T21:27:31.287556Z",
     "shell.execute_reply": "2025-11-24T21:27:31.286684Z",
     "shell.execute_reply.started": "2025-11-24T21:27:29.876108Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The last US market close was on Friday, November 21, 2025, at 8:00:00 PM."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"When was the last US market close?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:27:31.29284Z",
     "iopub.status.busy": "2025-11-24T21:27:31.291762Z",
     "iopub.status.idle": "2025-11-24T21:27:33.80422Z",
     "shell.execute_reply": "2025-11-24T21:27:33.803037Z",
     "shell.execute_reply.started": "2025-11-24T21:27:31.292807Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score similarity to query: 100%|██████████| 10/10 [00:00<00:00, 17.35it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The stock ticker for Apple is AAPL."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is Apple's stock ticker?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:27:33.805256Z",
     "iopub.status.busy": "2025-11-24T21:27:33.804978Z",
     "iopub.status.idle": "2025-11-24T21:27:41.482032Z",
     "shell.execute_reply": "2025-11-24T21:27:41.48073Z",
     "shell.execute_reply.started": "2025-11-24T21:27:33.805233Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score similarity to query: 100%|██████████| 2/2 [00:00<00:00,  7.00it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "Api.generation_fail.next_model: model is now gemini-2.0-flash-exp\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate quote embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The current price of Amazon stock (AMZN) is $226.06 as of Mon Nov 24 16:00:00 2025. The change from the previous close is $5.37, representing a 2.4333% increase. The high for the day is $227.33, and the low is $222.27. The opening price for the day was $222.555, and the previous close price was $220.69.\n",
       "\n",
       "```json\n",
       "{\n",
       "\"c\": 226.06,\n",
       "\"d\": 5.37,\n",
       "\"dp\": 2.4333,\n",
       "\"h\": 227.33,\n",
       "\"l\": 222.27,\n",
       "\"o\": 222.555,\n",
       "\"pc\": 220.69,\n",
       "\"t\": 1764018000\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is the current price of Amazon stock? Display the result as a json string in markdown.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:27:41.483586Z",
     "iopub.status.busy": "2025-11-24T21:27:41.483223Z",
     "iopub.status.idle": "2025-11-24T21:27:51.390095Z",
     "shell.execute_reply": "2025-11-24T21:27:51.389091Z",
     "shell.execute_reply.started": "2025-11-24T21:27:41.483545Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here's an overview of Apple's financial performance based on the provided data:\n",
       "\n",
       "**Financial Health & Performance Metrics:**\n",
       "\n",
       "*   **Profitability:**\n",
       "    *   **Net Profit Margin (TTM):** 26.92%, indicating strong profitability.\n",
       "    *   **Operating Margin (TTM):** 31.97%, reflecting efficient operations.\n",
       "    *   **Gross Margin (TTM):** 46.91%, showcasing a healthy ability to manage production costs.\n",
       "    *   **Return on Equity (ROE) (TTM):** 164.05%, suggesting effective use of shareholder equity.\n",
       "    *   **Return on Assets (ROA) (TTM):** 32.80%, indicating good asset utilization.\n",
       "\n",
       "*   **Revenue & Growth:**\n",
       "    *   **Revenue Growth (TTM YoY):** 6.43%, demonstrating continued growth.\n",
       "    *   **EPS Growth (TTM YoY):** 22.89%, indicating strong earnings growth.\n",
       "    *   **Revenue Per Share (TTM):** 27.9987\n",
       "    *   **Asset Turnover TTM:** 1.2186, reflecting efficient asset management to generate revenue.\n",
       "\n",
       "*   **Liquidity & Solvency:**\n",
       "    *   **Current Ratio (Annual):** 0.8933, suggesting potential short-term liquidity challenges.\n",
       "    *   **Quick Ratio (Annual):** 0.8588, reinforcing the need to monitor short-term obligations.\n",
       "    *   **Long Term Debt/Equity (Annual):** 1.0623, indicating a moderate level of debt relative to equity.\n",
       "\n",
       "*   **Valuation:**\n",
       "    *   **Price-to-Earnings Ratio (P/E) (TTM):** 36.278, suggesting investors are willing to pay a premium for Apple's earnings.\n",
       "    *   **Forward P/E:** 33.52, indicating expected future earnings.\n",
       "    *   **Price-to-Book Ratio (P/B):** 55.111, reflecting a high market valuation compared to book value.\n",
       "    *   **PEG Ratio (TTM):** 1.59, suggesting the stock might be slightly overvalued relative to its earnings growth.\n",
       "\n",
       "*   **Stock Performance:**\n",
       "    *   **52 Week Price Return Daily:** 18.55%\n",
       "    *   **Year-to-Date Price Return Daily:** 8.41%\n",
       "    *   **13 Week Price Return Daily:** 19.2%\n",
       "    *   **5 Day Price Return Daily:** 1.51%\n",
       "\n",
       "**Key Observations & Potential Interpretations:**\n",
       "\n",
       "*   Apple exhibits strong profitability, efficient operations, and good asset utilization.\n",
       "*   The company demonstrates continued revenue and earnings growth.\n",
       "*   Liquidity ratios suggest a need for careful management of short-term obligations.\n",
       "*   Valuation metrics indicate that the stock is trading at a premium.\n",
       "*   Stock performance has been positive over the past year.\n",
       "\n",
       "**Additional Considerations:**\n",
       "\n",
       "*   It's important to compare these metrics to Apple's industry peers and historical performance to gain a more comprehensive understanding.\n",
       "*   Analyzing the trends in these metrics over time can provide valuable insights into the company's long-term performance.\n",
       "*   External factors, such as economic conditions and industry trends, can also impact Apple's financial performance.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"Show me Apple's basic financials and help me understand key performance metrics. \n",
    "How has the stock performed?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:27:51.391377Z",
     "iopub.status.busy": "2025-11-24T21:27:51.391113Z",
     "iopub.status.idle": "2025-11-24T21:27:53.851734Z",
     "shell.execute_reply": "2025-11-24T21:27:53.850722Z",
     "shell.execute_reply.started": "2025-11-24T21:27:51.391354Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "OK. On 2025-05-05, Apple's stock (AAPL) had the following daily candlestick data:\n",
       "*   Open: 203.1\n",
       "*   High: 204.1\n",
       "*   Low: 198.21\n",
       "*   Close: 198.89\n",
       "*   Volume: 69018452\n",
       "*   PreMarket: 205.0\n",
       "*   AfterHours: 198.6"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"I need Apple's daily candlestick from 2025-05-05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:27:53.85326Z",
     "iopub.status.busy": "2025-11-24T21:27:53.852987Z",
     "iopub.status.idle": "2025-11-24T21:28:04.4839Z",
     "shell.execute_reply": "2025-11-24T21:28:04.483022Z",
     "shell.execute_reply.started": "2025-11-24T21:27:53.853237Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score similarity to query: 100%|██████████| 5/5 [00:00<00:00, 32.60it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.84it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 5/5 [00:00<00:00, 37.55it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 2/2 [00:00<00:00, 14.26it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  6.07it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 2/2 [00:00<00:00, 13.04it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.45it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  6.94it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Generate peers embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "Api.generation_fail.next_model: model is now gemini-2.0-flash\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here are some of Apple's peers: DELL (DELL TECHNOLOGIES -C), WDC (WESTERN DIGITAL CORP), SNDK (SANDISK CORP), HPE (HEWLETT PACKARD ENTERPRISE), PSTG (PURE STORAGE INC - CLASS A), HPQ (HP INC), NTAP (NETAPP INC), SMCI (SUPER MICRO COMPUTER INC), IONQ (IONQ INC), QUBT (QUANTUM COMPUTING INC), and CMPO (COMPOSECURE INC-A).\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"Tell me who are Apple's peers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:28:04.485366Z",
     "iopub.status.busy": "2025-11-24T21:28:04.485047Z",
     "iopub.status.idle": "2025-11-24T21:28:12.993921Z",
     "shell.execute_reply": "2025-11-24T21:28:12.992975Z",
     "shell.execute_reply.started": "2025-11-24T21:28:04.485333Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 2/2 [00:00<00:00, 16.42it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.69it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 5/5 [00:00<00:00, 37.76it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 11/11 [00:00<00:00, 65.73it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Api.zero_error: model is now gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score similarity to query: 100%|██████████| 2/2 [00:00<00:00, 15.11it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.39it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|██████████| 1/1 [00:00<00:00,  7.97it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Generate peers embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Amazon's peers include Coupang Inc (CPNG), eBay Inc (EBAY), Dillard's Inc-CL A (DDS), Ollie's Bargain Outlet Holdi (OLLI), Macy's Inc (M), Etsy Inc (ETSY), Pattern Group Inc-CL A (PTRN), Kohl's Corp (KSS), Savers Value Village Inc (SVV), and Groupon Inc (GRPN)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"Tell me who are Amazon's peers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:28:12.995145Z",
     "iopub.status.busy": "2025-11-24T21:28:12.994843Z",
     "iopub.status.idle": "2025-11-24T21:28:28.260087Z",
     "shell.execute_reply": "2025-11-24T21:28:28.259202Z",
     "shell.execute_reply.started": "2025-11-24T21:28:12.995113Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here's a comparison of the latest recommendation trends (as of November 2025) for Apple's peers in the sub-industry:\n",
       "\n",
       "*   **DELL TECHNOLOGIES -C (DELL):** 18 Buy, 6 Hold, 0 Sell, 8 Strong Buy, 0 Strong Sell\n",
       "*   **WESTERN DIGITAL CORP (WDC):** 19 Buy, 7 Hold, 0 Sell, 6 Strong Buy, 0 Strong Sell\n",
       "*   **SANDISK CORP (SNDK):** 10 Buy, 8 Hold, 0 Sell, 7 Strong Buy, 0 Strong Sell\n",
       "*   **HEWLETT PACKARD ENTERPRISE (HPE):** 8 Buy, 12 Hold, 0 Sell, 6 Strong Buy, 0 Strong Sell\n",
       "*   **PURE STORAGE INC - CLASS A (PSTG):** 13 Buy, 7 Hold, 1 Sell, 6 Strong Buy, 0 Strong Sell\n",
       "*   **HP INC (HPQ):** 3 Buy, 16 Hold, 1 Sell, 2 Strong Buy, 0 Strong Sell\n",
       "*   **NETAPP INC (NTAP):** 9 Buy, 15 Hold, 0 Sell, 3 Strong Buy, 0 Strong Sell\n",
       "*   **SUPER MICRO COMPUTER INC (SMCI):** 10 Buy, 11 Hold, 3 Sell, 2 Strong Buy, 0 Strong Sell\n",
       "*   **IONQ INC (IONQ):** 10 Buy, 3 Hold, 0 Sell, 2 Strong Buy, 0 Strong Sell\n",
       "*   **QUANTUM COMPUTING INC (QUBT):** 5 Buy, 2 Hold, 0 Sell, 2 Strong Buy, 0 Strong Sell\n",
       "*   **COMPOSECURE INC-A (CMPO):** 8 Buy, 1 Hold, 1 Sell, 2 Strong Buy, 0 Strong Sell"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"Locate Apple's stock ticker, then download recommendation trends of all Apple's peers by sub-industry, \n",
    "and then finally compare them.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:28:28.261256Z",
     "iopub.status.busy": "2025-11-24T21:28:28.261024Z",
     "iopub.status.idle": "2025-11-24T21:28:56.35919Z",
     "shell.execute_reply": "2025-11-24T21:28:56.358381Z",
     "shell.execute_reply.started": "2025-11-24T21:28:28.261237Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate quote embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n",
      "send_message: updating state\n",
      "Api.generation_fail.next_model: model is now gemini-2.5-flash-preview-09-2025\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The current share price for **Amazon (AMZN)** is **$226.06** as of **Mon Nov 24 16:00:00 2025**. The stock is up **$5.37** (+2.43%) from the previous close.\n",
       "\n",
       "Here is the daily candlestick data for Amazon's stock price over the past month, sorted in descending order by date:\n",
       "\n",
       "| Date | Open | High | Low | Close | Volume |\n",
       "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
       "| Fri Nov 21 00:00:00 2025 | $216.35 | $222.21 | $215.18 | $220.69 | 68,490,453 |\n",
       "| Thu Nov 20 00:00:00 2025 | $227.05 | $227.41 | $216.74 | $217.14 | 50,308,862 |\n",
       "| Wed Nov 19 00:00:00 2025 | $223.74 | $223.74 | $218.52 | $222.69 | 58,335,353 |\n",
       "| Tue Nov 18 00:00:00 2025 | $228.10 | $230.20 | $222.42 | $222.55 | 60,608,442 |\n",
       "| Mon Nov 17 00:00:00 2025 | $233.25 | $234.60 | $229.19 | $232.87 | 59,918,908 |\n",
       "| Fri Nov 14 00:00:00 2025 | $235.06 | $238.73 | $232.89 | $234.69 | 38,956,619 |\n",
       "| Thu Nov 13 00:00:00 2025 | $243.05 | $243.75 | $236.50 | $237.58 | 41,401,638 |\n",
       "| Wed Nov 12 00:00:00 2025 | $250.24 | $250.37 | $243.75 | $244.20 | 31,190,063 |\n",
       "| Tue Nov 11 00:00:00 2025 | $248.41 | $249.75 | $247.23 | $249.10 | 23,563,960 |\n",
       "| Mon Nov 10 00:00:00 2025 | $248.34 | $251.75 | $245.59 | $248.40 | 36,476,474 |\n",
       "| Fri Nov 7 00:00:00 2025 | $242.90 | $244.90 | $238.49 | $244.41 | 46,374,294 |\n",
       "| Thu Nov 6 00:00:00 2025 | $249.16 | $250.38 | $242.17 | $243.04 | 46,004,201 |\n",
       "| Wed Nov 5 00:00:00 2025 | $249.03 | $251.00 | $246.16 | $250.20 | 40,610,602 |\n",
       "| Tue Nov 4 00:00:00 2025 | $250.38 | $257.01 | $248.66 | $249.32 | 51,546,311 |\n",
       "| Mon Nov 3 00:00:00 2025 | $255.36 | $258.60 | $252.90 | $254.00 | 95,997,714 |\n",
       "| Fri Oct 31 00:00:00 2025 | $250.10 | $250.50 | $243.98 | $244.22 | 166,340,683 |\n",
       "| Thu Oct 30 00:00:00 2025 | $227.06 | $228.44 | $222.75 | $222.86 | 102,252,888 |\n",
       "| Wed Oct 29 00:00:00 2025 | $231.67 | $232.82 | $227.76 | $230.30 | 52,035,936 |\n",
       "| Tue Oct 28 00:00:00 2025 | $228.22 | $231.49 | $226.21 | $229.25 | 47,099,924 |\n",
       "| Mon Oct 27 00:00:00 2025 | $227.66 | $228.40 | $225.54 | $226.97 | 38,266,995 |\n",
       "| Fri Oct 24 00:00:00 2025 | $221.97 | $225.40 | $221.90 | $224.21 | 38,684,853 |\n",
       "\n",
       "***\n",
       "\n",
       "### Price Pattern Analysis and Correlation with News\n",
       "\n",
       "The price data for Amazon (AMZN) over the past month (October 24, 2025, to November 21, 2025) reveals a distinct **V-shaped pattern** characterized by a sharp surge followed by a gradual decline and a recent stabilization.\n",
       "\n",
       "#### 1. The Initial Surge (Late October to Early November)\n",
       "*   **Pattern:** The stock experienced a significant and rapid upward movement, starting from a low of **$224.21** on October 24 and peaking at **$254.00** on November 3. This represents a gain of approximately **13.37%** in just over a week. The volume on October 31 (**166.34 million**) and November 3 (**95.99 million**) was exceptionally high, confirming strong buying pressure.\n",
       "*   **Correlation with News:** This surge is directly correlated with a series of highly positive news events, primarily centered around Amazon's cloud computing division, **AWS**, and its strategic positioning in the **Artificial Intelligence (AI)** race:\n",
       "    *   **October 31:** Amazon reported **strong Q3 earnings** with AWS revenue growing 20% year-over-year, causing the stock to surge 10% in a single day (Nasdaq 100 Rebounds, Amazon Jumps 10% On Strong Earnings).\n",
       "    *   **November 3-4:** News broke of a massive **$38 billion cloud infrastructure deal with OpenAI**, which will utilize AWS servers and hundreds of thousands of Nvidia chips. This news was a major catalyst, with the stock jumping 5% on November 3 alone (Amazon Strikes $38B OpenAI Deal, Why Did Amazon Stock Jump 5% Today?).\n",
       "    *   **General Sentiment:** Multiple articles during this period highlighted Amazon's strong AI potential, diversified business model, and attractive valuation, with analysts raising price targets.\n",
       "\n",
       "#### 2. The Correction/Pullback (Mid-November)\n",
       "*   **Pattern:** Following the peak on November 3, the stock entered a clear downtrend, dropping from **$254.00** to a low of **$217.14** on November 20. This represents a decline of approximately **14.51%**. The trading volume remained relatively high during this period, suggesting significant selling pressure.\n",
       "*   **Correlation with News:** This sharp pullback aligns with broader market skepticism and specific concerns about AI investment sustainability:\n",
       "    *   **November 13:** Tech stocks experienced a massive market value decline of over $700 billion due to skepticism about Federal Reserve rate cuts and potential AI infrastructure bottlenecks, with Amazon shedding around **$70 billion in market value** (Tech Stocks Wipe Out Over $700 Billion As Traders Flee AI Hype).\n",
       "    *   **November 18:** A major system failure at Cloudflare caused a global web services outage, impacting AWS services and contributing to a broader tech stock selloff, with AMZN's stock price declining by 3.29% (Cloudflare Stumbled — And Tech Stocks Extend The Selloff).\n",
       "    *   **November 19-21:** Concerns about AI overspending and high valuations continued to pressure the stock. An article on November 21 noted a **12% stock decline** due to concerns about an AWS cloud optimization slowdown and potential impact of reduced consumer discretionary spending (3 Big Tech Stocks Sliding: What’s Behind the Drop?).\n",
       "\n",
       "#### 3. Recent Stabilization (Late November)\n",
       "*   **Pattern:** In the final days of the data (November 19-21), the stock appears to be attempting to stabilize, with the closing price on November 21 at **$220.69**, and the current price on November 24 at **$226.06**.\n",
       "*   **Correlation with News:** The recent stabilization and slight rebound on November 24 is supported by renewed positive sentiment:\n",
       "    *   **November 24:** News reported that Amazon gained nearly 2% after announcing a **$50 billion AI and supercomputing infrastructure investment**, suggesting the company is doubling down on its AI strategy despite earlier market jitters (Stocks Soar, Nasdaq 100 Eyes Best Day In 6 Months).\n",
       "    *   **General Sentiment:** Positive analyst commentary continued to emerge, highlighting Amazon's strong growth in AWS, advertising, and AI-powered chatbot Rufus, reinforcing its long-term growth potential (My 2 Favorite Stocks to Buy Right Now).\n",
       "\n",
       "In summary, Amazon's stock price over the past month was highly volatile, driven almost entirely by the market's reaction to its **AI and cloud computing strategy**. The initial surge was a direct response to strong earnings and the massive OpenAI deal, while the subsequent sharp decline reflected broader market concerns about AI investment costs and a temporary service outage. The stock is currently attempting to recover, supported by the company's continued commitment to massive AI infrastructure spending."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"Tell me Amazon's current share price and provide candlestick data for the past month. \n",
    "Sort the data in descending order by date. Format the prices consistently as currency. \n",
    "Round prices to two decimal places. \n",
    "Present the data with multiple columns for display in markdown. \n",
    "Discuss and provide details about any patterns you notice in the price data. \n",
    "Correlate recent patterns with news over the same date range.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:28:56.360954Z",
     "iopub.status.busy": "2025-11-24T21:28:56.360559Z",
     "iopub.status.idle": "2025-11-24T21:28:59.54618Z",
     "shell.execute_reply": "2025-11-24T21:28:59.545347Z",
     "shell.execute_reply.started": "2025-11-24T21:28:56.360928Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Apple Inc. (AAPL) is a major global company known for its hardware and software products, including the iPhone, Mac, iPad, and Watch.\n",
       "\n",
       "Here is an overview of the company:\n",
       "\n",
       "*   **Name:** Apple Inc.\n",
       "*   **Ticker:** AAPL\n",
       "*   **Primary Exchange:** XNAS (NASDAQ)\n",
       "*   **Market Cap:** $4,011,632,075,970.00\n",
       "*   **CIK:** 0000320193\n",
       "*   **Phone Number:** (408) 996-1010\n",
       "*   **Address:** ONE APPLE PARK WAY, CUPERTINO, CA, 95014\n",
       "*   **Total Employees:** 166,000\n",
       "*   **List Date:** 1980-12-12\n",
       "*   **SIC Description:** ELECTRONIC COMPUTERS\n",
       "*   **Homepage:** https://www.apple.com\n",
       "\n",
       "**Description:**\n",
       "Apple is one of the largest companies in the world. Its portfolio is centered around the iPhone, which accounts for a majority of its sales. Products like the Mac, iPad, and Watch are designed to integrate within the expansive Apple software ecosystem. The company is also expanding into new applications such as streaming video, subscription bundles, and augmented reality. Apple designs its own software and semiconductors, with manufacturing handled by subcontractors like Foxconn and TSMC. Sales are made both directly through its flagship stores and indirectly through partnerships and distribution channels."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is Apple's ticker overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:28:59.547457Z",
     "iopub.status.busy": "2025-11-24T21:28:59.547046Z",
     "iopub.status.idle": "2025-11-24T21:29:09.904562Z",
     "shell.execute_reply": "2025-11-24T21:29:09.903475Z",
     "shell.execute_reply.started": "2025-11-24T21:28:59.547427Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score wiki search by similarity to topic: 0it [00:00, ?it/s]\n",
      "Generate wiki embeddings: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Google's stock is listed on the NASDAQ stock exchange under two ticker symbols: **GOOGL** and **GOOG**.\n",
       "\n",
       "These symbols now represent **Alphabet Inc.**, which is Google's holding company, a change that took effect in the fourth quarter of 2015. The company is also listed on the Frankfurt Stock Exchange under the ticker symbol **GGQ1**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is Google's stock ticker symbol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:29:09.906191Z",
     "iopub.status.busy": "2025-11-24T21:29:09.905911Z",
     "iopub.status.idle": "2025-11-24T21:29:20.843859Z",
     "shell.execute_reply": "2025-11-24T21:29:20.842634Z",
     "shell.execute_reply.started": "2025-11-24T21:29:09.90617Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Api.generation_fail.next_model: model is now gemini-2.0-flash-exp\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score wiki search by similarity to topic: 0it [00:00, ?it/s]\n",
      "Generate wiki embeddings: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I am unable to find the stock symbol for MGM Studios.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is MGM Studio's stock symbol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:29:20.845185Z",
     "iopub.status.busy": "2025-11-24T21:29:20.844885Z",
     "iopub.status.idle": "2025-11-24T21:29:25.537992Z",
     "shell.execute_reply": "2025-11-24T21:29:25.536967Z",
     "shell.execute_reply.started": "2025-11-24T21:29:20.845154Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n",
      "send_message: updating state\n",
      "Api.generation_fail.next_model: model is now gemini-2.0-flash\n",
      "Api.zero_error: model is now gemini-2.5-flash\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "MGM Studios is owned by Amazon. The stock symbol for Amazon is AMZN."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is MGM Studio's owner company stock symbol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:29:25.539341Z",
     "iopub.status.busy": "2025-11-24T21:29:25.53902Z",
     "iopub.status.idle": "2025-11-24T21:29:35.3803Z",
     "shell.execute_reply": "2025-11-24T21:29:35.37947Z",
     "shell.execute_reply.started": "2025-11-24T21:29:25.539312Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score wiki search by similarity to topic: 0it [00:00, ?it/s]\n",
      "Generate wiki embeddings: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The stock ticker symbol for Facebook, which is now Meta Platforms, Inc., is META. The company trades on the Nasdaq exchange."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is Facebook's stock ticker symbol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:29:35.381686Z",
     "iopub.status.busy": "2025-11-24T21:29:35.38144Z",
     "iopub.status.idle": "2025-11-24T21:30:26.595845Z",
     "shell.execute_reply": "2025-11-24T21:30:26.594938Z",
     "shell.execute_reply.started": "2025-11-24T21:29:35.381667Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n",
      "send_message: generated wrong function arguments\n",
      "Api.generation_fail.next_model: model is now gemini-2.5-flash-preview-09-2025\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "Api.zero_error: model is now gemini-2.5-flash\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Based on the analysis of analyst recommendations and news sentiment for Amazon (AMZN) from October 1, 2025, until today, November 24, 2025, the predictions are overwhelmingly **bullish**, driven by the company's strategic pivot toward Artificial Intelligence (AI) and the continued strength of its cloud computing division.\n",
       "\n",
       "### **Recommendation Trends (Bullish vs. Bearish)**\n",
       "\n",
       "Analyst sentiment for Amazon during this period was near-unanimously bullish:\n",
       "\n",
       "| Metric | Oct 1, 2025 | Nov 1, 2025 | Trend |\n",
       "| :--- | :--- | :--- | :--- |\n",
       "| **Bullish (Strong Buy + Buy)** | 75 | 76 | Slight Increase |\n",
       "| **Neutral (Hold)** | 3 | 2 | Slight Decrease |\n",
       "| **Bearish (Sell + Strong Sell)** | 0 | 0 | None |\n",
       "\n",
       "**Conclusion:** The analyst community maintained a **Strong Buy** consensus throughout the period, with zero \"Sell\" or \"Strong Sell\" recommendations. This indicates a high degree of confidence in Amazon's long-term growth trajectory.\n",
       "\n",
       "***\n",
       "\n",
       "### **Sentiment Analysis of News (Oct 1, 2025 - Nov 24, 2025)**\n",
       "\n",
       "The news coverage was predominantly positive, with bullish articles outnumbering bearish ones by a ratio of over 5-to-1.\n",
       "\n",
       "#### **Bullish Predictions and Themes**\n",
       "\n",
       "The core of the bullish case is centered on Amazon's high-margin, high-growth segments:\n",
       "\n",
       "*   **AWS Dominance and Acceleration:** News repeatedly highlighted the accelerating growth of Amazon Web Services (AWS), which reported a **20% year-over-year revenue increase** in its Q3 earnings. AWS is consistently cited as the company's most lucrative segment, generating a significant portion of its operating profit.\n",
       "*   **Strategic AI Investments:** The market reacted strongly to Amazon's aggressive AI strategy, including:\n",
       "    *   A massive **$38 billion cloud infrastructure deal with OpenAI** (reported early November).\n",
       "    *   Commitments to **$50 billion in AI and supercomputing infrastructure** investment.\n",
       "    *   Development of **custom AI chips** (Trainium and Inferentia) and AI-powered tools like the Rufus chatbot.\n",
       "*   **Strong Financial Performance:** The Q3 earnings report (late October/early November) was a major catalyst, with the stock surging up to 10% after reporting **13% sales growth** and a **38% increase in net income**. Analysts subsequently raised price targets, projecting up to **50% potential stock price growth** over the next three years.\n",
       "*   **E-commerce and Advertising Strength:** Positive sentiment was also tied to the continued dominance of the e-commerce platform (40% U.S. market share) and the rapid growth of the high-margin digital advertising business (up 22% YoY).\n",
       "\n",
       "#### **Bearish Predictions and Themes**\n",
       "\n",
       "The bearish and mixed sentiment focused on short-term risks and the high cost of the AI pivot:\n",
       "\n",
       "*   **High Capital Expenditure Risk:** Several articles expressed concern that Amazon's massive AI infrastructure spending (projected to be over $100 billion) could lead to a **45% decline in Free Cash Flow (FCF)** in 2025, creating uncertainty about the return on investment.\n",
       "*   **Massive Job Cuts:** The company announced plans to cut up to **30,000 corporate jobs** (nearly 10% of its corporate workforce) across multiple divisions, including HR. While this is a cost-cutting measure aimed at efficiency, it was widely reported as a negative for the labor market and a sign of aggressive restructuring.\n",
       "*   **Operational Setbacks:** The company faced negative press and stock drops following a **major AWS service outage** in late October, which temporarily impacted thousands of websites and services.\n",
       "\n",
       "***\n",
       "\n",
       "### **Patterns and Correlations**\n",
       "\n",
       "A clear pattern emerges from the data:\n",
       "\n",
       "**The market is willing to overlook short-term operational and financial risks for long-term AI growth.**\n",
       "\n",
       "*   **Correlation:** The near-unanimous **bullish analyst consensus** is directly correlated with the **strategic AI and AWS growth narrative** in the news. Analysts view the massive AI spending and the resulting FCF pressure as a necessary, high-stakes investment that will cement Amazon's dominance in the next decade.\n",
       "*   **Pattern:** The negative news events (job cuts, FCF concerns, AWS outage) caused temporary stock price drops and generated bearish commentary, but these were quickly overshadowed by the positive Q3 earnings and the announcement of major AI deals (like the OpenAI partnership). This suggests that investors are prioritizing Amazon's long-term potential as an **AI infrastructure and cloud leader** over its short-term operational challenges. The market is essentially betting that the aggressive cost-cutting (layoffs) will fund the massive AI investment, leading to superior profitability in the future."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"Compare Amazon's bullish versus bearish predictions from Oct 01 2025 until today. \n",
    "Include a discussion of recommendation trends, and sentiment analysis of news from the same dates. \n",
    "Discuss any patterns or correlations you find.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:30:26.597213Z",
     "iopub.status.busy": "2025-11-24T21:30:26.596883Z",
     "iopub.status.idle": "2025-11-24T21:31:11.346802Z",
     "shell.execute_reply": "2025-11-24T21:31:11.34572Z",
     "shell.execute_reply.started": "2025-11-24T21:30:26.597182Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate grounding embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "Api.generation_fail.next_model: model is now gemini-2.5-flash-preview-09-2025\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Google's parent company, Alphabet Inc., trades under the ticker symbols **GOOGL** (Class A) and **GOOG** (Class C). The predictions for the company from October 1, 2025, to November 24, 2025, were overwhelmingly bullish across both formal analyst recommendations and real-time news sentiment.\n",
       "\n",
       "Here is a detailed comparison and analysis of the trends and sentiment during this period.\n",
       "\n",
       "---\n",
       "\n",
       "### 1. Recommendation Trends (Bullish vs. Bearish Predictions)\n",
       "\n",
       "Analyst sentiment for Alphabet was unanimously bullish throughout October and November 2025, with **zero** bearish ratings.\n",
       "\n",
       "| Period | Strong Buy | Buy | Hold | Sell | Strong Sell | Total Bullish | Total Bearish |\n",
       "| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n",
       "| **2025-10-01** | 21 | 39 | 13 | 0 | 0 | **60** | **0** |\n",
       "| **2025-11-01** | 21 | 41 | 12 | 0 | 0 | **62** | **0** |\n",
       "\n",
       "*   **Bullish Prediction:** The consensus was overwhelmingly positive, with 60 \"Strong Buy\" or \"Buy\" ratings in October, which slightly increased to 62 by November. This indicates a sustained and growing confidence among analysts in the company's future performance.\n",
       "*   **Bearish Prediction:** There were no \"Sell\" or \"Strong Sell\" recommendations, suggesting analysts saw no fundamental reason for a significant decline in the stock price. The few \"Hold\" ratings (13 in October, 12 in November) typically reflect a belief that the stock is fairly valued at its current price, rather than a bearish outlook.\n",
       "\n",
       "### 2. Sentiment Analysis of News (Bullish vs. Bearish Predictions)\n",
       "\n",
       "An analysis of news articles from October 1, 2025, to November 24, 2025, reveals a heavily positive sentiment, driven by major corporate and market developments.\n",
       "\n",
       "#### Bullish Themes (Positive Sentiment)\n",
       "\n",
       "The vast majority of news articles focused on positive developments, with approximately **70 distinct positive mentions** for GOOGL/GOOG. Key bullish themes included:\n",
       "\n",
       "*   **Record Financial Performance:** The company reported its first-ever **$100 billion quarterly revenue** in Q3, with strong double-digit growth in Google Services and a **34% year-over-year surge in Google Cloud** revenue.\n",
       "*   **AI Leadership and Monetization:** News highlighted the successful integration of the **Gemini AI model** across its ecosystem, driving growth in both Search and Cloud. Analysts praised Alphabet's AI strategy as \"healthy\" and \"disciplined,\" contrasting it favorably with competitors.\n",
       "*   **Institutional Confidence:** A massive vote of confidence came from **Warren Buffett's Berkshire Hathaway**, which disclosed a significant **$4.3 billion to $5 billion stake** in Alphabet in Q3, a move widely interpreted as a strong endorsement of the company's value and AI potential.\n",
       "*   **Strategic Wins:** The company secured a multi-million dollar cloud infrastructure contract with **NATO** and announced a **$40 billion investment in Texas** for cloud and AI infrastructure, reinforcing its long-term growth commitment.\n",
       "*   **Valuation:** Alphabet was frequently cited as the **\"cheapest\"** or **\"least overvalued\"** among the \"Magnificent Seven\" tech stocks, making it an attractive buy for value-oriented investors like Buffett.\n",
       "\n",
       "#### Bearish/Neutral Themes (Negative Sentiment)\n",
       "\n",
       "Negative sentiment was minimal, with only **4 distinct negative mentions** for GOOGL/GOOG, primarily related to external competitive threats:\n",
       "\n",
       "*   **Competitive Threats:** The stock experienced a brief drop after **OpenAI launched its ChatGPT Atlas browser**, which was seen as a direct challenge to Google's core search and Chrome dominance.\n",
       "*   **Legal/Regulatory Risk:** The company was named in a **NYC lawsuit** against social media companies over alleged child addiction, introducing a non-core business risk.\n",
       "*   **AI Spending Scrutiny:** While generally praised, Alphabet was included in broader market discussions warning that major tech companies might be **\"overspending\"** on AI infrastructure, raising concerns about the return on investment.\n",
       "\n",
       "### 3. Patterns and Correlations\n",
       "\n",
       "There is a **strong, direct correlation** between the formal analyst recommendations and the real-time news sentiment:\n",
       "\n",
       "1.  **News Validates Recommendations:** The overwhelmingly bullish analyst consensus (zero sells) was consistently validated by the positive news flow. The major events of the period—the record earnings and the Berkshire Hathaway investment—provided concrete, fundamental reasons for analysts to maintain or upgrade their \"Buy\" and \"Strong Buy\" ratings.\n",
       "2.  **AI as the Central Catalyst:** Both sets of data point to **Artificial Intelligence** as the primary driver of bullish sentiment. Analysts are bullish because of Alphabet's AI strategy, and the news is positive because of successful AI execution (Gemini, Cloud growth, custom chips).\n",
       "3.  **Resilience to Bearish News:** The few negative news items (e.g., the OpenAI browser launch) caused only minor, temporary stock fluctuations, failing to shift the overall market or analyst sentiment. This resilience suggests that the market views Alphabet's core business and AI momentum as strong enough to withstand competitive challenges.\n",
       "\n",
       "In summary, the period from October 1, 2025, to November 24, 2025, was characterized by a powerful **bullish feedback loop** for Alphabet, where strong financial results and strategic AI execution reinforced the already positive analyst outlook."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"Compare Google's bullish versus bearish predictions from Oct 01 2025 until today. \n",
    "Include a discussion of recommendation trends, and sentiment analysis of news from the same dates. \n",
    "Discuss any patterns or correlations you find.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:31:11.349496Z",
     "iopub.status.busy": "2025-11-24T21:31:11.348083Z",
     "iopub.status.idle": "2025-11-24T21:40:01.408881Z",
     "shell.execute_reply": "2025-11-24T21:40:01.407741Z",
     "shell.execute_reply.started": "2025-11-24T21:31:11.349458Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "Api.zero_error: model is now gemini-2.5-flash\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "Api.refill_rpm 10\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "Api.refill_rpm 10\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "Api.refill_rpm 10\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "Api.refill_rpm 10\n",
      "send_message: got a response\n",
      "Api.generation_fail.next_model: model is now gemini-2.5-flash-preview-09-2025\n",
      "Api.zero_error: model is now gemini-2.5-flash\n",
      "send_message: get function response\n",
      "send_message: updating state\n",
      "send_message: got a response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here's an outlook for Apple based on recommendation trends and news sentiment from July 01, 2025, until today (November 24, 2025), along with a comparison to its peers in the Computer Hardware, Storage & Peripherals sub-industry:\n",
       "\n",
       "**Apple (AAPL) Outlook:**\n",
       "\n",
       "*   **Recommendation Trends (as of November 1, 2025):** Analysts generally hold a positive view, with 15 \"Strong Buy,\" 23 \"Buy,\" 17 \"Hold,\" and 2 \"Sell\" recommendations. This indicates a predominantly bullish sentiment from financial experts.\n",
       "*   **News Sentiment (July 01, 2025 - November 24, 2025):**\n",
       "    *   **Positive:** News highlights strong iPhone 17 sales, consistent growth in its Services segment, strategic investments in U.S. manufacturing, FDA approval for new Apple Watch health features, and its continued status as a significant holding in many investment funds. Some articles predict Apple's stock could double by 2030, driven by innovation and its ecosystem.\n",
       "    *   **Negative:** Recurring concerns about Apple lagging in AI innovation compared to competitors, potential impacts from antitrust lawsuits (in China and the EU, and from Elon Musk's X Corp), tariff risks, and reduced production orders for the iPhone Air. Warren Buffett's reduction in his Apple stake is also noted as a cautionary signal.\n",
       "    *   **Neutral/Mixed:** There's a mixed perception regarding Apple's AI strategy, with some viewing its cautious approach as prudent while others see it as falling behind. Market concentration risks within ETFs are also mentioned.\n",
       "\n",
       "**Summary for Apple:** Apple's outlook is generally positive from analysts, supported by strong product sales and a growing services division. However, the company faces significant challenges in accelerating its AI development to keep pace with rivals and navigating increasing regulatory scrutiny and trade tensions.\n",
       "\n",
       "---\n",
       "\n",
       "**Peer Comparison (Computer Hardware, Storage & Peripherals):**\n",
       "\n",
       "Apple's peers in this sub-industry exhibit a range of outlooks, largely driven by their direct involvement in the burgeoning AI infrastructure market.\n",
       "\n",
       "**1. DELL TECHNOLOGIES (DELL):**\n",
       "*   **Recommendation Trends (as of November 1, 2025):** Very positive, with 8 \"Strong Buy\" and 18 \"Buy\" recommendations.\n",
       "*   **News Sentiment:** Highly positive. Dell is seen as a leader in AI infrastructure, with strong growth in AI server sales (projected over $20 billion), significant contracts, raised financial guidance, and a commitment to increasing dividends. A recent downgrade by Morgan Stanley due to rising memory costs is a minor negative.\n",
       "\n",
       "**2. WESTERN DIGITAL CORP (WDC):**\n",
       "*   **Recommendation Trends (as of November 1, 2025):** Very positive, with 6 \"Strong Buy\" and 19 \"Buy\" recommendations.\n",
       "*   **News Sentiment:** Extremely positive. Western Digital is a top S&P 500 performer, driven by high demand for data storage from AI companies. It reported strong earnings and a significant dividend increase. Technical indicators suggest it might be \"overbought,\" indicating a potential short-term pullback.\n",
       "\n",
       "**3. SANDISK CORP (SNDK):**\n",
       "*   **Recommendation Trends (as of November 1, 2025):** Positive, with 7 \"Strong Buy\" and 10 \"Buy\" recommendations.\n",
       "*   **News Sentiment:** Strong positive. SanDisk has seen massive stock gains (over 300% this year) due to improving NAND flash market conditions and AI-related storage demand. However, some analysts predict falling memory chip prices in late 2025, and it's also technically \"overbought.\"\n",
       "\n",
       "**4. HEWLETT PACKARD ENTERPRISE (HPE):**\n",
       "*   **Recommendation Trends (as of November 1, 2025):** Moderately positive, with 6 \"Strong Buy\" and 8 \"Buy\" recommendations.\n",
       "*   **News Sentiment:** Moderately positive. HPE is strategically expanding into 5G and AI networking through acquisitions and partnerships. While it reported record revenue from AI demand, restructuring costs have impacted profit margins.\n",
       "\n",
       "**5. PURE STORAGE INC - CLASS A (PSTG):**\n",
       "*   **Recommendation Trends (as of November 1, 2025):** Positive, with 6 \"Strong Buy\" and 13 \"Buy\" recommendations.\n",
       "*   **News Sentiment:** Positive. Pure Storage is experiencing strong revenue growth, driven by its subscription-based model and key clients in the AI sector.\n",
       "\n",
       "**6. HP INC (HPQ):**\n",
       "*   **Recommendation Trends (as of November 1, 2025):** Neutral to slightly positive, with 2 \"Strong Buy\" and 3 \"Buy\" recommendations.\n",
       "*   **News Sentiment:** Neutral to slightly positive. HP is innovating in AI PCs and gaming hardware and focusing on sustainability. However, profitability concerns temper the positive sentiment from its product developments.\n",
       "\n",
       "**7. NETAPP INC (NTAP):**\n",
       "*   **Recommendation Trends (as of November 1, 2025):** Moderately positive, with 3 \"Strong Buy\" and 9 \"Buy\" recommendations.\n",
       "*   **News Sentiment:** Moderately positive. NetApp is aligning with new AI-powered storage technologies, as indicated by its collaboration with Broadcom. Limited detailed news sentiment is available.\n",
       "\n",
       "**8. SUPER MICRO COMPUTER INC (SMCI):**\n",
       "*   **Recommendation Trends (as of November 1, 2025):** Mixed to slightly positive, with 2 \"Strong Buy\" and 10 \"Buy\" recommendations.\n",
       "*   **News Sentiment:** Mixed. SMCI has strong partnerships with Nvidia and significant AI order backlogs. However, it has faced challenges with missed revenue expectations, declining margins, and negative cash flow, leading to recent stock declines.\n",
       "\n",
       "**9. IONQ INC (IONQ):**\n",
       "*   **Recommendation Trends (as of November 1, 2025):** Very positive, with 2 \"Strong Buy\" and 10 \"Buy\" recommendations.\n",
       "*   **News Sentiment:** Highly mixed. IonQ shows promising technological advancements in quantum computing and strategic acquisitions. However, it's characterized by extremely high valuations, minimal revenue, substantial operating losses, and reliance on equity issuances, making it a very high-risk, speculative investment. Recent stock declines are a concern.\n",
       "\n",
       "**10. QUANTUM COMPUTING INC (QUBT):**\n",
       "*   **Recommendation Trends (as of November 1, 2025):** Very positive, with 2 \"Strong Buy\" and 5 \"Buy\" recommendations.\n",
       "*   **News Sentiment:** Highly mixed. QUBT has reported strong Q3 earnings and a significant capital raise. However, its extremely high valuation, minimal revenue, and substantial stock declines make it a very high-risk, speculative investment.\n",
       "\n",
       "**11. COMPOSECURE INC-A (CMPO):**\n",
       "*   **Recommendation Trends:** No specific recommendation trends available.\n",
       "*   **News Sentiment:** Limited, but suggests positive strategic moves with a planned business combination.\n",
       "\n",
       "---\n",
       "\n",
       "**Comparison of Apple to its Peers:**\n",
       "\n",
       "*   **AI Leadership:** Apple is generally perceived as *lagging* in AI innovation compared to many of its peers, particularly those directly involved in AI infrastructure like Dell, Western Digital, and SanDisk. These peers are actively reporting significant revenue growth and strategic expansions directly tied to the AI boom. While Apple is investing in AI, its progress is often described as \"cautious\" or \"slow.\"\n",
       "*   **Valuation vs. Growth:** Apple's stock is frequently cited as having a high valuation without a corresponding high growth rate, leading to concerns from some investors. In contrast, some AI infrastructure peers (e.g., Dell) are seen as potentially undervalued despite strong AI-driven growth. Quantum computing peers (IonQ, QUBT) have *extremely* high valuations relative to their minimal revenue, highlighting their speculative nature.\n",
       "*   **Growth Drivers:** Apple's primary growth drivers are iPhone sales and its expanding Services segment. Its peers in the hardware and storage sector are experiencing growth directly from the massive demand for AI servers, data storage, and memory solutions, which is a more direct and immediate benefit from the current AI trend.\n",
       "*   **Investor Sentiment:** While Apple benefits from a strong brand and loyal customer base, investor sentiment is somewhat cautious due to its AI position and regulatory challenges. Many of its AI-focused peers are enjoying strong investor confidence and significant stock surges directly linked to the AI boom.\n",
       "*   **Risks:** Apple faces unique risks related to regulatory pressures (antitrust), trade tariffs, and the challenge of accelerating its AI strategy. Its AI infrastructure peers face risks related to market competition and supply chain dynamics. The quantum computing peers carry the highest risk due to the nascent stage of their technology, unproven commercial viability, and high cash burn.\n",
       "\n",
       "**Overall Conclusion:**\n",
       "\n",
       "While Apple remains a robust company with strong fundamentals, its outlook is somewhat tempered by its perceived lag in AI innovation and ongoing regulatory challenges. Many of its peers in the computer hardware, storage, and peripherals sub-industry, particularly those directly contributing to AI infrastructure, are currently experiencing more dynamic and significant positive momentum driven by the AI revolution. Apple needs to demonstrate more tangible and impactful AI advancements to fully capitalize on the current technological trends and potentially outperform its more AI-centric peers."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"How is the outlook for Apple based on trends and news sentiment from July 01 2025 until today? \n",
    "Perform the same analysis on all peers by sub-industry. Then compare Apple result to it's peers.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T21:40:01.41022Z",
     "iopub.status.busy": "2025-11-24T21:40:01.409936Z",
     "iopub.status.idle": "2025-11-24T21:40:19.581391Z",
     "shell.execute_reply": "2025-11-24T21:40:19.580338Z",
     "shell.execute_reply.started": "2025-11-24T21:40:01.410197Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: get function response\n",
      "send_message: get function response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "send_message: updating state\n",
      "send_message: got a response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here's a detailed analysis of the recent news about Apple and the impact of tariffs, along with candlestick data for the period of September 1, 2025, to November 24, 2025, and a discussion of their correlations.\n",
       "\n",
       "**News Regarding Apple and Tariffs (September 1, 2025 - November 24, 2025):**\n",
       "\n",
       "Several news articles during this period discuss the impact of tariffs on Apple, with varying sentiments:\n",
       "\n",
       "*   **September 3, 2025:** News broke that a U.S. federal judge ruled that Alphabet (Google) does not have to divest Chrome and can continue paying partners like Apple to feature its search engine. This was seen as positive for Apple, with its stock rising over 3% due to the favorable Google lawsuit outcome and a \"potential reduction in tariff concerns.\"\n",
       "*   **September 4, 2025:** Another article reiterated the positive impact of the Alphabet antitrust ruling on Apple, stating that Apple's stock rallied 4% as its \"lucrative search engine deal with Google is expected to continue in some form.\" However, another article on the same day mentioned Apple \"falling behind in AI, facing potential tariff threats, and showing slower revenue growth compared to competitors,\" indicating a mixed outlook.\n",
       "*   **September 10, 2025:** Goldman Sachs warned that \"Magnificent Seven\" tech companies, including Apple, are diverting significant funds to AI data center construction, which is slowing down their share buyback activities. This suggests a strategic shift in capital allocation, potentially influenced by broader economic factors like tariffs.\n",
       "*   **September 17, 2025:** An article noted that global notebook shipments are expected to grow in 2025, driven by production capacity expansion in Southeast Asia, with Apple \"investing large-scale in Vietnam, supporting regional production expansion.\" This indicates Apple's strategy to mitigate trade risks and diversify its supply chain, likely in response to tariff concerns.\n",
       "*   **September 18, 2025:** Apple was mentioned as having pledged \"$500 billion investment in AI over four years, demonstrating long-term technological commitment.\" This significant investment could be a strategic move to enhance its competitive edge amidst various market challenges, including tariffs.\n",
       "*   **October 6, 2025:** An article mentioned Apple \"striking side deals to mitigate tariff impacts, indicating strategic adaptability.\" This highlights Apple's proactive approach to navigating trade tensions.\n",
       "*   **October 9, 2025:** News reported that \"Trump Shocks Markets: VIX Spikes 25%, S&P 500 Eyes Worst Day Since April\" due to \"President Trump's renewed tariff threats against China.\" Apple was specifically mentioned as having \"experienced significant stock price decline as part of broader market selloff.\"\n",
       "*   **October 10, 2025:** Qualcomm's stock dropped after China launched an antitrust investigation, signaling \"increased regulatory scrutiny on U.S. tech firms ahead of a potential summit between Presidents Trump and Xi Jinping.\" Apple was mentioned in this context as potentially losing business, though no direct negative impact was reported.\n",
       "*   **October 14, 2025:** An article discussed the \"Massive News for Stock Market Investors as the Trade War Between the U.S. and China Escalates,\" mentioning Apple in the disclosure without specific insights.\n",
       "*   **October 16, 2025:** MP Materials, a rare-earth metal mining company, secured a \"$500 million agreement with Apple,\" positioning itself to support domestic supply chains for advanced technologies. This is a positive development for Apple in securing critical materials, potentially reducing its vulnerability to rare earth element export restrictions.\n",
       "*   **October 26, 2025:** A news piece titled \"Is Apple Going to Be Hit Hard by President Trump's Tariffs?\" highlighted \"potential significant challenges from US-China trade tensions, particularly around rare earth element export restrictions that could disrupt iPhone component supply chains by November 1st.\" The sentiment for Apple was \"negative\" due to these potential impacts.\n",
       "*   **October 28, 2025:** An article stated that Apple \"successfully avoided arduous tariffs through strategic U.S. investments, relocated iPhone production, achieved exemptions from Chinese and Indian tariffs, shares up 53% from April lows.\" This indicates Apple's successful mitigation strategies. Another article on the same day mentioned Apple preparing for an investor update focusing on \"tariff impacts and AI progress,\" with early indications of strong iPhone 17 sales.\n",
       "*   **October 31, 2025:** A report on \"Global Rare Earth Magnets\" mentioned Apple \"invested $500M in MP Materials for recycling facility development, proactively addressing supply chain risks.\" This reinforces Apple's efforts to secure its supply chain against disruptions like tariffs.\n",
       "*   **November 2, 2025:** An article on MP Materials reiterated Apple's \"$500 million in partnership with MP Materials to secure long-term supply of recycled magnets, indicating strategic interest in rare earth metal supply chain.\"\n",
       "*   **November 18, 2025:** \"The Stock Market Flashes a Warning as Investors Get Bad News About President Trump's Tariffs\" reported that Apple \"reported $1.1 billion in tariff-related cost increases, expected to rise to $1.4 billion.\" This indicates a direct financial impact of tariffs on Apple.\n",
       "*   **November 19, 2025:** Goldman Sachs initiated coverage on MP Materials with a Buy rating, highlighting its strategic importance and mentioning Apple as a partner in magnet supply and recycling with a \"$500 million commitment.\"\n",
       "\n",
       "**Candlestick Data for Apple (AAPL) (September 1, 2025 - November 24, 2025):**\n",
       "\n",
       "Here's a summary of the candlestick data, focusing on significant movements:\n",
       "\n",
       "*   **Early September (Sept 1-4):** The stock opened around $229.25 on Sept 1st and saw a notable increase, closing at $239.69 on Sept 4th.\n",
       "*   **Mid-September (Sept 5-12):** There was a dip to $226.79 on Sept 7th, followed by a recovery and a significant jump to $245.50 on Sept 12th, and then to $256.08 on Sept 15th.\n",
       "*   **Late September - Early October (Sept 15 - Oct 9):** The stock generally trended upwards, reaching a high of $277.32 on Oct 3rd, but then experienced a sharp decline, closing at $245.27 on Oct 9th.\n",
       "*   **Mid-October (Oct 10-16):** The stock recovered some losses, reaching $262.24 on Oct 16th.\n",
       "*   **Late October - Early November (Oct 17 - Nov 7):** The stock showed some volatility, with a high of $275.96 on Nov 5th, and then a decline to $267.46 on Nov 7th.\n",
       "*   **Mid-November (Nov 8 - Nov 24):** The stock generally remained in a range, with some fluctuations. The last recorded close on Nov 24th was $271.49.\n",
       "\n",
       "**Correlations in Patterns between Candlestick and News Data:**\n",
       "\n",
       "1.  **Early September Rally (Sept 1-4) and Google Antitrust Ruling:** The positive news on September 3rd and 4th regarding the favorable Google antitrust ruling, which was seen to reduce tariff concerns and secure Apple's lucrative search engine deal, directly correlates with the upward movement in Apple's stock price during the first few days of September. The stock rose from around $229 to nearly $240.\n",
       "\n",
       "2.  **Mid-September Dip (Sept 7) and AI/Tariff Concerns:** While the overall trend in mid-September was upward, a dip to $226.79 on September 7th could be loosely correlated with the news on September 4th mentioning Apple \"falling behind in AI, facing potential tariff threats.\" Although the news was from a few days prior, market sentiment can sometimes have a delayed reaction or be influenced by a confluence of factors.\n",
       "\n",
       "3.  **October 9th Sharp Decline and Trump's Tariff Threats:** This is a very strong correlation. The news on October 9th explicitly stated that \"President Trump's renewed tariff threats against China triggered a significant market selloff,\" and Apple \"experienced significant stock price decline.\" The candlestick data clearly shows a sharp drop in Apple's stock on October 9th, closing at $245.27 after being in the $250-$270 range in the preceding days.\n",
       "\n",
       "4.  **Late October - Early November Recovery and Tariff Mitigation Strategies:** Following the sharp decline on October 9th, Apple's stock showed a recovery in late October and early November. This aligns with news on October 28th stating that Apple \"successfully avoided arduous tariffs through strategic U.S. investments, relocated iPhone production, achieved exemptions from Chinese and Indian tariffs.\" The news about Apple's proactive measures to mitigate tariff impacts likely contributed to renewed investor confidence and a rebound in the stock price. Additionally, the news on October 16th and October 31st about Apple's strategic partnership with MP Materials to secure rare earth magnets also likely played a role in this recovery, as it addressed a key supply chain vulnerability related to trade tensions.\n",
       "\n",
       "5.  **November 18th Tariff-Related Cost Increase and Stock Performance:** The news on November 18th, reporting that Apple \"reported $1.1 billion in tariff-related cost increases, expected to rise to $1.4 billion,\" indicates a direct negative financial impact. While the candlestick data for November 18th shows a close of $267.44, which isn't a drastic drop, it's important to note that the stock had been in a slightly higher range in the days leading up to this, suggesting that the news might have capped further upward movement or contributed to a slight downward pressure.\n",
       "\n",
       "**Conclusion:**\n",
       "\n",
       "There are clear correlations between the news regarding tariffs and Apple's stock performance during the specified period. Positive news related to tariff mitigation or favorable rulings (like the Google antitrust case) tended to coincide with upward movements in Apple's stock. Conversely, renewed tariff threats from the U.S. government directly led to a significant decline in Apple's stock. Apple's strategic investments in diversifying its supply chain and relocating production, as reported in the news, appear to have played a crucial role in mitigating some of the negative impacts of tariffs and contributing to stock recoveries. The direct reporting of tariff-related cost increases also had a discernible, albeit sometimes subtle, impact on the stock's trajectory."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"What does the recent news say about Apple and the impact of tariffs? From 2025-09-01 up to today. \n",
    "Also locate candlestick data for the same dates. \n",
    "Discuss in detail any correlations in patterns between the candlestick and news data. Ignore duplicate news entry.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StockChat: Agents Edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setup working directory on Kaggle.\n",
    "if os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
    "    if not os.path.isdir(\"sc2/\"):\n",
    "        !git init -b main\n",
    "        !git remote add origin https://github.com/lol-dungeonmaster/kaggle-agents-2025.git\n",
    "        !git config core.sparseCheckout true\n",
    "        !echo \"sc2/\" >> .git/info/sparse-checkout\n",
    "        !git pull origin main\n",
    "        for api_key in [\"GOOGLE_API_KEY\",\"POLYGON_API_KEY\",\"FINNHUB_API_KEY\"]:\n",
    "            env_key = UserSecretsClient().get_secret(api_key)\n",
    "            !echo \"$api_key=$env_key\" >> sc2/.env # from .venv on local runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sc2.src import log\n",
    "from sc2.agent import app\n",
    "\n",
    "async def on_event(e: Event, q: str):\n",
    "    try:\n",
    "        response = e.content.parts[0].text\n",
    "        if response and response != \"None\":\n",
    "            log.info(f\"USER  > {q}\")\n",
    "            log.info(f\"MODEL > {response}\\n\")\n",
    "    except Exception as err:\n",
    "        log.error(f\"on_event.exception: {str(err)}\")\n",
    "\n",
    "async def run_queries(app: App, sessions: SessionService, queries: list[str],\n",
    "                      session_id: str = \"default\", user_id: str = \"default\"):\n",
    "    runner = Runner(app=app, session_service=sessions)\n",
    "    try:\n",
    "        session = await sessions.create_session(\n",
    "            app_name=runner.app_name, user_id=user_id, session_id=session_id\n",
    "        )\n",
    "    except:\n",
    "        session = await sessions.get_session(\n",
    "            app_name=runner.app_name, user_id=user_id, session_id=session_id\n",
    "        )\n",
    "    finally:\n",
    "        log.info(f\"### Agent session: (uid={user_id}) {session_id}\")\n",
    "        for q in queries:\n",
    "            query = types.Content(role=\"user\", parts=[types.Part(text=q)])\n",
    "            try:\n",
    "                async for response in runner.run_async(\n",
    "                    user_id=user_id, session_id=session.id, new_message=query\n",
    "                ): await on_event(response, q)\n",
    "            except Exception as e:\n",
    "                log.error(f\"run_async (q={\" \".join(q.split()[:5])}): ({type(e).__name__}) {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inmemory = InMemorySessionService()\n",
    "\n",
    "await run_queries(\n",
    "    app=app,\n",
    "    sessions=inmemory,\n",
    "    queries=[\n",
    "        \"What tools do you know how to use?\",\n",
    "        \"What functions does fncall_pipeline have knowledge about?\",\n",
    "        \"What is a short trade?\"])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7122584,
     "sourceId": 11376588,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
