{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/oswind/stockchat-agents-edition?scriptVersionId=279296762\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-17T22:27:52.173526Z",
     "iopub.status.busy": "2025-11-17T22:27:52.173082Z",
     "iopub.status.idle": "2025-11-17T22:31:05.912562Z",
     "shell.execute_reply": "2025-11-17T22:31:05.911679Z",
     "shell.execute_reply.started": "2025-11-17T22:27:52.173496Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Setup the notebook based on running environment.\n",
    "import os\n",
    "# Optional: Enable telemetry in browser_use and chromadb.\n",
    "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"false\"\n",
    "# Check for kaggle environment.\n",
    "if os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
    "    # Kaggle Run: update the system.\n",
    "    !pip uninstall -qqy google-ai-generativelanguage pydrive2 tensorflow tensorflow-decision-forests cryptography pyOpenSSL langchain langchain-core nltk ray click google-generativeai google-cloud-translate datasets cesium bigframes plotnine mlxtend fastai spacy thinc google-colab gcsfs jupyter-kernel-gateway\n",
    "    !pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n",
    "    !pip install -qU langchain-community langchain-text-splitters wikipedia lmnr[all] google-adk google-cloud-translate\n",
    "    from kaggle_secrets import UserSecretsClient # type: ignore\n",
    "    from jupyter_server.serverapp import list_running_servers # type: ignore\n",
    "else:\n",
    "    # Mock the kaggle secrets client.\n",
    "    class UserSecretsClient:\n",
    "        @classmethod\n",
    "        def set_secret(cls, id: str, value: str):\n",
    "            os.environ[id] = value\n",
    "        @classmethod\n",
    "        def get_secret(cls, id: str):\n",
    "            try:\n",
    "                return os.environ[id]\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError: authentication token for {id} is undefined\")\n",
    "    # Local Run: update the venv.\n",
    "    %pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n",
    "    %pip install -qU langchain-community langchain-text-splitters wikipedia pandas google-api-core \"lmnr[all]\" browser-use ollama google-adk\n",
    "    from browser_use import Agent as BrowserAgent\n",
    "\n",
    "import ast, chromadb, json, logging, pandas, platform, pytz, re, requests, threading, time, warnings, wikipedia\n",
    "from bs4 import Tag\n",
    "from chromadb import Documents, Embeddings\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from enum import Enum\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google import genai\n",
    "from google.api_core import retry, exceptions\n",
    "from google.genai.models import Models\n",
    "from google.genai import types, errors\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_text_splitters.html import HTMLSemanticPreservingSplitter\n",
    "from langchain_text_splitters.json import RecursiveJsonSplitter\n",
    "from lmnr import Laminar\n",
    "from math import inf\n",
    "from pydantic import BaseModel, field_validator\n",
    "from threading import Timer\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Callable, NewType, NamedTuple\n",
    "from wikipedia.exceptions import DisambiguationError, PageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:31:05.915255Z",
     "iopub.status.busy": "2025-11-17T22:31:05.914487Z",
     "iopub.status.idle": "2025-11-17T22:31:06.097509Z",
     "shell.execute_reply": "2025-11-17T22:31:06.09621Z",
     "shell.execute_reply.started": "2025-11-17T22:31:05.915221Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError: authentication token for LMNR_PROJECT_API_KEY is undefined\n",
      "Skipping Laminar.initialize()\n"
     ]
    }
   ],
   "source": [
    "# Prepare the Gemini api for use.\n",
    "# Setup a retry helper for generation not run through the below api-helper.\n",
    "is_retriable = lambda e: (isinstance(e, errors.APIError) and e.code in {429, 503, 500})\n",
    "Models.generate_content = retry.Retry(predicate=is_retriable)(Models.generate_content)\n",
    "Models.embed_content = retry.Retry(predicate=is_retriable)(Models.embed_content)\n",
    "\n",
    "# Activate Laminar auto-instrumentation.\n",
    "try:\n",
    "    Laminar.initialize(project_api_key=UserSecretsClient().get_secret(\"LMNR_PROJECT_API_KEY\"))\n",
    "except:\n",
    "    print(\"Skipping Laminar.initialize()\")\n",
    "\n",
    "class GeminiModel:\n",
    "    def __init__(self, rpm: list, tpm: list, rpd: list):\n",
    "        self.rpm = rpm # requests per minute\n",
    "        self.tpm = tpm # tokens per minute in millions\n",
    "        self.rpd = rpd # requests per day\n",
    "        self.err = [0,0] # validation, api_related\n",
    "\n",
    "# A python api-helper with model fail-over/chaining/retry support.\n",
    "GeminiEmbedFunction = NewType(\"GeminiEmbedFunction\", None) # forward-decl\n",
    "class Gemini:\n",
    "    gen_limit_in = 1048576\n",
    "    emb_limit_in = 2048\n",
    "    gen_model = {\n",
    "        \"gemini-2.0-flash\": GeminiModel([15,2000,10000,30000],[1,4,10,30],[200,inf,inf,inf]), # stable wo/thinking: 15 RPM/1M TPM/200 RPD\n",
    "        \"gemini-2.0-flash-exp\": GeminiModel([15,2000,10000,30000],[1,4,10,30],[200,inf,inf,inf]), # latest w/thinking: 15 RPM/1M TPM/200 RPD\n",
    "        \"gemini-2.5-flash-preview-09-2025\": GeminiModel([10,1000,2000,10000],[.25,1,3,8],[250,10000,100000,inf]), # exp: 10 RPM/250K TPM/250 RPD\n",
    "        \"gemini-2.5-flash\": GeminiModel([10,1000,2000,10000],[.25,1,3,8],[250,10000,100000,inf]), # stable: 10 RPM/250K TPM/250 RPD\n",
    "        \"gemini-2.5-flash-lite-preview-09-2025\": GeminiModel([15,4000,10000,30000],[.25,4,10,30],[1000,inf,inf,inf]), # exp: 15 RPM/250K TPM/1K RPD\n",
    "        \"gemini-2.5-flash-lite\": GeminiModel([15,4000,10000,30000],[.25,4,10,30],[1000,inf,inf,inf]), # stable: 15 RPM/250K TPM/1K RPD\n",
    "        \"gemini-2.5-pro\": GeminiModel([5,150,1000,2000],[.25,2,5,8],[100,10000,50000,inf]), # stable: 5 RPM/250K TPM/100 RPD\n",
    "    }\n",
    "    gen_local = [\"gemma3n:e4b\",\"gemma3:12b-it-qat\"]\n",
    "    default_local = 0\n",
    "    default_model = []\n",
    "    embed_model = \"gemini-embedding-001\", GeminiModel([100,3000,5000,10000],[.03,1,5,10],[1000,inf,inf,inf]) # stable: 100 RPM/30K TPM/1000 RPD/100 per batch\n",
    "    embed_local = False\n",
    "    error_total = 0\n",
    "    min_rpm = 3\n",
    "    dt_between = 2.0\n",
    "    errored = False\n",
    "    running = False\n",
    "    dt_err = 60.0\n",
    "    dt_rpm = 60.0\n",
    "\n",
    "    @classmethod\n",
    "    def get(cls, url: str):\n",
    "        # Create a header matching the OS' tcp-stack fingerprint.\n",
    "        system_ua = None\n",
    "        match platform.system():\n",
    "            case 'Linux':\n",
    "                system_ua = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'\n",
    "            case 'Darwin':\n",
    "                system_ua = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 15_7_2) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/26.0 Safari/605.1.15'\n",
    "            case 'Windows':\n",
    "                system_ua = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'\n",
    "        try:\n",
    "            request = requests.get(url, headers={'User-Agent': system_ua})\n",
    "            if request.status_code != requests.codes.ok:\n",
    "                print(f\"Gemini.get() returned status {request.status_code}\")\n",
    "            return request.text\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    class Limit(Enum):\n",
    "        FREE = 0\n",
    "        TIER_1 = 1\n",
    "        TIER_2 = 2\n",
    "        TIER_3 = 3\n",
    "    \n",
    "    class Model(Enum):\n",
    "        GEN = 1\n",
    "        EMB = 2\n",
    "        LOC = 3\n",
    "\n",
    "    class Const(Enum):\n",
    "        STOP = \"I don't know.\"\n",
    "        METRIC_BATCH = 20\n",
    "        SERIES_BATCH = 40\n",
    "        EMBED_BATCH = 100\n",
    "        CHUNK_MAX = 1500\n",
    "\n",
    "        @classmethod\n",
    "        def Stop(cls):\n",
    "            return cls.STOP.value\n",
    "\n",
    "        @classmethod\n",
    "        def MetricBatch(cls):\n",
    "            return cls.METRIC_BATCH.value\n",
    "\n",
    "        @classmethod\n",
    "        def SeriesBatch(cls):\n",
    "            return cls.SERIES_BATCH.value\n",
    "\n",
    "        @classmethod\n",
    "        def EmbedBatch(cls):\n",
    "            return cls.EMBED_BATCH.value\n",
    "\n",
    "        @classmethod\n",
    "        def ChunkMax(cls):\n",
    "            return cls.CHUNK_MAX.value\n",
    "    \n",
    "    class Env(NamedTuple): # Make init args immutable.\n",
    "        CLIENT: genai.Client\n",
    "        API_LIMIT: int\n",
    "        GEN_DEFAULT: str\n",
    "\n",
    "    def __init__(self, with_limit: Limit, default_model: str):\n",
    "        if default_model in self.gen_model.keys():\n",
    "            self.write_lock = threading.RLock()\n",
    "            self.args = Gemini.Env(\n",
    "                genai.Client(api_key=UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")),\n",
    "                with_limit.value,\n",
    "                default_model)\n",
    "            self.m_id = list(self.gen_model.keys()).index(default_model)\n",
    "            self.default_model.append(default_model)\n",
    "            self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.args.API_LIMIT]\n",
    "            self.s_embed = GeminiEmbedFunction(self.args.CLIENT, semantic_mode = True) # type: ignore\n",
    "            logging.getLogger(\"google_genai\").setLevel(logging.WARNING) # suppress info on generate\n",
    "        else:\n",
    "            print(f\"{default_model} not found in gen_model.keys()\")\n",
    "        \n",
    "\n",
    "    def __call__(self, model: Model) -> str:\n",
    "        if model == self.Model.GEN:\n",
    "            return \"models/\" + list(self.gen_model.keys())[self.m_id]\n",
    "        elif model == self.Model.LOC:\n",
    "            return self.gen_local[self.default_local]\n",
    "        else:\n",
    "            return \"models/\" + self.embed_model[0] if not self.embed_local else \"embeddinggemma:latest\"\n",
    "\n",
    "    def push_default_model(self, model_id: str):\n",
    "        if model_id in self.gen_model.keys():\n",
    "            self.write_lock.acquire()\n",
    "            self.stop_running()\n",
    "            self.default_model.append(model_id)\n",
    "            self.m_id = list(self.gen_model.keys()).index(model_id)\n",
    "            self.write_lock.release()\n",
    "        else:\n",
    "            print(f\"{model_id} not found in gen_model.keys()\")\n",
    "\n",
    "    def pop_default_model(self):\n",
    "        if len(self.default_model) > 1:\n",
    "            self.write_lock.acquire()\n",
    "            self.stop_running()\n",
    "            self.default_model.pop(-1)\n",
    "            self.m_id = list(self.gen_model.keys()).index(self.default_model[-1])\n",
    "            self.write_lock.release()\n",
    "\n",
    "    def retriable(self, retry_fn: Callable, *args, **kwargs):\n",
    "        for attempt in range(len(self.gen_model.keys())):\n",
    "            try:\n",
    "                self.write_lock.acquire()\n",
    "                if self.gen_rpm > self.min_rpm:\n",
    "                    self.gen_rpm -= 1\n",
    "                else:\n",
    "                    self.on_error(kwargs)\n",
    "                if not self.running and not self.errored:\n",
    "                    self.rpm_timer = Timer(self.dt_rpm, self.refill_rpm)\n",
    "                    self.rpm_timer.start()\n",
    "                    self.running = True\n",
    "                return retry_fn(*args, **kwargs)\n",
    "            except (errors.APIError, exceptions.RetryError) as api_error:\n",
    "                if isinstance(api_error, errors.APIError):\n",
    "                    is_retry = api_error.code in {429, 503, 500, 400} # code 400 when TPM exceeded\n",
    "                    if not is_retry or attempt == len(self.gen_model.keys())-1:\n",
    "                        raise api_error\n",
    "                self.on_error(kwargs)\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "            finally:\n",
    "                self.write_lock.release()\n",
    "\n",
    "    def on_error(self, kwargs):\n",
    "        self.generation_fail()\n",
    "        kwargs[\"model\"] = self(Gemini.Model.GEN)\n",
    "        time.sleep(self.dt_between)\n",
    "\n",
    "    def stop_running(self):\n",
    "        if self.running:\n",
    "            self.rpm_timer.cancel()\n",
    "            self.running = False\n",
    "\n",
    "    def validation_fail(self):\n",
    "        list(self.gen_model.values())[self.m_id].err[0] += 1\n",
    "        self.error_total += 1\n",
    "\n",
    "    def generation_fail(self):\n",
    "        self.stop_running()\n",
    "        self.save_error()\n",
    "        self.next_model()\n",
    "        print(\"api.generation_fail.next_model: model is now \", list(self.gen_model.keys())[self.m_id])\n",
    "        if not self.errored:\n",
    "            self.error_timer = Timer(self.dt_err, self.zero_error)\n",
    "            self.error_timer.start()\n",
    "            self.errored = True\n",
    "\n",
    "    def save_error(self):\n",
    "        list(self.gen_model.values())[self.m_id].err[1] += 1\n",
    "        self.error_total += 1\n",
    "\n",
    "    def next_model(self):\n",
    "        self.m_id = (self.m_id+1)%len(self.gen_model.keys())\n",
    "        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.args.API_LIMIT]\n",
    "\n",
    "    def refill_rpm(self):\n",
    "        self.running = False\n",
    "        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.args.API_LIMIT]\n",
    "        print(\"api.refill_rpm \", self.gen_rpm)\n",
    "\n",
    "    def zero_error(self):\n",
    "        self.errored = False\n",
    "        self.m_id = list(self.gen_model.keys()).index(self.default_model[-1])\n",
    "        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.args.API_LIMIT]\n",
    "        print(\"api.zero_error: model is now \", list(self.gen_model.keys())[self.m_id])\n",
    "\n",
    "    def token_count(self, expr: str):\n",
    "        count = self.args.CLIENT.models.count_tokens(\n",
    "            model=self(Gemini.Model.GEN),\n",
    "            contents=json.dumps(expr))\n",
    "        return count.total_tokens\n",
    "\n",
    "    def errors(self):\n",
    "        errors = {\"total\": self.error_total, \"by_model\": {}}\n",
    "        for m_code, m in self.gen_model.items():\n",
    "            errors[\"by_model\"].update({\n",
    "                m_code: {\n",
    "                    \"api_related\": m.err[1],\n",
    "                    \"validation\": m.err[0]\n",
    "                }})\n",
    "        return errors\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def similarity(self, content: list):\n",
    "        return self.s_embed.sts(content) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:31:06.098675Z",
     "iopub.status.busy": "2025-11-17T22:31:06.098341Z",
     "iopub.status.idle": "2025-11-17T22:31:06.109778Z",
     "shell.execute_reply": "2025-11-17T22:31:06.108685Z",
     "shell.execute_reply.started": "2025-11-17T22:31:06.098653Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the embedding function.\n",
    "api = NewType(\"Gemini\", None) # type: ignore (forward-decl)\n",
    "class GeminiEmbedFunction:\n",
    "    document_mode = True  # Generate embeddings for documents (T,F), or queries (F,F).\n",
    "    semantic_mode = False # Semantic text similarity mode is exclusive (F,T).\n",
    "    \n",
    "    def __init__(self, genai_client, semantic_mode: bool = False):\n",
    "        self.client = genai_client\n",
    "        if semantic_mode:\n",
    "            self.document_mode = False\n",
    "            self.semantic_mode = True\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def __embed__(self, input: Documents) -> Embeddings:\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\"\n",
    "        elif not self.document_mode and not self.semantic_mode:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "        elif not self.document_mode and self.semantic_mode:\n",
    "            embedding_task = \"semantic_similarity\"\n",
    "        partial = self.client.models.embed_content(\n",
    "            model=api(Gemini.Model.EMB),\n",
    "            contents=input,\n",
    "            config=types.EmbedContentConfig(task_type=embedding_task)) # type: ignore\n",
    "        return [e.values for e in partial.embeddings]\n",
    "    \n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        try:\n",
    "            response = []\n",
    "            for i in range(0, len(input), Gemini.Const.EmbedBatch()):  # Gemini max-batch-size is 100.\n",
    "                response += self.__embed__(input[i:i + Gemini.Const.EmbedBatch()])\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"caught exception of type {type(e)}\\n{e}\")\n",
    "            raise e\n",
    "\n",
    "    def sts(self, content: list) -> float:\n",
    "        df = pandas.DataFrame(self(content), index=content)\n",
    "        score = df @ df.T\n",
    "        return score.iloc[0].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Gemini API Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:31:06.112101Z",
     "iopub.status.busy": "2025-11-17T22:31:06.111792Z",
     "iopub.status.idle": "2025-11-17T22:31:06.519202Z",
     "shell.execute_reply": "2025-11-17T22:31:06.517693Z",
     "shell.execute_reply.started": "2025-11-17T22:31:06.112078Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the api-helper with usage limit => FREE.\n",
    "# Optional: Set limit here to one of [FREE,TIER_1,TIER_2,TIER_3]\n",
    "api = Gemini(with_limit=Gemini.Limit.FREE, default_model=\"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini Baseline Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:30:47.128595Z",
     "iopub.status.busy": "2025-11-17T20:30:47.128224Z",
     "iopub.status.idle": "2025-11-17T20:30:52.902225Z",
     "shell.execute_reply": "2025-11-17T20:30:52.90092Z",
     "shell.execute_reply.started": "2025-11-17T20:30:47.128563Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, I do. Here's some information about the stock market:\n",
       "\n",
       "**What it is:**\n",
       "\n",
       "*   A stock market is a place where stocks (shares of ownership in companies), bonds, and other securities are bought and sold. It can be a physical exchange or an electronic network.\n",
       "*   Stock exchanges facilitate trading between buyers and sellers, providing a marketplace and real-time trading information to help with price discovery.\n",
       "\n",
       "**Key functions:**\n",
       "\n",
       "*   **Facilitating trading:** Stock exchanges provide a platform for buyers and sellers to exchange securities.\n",
       "*   **Price discovery:** The interaction of buyers and sellers helps determine the prices of securities.\n",
       "*   **Liquidity:** Stock markets make it easier to buy and sell stocks, increasing their liquidity and attractiveness to investors.\n",
       "\n",
       "**Major stock exchanges:**\n",
       "\n",
       "*   Examples include the New York Stock Exchange (NYSE), Nasdaq, and the London Stock Exchange.\n",
       "\n",
       "**Market size:**\n",
       "\n",
       "*   The total market capitalization of all publicly traded stocks worldwide was US$111 trillion by the end of 2023.\n",
       "\n",
       "**Indices:**\n",
       "\n",
       "*   Stock market indices track the performance of a group of stocks, providing a snapshot of the market or a sector. Examples include the S&P 500, FTSE, and Nasdaq Composite.\n",
       "\n",
       "**Strategies:**\n",
       "\n",
       "*   **Short selling:** Borrowing stock and selling it, hoping the price will fall so you can buy it back at a lower price and return it to the lender.\n",
       "*   **Margin buying:** Borrowing money to buy stocks.\n",
       "\n",
       "**Recent Market Activity:**\n",
       "\n",
       "*   On November 17, 2025, the US500 fell to 6685 points, a 0.73% decrease from the previous session.\n",
       "*   The S&P 500 is down approximately 0.5%.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is an accurate retelling of events. \n",
    "config_with_search = types.GenerateContentConfig(\n",
    "    tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "chat = api.args.CLIENT.chats.create(\n",
    "    model=api(Gemini.Model.GEN),\n",
    "    config=config_with_search,\n",
    "    history=[]) # Ignoring the part about dark elves, and tengwar.\n",
    "\n",
    "response = chat.send_message('Do you know anything about the stock market?')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:30:52.903823Z",
     "iopub.status.busy": "2025-11-17T20:30:52.903504Z",
     "iopub.status.idle": "2025-11-17T20:30:56.890594Z",
     "shell.execute_reply": "2025-11-17T20:30:56.889482Z",
     "shell.execute_reply.started": "2025-11-17T20:30:52.903796Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, here's some information regarding AMZN (Amazon) stock as of November 17, 2025:\n",
       "\n",
       "**Key Data:**\n",
       "\n",
       "*   **Current Price:** \\$235.52. It has fluctuated between \\$229.19 and \\$238.00 today.\n",
       "*   **Market Cap:** \\$2.49 Trillion.\n",
       "*   **Price-to-Earnings Ratio:** 33.15.\n",
       "*   **Average Volume:** 45.21 Million.\n",
       "*   **Volume:** 59.92 Million.\n",
       "*   **52 Week Range:** \\$161.38 - \\$258.60.\n",
       "*   **Analyst Target:** The average analyst price target is \\$296.10.\n",
       "*   **Volatility:** AMZN stock is 2.40% volatile and has a beta coefficient of 1.36.\n",
       "\n",
       "**Analyst Ratings:**\n",
       "\n",
       "*   The consensus is a \"Strong Buy\".\n",
       "\n",
       "**Recent Performance:**\n",
       "\n",
       "*   The stock has fallen by -6.57% compared to the previous week.\n",
       "*   The month change is a 8.14% rise.\n",
       "*   Over the last year, Amazon.com, Inc. has showed a 12.63% increase.\n",
       "\n",
       "**Factors Influencing the Stock Price:**\n",
       "\n",
       "*   Amazon's expansion in artificial intelligence, cloud computing, e-commerce, streaming, and logistics automation.\n",
       "\n",
       "**Business Segments:**\n",
       "\n",
       "*   North America\n",
       "*   International\n",
       "*   Amazon Web Services\n",
       "\n",
       "**Keep in Mind:**\n",
       "\n",
       "*   The stock market is dynamic, and prices can change rapidly.\n",
       "*   Consider consulting with a financial advisor before making any investment decisions.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message('I have an interest in AMZN stock')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:30:56.891845Z",
     "iopub.status.busy": "2025-11-17T20:30:56.891562Z",
     "iopub.status.idle": "2025-11-17T20:31:03.820892Z",
     "shell.execute_reply": "2025-11-17T20:31:03.819618Z",
     "shell.execute_reply.started": "2025-11-17T20:30:56.891822Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's an overview of AMZN (Amazon) stock, including its current share price, short-term trends, and bullish/bearish predictions:\n",
       "\n",
       "**Current Share Price:**\n",
       "\n",
       "*   As of November 17, 2025, the current price of AMZN is \\$232.87.\n",
       "*   During the day, the stock has fluctuated between \\$229.19 and \\$238.00.\n",
       "\n",
       "**Short-Term Trends:**\n",
       "\n",
       "*   **Mixed Signals:** The stock has shown mixed signals recently.\n",
       "*   **Recent Decline:** AMZN stock has fallen by -6.57% compared to the previous week.\n",
       "*   **Monthly Increase:** Despite the weekly drop, the stock has risen 8.14% over the past month.\n",
       "*   **Short-Term Prediction:** Expectations are that the stock will rise 3.43% during the next 3 months.\n",
       "*   **Moving Averages:** The stock holds a sell signal from the short-term Moving Average, but a buy signal from the long-term average.\n",
       "\n",
       "**Analyst Ratings:**\n",
       "\n",
       "*   The consensus rating among analysts is \"Strong Buy\".\n",
       "\n",
       "**Bullish Predictions:**\n",
       "\n",
       "*   **Upside Potential:** Wall Street analysts anticipate a potential upside, with a mean price target of \\$294.40, suggesting a 25.4% increase.\n",
       "*   **Revenue Growth:** Analysts project the company's revenue to increase from \\$710 billion in 2025 to \\$1.153 trillion by the end of 2030.\n",
       "*   **Earnings Growth:** Net income is projected to grow from \\$48.9 billion to \\$110.7 billion by 2030.\n",
       "*   **Average Price Target:** The average price target for Amazon is \\$296.10.\n",
       "*   **High Estimates:** Some analysts have a high price estimate of \\$340.00.\n",
       "*   **Bull Case Scenario:** Under a bull case scenario, Amazon is estimated to be worth \\$5.25 trillion in 2030, or about \\$431 per share.\n",
       "\n",
       "**Bearish Considerations:**\n",
       "\n",
       "*   **Slowing Revenue Growth:** Fitch forecasts Amazon's revenue growth to slow to high single digits in 2025.\n",
       "*   **Insider Selling:** Notable insider selling has occurred recently, potentially raising concerns about executives' confidence in the company's future.\n",
       "*   **Bear Case Scenario:** A baseline case share price of about \\$250, which would be a 5.2% gain, is also considered.\n",
       "*   **Low Estimates:** Some analysts have a low price estimate of \\$255.00.\n",
       "*   **Short-Term Sell Signal:** The Amazon stock holds a sell signal from the short-term Moving Average.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message('''Tell me about AMZN current share price, short-term trends, and bullish versus bearish predictions''')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:31:03.822644Z",
     "iopub.status.busy": "2025-11-17T20:31:03.8222Z",
     "iopub.status.idle": "2025-11-17T20:31:06.451567Z",
     "shell.execute_reply": "2025-11-17T20:31:06.450552Z",
     "shell.execute_reply.started": "2025-11-17T20:31:03.822608Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The ticker symbol for MGM Resorts International is **MGM**. Please note that this is for MGM Resorts International, not MGM Studios. In 2022, Amazon acquired MGM Studios. Therefore, MGM Studios is no longer a publicly traded company with its own stock ticker.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message('''What is mgm studio's stock ticker symbol?''')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:31:06.452738Z",
     "iopub.status.busy": "2025-11-17T20:31:06.452389Z",
     "iopub.status.idle": "2025-11-17T20:31:08.155395Z",
     "shell.execute_reply": "2025-11-17T20:31:08.154303Z",
     "shell.execute_reply.started": "2025-11-17T20:31:06.452711Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "As of the latest trading day, November 14, 2025, here's the data for AMZN:\n",
       "\n",
       "*   **Open:** \\$235.06\n",
       "*   **Close:** \\$234.69\n",
       "*   **High:** \\$238.73\n",
       "*   **Low:** \\$232.89\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message('''What was the last open,close,high,low data for AMZN again?''')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T20:31:08.159658Z",
     "iopub.status.busy": "2025-11-17T20:31:08.159318Z",
     "iopub.status.idle": "2025-11-17T20:31:12.069665Z",
     "shell.execute_reply": "2025-11-17T20:31:12.068719Z",
     "shell.execute_reply.started": "2025-11-17T20:31:08.159632Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Okay, here's the AMZN (Amazon) open, close, high, and low data for the past month (October 18, 2025 - November 17, 2025).\n",
       "\n",
       "| Date       | Open    | Close   | High    | Low     |\n",
       "| ---------- | ------- | ------- | ------- | ------- |\n",
       "| 2025-10-17 | 215.23  | 217.03  | 217.48  | 214.21  |\n",
       "| 2025-10-20 | 217.50  | 220.75  | 221.43  | 216.73  |\n",
       "| 2025-10-21 | 221.32  | 222.08  | 223.31  | 220.02  |\n",
       "| 2025-10-22 | 222.50  | 220.31  | 223.22  | 219.64  |\n",
       "| 2025-10-23 | 220.05  | 222.87  | 223.24  | 218.76  |\n",
       "| 2025-10-24 | 223.44  | 224.43  | 225.34  | 222.57  |\n",
       "| 2025-10-27 | 224.93  | 226.41  | 227.23  | 224.23  |\n",
       "| 2025-10-28 | 226.90  | 225.85  | 227.88  | 225.22  |\n",
       "| 2025-10-29 | 225.03  | 223.33  | 225.44  | 222.34  |\n",
       "| 2025-10-30 | 223.88  | 224.11  | 225.42  | 222.87  |\n",
       "| 2025-10-31 | 224.88  | 226.78  | 227.44  | 224.32  |\n",
       "| 2025-11-03 | 227.01  | 230.44  | 231.09  | 226.78  |\n",
       "| 2025-11-04 | 230.90  | 231.45  | 232.50  | 229.88  |\n",
       "| 2025-11-05 | 231.99  | 233.88  | 234.56  | 231.34  |\n",
       "| 2025-11-06 | 234.44  | 235.01  | 236.22  | 233.67  |\n",
       "| 2025-11-07 | 235.50  | 236.12  | 237.00  | 234.89  |\n",
       "| 2025-11-10 | 236.55  | 237.89  | 238.50  | 235.90  |\n",
       "| 2025-11-11 | 238.22  | 236.77  | 239.10  | 236.11  |\n",
       "| 2025-11-12 | 237.00  | 235.55  | 237.88  | 234.90  |\n",
       "| 2025-11-13 | 235.00  | 235.90  | 236.67  | 234.12  |\n",
       "| 2025-11-14 | 235.06  | 234.69  | 238.73  | 232.89  |\n",
       "| 2025-11-17 | 235.52  | 232.87  | 238.00  | 229.19  |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message('''What is AMZN open,close,high,low data for the past month? \n",
    "Present the data with multiple columns for display in markdown.''')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previously on Kaggle: StockChat 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation BaseModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:26.383723Z",
     "iopub.status.busy": "2025-11-17T21:00:26.382609Z",
     "iopub.status.idle": "2025-11-17T21:00:26.473639Z",
     "shell.execute_reply": "2025-11-17T21:00:26.472451Z",
     "shell.execute_reply.started": "2025-11-17T21:00:26.383688Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Validation BaseModels in pydantic schema.\n",
    "class RestStatus(Enum):\n",
    "    OK = \"OK\"\n",
    "    DELAY = \"DELAYED\"\n",
    "    NONE = \"NOT_FOUND\"\n",
    "    AUTH = \"NOT_AUTHORIZED\"\n",
    "\n",
    "class StopGeneration(BaseModel):\n",
    "    result: str = Gemini.Const.Stop()\n",
    "\n",
    "class RestResultPoly(BaseModel):\n",
    "    request_id: Optional[str] = None\n",
    "    count: Optional[int] = None\n",
    "    next_url: Optional[str] = None\n",
    "    status: RestStatus  \n",
    "\n",
    "class MarketSession(Enum):\n",
    "    PRE = \"pre-market\"\n",
    "    REG = \"regular\"\n",
    "    POST = \"post-market\"\n",
    "    CLOSED = \"closed\"\n",
    "    NA = \"not applicable\"\n",
    "\n",
    "class MarketEvent(Enum):\n",
    "    PRE_OPEN = 0\n",
    "    REG_OPEN = 1\n",
    "    REG_CLOSE = 2\n",
    "    POST_CLOSE = 3\n",
    "    LAST_CLOSE = 4\n",
    "\n",
    "class AssetClass(Enum):\n",
    "    STOCKS = \"stocks\"\n",
    "    OPTION = \"options\"\n",
    "    CRYPTO = \"crypto\"\n",
    "    FOREX = \"fx\"\n",
    "    INDEX = \"indices\"\n",
    "    OTC = \"otc\"\n",
    "\n",
    "class SymbolType(Enum):\n",
    "    COMMON = \"Common Stock\"\n",
    "    ETP = \"ETP\"\n",
    "    ADR = \"ADR\"\n",
    "    REIT = \"REIT\"\n",
    "    DELISTED = \"\"\n",
    "    CEF = \"Closed-End Fund\"\n",
    "    UNIT = \"Unit\"\n",
    "    RIGHT = \"Right\"\n",
    "    EQUITY = \"Equity WRT\"\n",
    "    GDR = \"GDR\"\n",
    "    PREF = \"Preference\"\n",
    "    CDI = \"CDI\"\n",
    "    NVDR = \"NVDR\"\n",
    "    REG = \"NY Reg Shrs\"\n",
    "    MLP = \"MLP\"\n",
    "    MUTUAL = \"Mutual Fund\"\n",
    "\n",
    "class Locale(Enum):\n",
    "    US = \"us\"\n",
    "    GLOBAL = \"global\"\n",
    "\n",
    "class Sentiment(Enum):\n",
    "    V_POS = \"very positive\"\n",
    "    POSITIVE = \"positive\"\n",
    "    NEUTRAL_P = \"neutral/positive\"\n",
    "    NEUTRAL_SP = \"neutral/slightly positive\"\n",
    "    NEUTRAL = \"neutral\"\n",
    "    NEUTRAL_SN = \"neutral/slightly negative\"\n",
    "    NEUTRAL_N = \"neutral/negative\"\n",
    "    MIXED = \"mixed\"\n",
    "    NEGATIVE = \"negative\"\n",
    "    V_NEG = \"very negative\"\n",
    "\n",
    "class Trend(Enum):\n",
    "    S_BUY = \"strong-buy\"\n",
    "    BUY = \"buy\"\n",
    "    HOLD = \"hold\"\n",
    "    SELL = \"sell\"\n",
    "    S_SELL = \"strong-sell\"\n",
    "\n",
    "class MarketCondition(Enum):\n",
    "    BULL = \"bullish\"\n",
    "    BULLN = \"cautiously bullish\"\n",
    "    HOLD = \"hold\"\n",
    "    BEARN = \"cautiously bearish\"\n",
    "    BEAR = \"bearish\"\n",
    "\n",
    "class GeneratedEvent(BaseModel):\n",
    "    last_close: str\n",
    "    pre_open: str\n",
    "    reg_open: str\n",
    "    reg_close: str\n",
    "    post_close: str\n",
    "    timestamp: Optional[str] = None\n",
    "    is_holiday: Optional[bool] = None\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        if self.timestamp is None:\n",
    "            self.timestamp = datetime.now(self.tz()).strftime('%c')\n",
    "        if self.is_holiday is None:\n",
    "            self.is_holiday = False\n",
    "\n",
    "    def session(self, with_date: Optional[str] = None) -> MarketSession:\n",
    "        if with_date is None:\n",
    "            with_date = datetime.now(self.tz()).strftime('%c')\n",
    "        compare = parse(with_date)\n",
    "        if self.is_holiday or compare.weekday() > 4: # weekend\n",
    "            return MarketSession.CLOSED\n",
    "        events = [parse(event).time() for event in [self.pre_open,self.reg_open,self.reg_close,self.post_close]]\n",
    "        if compare.time() < events[0]:\n",
    "            return MarketSession.CLOSED\n",
    "        else:\n",
    "            session = MarketSession.NA\n",
    "            if compare.time() >= events[0]:\n",
    "                session = MarketSession.PRE\n",
    "            if compare.time() >= events[1]:\n",
    "                session = MarketSession.REG\n",
    "            if compare.time() >= events[2]:\n",
    "                session = MarketSession.POST\n",
    "            if compare.time() >= events[3]:\n",
    "                session = MarketSession.CLOSED\n",
    "        return session\n",
    "\n",
    "    def is_open(self) -> bool:\n",
    "        return self.session() != MarketSession.CLOSED\n",
    "\n",
    "    def has_update(self) -> bool:\n",
    "        datetime_now = datetime.now(self.tz())\n",
    "        self_ts = parse(self.timestamp)\n",
    "        # Re-generate events for a new day.\n",
    "        if datetime_now.day > self_ts.day:\n",
    "            return True\n",
    "        # No updates on holidays or when generated after post_close.\n",
    "        if self.is_holiday or self_ts.time() >= parse(self.post_close).time():\n",
    "            return False\n",
    "        # Compare current time to generated event times.\n",
    "        for event in [self.pre_open,self.reg_open,self.reg_close]:\n",
    "            if datetime_now.time() > parse(event).time():\n",
    "                return True\n",
    "        # Current time is before pre_open.\n",
    "        return False\n",
    "\n",
    "    @classmethod\n",
    "    def tz(cls):\n",
    "        return pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\n",
    "    \n",
    "    @classmethod\n",
    "    def apply_fix(cls, value, fix: datetime) -> tuple[str, datetime]:\n",
    "        api.validation_fail()\n",
    "        value = fix.strftime('%c')\n",
    "        return value, fix\n",
    "    \n",
    "    @field_validator(\"last_close\")\n",
    "    def valid_close(cls, value):\n",
    "        date_gen = parse(value) # Generated close is in eastern time and tzinfo naive.\n",
    "        date_now = parse(datetime.now(cls.tz()).strftime('%c')) # Need now in same format as generated.\n",
    "        # Soft-pass: when actual session is closed after post-market\n",
    "        if date_now.day == date_gen.day+1 and date_now.weekday() <= 4:\n",
    "            date_fix = date_gen.replace(day=date_now.day)\n",
    "            if date_fix.timestamp() < date_now.timestamp():\n",
    "                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use today's close\n",
    "        # Soft-pass: when actual session is open post-market\n",
    "        if date_now.day == date_gen.day and date_now.timestamp() < date_gen.timestamp():\n",
    "            if date_now.weekday() > 0:\n",
    "                date_fix = date_gen.replace(day=date_now.day-1)\n",
    "            else:\n",
    "                date_fix = date_gen.replace(day=date_now.day-3)\n",
    "            if date_now.timestamp() > date_fix.timestamp():\n",
    "                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use previous close\n",
    "        if date_now.weekday() == 0 or date_now.weekday() == 1 and date_gen.weekday() <= 4: # 0=monday, 4=friday\n",
    "            return value # pass: generated thurs/friday on a monday/tues\n",
    "        elif date_now.weekday() > 0 and date_now.weekday() <= 4 and date_gen.weekday() <= date_now.weekday()-1:\n",
    "            return value # pass: generated yesterday/prior on a tues-fri\n",
    "        elif date_now.weekday() > 4 and date_gen.weekday() <= 4:\n",
    "            return value # pass: generated thurs/friday on a weekend\n",
    "        elif date_now.day == date_gen.day and date_now.timestamp() > date_gen.timestamp():\n",
    "            return value # pass: generated today after closed\n",
    "        elif date_now.timestamp() < date_gen.timestamp():\n",
    "            raise ValueError(\"last close cannot be a future value\")\n",
    "        else:\n",
    "            raise ValueError(\"generated invalid last close\")\n",
    "        api.validation_fail()\n",
    "\n",
    "class VectorStoreResult(BaseModel):\n",
    "    docs: str\n",
    "    dist: Optional[float] # requires query\n",
    "    meta: Optional[dict]  # requires get or query\n",
    "    store_id: str\n",
    "\n",
    "class Aggregate(RestResultPoly):\n",
    "    symbol: str\n",
    "    open: float\n",
    "    high: float\n",
    "    low: float\n",
    "    close: float\n",
    "    volume: int\n",
    "    otc: Optional[bool] = None\n",
    "    preMarket: Optional[float] = None\n",
    "    afterHours: Optional[float] = None\n",
    "\n",
    "class DailyCandle(Aggregate):\n",
    "    from_date: str\n",
    "\n",
    "class AggregateWindow(BaseModel):\n",
    "    o: float\n",
    "    h: float\n",
    "    l: float\n",
    "    c: float\n",
    "    v: int # traded volume\n",
    "    n: Optional[int] = None # transaction count\n",
    "    vw: Optional[float] = None # volume weighted average price\n",
    "    otc: Optional[bool] = None\n",
    "    t: int\n",
    "\n",
    "    @field_validator(\"t\")\n",
    "    def valid_t(cls, value):\n",
    "        if not value > 0:\n",
    "            raise ValueError(\"invalid timestamp\")\n",
    "        if len(str(value)) == 13:\n",
    "            return int(value/1000)\n",
    "        return value\n",
    "\n",
    "class CustomCandle(RestResultPoly): \n",
    "    ticker: str\n",
    "    adjusted: bool\n",
    "    queryCount: int\n",
    "    resultsCount: int\n",
    "    results: list[AggregateWindow]\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[AggregateWindow]:\n",
    "        return self.results\n",
    "    \n",
    "class MarketStatus(BaseModel):\n",
    "    exchange: str\n",
    "    holiday: Optional[str] = None\n",
    "    isOpen: bool\n",
    "    session: Optional[MarketSession] = None\n",
    "    t: int\n",
    "    timezone: str\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        if self.session is None:\n",
    "            self.session = MarketSession.CLOSED\n",
    "        if self.holiday is None:\n",
    "            self.holiday = MarketSession.NA.value\n",
    "\n",
    "class MarketStatusResult(BaseModel):\n",
    "    results: MarketStatus\n",
    "\n",
    "    def get(self) -> MarketStatus:\n",
    "        return self.results\n",
    "\n",
    "class Symbol(BaseModel):\n",
    "    description: str\n",
    "    displaySymbol: str\n",
    "    symbol: str\n",
    "    type: SymbolType\n",
    "\n",
    "class SymbolResult(BaseModel):\n",
    "    count: int\n",
    "    result: list[Symbol]\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.result)\n",
    "\n",
    "    def get(self) -> list[Symbol]:\n",
    "        return self.result\n",
    "\n",
    "class Quote(BaseModel):\n",
    "    c: float\n",
    "    d: float\n",
    "    dp: float\n",
    "    h: float\n",
    "    l: float\n",
    "    o: float\n",
    "    pc: float\n",
    "    t: int\n",
    "\n",
    "    @field_validator(\"t\")\n",
    "    def valid_t(cls, value):\n",
    "        if not value > 0:\n",
    "            raise ValueError(\"invalid timestamp\")\n",
    "        return value\n",
    "\n",
    "class PeersResult(BaseModel):\n",
    "    results: list[str]\n",
    "    count: Optional[int] = None\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[str]:\n",
    "        return self.results\n",
    "\n",
    "class BasicFinancials(BaseModel):\n",
    "    metric: dict\n",
    "    metricType: str\n",
    "    series: dict\n",
    "    symbol: str\n",
    "\n",
    "class Insight(BaseModel):\n",
    "    sentiment: Sentiment|MarketCondition\n",
    "    sentiment_reasoning: str\n",
    "    ticker: str\n",
    "\n",
    "class Publisher(BaseModel):\n",
    "    favicon_url: Optional[str]\n",
    "    homepage_url: str\n",
    "    logo_url: str\n",
    "    name: str\n",
    "\n",
    "class NewsSummary(BaseModel):\n",
    "    title: str\n",
    "    summary: Optional[str]\n",
    "    insights: Optional[list[Insight]]\n",
    "    published_utc: str\n",
    "\n",
    "class NewsTypePoly(BaseModel):\n",
    "    amp_url: Optional[str] = None\n",
    "    article_url: str\n",
    "    title: str\n",
    "    author: str\n",
    "    description: Optional[str] = None\n",
    "    id: str\n",
    "    image_url: Optional[str] = None\n",
    "    insights: Optional[list[Insight]] = None\n",
    "    keywords: Optional[list[str]] = None\n",
    "    published_utc: str\n",
    "    publisher: Publisher\n",
    "    tickers: list[str]\n",
    "\n",
    "    def summary(self):\n",
    "        return NewsSummary(title=self.title,\n",
    "                           summary=self.description,\n",
    "                           insights=self.insights,\n",
    "                           published_utc=self.published_utc)\n",
    "\n",
    "class NewsResultPoly(RestResultPoly):\n",
    "    results: list[NewsTypePoly]\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[NewsTypePoly]:\n",
    "        return self.results\n",
    "\n",
    "class NewsTypeFinn(BaseModel):\n",
    "    category: str\n",
    "    datetime: int\n",
    "    headline: str\n",
    "    id: int\n",
    "    image: str\n",
    "    related: str # symbol\n",
    "    source: str\n",
    "    summary: str\n",
    "    url: str\n",
    "\n",
    "    def summary(self):\n",
    "        return NewsSummary(title=self.headline,\n",
    "                           summary=self.summary,\n",
    "                           insights=None,\n",
    "                           published_utc=self.datetime)\n",
    "\n",
    "class NewsResultFinn(BaseModel):\n",
    "    results: list[NewsTypeFinn]\n",
    "    count: Optional[int] = None\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[NewsTypeFinn]:\n",
    "        return self.results\n",
    "\n",
    "class NewsTypeGenerated(BaseModel):\n",
    "    title: str\n",
    "    summary: str\n",
    "    insights: list[Insight]\n",
    "    keywords: list[str]\n",
    "    source: Publisher\n",
    "    published_utc: str\n",
    "    tickers: list[str]\n",
    "    url: str\n",
    "\n",
    "    def summary(self):\n",
    "        return NewsSummary(title=self.title,\n",
    "                           summary=self.summary,\n",
    "                           insights=self.insights,\n",
    "                           published_utc=self.published_utc)\n",
    "\n",
    "class TickerOverview(BaseModel):\n",
    "    ticker: str\n",
    "    name: str\n",
    "    market: AssetClass\n",
    "    locale: Locale\n",
    "    primary_exchange: Optional[str] = None\n",
    "    active: bool\n",
    "    currency_name: str\n",
    "    cik: Optional[str] = None\n",
    "    composite_figi: Optional[str] = None\n",
    "    share_class_figi: Optional[str] = None\n",
    "    market_cap: Optional[int|float] = None\n",
    "    phone_number: Optional[str] = None\n",
    "    address: Optional[dict] = None\n",
    "    description: Optional[str] = None\n",
    "    sic_code: Optional[str] = None\n",
    "    sic_description: Optional[str] = None\n",
    "    ticker_root: Optional[str] = None\n",
    "    homepage_url: Optional[str] = None\n",
    "    total_employees: Optional[int] = None\n",
    "    list_date: Optional[str] = None\n",
    "    branding: Optional[dict] = None\n",
    "    share_class_shares_outstanding: Optional[int] = None\n",
    "    weighted_shares_outstanding: Optional[int] = None\n",
    "    round_lot: Optional[int] = None\n",
    "\n",
    "class OverviewResult(RestResultPoly):\n",
    "    results: TickerOverview\n",
    "\n",
    "    def get(self) -> TickerOverview:\n",
    "        return self.results\n",
    "\n",
    "class RecommendationTrend(BaseModel):\n",
    "    buy: int\n",
    "    hold: int\n",
    "    period: str\n",
    "    sell: int\n",
    "    strongBuy: int\n",
    "    strongSell: int\n",
    "    symbol: str\n",
    "\n",
    "class TrendsResult(BaseModel):\n",
    "    results: list[RecommendationTrend]\n",
    "    count: Optional[int] = None\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[RecommendationTrend]:\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:26.47553Z",
     "iopub.status.busy": "2025-11-17T21:00:26.475194Z",
     "iopub.status.idle": "2025-11-17T21:00:26.48676Z",
     "shell.execute_reply": "2025-11-17T21:00:26.4856Z",
     "shell.execute_reply.started": "2025-11-17T21:00:26.475504Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# A contents-memory object.\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.system = f\"\"\"Give a concise, and detailed summary. Use information that you learn from the API responses.\n",
    "        Use your tools and function calls according to the rules. Convert any all-upper case identifiers\n",
    "        to proper case in your response. Convert any abbreviated or shortened identifiers to their full forms.\n",
    "        Convert timestamps according to the rules before including them. Think step by step.\n",
    "        \"\"\"\n",
    "        self.revery = {}\n",
    "        self.prompt = None\n",
    "        self.summary = None\n",
    "    \n",
    "    def set_prompt(self, prompt):\n",
    "        self.prompt = f\"\"\"\n",
    "        The current date and time is: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n",
    "        \n",
    "        {prompt}\n",
    "        \"\"\"\n",
    "        self.contents = [types.Content(role=\"user\", parts=[types.Part(text=self.prompt)])]\n",
    "\n",
    "    def set_reason(self, step):\n",
    "        # Append the model's reasoning part.\n",
    "        self.contents.append(types.Content(role=\"model\", parts=[types.Part(thought=True,text=step)]))\n",
    "\n",
    "    def append_code(self, prompt, code_response_parts):\n",
    "        subroutine_content = [types.Content(role=\"user\", parts=[types.Part(text=prompt)]),\n",
    "                              types.Content(role=\"model\", parts=code_response_parts)]\n",
    "        # Append the model's generated code and execution result.\n",
    "        self.revery[datetime.now(GeneratedEvent.tz()).strftime('%c')] = { \n",
    "            \"contents\": subroutine_content\n",
    "        }\n",
    "\n",
    "    def update_contents(self, function_call, api_response_part):\n",
    "        # Append the model's function call part.\n",
    "        self.contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=function_call)])) \n",
    "        # Append the api response part.\n",
    "        self.contents.append(types.Content(role=\"user\", parts=[api_response_part]))\n",
    "\n",
    "    def set_summary(self, summary):\n",
    "        self.summary = summary\n",
    "        self.contents.append(types.Content(role=\"model\", parts=[types.Part(text=summary)]))\n",
    "        self.revery[datetime.now(GeneratedEvent.tz()).strftime('%c')] = {\n",
    "            \"prompt\": self.prompt, \n",
    "            \"summary\": self.summary, \n",
    "            \"contents\": self.contents\n",
    "        }\n",
    "        self.contents = None\n",
    "\n",
    "memory = Memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:27.099199Z",
     "iopub.status.busy": "2025-11-17T21:00:27.098837Z",
     "iopub.status.idle": "2025-11-17T21:00:28.242133Z",
     "shell.execute_reply": "2025-11-17T21:00:28.240922Z",
     "shell.execute_reply.started": "2025-11-17T21:00:27.099175Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: retrieval-augmented generation.\n",
    "# - using Chroma and text-embedding-004 for storage and retrieval\n",
    "# - using gemini-2.0-flash for augmented generation\n",
    "class RetrievalAugmentedGenerator:\n",
    "    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n",
    "    config_temp = types.GenerateContentConfig(temperature=0.0)\n",
    "    exchange_codes: Optional[dict] = None\n",
    "    exchange_lists: dict = {}\n",
    "    events: dict = {}\n",
    "    holidays: dict = {}\n",
    "\n",
    "    def __init__(self, genai_client, collection_name):\n",
    "        self.client = genai_client\n",
    "        self.embed_fn = GeminiEmbedFunction(genai_client)\n",
    "        self.db = self.chroma_client.get_or_create_collection(\n",
    "            name=collection_name, \n",
    "            embedding_function=self.embed_fn,  # type: ignore\n",
    "            metadata={\"hnsw:space\": \"cosine\"})\n",
    "        logging.getLogger(\"chromadb\").setLevel(logging.ERROR) # suppress warning on existing id\n",
    "        self.set_holidays(\"US\", [\"09-01-2025\",\"10-13-2025\",\"11-11-2025\",\"11-27-2025\",\"12-25-2025\"])\n",
    "        #self.generated_events(\"US\")\n",
    "\n",
    "    def set_holidays(self, exchange_code: str, holidays: list):\n",
    "        self.holidays[exchange_code] = [datetime.strptime(h, \"%m-%d-%Y\").date() for h in holidays]\n",
    "\n",
    "    def get_exchange_codes(self, with_query: Optional[str] = None):\n",
    "        gen = None\n",
    "        if with_query and with_query not in self.exchange_lists.keys():\n",
    "            gen = tqdm(total=1, desc=\"Generate exchange codes with_query\")\n",
    "            data = self.get_exchanges_csv(\n",
    "                f\"\"\"What is the {with_query} exchange code? Return only the exchange codes \n",
    "                as a list in string form. Just the list string. \n",
    "                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n",
    "            self.exchange_lists[with_query] = ast.literal_eval(data.parts[-1].text)\n",
    "        elif with_query is None and self.exchange_codes is None:\n",
    "            gen = tqdm(total=1, desc=\"Generate exchange codes\")\n",
    "            data = self.get_exchanges_csv(\n",
    "                \"\"\"Give me a dictionary in string form. It must contain key:value pairs \n",
    "                mapping exchange code to name. Just the dictionary string. \n",
    "                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n",
    "            self.exchange_codes = ast.literal_eval(data.parts[-1].text.strip(\"\\\\`\"))\n",
    "        if gen:\n",
    "            gen.update(1)\n",
    "        return self.exchange_lists[with_query] if with_query else self.exchange_codes\n",
    "\n",
    "    def get_event_date(self, event_t: str, exchange_code: str, event: MarketEvent):\n",
    "        current_dt_str = datetime.now(GeneratedEvent.tz()).strftime('%c')\n",
    "        current_dt = datetime.strptime(current_dt_str, \"%a %b %d %H:%M:%S %Y\")\n",
    "        current_t_str = datetime.now(GeneratedEvent.tz()).strftime('%H:%M:%S')\n",
    "        current_t = datetime.strptime(current_t_str, \"%H:%M:%S\").time()\n",
    "        event_time = parse(event_t).time()\n",
    "        gen_datetime = None\n",
    "        if event is MarketEvent.LAST_CLOSE:\n",
    "            last_close_day = current_dt.date() - timedelta(days=0 if current_t > event_time else 1)\n",
    "            # Loop backwards to find the last valid trading day (not a weekend or holiday).\n",
    "            while last_close_day.weekday() >= 5 or last_close_day in self.holidays[exchange_code]: # 5 = Sat, 6 = Sun\n",
    "                last_close_day -= timedelta(days=1)\n",
    "            # Combine the date and time.\n",
    "            gen_datetime = datetime.combine(last_close_day, event_time)\n",
    "        else:\n",
    "            next_event_day = current_dt.date() + timedelta(days=0 if current_t < event_time else 1)\n",
    "            # Loop forward to find the next valid trading day (not a weekend or holiday).\n",
    "            while next_event_day.weekday() >= 5 or next_event_day in self.holidays[exchange_code]: # 5 = Sat, 6 = Sun\n",
    "                next_event_day += timedelta(days=1)\n",
    "            # Combine date and time.\n",
    "            gen_datetime = datetime.combine(next_event_day, event_time)\n",
    "        # Format the result as requested.\n",
    "        return gen_datetime.strftime('%a %b %d %X %Y')\n",
    "\n",
    "    def generate_event(self, exchange_code: str, event: MarketEvent):\n",
    "        if event is MarketEvent.LAST_CLOSE or event is MarketEvent.POST_CLOSE:\n",
    "            prompt = f\"\"\"What is the closing time including post_market hours.\"\"\"\n",
    "        elif event is MarketEvent.PRE_OPEN or event is MarketEvent.REG_OPEN:\n",
    "            is_pre = \"including\" if event is MarketEvent.PRE_OPEN else \"excluding\"\n",
    "            prompt = f\"\"\"What is the opening time {is_pre} pre_market hours.\"\"\"\n",
    "        elif event is MarketEvent.REG_CLOSE:\n",
    "            prompt = f\"\"\"What is the closing time excluding post_market hours.\"\"\"\n",
    "        prompt = f\"\"\"Answer based on your knowledge of exchange operating hours.\n",
    "            Do not answer in full sentences. Omit all chat and provide the answer only.\n",
    "            The fields pre_market and post_market both represent extended operating hours.\n",
    "\n",
    "            The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n",
    "            \n",
    "            Consider the {exchange_code} exchange's operating hours.\n",
    "            {prompt}\n",
    "            \n",
    "            Answer with the time in this format: '%H:%M:%S'.\n",
    "            Omit all other chat and details. Do not use sentences.\"\"\"\n",
    "        progress = tqdm(total=1, desc=f\"Generate {exchange_code}->{event}\")\n",
    "        response = self.get_exchanges_csv(prompt).candidates[0].content\n",
    "        if api.Const.Stop() in f\"{response.parts[-1].text}\":\n",
    "            progress.close()\n",
    "            api.generation_fail()\n",
    "            time.sleep(api.dt_between)\n",
    "            return self.generate_event(exchange_code, event)\n",
    "        else:\n",
    "            response = self.get_event_date(response.parts[-1].text, exchange_code, event)\n",
    "            progress.update(1)\n",
    "            return response\n",
    "\n",
    "    def generated_events(self, exchange_code: str) -> GeneratedEvent:\n",
    "        # Check for an existing GeneratedEvent object having updates.\n",
    "        if exchange_code in self.events.keys() and self.events[exchange_code].has_update():\n",
    "            event_obj = self.events[exchange_code]\n",
    "            event_state = [(event_obj.pre_open, MarketEvent.PRE_OPEN),\n",
    "                           (event_obj.reg_open, MarketEvent.REG_OPEN),\n",
    "                           (event_obj.reg_close, MarketEvent.REG_CLOSE),\n",
    "                           (event_obj.post_close, MarketEvent.POST_CLOSE)]\n",
    "            # Need now in same format as generated.\n",
    "            datetime_now = parse(datetime.now(event_obj.tz()).strftime('%c'))\n",
    "            gen_ts = parse(event_obj.timestamp)\n",
    "            # Re-generate events when day changes.\n",
    "            if datetime_now.day > gen_ts.day:\n",
    "                del self.events[exchange_code]\n",
    "                return self.generated_events(exchange_code)\n",
    "            # Update changed events on trading days.\n",
    "            for e in event_state:\n",
    "                if datetime_now > parse(e[0]):\n",
    "                    event_dt = self.generate_event(exchange_code, e[1])\n",
    "                    match e[1]:\n",
    "                        case MarketEvent.PRE_OPEN:\n",
    "                            event_obj.pre_open = event_dt\n",
    "                        case MarketEvent.REG_OPEN:\n",
    "                            event_obj.reg_open = event_dt\n",
    "                        case MarketEvent.REG_CLOSE:\n",
    "                            event_obj.reg_close = event_dt\n",
    "                        case MarketEvent.POST_CLOSE:\n",
    "                            event_obj.post_close = event_dt\n",
    "            event_obj.timestamp = datetime.now(event_obj.tz()).strftime('%c')\n",
    "            self.events[exchange_code] = event_obj\n",
    "        # Generate events for an exchange code not in cache.\n",
    "        elif exchange_code not in self.events.keys():\n",
    "            self.events[exchange_code] = GeneratedEvent(\n",
    "                last_close=self.generate_event(exchange_code, MarketEvent.LAST_CLOSE),\n",
    "                pre_open=self.generate_event(exchange_code, MarketEvent.PRE_OPEN),\n",
    "                reg_open=self.generate_event(exchange_code, MarketEvent.REG_OPEN),\n",
    "                reg_close=self.generate_event(exchange_code, MarketEvent.REG_CLOSE),\n",
    "                post_close=self.generate_event(exchange_code, MarketEvent.POST_CLOSE),\n",
    "                is_holiday=datetime.now().date() in self.holidays[exchange_code])\n",
    "        return self.events[exchange_code]\n",
    "\n",
    "    def set_holiday_event(self, exchange_code: str):\n",
    "        self.generated_events(exchange_code).is_holiday = True\n",
    "\n",
    "    def last_market_close(self, exchange_code: str):\n",
    "        return self.generated_events(exchange_code).last_close\n",
    "\n",
    "    def add_documents_list(self, docs: list):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n",
    "        metas=[{\"source\": doc.metadata[\"source\"]} for doc in docs]\n",
    "        content=[doc.page_content for doc in docs]\n",
    "        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate document embedding\")\n",
    "\n",
    "    def add_api_document(self, query: str, api_response: str, topic: str, source: str = \"add_api_document\"):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        splitter = RecursiveJsonSplitter(max_chunk_size=Gemini.Const.ChunkMax())\n",
    "        docs = splitter.create_documents(texts=[api_response], convert_lists=True)\n",
    "        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n",
    "        content = [json.dumps(doc.page_content) for doc in docs]\n",
    "        metas = [{\"source\": source, \"topic\": topic}]*len(docs)\n",
    "        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate api embedding\")\n",
    "\n",
    "    def add_peers_document(self, query: str, names: list, topic: str, source: str, group: str):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        peers = {\"symbol\": topic, \"peers\": names}\n",
    "        tqdm(self.db.add(ids=str(self.db.count()),\n",
    "                         documents=[json.dumps(peers)],\n",
    "                         metadatas=[{\"source\": source, \"topic\": topic, \"group\": group}]),\n",
    "             desc=\"Generate peers embedding\")\n",
    "\n",
    "    def get_peers_document(self, query: str, topic: str, group: str):\n",
    "        return self.get_documents_list(query, where={\"$and\": [{\"group\": group}, {\"topic\": topic}]})\n",
    "\n",
    "    def add_rest_chunks(self, chunks: list, topic: str, source: str, ids: Optional[list[str]] = None,\n",
    "                        meta_opt: Optional[list[dict]] = None, is_update: bool = True):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode\n",
    "        if ids is None:\n",
    "            ids = list(map(str, range(self.db.count(), self.db.count()+len(chunks))))\n",
    "        if isinstance(chunks[0], BaseModel):\n",
    "            docs = [model.model_dump_json() for model in chunks]\n",
    "        else:\n",
    "            docs = [json.dumps(obj) for obj in chunks]\n",
    "        meta_base = {\"source\": source, \"topic\": topic}\n",
    "        if meta_opt is not None:\n",
    "            for m in meta_opt:\n",
    "                m.update(meta_base)\n",
    "        metas = [meta_base]*len(chunks) if meta_opt is None else meta_opt\n",
    "        if is_update:\n",
    "            tqdm(self.db.upsert(ids=ids, documents=docs, metadatas=metas), desc=\"Upsert chunks embedding\")\n",
    "        else:\n",
    "            tqdm(self.db.add(ids=ids, documents=docs, metadatas=metas), desc=\"Add chunks embedding\")\n",
    "\n",
    "    def get_market_status(self, exchange_code: str) -> tuple[list[VectorStoreResult], bool]: # result, has rest update\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        stored = self.stored_result(self.db.get(where={\n",
    "            \"$and\": [{\"exchange\": exchange_code}, {\"topic\": \"market_status\"}]}))\n",
    "        if len(stored) == 0:\n",
    "            return stored, True\n",
    "        # Check for a daily market status update.\n",
    "        status = json.loads(stored[0].docs)\n",
    "        gen_day = parse(self.generated_events(exchange_code).timestamp).day\n",
    "        store_day = parse(stored[0].meta['timestamp']).day\n",
    "        if status[\"holiday\"] != MarketSession.NA.value and gen_day == store_day:\n",
    "            return stored, False\n",
    "        elif gen_day > store_day:\n",
    "            return stored, True\n",
    "        # Update with generated events to avoid rest api requests.\n",
    "        status[\"session\"] = self.generated_events(exchange_code).session().value\n",
    "        status[\"isOpen\"] = self.generated_events(exchange_code).is_open()\n",
    "        stored[0].docs = json.dumps(status)\n",
    "        return stored, False\n",
    "\n",
    "    def get_basic_financials(self, query: str, topic: str, source: str = \"get_financials_1\"):\n",
    "        return self.get_documents_list(\n",
    "            query, max_sources=200, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n",
    "\n",
    "    def add_quote_document(self, query: str, quote: str, topic: str, timestamp: int, source: str):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        tqdm(self.db.add(ids=str(self.db.count()), \n",
    "                             documents=[quote], \n",
    "                             metadatas=[{\"source\": source, \"topic\": topic, \"timestamp\": timestamp}]), \n",
    "             desc=\"Generate quote embedding\")\n",
    "\n",
    "    def get_api_documents(self, query: str, topic: str, source: str = \"add_api_document\", \n",
    "                          meta_opt: Optional[list[dict]] = None):\n",
    "        where = [{\"source\": source}, {\"topic\": topic}]\n",
    "        if meta_opt is None:\n",
    "            return self.get_documents_list(query, where={\"$and\": where})\n",
    "        else:\n",
    "            for meta in meta_opt:\n",
    "                for k,v in meta.items():\n",
    "                    where.append({k: v})\n",
    "            return self.get_documents_list(query, where={\"$and\": where})\n",
    "\n",
    "    def query_api_documents(self, query: str, topic: str, source: str = \"add_api_document\"):\n",
    "        return self.generate_answer(query, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n",
    "\n",
    "    def add_grounded_document(self, query: str, topic: str, result):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        chunks = result.candidates[0].grounding_metadata.grounding_chunks\n",
    "        supports = result.candidates[0].grounding_metadata.grounding_supports\n",
    "        if supports is not None: # Only add grounded documents which have supports\n",
    "            grounded_text = [f\"{s.segment.text}\" for s in supports]\n",
    "            source = [f\"{c.web.title}\" for c in chunks]\n",
    "            score = [f\"{s.confidence_scores}\" for s in supports]\n",
    "            tqdm(self.db.add(ids=str(self.db.count()),\n",
    "                             documents=json.dumps(grounded_text),\n",
    "                             metadatas=[{\"source\": \", \".join(source),\n",
    "                                         \"confidence_score\": \", \".join(score),\n",
    "                                         \"topic\": topic,\n",
    "                                         \"question\": query}]),\n",
    "                 desc=\"Generate grounding embedding\")\n",
    "\n",
    "    def get_grounding_documents(self, query: str, topic: str):\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        return self.stored_result(self.db.get(where={\"$and\": [{\"question\": query}, {\"topic\": topic}]}))\n",
    "            \n",
    "    def add_wiki_documents(self, title: str, wiki_chunks: list):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        result = self.get_wiki_documents(title)\n",
    "        if len(result) == 0:\n",
    "            ids = list(map(str, range(self.db.count(), self.db.count()+len(wiki_chunks))))\n",
    "            metas=[{\"title\": title, \"source\": \"add_wiki_documents\"}]*len(wiki_chunks)\n",
    "            tqdm(self.db.add(ids=ids, documents=wiki_chunks, metadatas=metas), desc=\"Generate wiki embeddings\")\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def generate_with_wiki_passages(self, query: str, title: str, passages: list[str]):\n",
    "        return self.generate_answer(query, where={\"title\": title}, passages=passages)\n",
    "    \n",
    "    def get_wiki_documents(self, title: Optional[str] = None):\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        if title is None:\n",
    "            return self.stored_result(self.db.get(where={\"source\": \"add_wiki_document\"}))\n",
    "        else:\n",
    "            return self.stored_result(self.db.get(where={\"title\": title}))\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def get_documents_list(self, query: str, max_sources: int = 5000, where: Optional[dict] = None):\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        return self.stored_result(\n",
    "            self.db.query(query_texts=[query], \n",
    "                          n_results=max_sources, \n",
    "                          where=where), \n",
    "            is_query = True)\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def get_exchanges_csv(self, query: str):\n",
    "        return self.generate_answer(query, max_sources=100, where={\"source\": \"exchanges.csv\"})\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def generate_answer(self, query: str, max_sources: int = 10, \n",
    "                        where: Optional[dict] = None, passages: Optional[list[str]] = None):\n",
    "        stored = self.get_documents_list(query, max_sources, where)\n",
    "        query_oneline = query.replace(\"\\n\", \" \")\n",
    "        prompt = f\"\"\"You're an expert writer. You understand how to interpret html and markdown. You will accept the\n",
    "        question below and answer based only on the passages. Never mention the passages in your answers. Be sure to \n",
    "        respond in concise sentences. Include all relevant background information when possible. If a passage is not \n",
    "        relevant to the answer you must ignore it. If no passage answers the question respond with: I don't know.\n",
    "\n",
    "        QUESTION: {query_oneline}\n",
    "        \n",
    "        \"\"\"\n",
    "        # Add the retrieved documents to the prompt.\n",
    "        stored_docs = [passage.docs for passage in stored]\n",
    "        for passage in stored_docs if passages is None else stored_docs + passages:\n",
    "            passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "            prompt += f\"PASSAGE: {passage_oneline}\\n\"\n",
    "        # Generate the response.\n",
    "        response = api.retriable(\n",
    "            self.client.models.generate_content,\n",
    "            model=api(Gemini.Model.GEN),\n",
    "            config=self.config_temp,\n",
    "            contents=prompt)\n",
    "        # Check for generated code and store in memory.\n",
    "        content = response.candidates[0].content\n",
    "        if len(content.parts) > 1 and content.parts[0].executable_code:\n",
    "            memory.append_code(prompt, content.parts)\n",
    "        return response\n",
    "\n",
    "    def stored_result(self, result, is_query: bool = False) -> list[VectorStoreResult]:\n",
    "        try:\n",
    "            results = []\n",
    "            if len(result[\"documents\"]) == 0:\n",
    "                return results\n",
    "            if isinstance(result[\"documents\"][0], list):\n",
    "                for i in range(len(result[\"documents\"][0])):\n",
    "                    obj = VectorStoreResult(docs=result[\"documents\"][0][i],\n",
    "                                            dist=result[\"distances\"][0][i] if is_query else None,\n",
    "                                            meta=result[\"metadatas\"][0][i],\n",
    "                                            store_id=result[\"ids\"][0][i])\n",
    "                    results.append(obj)\n",
    "            else:\n",
    "                results.append(\n",
    "                    VectorStoreResult(docs=result[\"documents\"][0],\n",
    "                                      dist=result[\"distances\"][0] if is_query else None,\n",
    "                                      meta=result[\"metadatas\"][0],\n",
    "                                      store_id=result[\"ids\"][0]))\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiki Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:28.244162Z",
     "iopub.status.busy": "2025-11-17T21:00:28.243806Z",
     "iopub.status.idle": "2025-11-17T21:00:28.255421Z",
     "shell.execute_reply": "2025-11-17T21:00:28.254511Z",
     "shell.execute_reply.started": "2025-11-17T21:00:28.244132Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: wiki-grounding generation.\n",
    "# - using gemini-2.0-flash for response generation\n",
    "# - using a RAG-implementation to store groundings\n",
    "# - create new groundings by similarity to topic\n",
    "# - retrieve existing groundings by similarity to topic\n",
    "class WikiGroundingGenerator:   \n",
    "    def __init__(self, genai_client, rag_impl):\n",
    "        self.client = genai_client\n",
    "        self.rag = rag_impl\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\") # suppress beta-warning\n",
    "            self.splitter = HTMLSemanticPreservingSplitter(\n",
    "                headers_to_split_on=[(\"h2\", \"Main Topic\"), (\"h3\", \"Sub Topic\")],\n",
    "                separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \"],\n",
    "                max_chunk_size=Gemini.Const.ChunkMax(),\n",
    "                chunk_overlap=50,\n",
    "                preserve_links=True,\n",
    "                preserve_images=True,\n",
    "                preserve_videos=True,\n",
    "                preserve_audio=True,\n",
    "                elements_to_preserve=[\"table\", \"ul\", \"ol\", \"code\"],\n",
    "                denylist_tags=[\"script\", \"style\", \"head\"],\n",
    "                custom_handlers={\"code\": self.code_handler},\n",
    "            )\n",
    "\n",
    "    def generate_answer(self, query: str, topic: str):\n",
    "        stored = self.rag.get_wiki_documents(topic)\n",
    "        if len(stored) > 0:\n",
    "            return self.rag.generate_with_wiki_passages(query, topic, [chunk.docs for chunk in stored]).text\n",
    "        else:\n",
    "            pages = wikipedia.search(topic + \" company\")\n",
    "            if len(pages) > 0:\n",
    "                p_topic_match = 0.80\n",
    "                for i in range(len(pages)):\n",
    "                    if tqdm(api.similarity([topic + \" company\", pages[i]]) > p_topic_match, \n",
    "                            desc= \"Score wiki search by similarity to topic\"):\n",
    "                        page_html = Gemini.get(f\"https://en.wikipedia.org/wiki/{pages[i]}\")\n",
    "                        chunks = [chunk.page_content for chunk in self.splitter.split_text(page_html)]\n",
    "                        self.rag.add_wiki_documents(topic, chunks)\n",
    "                        return self.rag.generate_with_wiki_passages(query, topic, chunks).text\n",
    "            return Gemini.Const.Stop()\n",
    "\n",
    "    def code_handler(self, element: Tag) -> str:\n",
    "        data_lang = element.get(\"data-lang\")\n",
    "        code_format = f\"<code:{data_lang}>{element.get_text()}</code>\"\n",
    "        return code_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:28.256974Z",
     "iopub.status.busy": "2025-11-17T21:00:28.256664Z",
     "iopub.status.idle": "2025-11-17T21:00:28.289492Z",
     "shell.execute_reply": "2025-11-17T21:00:28.288311Z",
     "shell.execute_reply.started": "2025-11-17T21:00:28.256952Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: search-grounding generation.\n",
    "# - using gemini-2.0-flash with GoogleSearch tool for response generation\n",
    "# - using a RAG-implementation to store groundings\n",
    "# - create new groundings by exact match to topic\n",
    "# - retrieve existing groundings by similarity to topic\n",
    "class SearchGroundingGenerator:\n",
    "    config_ground = types.GenerateContentConfig(\n",
    "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    \n",
    "    def __init__(self, genai_client, rag_impl):\n",
    "        self.client = genai_client\n",
    "        self.rag = rag_impl\n",
    "\n",
    "    def generate_answer(self, query: str, topic: str):\n",
    "        stored = self.rag.get_grounding_documents(query, topic)\n",
    "        if len(stored) > 0:\n",
    "            for i in range(len(stored)):\n",
    "                meta_q = stored[i].meta[\"question\"]\n",
    "                p_ground_match = 0.95 # This can be really high ~ 95-97%\n",
    "                if tqdm(api.similarity([query, meta_q]) > p_ground_match,\n",
    "                        desc=\"Score similarity to stored grounding\"):\n",
    "                    return ast.literal_eval(stored[i].docs)\n",
    "        return self.get_grounding(query, topic)\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def get_grounding(self, query: str, topic: str):\n",
    "        contents = [types.Content(role=\"user\", parts=[types.Part(text=query)])]\n",
    "        contents += f\"\"\"\n",
    "        You're a search assistant that provides grounded answers to questions about {topic}. You will provide only \n",
    "        results that discuss {topic}. Be brief and specific in answering and omit extra details.\n",
    "        If an answer is not possible respond with: I don't know.\"\"\"\n",
    "        response = api.retriable(self.client.models.generate_content, \n",
    "                                 model=api(Gemini.Model.GEN), \n",
    "                                 config=self.config_ground, \n",
    "                                 contents=contents)\n",
    "        if response.candidates[0].grounding_metadata.grounding_supports is not None:\n",
    "            if self.is_consistent(query, topic, response.text):\n",
    "                self.rag.add_grounded_document(query, topic, response)\n",
    "                return response.text \n",
    "        return Gemini.Const.Stop() # Empty grounding supports or not consistent in response\n",
    "\n",
    "    def is_consistent(self, query: str, topic: str, model_response: str) -> bool:\n",
    "        topic = topic.replace(\"'\", \"\")\n",
    "        id_strs = topic.split()\n",
    "        if len(id_strs) == 1:\n",
    "            matches = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", query)\n",
    "            if len(matches) > 0:\n",
    "                topic = matches[0]\n",
    "        compound_match = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", model_response)\n",
    "        model_response = model_response.replace(\"'\", \"\")\n",
    "        if len(compound_match) == 0 and topic in model_response:\n",
    "            return True # not a compound topic id and exact topic match\n",
    "        for match in compound_match:\n",
    "            if topic not in match:\n",
    "                return False\n",
    "        return True # all prefix matches contained topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:28.291976Z",
     "iopub.status.busy": "2025-11-17T21:00:28.291654Z",
     "iopub.status.idle": "2025-11-17T21:00:28.318476Z",
     "shell.execute_reply": "2025-11-17T21:00:28.317435Z",
     "shell.execute_reply.started": "2025-11-17T21:00:28.291952Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Rest api-helpers to manage request-per-minute limits.\n",
    "# - define an entry for each endpoint limit\n",
    "# - init rest tool with limits to create blocking queues\n",
    "# - apply a limit to requests with rest_tool.try_url\n",
    "class ApiLimit(Enum):\n",
    "    FINN = \"finnhub.io\",50\n",
    "    POLY = \"polygon.io\",4 # (id_url,rpm)\n",
    "\n",
    "class BlockingUrlQueue:\n",
    "    on_cooldown = False\n",
    "    cooldown = None\n",
    "    cooldown_start = None\n",
    "    \n",
    "    def __init__(self, rest_fn: Callable, per_minute: int):\n",
    "        self.per_minute_max = per_minute\n",
    "        self.quota = per_minute\n",
    "        self.rest_fn = rest_fn\n",
    "\n",
    "    def push(self, rest_url: str):\n",
    "        if not self.on_cooldown:\n",
    "            self.cooldown = Timer(60, self.reset_quota)\n",
    "            self.cooldown.start()\n",
    "            self.cooldown_start = time.time()\n",
    "            self.on_cooldown = True\n",
    "        if self.quota > 0:\n",
    "            self.quota -= 1\n",
    "            time.sleep(0.034) # ~30 requests per second\n",
    "            return self.rest_fn(rest_url)\n",
    "        else:\n",
    "            print(f\"limited {self.per_minute_max}/min, waiting {self.limit_expiry()}s\")\n",
    "            time.sleep(max(self.limit_expiry(),0.5))\n",
    "            return self.push(rest_url)\n",
    "\n",
    "    def reset_quota(self):\n",
    "        self.quota = self.per_minute_max\n",
    "        self.on_cooldown = False\n",
    "        self.cooldown_start = None\n",
    "\n",
    "    def limit_expiry(self):\n",
    "        if self.cooldown_start:\n",
    "            return max(60-(time.time()-self.cooldown_start),0)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:28.32078Z",
     "iopub.status.busy": "2025-11-17T21:00:28.320419Z",
     "iopub.status.idle": "2025-11-17T21:00:28.369666Z",
     "shell.execute_reply": "2025-11-17T21:00:28.368615Z",
     "shell.execute_reply.started": "2025-11-17T21:00:28.320757Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: rest-grounding generation.\n",
    "# - using gemini-2.0-flash for response generation\n",
    "# - using a RAG-implementation to store groundings\n",
    "# - reduce long-context by chunked pre-processing\n",
    "class RestGroundingGenerator:    \n",
    "    limits = None\n",
    "\n",
    "    def __init__(self, rag_impl, with_limits: bool):\n",
    "        self.rag = rag_impl\n",
    "        if with_limits:\n",
    "            self.limits = {}\n",
    "            for rest_api in ApiLimit:\n",
    "                self.limits[rest_api.value[0]] = BlockingUrlQueue(Gemini.get, rest_api.value[1])\n",
    "\n",
    "    def get_limit(self, rest_api: ApiLimit) -> Optional[BlockingUrlQueue]:\n",
    "        return self.limits[rest_api.value[0]] if self.limits else None\n",
    "\n",
    "    def basemodel(self, data: str, schema: BaseModel, from_lambda: bool = False) -> Optional[BaseModel]:\n",
    "        try:\n",
    "            if from_lambda:\n",
    "                return schema(results=json.loads(data))\n",
    "            return schema.model_validate_json(data)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def dailycandle(self, data: str) -> Optional[DailyCandle]:\n",
    "        try:\n",
    "            candle = json.loads(data)\n",
    "            if \"from\" not in candle:\n",
    "                raise ValueError(\"not a dailycandle / missing value for date\")\n",
    "            agg = self.basemodel(data, Aggregate)\n",
    "            return DailyCandle(from_date=candle[\"from\"], \n",
    "                               status=agg.status.value, \n",
    "                               symbol=agg.symbol, \n",
    "                               open=agg.open, \n",
    "                               high=agg.high, \n",
    "                               low=agg.low, \n",
    "                               close=agg.close, \n",
    "                               volume=agg.volume, \n",
    "                               otc=agg.otc, \n",
    "                               preMarket=agg.preMarket, \n",
    "                               afterHours=agg.afterHours)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    @retry.Retry(timeout=600)\n",
    "    def try_url(self, url: str, schema: BaseModel, as_lambda: bool, with_limit: Optional[BlockingUrlQueue],\n",
    "                success_fn: Callable, *args, **kwargs):\n",
    "        try:\n",
    "            if self.limits is None:\n",
    "                data = Gemini.get(url)\n",
    "            elif with_limit:\n",
    "                data = with_limit.push(url)\n",
    "            if schema is DailyCandle:\n",
    "                model = self.dailycandle(data)\n",
    "            else:\n",
    "                model = self.basemodel(data, schema, as_lambda)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                print(f\"try_url exception: {e}\")\n",
    "                if issubclass(schema, RestResultPoly):\n",
    "                    return success_fn(*args, **kwargs, result=self.basemodel(data, RestResultPoly))\n",
    "            except Exception as not_a_result:\n",
    "                print(not_a_result)\n",
    "            return StopGeneration()\n",
    "        else:\n",
    "            return success_fn(*args, **kwargs, model=model)\n",
    "\n",
    "    def get_symbol_matches(self, with_content, by_name: bool, model: SymbolResult):\n",
    "        matches = []\n",
    "        max_failed_match = model.count if not by_name else 3\n",
    "        p_desc_match = 0.92\n",
    "        p_symb_match = 0.95\n",
    "        if model.count > 0:\n",
    "            for obj in tqdm(model.get(), desc=\"Score similarity to query\"):\n",
    "                if max_failed_match > 0:\n",
    "                    desc = [with_content[\"q\"].upper(), obj.description.split(\"-\", -1)[0]]\n",
    "                    symb = [with_content[\"q\"].upper(), obj.symbol]\n",
    "                    if by_name and api.similarity(desc) > p_desc_match: \n",
    "                        matches.append(obj.symbol)\n",
    "                    elif not by_name and api.similarity(symb) > p_symb_match:\n",
    "                        matches.append(obj.description)\n",
    "                        max_failed_match = 0\n",
    "                    else:\n",
    "                        max_failed_match -= 1\n",
    "        if len(matches) > 0:\n",
    "            self.rag.add_api_document(with_content[\"query\"], matches, with_content[\"q\"], \"get_symbol_1\")\n",
    "            return matches\n",
    "        return Gemini.Const.Stop()\n",
    "\n",
    "    def get_quote(self, with_content, model: Quote):\n",
    "        quote = model.model_dump_json()\n",
    "        self.rag.add_quote_document(with_content[\"query\"], quote, with_content[\"symbol\"], model.t, \"get_quote_1\")\n",
    "        return quote\n",
    "\n",
    "    def parse_financials(self, with_content, model: BasicFinancials):\n",
    "        metric = list(model.metric.items())\n",
    "        chunks = []\n",
    "        # Chunk the metric data.\n",
    "        for i in range(0, len(metric), Gemini.Const.MetricBatch()):\n",
    "            batch = metric[i:i + Gemini.Const.MetricBatch()]\n",
    "            chunks.append({\"question\": with_content[\"query\"], \"answer\": batch})\n",
    "        # Chunk the series data.\n",
    "        for key in model.series.keys():\n",
    "            series = list(model.series[key].items())\n",
    "            for s in series:\n",
    "                if api.token_count(s) <= Gemini.Const.ChunkMax():\n",
    "                    chunks.append({\"question\": with_content[\"query\"], \"answer\": s})\n",
    "                else:\n",
    "                    k = s[0]\n",
    "                    v = s[1]\n",
    "                    for i in range(0, len(v), Gemini.Const.SeriesBatch()):\n",
    "                        batch = v[i:i + Gemini.Const.SeriesBatch()]\n",
    "                        chunks.append({\"question\": with_content[\"query\"], \"answer\": {k: batch}})\n",
    "        self.rag.add_rest_chunks(chunks, topic=with_content[\"symbol\"], source=\"get_financials_1\")\n",
    "        return chunks\n",
    "\n",
    "    def parse_news(self, with_content, model: NewsResultFinn):\n",
    "        if model.count > 0:\n",
    "            metas = []\n",
    "            for digest in model.get():\n",
    "                pub_date = datetime.fromtimestamp(digest.datetime, tz=GeneratedEvent.tz()).strftime(\"%Y-%m-%d\")\n",
    "                metas.append({\"publisher\": digest.source,\n",
    "                              \"published_est\": parse(pub_date).timestamp(),\n",
    "                              \"news_id\": digest.id,\n",
    "                              \"related\": digest.related})\n",
    "            self.rag.add_rest_chunks(model.get(), topic=with_content[\"symbol\"], source=\"get_news_1\",\n",
    "                                     ids=[f\"{digest.id}+news\" for digest in model.get()],\n",
    "                                     meta_opt=metas, is_update=False)\n",
    "            return [digest.summary().model_dump_json() for digest in model.get()]\n",
    "        return Gemini.Const.Stop()\n",
    "\n",
    "    def parse_news(self, with_content, model: Optional[NewsResultPoly] = None,\n",
    "                   result: Optional[RestResultPoly] = None) -> tuple[list, str]: # list of summary, next list url\n",
    "        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n",
    "            metas = []\n",
    "            for news in model.get():\n",
    "                pub_date = parse(news.published_utc).strftime(\"%Y-%m-%d\")\n",
    "                metas.append({\"publisher\": news.publisher.name,\n",
    "                              \"published_utc\": parse(pub_date).timestamp(),\n",
    "                              \"news_id\": news.id,\n",
    "                              \"related\": json.dumps(news.tickers),\n",
    "                              \"keywords\": json.dumps(news.keywords)})\n",
    "            self.rag.add_rest_chunks(model.get(), topic=with_content[\"ticker\"], source=\"get_news_2\",\n",
    "                                     ids=[news.id for news in model.get()],\n",
    "                                     meta_opt=metas, is_update=False)\n",
    "            return [news.summary().model_dump_json() for news in model.get()], model.next_url\n",
    "        elif result:\n",
    "            return result.model_dump_json()\n",
    "\n",
    "    def parse_daily_candle(self, with_content, model: Optional[DailyCandle] = None,\n",
    "                           result: Optional[RestResultPoly] = None):\n",
    "        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n",
    "            self.rag.add_rest_chunks(\n",
    "                chunks=[model],\n",
    "                topic=with_content[\"stocksTicker\"],\n",
    "                source=\"daily_candle_2\",\n",
    "                meta_opt=[{\"from_date\": model.from_date, \"adjusted\": with_content[\"adjusted\"]}])\n",
    "            return model\n",
    "        elif result:\n",
    "            return result\n",
    "\n",
    "    def parse_custom_candle(self, with_content, model: Optional[CustomCandle] = None,\n",
    "                            result: Optional[RestResultPoly] = None):\n",
    "        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n",
    "            metas = [{\n",
    "                \"timespan\": with_content[\"timespan\"],\n",
    "                \"adjusted\": with_content[\"adjusted\"],\n",
    "                \"from\": with_content[\"from\"],\n",
    "                \"to\": with_content[\"to\"]}]*model.count\n",
    "            candles = [candle.model_dump_json() for candle in model.get()]\n",
    "            self.rag.add_rest_chunks(\n",
    "                chunks=candles,\n",
    "                topic=with_content[\"stocksTicker\"],\n",
    "                source=\"custom_candle_2\",\n",
    "                meta_opt=metas)\n",
    "            return candles\n",
    "        elif result:\n",
    "            return result.model_dump_json()\n",
    "\n",
    "    def parse_overview(self, with_content, model: OverviewResult):\n",
    "        overview = [model.get().model_dump_json()]\n",
    "        self.rag.add_rest_chunks(chunks=overview, topic=with_content[\"ticker\"], source=\"ticker_overview_2\")\n",
    "        return overview\n",
    "\n",
    "    def parse_trends(self, with_content, model: TrendsResult):\n",
    "        if model.count > 0:\n",
    "            metas = [{\"period\": trend.period} for trend in model.get()]\n",
    "            trends = [trend.model_dump_json() for trend in model.get()]\n",
    "            self.rag.add_rest_chunks(trends, topic=with_content[\"symbol\"], source=\"trends_1\", meta_opt=metas)\n",
    "            return trends\n",
    "        return Gemini.Const.Stop()\n",
    "\n",
    "    def augment_market_status(self, with_id: Optional[str], model: MarketStatusResult):\n",
    "        if model.get().holiday != MarketSession.NA.value:\n",
    "            self.rag.set_holiday_event(model.get().exchange)\n",
    "        events = self.rag.generated_events(model.get().exchange)\n",
    "        model.get().session = events.session()\n",
    "        model.get().isOpen = events.is_open()\n",
    "        meta = {\"exchange\": model.get().exchange,\n",
    "                \"last_close\": events.last_close,\n",
    "                \"pre_open\": events.pre_open,\n",
    "                \"reg_open\": events.reg_open,\n",
    "                \"reg_close\": events.reg_close,\n",
    "                \"post_close\": events.post_close,\n",
    "                \"timestamp\": events.timestamp }\n",
    "        self.rag.add_rest_chunks([model.get()],\n",
    "                                 topic=\"market_status\",\n",
    "                                 source=\"get_market_status_1\",\n",
    "                                 ids=[with_id] if with_id else None,\n",
    "                                 meta_opt=[meta])\n",
    "        return model.get().model_dump_json()\n",
    "\n",
    "    def get_symbol(self, content, by_name: bool = True):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/search?q={content['q']}&exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=SymbolResult,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.get_symbol_matches,\n",
    "            with_content=content,\n",
    "            by_name=by_name)\n",
    "\n",
    "    def get_current_price(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/quote?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=Quote,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.get_quote,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_market_status(self, content, store_id: Optional[str] = None):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/market-status?exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=MarketStatusResult,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.augment_market_status,\n",
    "            with_id=store_id)\n",
    "\n",
    "    def get_peers(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/peers?symbol={content['symbol']}&grouping={content['grouping']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=PeersResult,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=lambda model: model)\n",
    "\n",
    "    def get_basic_financials(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/metric?symbol={content['symbol']}&metric={content['metric']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=BasicFinancials,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.parse_financials,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_news_simple(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/company-news?symbol={content['symbol']}&from={content['from']}&to={content['to']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=NewsResultFinn,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.parse_news,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_news_tagged(self, content):\n",
    "        next_url = f\"https://api.polygon.io/v2/reference/news?ticker={content['ticker']}&published_utc.gte={content['published_utc.gte']}&published_utc.lte={content['published_utc.lte']}&order={content['order']}&limit={content['limit']}&sort={content['sort']}&apiKey={POLYGON_API_KEY}\"\n",
    "        news = []\n",
    "        while True:\n",
    "            news_list, next_url = self.try_url(\n",
    "                next_url,\n",
    "                schema=NewsResultPoly,\n",
    "                as_lambda=False,\n",
    "                with_limit=self.get_limit(ApiLimit.POLY),\n",
    "                success_fn=self.parse_news,\n",
    "                with_content=content)\n",
    "            news += news_list\n",
    "            if next_url is None:\n",
    "                break\n",
    "            next_url += f\"&apiKey={POLYGON_API_KEY}\"\n",
    "        return news\n",
    "\n",
    "    def get_daily_candle(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://api.polygon.io/v1/open-close/{content['stocksTicker']}/{content['date']}?adjusted={content['adjusted']}&apiKey={POLYGON_API_KEY}\",\n",
    "            schema=DailyCandle,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.POLY),\n",
    "            success_fn=self.parse_daily_candle,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_custom_candle(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://api.polygon.io/v2/aggs/ticker/{content['stocksTicker']}/range/{content['multiplier']}/{content['timespan']}/{content['from']}/{content['to']}?adjusted={content['adjusted']}&sort={content['sort']}&limit={content['limit']}&apiKey={POLYGON_API_KEY}\",\n",
    "            schema=CustomCandle,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.POLY),\n",
    "            success_fn=self.parse_custom_candle,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_overview(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://api.polygon.io/v3/reference/tickers/{content['ticker']}?apiKey={POLYGON_API_KEY}\",\n",
    "            schema=OverviewResult,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.POLY),\n",
    "            success_fn=self.parse_overview,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_trends_simple(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/recommendation?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=TrendsResult,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.parse_trends,\n",
    "            with_content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callable Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:28.680608Z",
     "iopub.status.busy": "2025-11-17T21:00:28.680148Z",
     "iopub.status.idle": "2025-11-17T21:00:28.718791Z",
     "shell.execute_reply": "2025-11-17T21:00:28.717789Z",
     "shell.execute_reply.started": "2025-11-17T21:00:28.680584Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Callable functions in openapi schema.\n",
    "decl_get_symbol_1 = types.FunctionDeclaration(\n",
    "    name=\"get_symbol_1\",\n",
    "    description=\"\"\"Search for the stock ticker symbol of a given company, security, isin or cusip. Each ticker\n",
    "                   entry provides a description, symbol, and asset type. If this doesn't help you should try \n",
    "                   calling get_wiki_tool_response next.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The company, security, isin or cusip to search for a symbol.\"\"\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"q\", \"exchange\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_symbols_1 = types.FunctionDeclaration(\n",
    "    name=\"get_symbols_1\",\n",
    "    description=\"\"\"List all supported symbols and tickers. The results are filtered by exchange code.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter the results.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"exchange\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_name_1 = types.FunctionDeclaration(\n",
    "    name=\"get_name_1\",\n",
    "    description=\"\"\"Search for the name associated with a stock ticker or symbol's company, security, isin or cusip. \n",
    "    Each ticker entry provides a description, matching symbol, and asset type.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The symbol or ticker to search for.\"\"\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            },\n",
    "            \"company\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The company you're searching for.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"q\", \"exchange\", \"query\", \"company\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_symbol_quote_1 = types.FunctionDeclaration(\n",
    "    name=\"get_symbol_quote_1\",\n",
    "    description=\"\"\"Search for the current price or quote of a stock ticker or symbol. The response is\n",
    "                   provided in json format. Each response contains the following key-value pairs:\n",
    "                   \n",
    "                   c: Current price,\n",
    "                   d: Change,\n",
    "                  dp: Percent change,\n",
    "                   h: High price of the day,\n",
    "                   l: Low price of the day,\n",
    "                   o: Open price of the day,\n",
    "                  pc: Previous close price,\n",
    "                   t: Epoch timestamp of price in seconds.\n",
    "\n",
    "                   Parse the response and respond according to this information.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The stock ticker symbol for a company, security, isin, or cusip.\" \n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The exchange code used to filter quotes. This must always be 'US'.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"query\", \"exchange\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_local_datetime = types.FunctionDeclaration(\n",
    "    name=\"get_local_datetime\",\n",
    "    description=\"\"\"Converts an array of timestamps from epoch time to the local timezone format. The result is an array\n",
    "                   of date and time in locale appropriate format. Suitable for use in a locale appropriate response.\n",
    "                   Treat this function as a vector function. Always prefer to batch timestamps for conversion. Use this\n",
    "                   function to format date and time in your responses.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"t\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"\"\"An array of timestamps in seconds since epoch to be converted. The order of\n",
    "                                  timestamps matches the order of conversion.\"\"\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"integer\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"t\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_market_status_1 = types.FunctionDeclaration(\n",
    "    name=\"get_market_status_1\",\n",
    "    description=\"\"\"Get the current market status of global exchanges. Includes whether exchanges are open or closed.  \n",
    "                   Also includes holiday details if applicable. The response is provided in json format. Each response \n",
    "                   contains the following key-value pairs:\n",
    "\n",
    "                   exchange: Exchange code,\n",
    "                   timezone: Timezone of the exchange,\n",
    "                    holiday: Holiday event name, or null if it's not a holiday,\n",
    "                     isOpen: Whether the market is open at the moment,\n",
    "                          t: Epoch timestamp of status in seconds (Eastern Time),\n",
    "                    session: The market session can be 1 of the following values: \n",
    "                    \n",
    "                    pre-market,regular,post-market when open, or null if closed.\n",
    "                    \n",
    "                    Parse the response and respond according to this information.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"exchange\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_market_session_1 = types.FunctionDeclaration(\n",
    "    name=\"get_market_session_1\",\n",
    "    description=\"Get the current market session of global exchanges.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"exchange\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_company_peers_1 = types.FunctionDeclaration(\n",
    "    name=\"get_company_peers_1\",\n",
    "    description=\"\"\"Search for a company's peers. Returns a list of peers operating in the same country and in the same\n",
    "                   sector, industry, or subIndustry. Each response contains the following key-value pairs: \n",
    "                   \n",
    "                   symbol: The company's stock ticker symbol, \n",
    "                   peers: A list containing the peers.\n",
    "                   \n",
    "                   Each peers entry contains the following key-value pairs:\n",
    "                   \n",
    "                   symbol: The peer company's stock ticker symbol, \n",
    "                   name: The peer company's name.\n",
    "                   \n",
    "                   Parse the response and respond according to this information.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The stock ticker symbol of a company to obtain peers.\"\n",
    "            },\n",
    "            \"grouping\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"This parameter may be one of the following values: sector, industry, subIndustry.\n",
    "                                  Always use subIndustry unless told otherwise.\"\"\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"grouping\", \"exchange\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_exchange_codes_1 = types.FunctionDeclaration(\n",
    "    name=\"get_exchange_codes_1\",\n",
    "    description=\"\"\"Get a dictionary mapping all supported exchange codes to their names.\"\"\"\n",
    ")\n",
    "\n",
    "decl_get_exchange_code_1 = types.FunctionDeclaration(\n",
    "    name=\"get_exchange_code_1\",\n",
    "    description=\"\"\"Search for the exchange code to use when filtering by exchange. The result will be one or\n",
    "                   more exchange codes provided as a comma-separated string value.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Specifies which exchange code to search for.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"q\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_financials_1 = types.FunctionDeclaration(\n",
    "    name=\"get_financials_1\",\n",
    "    description=\"\"\"Get company basic financials such as margin, P/E ratio, 52-week high/low, etc. Parse the response for \n",
    "                   key-value pairs in json format and interpret their meaning as stock market financial indicators.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol for a company.\"\n",
    "            },\n",
    "            \"metric\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"It must always be declared as the value 'all'\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"metric\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_daily_candlestick_2 = types.FunctionDeclaration(\n",
    "    name=\"get_daily_candlestick_2\",\n",
    "    description=\"\"\"Get a historical daily stock ticker candlestick / aggregate bar (OHLC). \n",
    "                   Includes historical daily open, high, low, and close prices. Also includes historical daily trade\n",
    "                   volume and pre-market/after-hours trade prices. It provides the last trading days' data after \n",
    "                   11:59PM Eastern Time.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"stocksTicker\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The stock ticker symbol of a company to search for.\",\n",
    "            },\n",
    "            \"date\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"The date of the requested candlestick in format YYYY-MM-DD.\"\"\"\n",
    "            },\n",
    "            \"adjusted\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n",
    "                                  Use true unless told otherwise.\"\"\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"stocksTicker\", \"date\", \"adjusted\", \"exchange\", \"query\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "decl_get_company_news_1 = types.FunctionDeclaration(\n",
    "    name=\"get_company_news_1\",\n",
    "    description=\"Retrieve the most recent news articles related to a specified ticker.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol for a company.\",\n",
    "            },\n",
    "            \"from\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be older than the parameter 'to'.\"\"\"\n",
    "            },\n",
    "            \"to\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be more recent than the parameter 'from'. The\n",
    "                                  default value is today's date.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"from\", \"to\", \"query\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "decl_get_custom_candlestick_2 = types.FunctionDeclaration(\n",
    "    name=\"get_custom_candlestick_2\",\n",
    "    description=\"\"\"Get a historical stock ticker candlestick / aggregate bar (OHLC) over a custom date range and \n",
    "                   time interval in Eastern Time. Includes historical open, high, low, and close prices. Also \n",
    "                   includes historical daily trade volume and pre-market/after-hours trade prices. It includes \n",
    "                   the last trading days' data after 11:59PM Eastern Time.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"stocksTicker\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The stock ticker symbol of a company to search for.\",\n",
    "            },\n",
    "            \"multiplier\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"This must be included and equal to 1 unless told otherwise.\"\n",
    "            },\n",
    "            \"timespan\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The size of the candlestick's time window. This is allowed to be one of the following:\n",
    "                                  second, minute, hour, day, week, month, quarter, or year. The default value is day.\"\"\"\n",
    "            },\n",
    "            \"from\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'to'.\"\"\"\n",
    "            },\n",
    "            \"to\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'from'. The \n",
    "                                  default is one weekday before get_last_market_close.\n",
    "                                  Replace more recent dates with the default.\"\"\"\n",
    "            },\n",
    "            \"adjusted\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n",
    "                                  Use true unless told otherwise.\"\"\"\n",
    "            },\n",
    "            \"sort\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"This must be included. May be one of asc or desc. asc will sort by timestmap in \n",
    "                                  ascending order. desc will sort by timestamp in descending order.\"\"\"\n",
    "            },\n",
    "            \"limit\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"\"\"Set the number of base aggregates used to create this candlestick. This must be 5000 \n",
    "                                  unless told to limit base aggregates to something else.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"stocksTicker\", \"multiplier\", \"timespan\", \"from\", \"to\", \"adjusted\", \"sort\", \"limit\", \"query\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "decl_get_last_market_close = types.FunctionDeclaration(\n",
    "    name=\"get_last_market_close\",\n",
    "    description=\"\"\"Get the last market close of the specified exchange in Eastern Time. The response has already\n",
    "                   been converted by get_local_datetime so this step should be skipped.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"exchange\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_ticker_overview_2 = types.FunctionDeclaration(\n",
    "    name=\"get_ticker_overview_2\",\n",
    "    description=\"\"\"Retrieve comprehensive details for a single ticker symbol. It's a deep look into a companys \n",
    "    fundamental attributes, including its primary exchange, standardized identifiers (CIK, composite FIGI, \n",
    "    share class FIGI), market capitalization, industry classification, and key dates. Also includes branding assets in\n",
    "    the form of icons and logos.\n",
    "    \"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"ticker\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol of a company.\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"ticker\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_recommendation_trends_1 = types.FunctionDeclaration(\n",
    "    name=\"get_recommendation_trends_1\",\n",
    "    description=\"\"\"Get the latest analyst recommendation trends for a company.\n",
    "                The data includes the latest recommendations as well as historical\n",
    "                recommendation data for each month. The data is classified according\n",
    "                to these categories: strongBuy, buy, hold, sell, and strongSell.\n",
    "                The date of a recommendation indicated by the value of 'period'.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol for a company.\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_news_with_sentiment_2 = types.FunctionDeclaration(\n",
    "    name=\"get_news_with_sentiment_2\",\n",
    "    description=\"\"\"Retrieve the most recent news articles related to a specified ticker. Each article includes \n",
    "                   comprehensive coverage. Including a summary, publisher information, article metadata, \n",
    "                   and sentiment analysis.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"ticker\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol for a company.\"\n",
    "            },\n",
    "            \"published_utc.gte\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'published_utc.lte'. \n",
    "                                  The default value is one-month ago from today's date.\"\"\"\n",
    "            },\n",
    "            \"published_utc.lte\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'published_utc.gte'.\n",
    "                                  The default is one weekday prior to get_last_market_close (excluding weekends).\n",
    "                                  Replace more recent dates with the default.\"\"\"\n",
    "            },\n",
    "            \"order\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"Must be desc for descending order, or asc for ascending order.\n",
    "                                  When order is not specified the default is descending order.\n",
    "                                  Ordering will be based on the parameter 'sort'.\"\"\"\n",
    "            },\n",
    "            \"limit\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"\"\"This must be included and equal to 1000 unless told otherwise.\"\"\"\n",
    "            },\n",
    "            \"sort\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The sort field used for ordering. This value must\n",
    "                                  always be published_utc.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"limit\", \"ticker\", \"published_utc.gte\", \"published_utc.lte\", \"order\", \"sort\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_rag_tool_response = types.FunctionDeclaration(\n",
    "    name=\"get_rag_tool_response\",\n",
    "    description=\"\"\"A database containing useful financial information. Always check here for answers first.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"A question needing an answer. Asked as a simple string.\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_wiki_tool_response = types.FunctionDeclaration(\n",
    "    name=\"get_wiki_tool_response\",\n",
    "    description=\"\"\"Answers questions that still have unknown answers. Retrieve a wiki page related to a company, \n",
    "                   product, or service. Each web page includes detailed company information, financial indicators, \n",
    "                   tickers, symbols, history, and products and services.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question's company or product. Just the name and no other details.\"\n",
    "            },\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The complete, unaltered, query string.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"id\", \"q\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_search_tool_response = types.FunctionDeclaration(\n",
    "    name=\"get_search_tool_response\",\n",
    "    description=\"Answers questions that still have unknown answers. Use it after checking all your other tools.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question needing an answer. Asked as a simple string.\"\n",
    "            },\n",
    "            \"id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question's company or product. In one word. Just the name and no other details.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"q\", \"id\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:28.720707Z",
     "iopub.status.busy": "2025-11-17T21:00:28.720368Z",
     "iopub.status.idle": "2025-11-17T21:00:28.745602Z",
     "shell.execute_reply": "2025-11-17T21:00:28.744342Z",
     "shell.execute_reply.started": "2025-11-17T21:00:28.720679Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the system prompt.\n",
    "\n",
    "instruction = f\"\"\"You are a helpful and informative bot that answers finance and stock market questions. \n",
    "Only answer the question asked and do not change topic. While the answer is still\n",
    "unknown you must follow these rules for predicting function call order:\n",
    "\n",
    "RULE#1: Always consult your other functions before get_search_tool_response.\n",
    "RULE#2: Always consult get_wiki_tool_response before get_search_tool_response.\n",
    "RULE#3: Always consult get_search_tool_response last.\n",
    "RULE#4: Always convert timestamps with get_local_datetime and use the converted date/time in your response.\n",
    "RULE#5: Always incorporate as much useful information from tools and functions in your response.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:12:38.971498Z",
     "iopub.status.busy": "2025-11-17T22:12:38.971056Z",
     "iopub.status.idle": "2025-11-17T22:12:39.116503Z",
     "shell.execute_reply": "2025-11-17T22:12:39.11538Z",
     "shell.execute_reply.started": "2025-11-17T22:12:38.97147Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import the finance api secret keys.\n",
    "\n",
    "POLYGON_API_KEY = UserSecretsClient().get_secret(\"POLYGON_API_KEY\")\n",
    "FINNHUB_API_KEY = UserSecretsClient().get_secret(\"FINNHUB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate document embedding: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tools and load the exchange data from source csv.\n",
    "# - Identifies exchanges by a 1-2 letter code which can be used to filter response data.\n",
    "# - Also maps the exchange code to exchange details.\n",
    "try:\n",
    "    df = pandas.read_csv(\"/kaggle/input/exchanges/exchanges_src.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    df = pandas.read_csv(\"exchanges_src.csv\") # local run\n",
    "df = df.drop([\"close_date\"], axis=1).fillna(\"\")\n",
    "df.to_csv(\"exchanges.csv\", index=False)\n",
    "exchanges = CSVLoader(file_path=\"exchanges.csv\", encoding=\"utf-8\", csv_args={\"delimiter\": \",\"}).load()\n",
    "\n",
    "# Prepare a RAG tool for use and add the exchange data.\n",
    "tool_rag = RetrievalAugmentedGenerator(api.args.CLIENT, \"finance\")\n",
    "tool_rag.add_documents_list(exchanges)\n",
    "\n",
    "# Prepare a the grounding tools for use.\n",
    "tool_wiki = WikiGroundingGenerator(api.args.CLIENT, tool_rag)\n",
    "tool_ground = SearchGroundingGenerator(api.args.CLIENT, tool_rag)\n",
    "tool_rest = RestGroundingGenerator(tool_rag, with_limits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:30.32044Z",
     "iopub.status.busy": "2025-11-17T21:00:30.3201Z",
     "iopub.status.idle": "2025-11-17T21:00:30.35385Z",
     "shell.execute_reply": "2025-11-17T21:00:30.352617Z",
     "shell.execute_reply.started": "2025-11-17T21:00:30.320413Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Implement the callable functions and function handler.\n",
    "\n",
    "def ask_rag_tool(content):\n",
    "    return tool_rag.generate_answer(content[\"question\"]).text\n",
    "\n",
    "def ask_wiki_tool(content):\n",
    "    return tool_wiki.generate_answer(content[\"q\"], content[\"id\"])\n",
    "\n",
    "def ask_search_tool(content):\n",
    "    return tool_ground.generate_answer(content[\"q\"], content[\"id\"])\n",
    "\n",
    "def get_exchange_codes_1(content):\n",
    "    return tool_rag.get_exchange_codes()\n",
    "\n",
    "def get_exchange_code_1(content):\n",
    "    return tool_rag.get_exchange_codes(with_query=content)\n",
    "    \n",
    "def last_market_close(content):\n",
    "    return tool_rag.last_market_close(content[\"exchange\"])\n",
    "    \n",
    "def get_symbol_1(content, by_name: bool = True):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"q\"], \"get_symbol_1\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_symbol(content, by_name)\n",
    "    return json.loads(stored[0].docs)\n",
    "\n",
    "def get_symbols_1(content):\n",
    "    return None # todo\n",
    "\n",
    "def get_name_1(content):\n",
    "    return get_symbol_1(content, by_name = False)\n",
    "\n",
    "def get_quote_1(content):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_quote_1\")\n",
    "    if tool_rag.generated_events(content[\"exchange\"]).is_open():\n",
    "        return get_current_price_1(content)\n",
    "    elif len(stored) > 0:\n",
    "        last_close = parse(tool_rag.last_market_close(content[\"exchange\"])).timestamp()\n",
    "        for quote in stored:\n",
    "            if quote.meta[\"timestamp\"] >= last_close:\n",
    "                return [quote.docs for quote in stored]\n",
    "    return get_current_price_1(content)\n",
    "\n",
    "def get_current_price_1(content):\n",
    "    return tool_rest.get_current_price(content)\n",
    "\n",
    "def get_market_status_1(content):\n",
    "    stored, has_update = tool_rag.get_market_status(content['exchange'])\n",
    "    if has_update:\n",
    "        with_id = stored[0].store_id if len(stored) > 0 else None\n",
    "        return tool_rest.get_market_status(content, with_id)\n",
    "    return stored[0].docs\n",
    "\n",
    "def get_session_1(content):\n",
    "    return json.loads(get_market_status_1(content))[\"session\"]\n",
    "\n",
    "def get_peers_1(content):\n",
    "    stored = tool_rag.get_peers_document(content[\"query\"], content[\"symbol\"], content['grouping'])\n",
    "    if len(stored) == 0:\n",
    "        peers = tool_rest.get_peers(content)\n",
    "        if peers.count > 0:\n",
    "            names = []\n",
    "            for peer in peers.get():\n",
    "                if peer == content[\"symbol\"]:\n",
    "                    continue # skip including the query symbol in peers\n",
    "                name = get_name_1(dict(q=peer, exchange=content[\"exchange\"], query=content[\"query\"]))\n",
    "                if name != Gemini.Const.Stop():\n",
    "                    data = {\"symbol\": peer, \"name\": name}\n",
    "                    names.append(data)\n",
    "            tool_rag.add_peers_document(content[\"query\"], names, content[\"symbol\"], \"get_peers_1\", content['grouping'])\n",
    "            return names\n",
    "        return Gemini.Const.Stop()\n",
    "    return json.loads(stored[0].docs)[\"peers\"]\n",
    "\n",
    "def local_datetime(content):\n",
    "    local_t = []\n",
    "    for timestamp in content[\"t\"]:\n",
    "        local_t.append(local_date_from_epoch(timestamp))\n",
    "    return local_t\n",
    "\n",
    "def local_date_from_epoch(timestamp):\n",
    "    if len(str(timestamp)) == 13:\n",
    "        return datetime.fromtimestamp(timestamp/1000, tz=GeneratedEvent.tz()).strftime('%c')\n",
    "    else:\n",
    "        return datetime.fromtimestamp(timestamp, tz=GeneratedEvent.tz()).strftime('%c')\n",
    "\n",
    "def get_financials_1(content):\n",
    "    stored = tool_rag.get_basic_financials(content[\"query\"], content[\"symbol\"], \"get_financials_1\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_basic_financials(content)\n",
    "    return [chunk.docs for chunk in stored]\n",
    "\n",
    "def get_news_1(content):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_news_1\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_news_simple(content)\n",
    "    return [NewsTypeFinn.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n",
    "\n",
    "def get_daily_candle_2(content):\n",
    "    stored = tool_rag.get_api_documents(\n",
    "        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"daily_candle_2\", \n",
    "        meta_opt=[{\"from_date\": content[\"date\"], \"adjusted\": content[\"adjusted\"]}])\n",
    "    if len(stored) == 0:\n",
    "        candle = tool_rest.get_daily_candle(content)\n",
    "        # Attempt to recover from choosing a holiday.\n",
    "        candle_date = parse(content[\"date\"])\n",
    "        if candle.status is RestStatus.NONE and candle_date.weekday() == 0 or candle_date.weekday() == 4:\n",
    "            if candle_date.weekday() == 0: # index 0 is monday, index 4 is friday\n",
    "                content[\"date\"] = candle_date.replace(day=candle_date.day-3).strftime(\"%Y-%m-%d\")\n",
    "            else:\n",
    "                content[\"date\"] = candle_date.replace(day=candle_date.day-1).strftime(\"%Y-%m-%d\")\n",
    "            return get_daily_candle_2(content)\n",
    "        return candle.model_dump_json()\n",
    "    return [json.loads(candle.docs) for candle in stored]\n",
    "\n",
    "def get_custom_candle_2(content):\n",
    "    stored = tool_rag.get_api_documents(\n",
    "        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"custom_candle_2\", \n",
    "        meta_opt=[{\n",
    "            \"timespan\": content[\"timespan\"],\n",
    "            \"adjusted\": content[\"adjusted\"],\n",
    "            \"from\": content[\"from\"],\n",
    "            \"to\": content[\"to\"]}])\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_custom_candle(content)\n",
    "    return [json.loads(candle.docs) for candle in stored]\n",
    "\n",
    "def get_overview_2(content):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"ticker\"], \"ticker_overview_2\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_overview(content)\n",
    "    return json.loads(stored[0].docs)\n",
    "\n",
    "def get_trends_1(content):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"trends_1\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_trends_simple(content)\n",
    "    return [json.loads(trend.docs) for trend in stored]\n",
    "\n",
    "def get_news_2(content):\n",
    "    timestamp_from = parse(content[\"published_utc.gte\"]).timestamp()\n",
    "    timestamp_to = parse(content[\"published_utc.lte\"]).timestamp()\n",
    "    news_from = tool_rag.get_api_documents(\n",
    "        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_from}])\n",
    "    news_to = tool_rag.get_api_documents(\n",
    "        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_to}])\n",
    "    if len(news_from) > 0 and len(news_to) > 0:\n",
    "        stored = tool_rag.get_api_documents(\n",
    "            content[\"query\"], content[\"ticker\"], \"get_news_2\",\n",
    "            [{\"published_utc\": {\"$gte\": timestamp_from}},\n",
    "             {\"published_utc\": {\"$lte\": timestamp_to}}])\n",
    "        return [NewsTypePoly.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n",
    "    return tool_rest.get_news_tagged(content)\n",
    "        \n",
    "finance_tool = types.Tool(\n",
    "    function_declarations=[\n",
    "        decl_get_symbol_1,\n",
    "        decl_get_symbols_1,\n",
    "        decl_get_name_1,\n",
    "        decl_get_symbol_quote_1,\n",
    "        decl_get_market_status_1,\n",
    "        decl_get_market_session_1,\n",
    "        decl_get_company_peers_1,\n",
    "        decl_get_local_datetime,\n",
    "        decl_get_last_market_close,\n",
    "        decl_get_exchange_codes_1,\n",
    "        decl_get_exchange_code_1,\n",
    "        decl_get_financials_1,\n",
    "        decl_get_daily_candlestick_2,\n",
    "        decl_get_custom_candlestick_2,\n",
    "        decl_get_ticker_overview_2,\n",
    "        decl_get_recommendation_trends_1,\n",
    "        decl_get_news_with_sentiment_2,\n",
    "        decl_get_rag_tool_response,\n",
    "        decl_get_wiki_tool_response,\n",
    "        decl_get_search_tool_response\n",
    "    ]\n",
    ")\n",
    "\n",
    "function_handler = {\n",
    "    \"get_symbol_1\": get_symbol_1,\n",
    "    \"get_symbols_1\": get_symbols_1,\n",
    "    \"get_name_1\": get_name_1,\n",
    "    \"get_symbol_quote_1\": get_quote_1,\n",
    "    \"get_market_status_1\": get_market_status_1,\n",
    "    \"get_market_session_1\": get_session_1,\n",
    "    \"get_company_peers_1\": get_peers_1,\n",
    "    \"get_local_datetime\": local_datetime,\n",
    "    \"get_last_market_close\": last_market_close,\n",
    "    \"get_exchange_codes_1\": get_exchange_codes_1,\n",
    "    \"get_exchange_code_1\": get_exchange_code_1,\n",
    "    \"get_financials_1\": get_financials_1,\n",
    "    \"get_daily_candlestick_2\": get_daily_candle_2,\n",
    "    \"get_custom_candlestick_2\": get_custom_candle_2,\n",
    "    \"get_ticker_overview_2\": get_overview_2,\n",
    "    \"get_recommendation_trends_1\": get_trends_1,\n",
    "    \"get_news_with_sentiment_2\": get_news_2,\n",
    "    \"get_rag_tool_response\": ask_rag_tool,\n",
    "    \"get_wiki_tool_response\": ask_wiki_tool,\n",
    "    \"get_search_tool_response\": ask_search_tool\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:30.355331Z",
     "iopub.status.busy": "2025-11-17T21:00:30.354959Z",
     "iopub.status.idle": "2025-11-17T21:00:30.385061Z",
     "shell.execute_reply": "2025-11-17T21:00:30.383578Z",
     "shell.execute_reply.started": "2025-11-17T21:00:30.3553Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Implement the function calling expert.\n",
    "\n",
    "@retry.Retry(\n",
    "    predicate=is_retriable,\n",
    "    initial=2.0,\n",
    "    maximum=64.0,\n",
    "    multiplier=2.0,\n",
    "    timeout=600,\n",
    ")\n",
    "def send_message(prompt):\n",
    "    #display(Markdown(\"#### Prompt\"))\n",
    "    #print(prompt, \"\\n\")\n",
    "    memory.set_prompt(prompt)\n",
    "    # Enable system prompt, function calling and minimum-randomness.\n",
    "    config_fncall = types.GenerateContentConfig(\n",
    "        system_instruction=instruction,\n",
    "        tools=[finance_tool],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    # Handle cases with multiple chained function calls.\n",
    "    function_calling_in_process = True\n",
    "    # Send the initial user prompt and function declarations.\n",
    "    response = api.retriable(api.args.CLIENT.models.generate_content,\n",
    "                             model=api(Gemini.Model.GEN),\n",
    "                             config=config_fncall,\n",
    "                             contents=memory.contents)\n",
    "    while function_calling_in_process:\n",
    "        # A part can be a function call or natural language response.\n",
    "        for part in response.candidates[0].content.parts:\n",
    "            if function_call := part.function_call:\n",
    "                # Extract the function call.\n",
    "                fn_name = function_call.name\n",
    "                #display(Markdown(\"#### Predicted function name\"))\n",
    "                #print(fn_name, \"\\n\")\n",
    "                # Extract the function call arguments.\n",
    "                fn_args = {key: value for key, value in function_call.args.items()}\n",
    "                #display(Markdown(\"#### Predicted function arguments\"))\n",
    "                #print(fn_args, \"\\n\")\n",
    "                # Call the predicted function.\n",
    "                try:\n",
    "                    api_response = function_handler[fn_name](fn_args)[:20000] # Stay within the input token limit\n",
    "                except KeyError as e: # Gemini sometimes omits required fn_args\n",
    "                    api.generation_fail()\n",
    "                    time.sleep(api.dt_between)\n",
    "                    send_message(prompt)\n",
    "                #display(Markdown(\"#### API response\"))\n",
    "                #print(api_response[:500], \"...\", \"\\n\")\n",
    "                # Create an API response part.\n",
    "                api_response_part = types.Part.from_function_response(\n",
    "                    name=fn_name,\n",
    "                    response={\"content\": api_response},\n",
    "                )\n",
    "                memory.update_contents(function_call, api_response_part)\n",
    "                # Send the updated prompt.\n",
    "                response = api.retriable(api.args.CLIENT.models.generate_content,\n",
    "                                         model=api(Gemini.Model.GEN),\n",
    "                                         config=config_fncall,\n",
    "                                         contents=memory.contents)\n",
    "            else:\n",
    "                # Response may be a summary or reasoning step.\n",
    "                if len(response.candidates[0].content.parts) == 1:\n",
    "                    function_calling_in_process = False\n",
    "                    memory.set_summary(response.text.replace(\"$\", \"\\\\$\"))\n",
    "                    break # No more parts in response.\n",
    "                else:\n",
    "                    #display(Markdown(\"#### Natural language reasoning step\"))\n",
    "                    #print(response)\n",
    "                    memory.set_reason(response.candidates[0].content.parts[0].text)\n",
    "                    continue # Next part contains a function call.\n",
    "        if not function_calling_in_process:\n",
    "            break # The function calling chain is complete.\n",
    "            \n",
    "    # Show the final natural language summary.\n",
    "    display(Markdown(\"#### Natural language response\"))\n",
    "    display(Markdown(memory.summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Baseline Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:30.388412Z",
     "iopub.status.busy": "2025-11-17T21:00:30.38741Z",
     "iopub.status.idle": "2025-11-17T21:00:44.965035Z",
     "shell.execute_reply": "2025-11-17T21:00:44.963902Z",
     "shell.execute_reply.started": "2025-11-17T21:00:30.388371Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "{\n",
      "    \"VN\": \"Vietnam exchanges including HOSE, HNX and UPCOM\",\n",
      "    \"AD\": \"ABU DHABI SECURITIES EXCHANGE\",\n",
      "    \"US\": \"US exchanges (NYSE, Nasdaq)\",\n",
      "    \"CO\": \"OMX NORDIC EXCHANGE COPENHAGEN A/S\",\n",
      "    \"QA\": \"QATAR EXCHANGE\",\n",
      "    \"BA\": \"BOLSA DE COMERCIO DE BUENOS AIRES\",\n",
      "    \"MX\": \"BOLSA MEXICANA DE VALORES (MEXICAN STOCK EXCHANGE)\",\n",
      "    \"PR\": \"PRAGUE STOCK EXCHANGE\",\n",
      "    \"HK\": \"HONG KONG EXCHANGES AND CLEARING LTD\",\n",
      "    \"CA\": \"Egyptian Stock Exchange\",\n",
      "    \"AX\": \"ASX - ALL MARKETS\",\n",
      "    \"SX\": \"DEUTSCHE BOERSE Stoxx\",\n",
      "    \"KQ\": \"KOREA EXCHANGE (KOSDAQ)\",\n",
      "    \"DB\": \"DUBAI FINANCIAL MARKET\",\n",
      "    \"PM\": \"Philippine Stock Exchange\",\n",
      "    \"KS\": \"KOREA EXCHANGE (STOCK MARKET)\",\n",
      "    \"ST\": \"NASDAQ OMX NORDIC STOCKHOLM\",\n",
      "    \"DU\": \"BOERSE DUESSELDORF\",\n",
      "    \"TL\": \"NASDAQ OMX TALLINN\",\n",
      "    \"AT\": \"ATHENS EXCHANGE S.A. CASH MARKET\",\n",
      "    \"SW\": \"SWISS EXCHANGE\",\n",
      "    \"LS\": \"NYSE EURONEXT - EURONEXT LISBON\",\n",
      "    \"SI\": \"SINGAPORE EXCHANGE\",\n",
      "    \"RG\": \"NASDAQ OMX RIGA\",\n",
      "    \"CR\": \"CARACAS STOCK EXCHANGE\",\n",
      "    \"SA\": \"Brazil Bolsa - Sao Paolo\",\n",
      "    \"BH\": \"BAHRAIN BOURSE\",\n",
      "    \"NZ\": \"NEW ZEALAND EXCHANGE LTD\",\n",
      "    \"L\": \"LONDON STOCK EXCHANGE\",\n",
      "    \"SZ\": \"SHENZHEN STOCK EXCHANGE\",\n",
      "    \"IC\": \"NASDAQ OMX ICELAND\",\n",
      "    \"KW\": \"Kuwait Stock Exchange\",\n",
      "    \"JK\": \"INDONESIA STOCK EXCHANGE\",\n",
      "    \"BE\": \"BOERSE BERLIN\",\n",
      "    \"TA\": \"TEL AVIV STOCK EXCHANGE\",\n",
      "    \"PA\": \"NYSE EURONEXT - MARCHE LIBRE PARIS\",\n",
      "    \"V\": \"TSX VENTURE EXCHANGE - NEX\",\n",
      "    \"SN\": \"SANTIAGO STOCK EXCHANGE\",\n",
      "    \"BD\": \"BUDAPEST STOCK EXCHANGE\",\n",
      "    \"KL\": \"BURSA MALAYSIA\",\n",
      "    \"CN\": \"CANADIAN NATIONAL STOCK EXCHANGE\",\n",
      "    \"VS\": \"NASDAQ OMX VILNIUS\",\n",
      "    \"ME\": \"MOSCOW EXCHANGE\",\n",
      "    \"CS\": \"CASABLANCA STOCK EXCHANGE\",\n",
      "    \"NL\": \"Nigerian Stock Exchange\",\n",
      "    \"BR\": \"NYSE EURONEXT - EURONEXT BRUSSELS\",\n",
      "    \"NS\": \"NATIONAL STOCK EXCHANGE OF INDIA\",\n",
      "    \"DE\": \"XETRA\",\n",
      "    \"WA\": \"WARSAW STOCK EXCHANGE/EQUITIES/MAIN MARKET\",\n",
      "    \"AS\": \"NYSE EURONEXT - EURONEXT AMSTERDAM\"\n",
      "}\n",
      "```\n",
      "DE, F, TG, SX, BE, DU, HA, HM, MU, SC, SG\n",
      " \n",
      "\n",
      "The Germany exchanges and their corresponding codes are: XETRA (DE), DEUTSCHE BOERSE AG (F), Hanover Stock Exchange (HA), DEUTSCHE BOERSE TradeGate (TG), BOERSE BERLIN (BE), BOERSE DUESSELDORF (DU), HANSEATISCHE WERTPAPIERBOERSE HAMBURG (HM), BOERSE MUENCHEN (MU), DEUTSCHE BOERSE Stoxx (SX), BOERSE_FRANKFURT_ZERTIFIKATE (SC), and BOERSE STUTTGART (SG).\n",
      " \n",
      "\n",
      "I don't know.\n",
      " \n",
      "\n",
      "I don't know.\n",
      " \n",
      "\n",
      "In the United States, the exchanges, such as NYSE and Nasdaq, operate on the America/New_York timezone. They have pre-market hours from 04:00-09:30, regular hours from 09:30-16:00, and post-market hours from 16:00-20:00.\n",
      " \n",
      "\n",
      "Fri Nov 14 20:00:00 2025\n"
     ]
    }
   ],
   "source": [
    "response = tool_rag.get_exchanges_csv(\n",
    "    \"\"\"Give me a dictionary in string form. It must contain key:value pairs mapping \n",
    "    exchange code to name. Just the dictionary string in pretty form.\"\"\")\n",
    "print(response.candidates[0].content.parts[-1].text)\n",
    "\n",
    "response = tool_rag.get_exchanges_csv(\n",
    "    \"\"\"What is the Germany exchange code? Return only the exchange codes as a simple \n",
    "    comma separated value that I can copy.\"\"\")\n",
    "print(response.candidates[0].content.parts[-1].text, \"\\n\")\n",
    "\n",
    "response = tool_rag.get_exchanges_csv(\"What are the Germany exchanges and thier corresponding exchange codes?\")\n",
    "print(response.text, \"\\n\")\n",
    "\n",
    "response = tool_rag.generate_answer(\"What are Google's stock ticker symbols?\")\n",
    "print(response.text, \"\\n\")\n",
    "\n",
    "response = tool_rag.generate_answer(\"What is Facebook's stock ticker symbol?\")\n",
    "print(response.text, \"\\n\")\n",
    "\n",
    "response = tool_rag.get_exchanges_csv(\"What are the US exchange operating hours?\")\n",
    "print(response.text, \"\\n\")\n",
    "\n",
    "response = tool_rag.get_exchanges_csv(\n",
    "    f\"\"\"Answer based on your knowledge of exchange operating hours.\n",
    "    Do not answer in full sentences. Omit all chat and provide the answer only.\n",
    "    The fields pre_market and post_market both represent extended operating hours.\n",
    "\n",
    "    The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n",
    "\n",
    "    Weekdays are: Mon, Tue, Wed, Thu, Fri.\n",
    "    On weekdays all exchanges open after pre-market and regular hours.\n",
    "    On weekdays all exchanges close after regular and post-market hours.\n",
    "    \n",
    "    Weekends are: Sat, Sun.\n",
    "    Always exclude weekends from exchange operating hours.\n",
    "    A list of holidays in date format mm-dd-yyyy: {tool_rag.holidays[\"US\"]}\n",
    "    Always exclude holidays from exchange operating hours.\n",
    "    When the answer is a holiday use the prior weekday for close.\n",
    "    When the answer is a holiday use the next weekday for open.\n",
    "    \n",
    "    Consider the US exchange's operating hours.\n",
    "    Provide the most recent weekday's close including post_market hours.\n",
    "    \n",
    "    Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\")\n",
    "print(response.candidates[0].content.parts[-1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SC1 Baseline Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:00:44.9667Z",
     "iopub.status.busy": "2025-11-17T21:00:44.966313Z",
     "iopub.status.idle": "2025-11-17T21:01:43.971391Z",
     "shell.execute_reply": "2025-11-17T21:01:43.970278Z",
     "shell.execute_reply.started": "2025-11-17T21:00:44.966677Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini API limit is FREE. Waiting 59s...\n",
      "api.refill_rpm  15\n"
     ]
    }
   ],
   "source": [
    "# Wait 59s for rate-limits to reset on FREE-tier.\n",
    "if api.args.API_LIMIT is Gemini.Limit.FREE.value:\n",
    "    print(\"Gemini API limit is FREE. Waiting 59s...\")\n",
    "    time.sleep(59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T21:01:43.97322Z",
     "iopub.status.busy": "2025-11-17T21:01:43.972834Z",
     "iopub.status.idle": "2025-11-17T21:01:52.605332Z",
     "shell.execute_reply": "2025-11-17T21:01:52.60456Z",
     "shell.execute_reply.started": "2025-11-17T21:01:43.973195Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate US->MarketEvent.LAST_CLOSE: 100%|| 1/1 [00:01<00:00,  1.49s/it]\n",
      "Generate US->MarketEvent.PRE_OPEN: 100%|| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Generate US->MarketEvent.REG_OPEN: 100%|| 1/1 [00:01<00:00,  1.55s/it]\n",
      "Generate US->MarketEvent.REG_CLOSE: 100%|| 1/1 [00:01<00:00,  1.34s/it]\n",
      "Generate US->MarketEvent.POST_CLOSE: 100%|| 1/1 [00:01<00:00,  1.40s/it]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The current session for US exchanges is closed.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is the current session for US exchanges?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The US market is currently closed (as of Mon Nov 17 20:33:29 2025 America/New_York). There is no holiday. The market session is 'closed'.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is the US market status?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The last US market close was Mon Nov 17 20:00:00 2025.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"When was the last US market close?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.generation_fail.next_model: model is now  gemini-2.0-flash-exp\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Apple's stock ticker is AAPL.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is Apple's stock ticker?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.144417Z",
     "iopub.status.idle": "2025-11-17T21:03:25.144808Z",
     "shell.execute_reply": "2025-11-17T21:03:25.144658Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.144641Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate quote embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here is the current price of Amazon stock:\n",
       "```json\n",
       "{\n",
       "\"c\": 232.87,\n",
       "\"d\": -1.82,\n",
       "\"dp\": -0.7755,\n",
       "\"h\": 234.6,\n",
       "\"l\": 229.19,\n",
       "\"o\": 233.25,\n",
       "\"pc\": 234.69,\n",
       "\"t\": 1763413200\n",
       "}\n",
       "```\n",
       "The current price is \\$232.87 as of Mon Nov 17 2025 16:00:00. The price changed by -1.82, which is -0.7755%. The high price of the day is \\$234.6, and the low price of the day is \\$229.19. The open price of the day is \\$233.25, and the previous close price was \\$234.69.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is the current price of Amazon stock? Display the result as a json object.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.146178Z",
     "iopub.status.idle": "2025-11-17T21:03:25.146679Z",
     "shell.execute_reply": "2025-11-17T21:03:25.146484Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.146463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.zero_error: model is now  gemini-2.0-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here's an overview of Apple's financial performance based on the data from September 27, 2025:\n",
       "\n",
       "**Key Financial Metrics:**\n",
       "*   **Revenue:** Revenue per share Annual is \\$27.74\n",
       "*   **Profitability:**\n",
       "    *   Gross Margin: 46.91%\n",
       "    *   Operating Margin: 31.97%\n",
       "    *   Net Profit Margin: 26.92%\n",
       "*   **Earnings Per Share (EPS):** \\$7.465 annually.\n",
       "*   **Price-to-Earnings Ratio (P/E):** 35.42 (TTM). The forward P/E ratio is 32.48.\n",
       "*   **Book Value Per Share:** \\$4.991 annually.\n",
       "*   **52-Week Performance:**\n",
       "    *   High: \\$277.32 on 2025-10-31\n",
       "    *   Low: \\$169.21 on 2025-04-08\n",
       "*   **Dividends:** The indicated annual dividend is \\$1.04 per share.\n",
       "*   **Debt:** The Long Term Debt/Equity Annual is 1.06.\n",
       "*   **Return on Assets (ROA):** 31.18%\n",
       "*   **Return on Equity (ROE):** 151.91%\n",
       "\n",
       "**Stock Performance:**\n",
       "*   The stock's beta is 1.09, indicating it is slightly more volatile than the market.\n",
       "*   The price is 21.01% up from its 52-week low.\n",
       "*   The price is 1.11% up over the last 5 days.\n",
       "*   The price is 0.75% up month-to-date.\n",
       "*   The price is 8.78% up year-to-date.\n",
       "\n",
       "**Financial Health:**\n",
       "*   The current ratio is 0.89, and the quick ratio is 0.86.\n",
       "*   The total debt to equity ratio is 1.34.\n",
       "\n",
       "**Valuation:**\n",
       "*   The price-to-book (P/B) ratio is 53.80.\n",
       "*   The price-to-sales (P/S) ratio is 9.53.\n",
       "\n",
       "**Additional Information:**\n",
       "*   Apple's market capitalization is approximately \\$3.97 trillion.\n",
       "*   The PEG ratio is 1.60. A PEG ratio above 1 may indicate that a stock is overvalued.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"Show me Apple's basic financials and help me understand key performance metrics. \n",
    "How has the stock performed?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.148633Z",
     "iopub.status.idle": "2025-11-17T21:03:25.148974Z",
     "shell.execute_reply": "2025-11-17T21:03:25.148847Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.148832Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "On 2025-05-05, Apple's stock (AAPL) had the following daily candlestick data:\n",
       "Open: 203.1, High: 204.1, Low: 198.21, Close: 198.89, Volume: 69018452, PreMarket: 205.0, AfterHours: 198.6."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"I need Apple's daily candlestick from 2025-05-05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.151509Z",
     "iopub.status.idle": "2025-11-17T21:03:25.152019Z",
     "shell.execute_reply": "2025-11-17T21:03:25.151829Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.151807Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score similarity to query: 100%|| 5/5 [00:00<00:00,  7.94it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 1/1 [00:00<00:00,  1.63it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 1/1 [00:00<00:00,  1.53it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 5/5 [00:00<00:00,  7.41it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 1/1 [00:00<00:00,  1.12it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 1/1 [00:00<00:00,  1.47it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 2/2 [00:00<00:00,  2.76it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 1/1 [00:00<00:00,  1.45it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 2/2 [00:00<00:00,  2.40it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 1/1 [00:00<00:00,  1.51it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 3/3 [00:00<00:00,  4.08it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Generate peers embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Apple's peers include DELL TECHNOLOGIES -C (DELL), WESTERN DIGITAL CORP (WDC), SANDISK CORP (SNDK), HEWLETT PACKARD ENTERPRISE (HPE), PURE STORAGE INC - CLASS A (PSTG), HP INC (HPQ), NETAPP INC (NTAP), SUPER MICRO COMPUTER INC (SMCI), IONQ INC (IONQ), COMPOSECURE INC-A (CMPO), and DIEBOLD NIXDORF INC (DBD).\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"Tell me who are Apple's peers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.153141Z",
     "iopub.status.idle": "2025-11-17T21:03:25.153606Z",
     "shell.execute_reply": "2025-11-17T21:03:25.153421Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.153371Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score similarity to query: 100%|| 1/1 [00:00<00:00,  1.54it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 2/2 [00:01<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.refill_rpm  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 1/1 [00:00<00:00,  1.41it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 5/5 [00:00<00:00,  7.65it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 2/2 [00:00<00:00,  3.77it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 11/11 [00:00<00:00, 13.89it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 1/1 [00:00<00:00,  1.50it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 1/1 [00:00<00:00,  1.45it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 1/1 [00:00<00:00,  1.70it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Score similarity to query: 100%|| 1/1 [00:00<00:00,  1.00it/s]\n",
      "Generate api embedding: 0it [00:00, ?it/s]\n",
      "Generate peers embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Amazon's peers include COUPANG INC (CPNG), EBAY INC (EBAY), DILLARDS INC-CL A (DDS), OLLIE'S BARGAIN OUTLET HOLDI (OLLI), ETSY INC (ETSY), MACY'S INC (M), PATTERN GROUP INC-CL A (PTRN), KOHLS CORP (KSS), SAVERS VALUE VILLAGE INC (SVV), and GROUPON INC (GRPN).\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"Tell me who are Amazon's peers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.155029Z",
     "iopub.status.idle": "2025-11-17T21:03:25.15549Z",
     "shell.execute_reply": "2025-11-17T21:03:25.155267Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.155249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n",
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n",
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n",
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n",
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n",
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n",
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n",
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n",
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.generation_fail.next_model: model is now  gemini-2.0-flash-exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I have downloaded the recommendation trends for Apple's peers in the sub-industry. Here's a summary of the latest analyst recommendation trends (November 2025):\n",
       "\n",
       "*   **DELL:** Buy: 18, Hold: 6, Sell: 0, Strong Buy: 8, Strong Sell: 0\n",
       "*   **WDC:** Buy: 19, Hold: 7, Sell: 0, Strong Buy: 6, Strong Sell: 0\n",
       "*   **HPE:** Buy: 8, Hold: 12, Sell: 0, Strong Buy: 6, Strong Sell: 0\n",
       "*   **PSTG:** Buy: 13, Hold: 7, Sell: 1, Strong Buy: 6, Strong Sell: 0\n",
       "*   **HPQ:** Buy: 3, Hold: 16, Sell: 1, Strong Buy: 2, Strong Sell: 0\n",
       "*   **NTAP:** Buy: 9, Hold: 15, Sell: 0, Strong Buy: 3, Strong Sell: 0\n",
       "*   **SMCI:** Buy: 10, Hold: 11, Sell: 3, Strong Buy: 2, Strong Sell: 0\n",
       "*   **IONQ:** Buy: 10, Hold: 3, Sell: 0, Strong Buy: 2, Strong Sell: 0\n",
       "*   **CMPO:** Buy: 8, Hold: 1, Sell: 1, Strong Buy: 2, Strong Sell: 0\n",
       "*   **DBD:** Buy: 4, Hold: 1, Sell: 0, Strong Buy: 2, Strong Sell: 0\n",
       "\n",
       "**Comparison:**\n",
       "\n",
       "*   **Highest Buy Recommendations:** WDC has the highest number of \"buy\" recommendations (19).\n",
       "*   **Highest Strong Buy Recommendations:** DELL has the highest number of \"strong buy\" recommendations (8).\n",
       "*   **Most Conservative Recommendations:** HPQ has the highest number of \"hold\" recommendations (16).\n",
       "*   **Companies with Sell Recommendations:** PSTG, HPQ, SMCI and CMPO have \"sell\" recommendations.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"Locate Apple's stock ticker, then download recommendation trends of all Apple's peers by sub-industry, \n",
    "and then finally compare them.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.156856Z",
     "iopub.status.idle": "2025-11-17T21:03:25.157121Z",
     "shell.execute_reply": "2025-11-17T21:03:25.157013Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.157002Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate quote embedding: 0it [00:00, ?it/s]\n",
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.refill_rpm  10\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Amazon's current share price is \\$232.87.\n",
       "\n",
       "Here is the candlestick data for Amazon (AMZN) for the past month, sorted in descending order by date:\n",
       "\n",
       "| Date       | Open     | High     | Low      | Close    | Volume     |\n",
       "|:-----------|:---------|:---------|:---------|:---------|:-----------|\n",
       "| 2025-11-13 | \\$235.06  | \\$238.73  | \\$232.89  | \\$234.69  | 38,956,619 |\n",
       "| 2025-11-12 | \\$243.05  | \\$243.75  | \\$236.50  | \\$237.58  | 41,401,638 |\n",
       "| 2025-11-11 | \\$250.23  | \\$250.37  | \\$243.75  | \\$244.20  | 31,190,063 |\n",
       "| 2025-11-08 | \\$248.41  | \\$249.75  | \\$247.23  | \\$249.10  | 23,563,960 |\n",
       "| 2025-11-07 | \\$248.34  | \\$251.75  | \\$245.59  | \\$248.40  | 36,476,474 |\n",
       "| 2025-11-04 | \\$242.90  | \\$244.90  | \\$238.49  | \\$244.41  | 46,374,294 |\n",
       "| 2025-11-03 | \\$249.15  | \\$250.38  | \\$242.17  | \\$243.04  | 46,004,201 |\n",
       "| 2025-11-02 | \\$249.03  | \\$251.00  | \\$246.16  | \\$250.20  | 40,610,602 |\n",
       "| 2025-11-01 | \\$250.38  | \\$257.01  | \\$248.66  | \\$249.32  | 51,546,311 |\n",
       "| 2025-10-31 | \\$255.36  | \\$258.60  | \\$252.90  | \\$254.00  | 95,997,714 |\n",
       "| 2025-10-28 | \\$250.10  | \\$250.50  | \\$243.98  | \\$244.22  | 166,340,683|\n",
       "| 2025-10-27 | \\$227.06  | \\$228.44  | \\$222.75  | \\$222.86  | 102,252,888|\n",
       "| 2025-10-26 | \\$231.67  | \\$232.82  | \\$227.76  | \\$230.30  | 52,035,936 |\n",
       "| 2025-10-25 | \\$228.21  | \\$231.48  | \\$226.21  | \\$229.25  | 47,099,924 |\n",
       "| 2025-10-24 | \\$227.66  | \\$228.40  | \\$225.54  | \\$226.97  | 38,266,995 |\n",
       "| 2025-10-21 | \\$221.97  | \\$225.40  | \\$221.90  | \\$224.21  | 38,684,853 |\n",
       "| 2025-10-20 | \\$219.00  | \\$221.30  | \\$218.18  | \\$221.09  | 31,539,699 |\n",
       "| 2025-10-19 | \\$219.30  | \\$220.00  | \\$216.52  | \\$217.95  | 44,308,538 |\n",
       "| 2025-10-18 | \\$218.43  | \\$223.32  | \\$217.99  | \\$222.03  | 50,494,565 |\n",
       "| 2025-10-17 | \\$213.88  | \\$216.69  | \\$213.59  | \\$216.48  | 38,882,819 |\n",
       "| 2025-10-14 | \\$214.56  | \\$214.80  | \\$211.03  | \\$213.04  | 45,986,944 |\n",
       "\n",
       "**Price Data Patterns and Correlation with News:**\n",
       "\n",
       "Looking at the candlestick data for Amazon over the past month, several patterns emerge, which can be correlated with recent news:\n",
       "\n",
       "*   **Early to Mid-October (around October 14 - October 27):** The stock price was relatively stable, trading in a lower range between approximately \\$213 and \\$230.\n",
       "    *   **Correlation:** During this period, there were some neutral news items, such as Amazon being mentioned in various market analyses and investment portfolios. However, a notable dip occurred around **October 27-28**. This coincides with news reports on **October 27th and 28th** stating that \"Amazon To Cut Up To 30,000 Jobs, Largest Layoff In Company History\" and \"Amazon Prepares to Cut Up to 30,000 Jobs This Week.\" Additionally, an **AWS outage** was reported on **October 24th**. These negative news events likely contributed to the downward pressure on the stock during this time.\n",
       "\n",
       "*   **Late October to Early November (around October 28 - November 2):** Amazon's stock experienced a significant upward surge, reaching its highest points in the observed period. The price jumped considerably on October 28th and continued a strong bullish trend, peaking around October 31st to November 1st.\n",
       "    *   **Correlation:** This strong rally is directly correlated with highly positive news. On **October 31st**, news broke that \"Nasdaq 100 Rebounds, Amazon Jumps 10% On Strong Earnings,\" indicating a very positive market reaction to Amazon's earnings report. Leading up to this, articles on **October 26th and 27th** provided positive earnings previews and reports, highlighting strong revenue growth in AWS and advertising segments. The most impactful news during this period was the announcement of **Amazon's \\$38 billion OpenAI deal**, reported extensively on **November 4th, 5th, and 6th**. Headlines like \"Amazon Strikes \\$38B OpenAI Deal, Wedbush Hikes Target To Street-High\" and \"Huge News for Amazon Stock Investors As It Signs Deal With OpenAI Worth Almost \\$40 Billion\" clearly fueled investor optimism and drove the stock to new highs. An article on **November 12th** even confirmed, \"Amazon Stock Just Hit an All-Time High.\"\n",
       "\n",
       "*   **Mid-November (around November 3 - November 13):** Following the strong rally, the stock price appears to be in a phase of consolidation or a slight downward correction. While still at a higher level than early October, there's a noticeable decrease from the early November peak.\n",
       "    *   **Correlation:** This period of slight decline and consolidation can be linked to a mix of broader market sentiment and some competitive news. On **November 9th**, \"The Biggest Risk for Amazon Stock Investors Right Now\" discussed management's aggressive spending. On **November 13th**, \"Tech Stocks Wipe Out Over \\$700 Billion As Traders Flee AI Hype\" indicated a broader tech market pullback, which would naturally affect Amazon. More specific to Amazon, news on **November 17th** like \"Is Amazon AWS in Trouble After Anthropic Partners With Google Cloud?\" highlighted potential competition for AWS, and \"CHIFFRE DAFFAIRES LEXIBOOK S1 2025-26...\" mentioned tense commercial relationships with Amazon, which could contribute to a more cautious investor sentiment.\n",
       "\n",
       "In conclusion, Amazon's stock performance over the past month has been highly reactive to significant company-specific news, particularly its earnings and major AI partnerships, as well as broader trends in the tech market. Negative news regarding layoffs and service outages caused initial dips, while strong earnings and a substantial AI deal with OpenAI propelled the stock to new highs, followed by a period of slight adjustment amidst general tech market caution and competitive developments."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"Tell me Amazon's current share price and provide candlestick data for the past month. \n",
    "Sort the data in descending order by date. Format the prices consistently as currency. \n",
    "Round prices to two decimal places. \n",
    "Present the data with multiple columns for display in markdown. \n",
    "Discuss and provide details about any patterns you notice in the price data. \n",
    "Correlate recent patterns with news over the same date range.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.159115Z",
     "iopub.status.idle": "2025-11-17T21:03:25.159593Z",
     "shell.execute_reply": "2025-11-17T21:03:25.159395Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.159373Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.zero_error: model is now  gemini-2.0-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Here is an overview of Apple Inc. (AAPL):\n",
       "\n",
       "General Information:\n",
       "*   **Name:** Apple Inc.\n",
       "*   **Market:** stocks\n",
       "*   **Locale:** us\n",
       "*   **Primary Exchange:** XNAS\n",
       "*   **Active:** true\n",
       "*   **Currency:** usd\n",
       "*   **CIK:** 0000320193\n",
       "*   **Composite FIGI:** BBG000B9XRY4\n",
       "*   **Share Class FIGI:** BBG001S5N8V8\n",
       "*   **Market Capitalization:** \\$4,025,226,320,730.0005\n",
       "*   **Phone Number:** (408) 996-1010\n",
       "*   **Address:** ONE APPLE PARK WAY, CUPERTINO, CA 95014\n",
       "*   **Description:** Apple is among the largest companies in the world, with a broad portfolio of hardware and software products targeted at consumers and businesses. Apple's iPhone makes up a majority of the firm sales, and Apple's other products like Mac, iPad, and Watch are designed around the iPhone as the focal point of an expansive software ecosystem. Apple has progressively worked to add new applications, like streaming video, subscription bundles, and augmented reality. The firm designs its own software and semiconductors while working with subcontractors like Foxconn and TSMC to build its products and chips. Slightly less than half of Apple's sales come directly through its flagship stores, with a majority of sales coming indirectly through partnerships and distribution.\n",
       "*   **SIC Code:** 3571\n",
       "*   **SIC Description:** ELECTRONIC COMPUTERS\n",
       "*   **Ticker Root:** AAPL\n",
       "*   **Homepage URL:** [https://www.apple.com](https://www.apple.com)\n",
       "*   **Total Employees:** 166000\n",
       "*   **List Date:** 1980-12-12\n",
       "\n",
       "Branding:\n",
       "\n",
       "*   **Logo URL:** [https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04\\_logo.svg](https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04_logo.svg)\n",
       "*   **Icon URL:** [https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04\\_icon.png](https://api.polygon.io/v1/reference/company-branding/YXBwbGUuY29t/images/2025-04-04_icon.png)\n",
       "\n",
       "Share Information:\n",
       "\n",
       "*   **Share Class Shares Outstanding:** 848,612,359\n",
       "*   **Weighted Shares Outstanding:** 14,776,353,000\n",
       "*   **Round Lot:** 100\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is Apple's ticker overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.163933Z",
     "iopub.status.idle": "2025-11-17T21:03:25.164838Z",
     "shell.execute_reply": "2025-11-17T21:03:25.164644Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.16462Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score wiki search by similarity to topic: 0it [00:00, ?it/s]\n",
      "Generate wiki embeddings: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Google's shares are traded on the NASDAQ stock exchange under the ticker symbols GOOGL and GOOG. These ticker symbols now refer to Alphabet Inc., Google's holding company, since the fourth quarter of 2015.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is Google's stock ticker symbol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.165424Z",
     "iopub.status.idle": "2025-11-17T21:03:25.165763Z",
     "shell.execute_reply": "2025-11-17T21:03:25.165648Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.165635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score wiki search by similarity to topic: 0it [00:00, ?it/s]\n",
      "Generate wiki embeddings: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "MGM Studio is a subsidiary of Amazon and therefore does not have its own stock symbol. Its parent company, Amazon, trades under the symbol AMZN."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.refill_rpm  10\n"
     ]
    }
   ],
   "source": [
    "send_message(\"What is MGM Studio's stock symbol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.167658Z",
     "iopub.status.idle": "2025-11-17T21:03:25.168035Z",
     "shell.execute_reply": "2025-11-17T21:03:25.167909Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.167889Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "MGM Studios is owned by Amazon, and Amazon's stock symbol is AMZN.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is MGM Studio's owner company stock symbol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.169397Z",
     "iopub.status.idle": "2025-11-17T21:03:25.169772Z",
     "shell.execute_reply": "2025-11-17T21:03:25.16965Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.169635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Score wiki search by similarity to topic: 0it [00:00, ?it/s]\n",
      "Generate wiki embeddings: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Facebook's stock ticker symbol is META.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"What is Facebook's stock ticker symbol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.171864Z",
     "iopub.status.idle": "2025-11-17T21:03:25.172179Z",
     "shell.execute_reply": "2025-11-17T21:03:25.172053Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.172042Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.zero_error: model is now  gemini-2.0-flash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Okay, I will analyze Amazon's bullish versus bearish predictions from October 1, 2025, until today, November 17, 2025. This will include a discussion of recommendation trends and sentiment analysis of news from the same dates, looking for patterns and correlations.\n",
       "\n",
       "**Recommendation Trends:**\n",
       "Based on the recommendation trends data:\n",
       "*   In August 2025, there were 51 buys, 4 holds, and 0 sells.\n",
       "*   In September 2025, there were 52 buys, 4 holds, and 0 sells.\n",
       "*   In October 2025, there were 52 buys, 3 holds, and 0 sells.\n",
       "*   In November 2025, there were 54 buys, 2 holds, and 0 sells.\n",
       "\n",
       "The overall trend shows a consistently strong buy recommendation for Amazon, with the number of \"buy\" recommendations increasing slightly over the months. There are very few \"hold\" recommendations and no \"sell\" recommendations, indicating a generally positive outlook from analysts.\n",
       "\n",
       "**Sentiment Analysis of News:**\n",
       "The news articles from October 1, 2025, to November 17, 2025, present a mixed sentiment regarding Amazon.\n",
       "\n",
       "*   **Positive Sentiments:** Several articles highlight Amazon's strong position in the AI cloud market, AWS growth, and strategic partnerships (e.g., with OpenAI). Some analysts suggest Amazon is a \"golden buying opportunity\" and is well-positioned for future growth. The company's diversified business model and cost control strategies are also viewed favorably.\n",
       "*   **Neutral Sentiments:** Many articles mention Amazon in the context of broader industry trends, such as AI infrastructure investments or holiday retail sales, without expressing a strong positive or negative sentiment specifically toward the company.\n",
       "*   **Negative Sentiments:** Some articles point out potential risks, such as increasing capital expenditures, potential AI infrastructure bottlenecks, and workforce reductions. There are also mentions of increasing competition in digital advertising and potential margin pressure.\n",
       "\n",
       "**Patterns and Correlations:**\n",
       "*   **AI Focus:** A significant portion of the news revolves around Amazon's involvement in AI, both as an infrastructure provider (AWS) and as a user of AI technologies to improve its operations. This aligns with the increasing \"buy\" recommendations, suggesting analysts are optimistic about Amazon's AI strategy.\n",
       "*   **Mixed Sentiments Despite Positive Recommendations:** While analyst recommendations are overwhelmingly positive, the news sentiment is more nuanced. This suggests that while analysts see long-term potential, there are also short-term concerns and challenges that investors should be aware of.\n",
       "*   **Market Volatility:** Some articles mention market volatility and potential corrections, which could impact Amazon's stock price regardless of its underlying performance.\n",
       "\n",
       "**Summary:**\n",
       "Overall, the analysis suggests a bullish outlook for Amazon, supported by strong analyst recommendations and positive sentiment surrounding its AI initiatives and diversified business model. However, there are also potential risks and challenges, such as increasing capital expenditures, competition, and market volatility, that investors should consider.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"Compare Amazon's bullish versus bearish predictions from Oct 01 2025 until today. \n",
    "Include a discussion of recommendation trends, and sentiment analysis of news from the same dates. \n",
    "Discuss any patterns or correlations you find.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.172816Z",
     "iopub.status.idle": "2025-11-17T21:03:25.173092Z",
     "shell.execute_reply": "2025-11-17T21:03:25.172979Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.172967Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n",
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "From October 1, 2025, to November 17, 2025, here's a comparison of Google's bullish versus bearish predictions based on recommendation trends and sentiment analysis of news:\n",
       "\n",
       "**Recommendation Trends:**\n",
       "\n",
       "*   The recommendation trends from October 1, 2025, to November 1, 2025, show a consistent analyst sentiment.\n",
       "    *   In October 2025, there were 39 buy, 13 hold, 0 sell, 21 strongBuy, and 0 strongSell recommendations.\n",
       "    *   In November 2025, there were 41 buy, 12 hold, 0 sell, 21 strongBuy, and 0 strongSell recommendations.\n",
       "    *   This indicates a stable and positive outlook from analysts during this period.\n",
       "\n",
       "**Sentiment Analysis of News:**\n",
       "\n",
       "*   The news articles from October 1, 2025, to November 17, 2025, present a mixed sentiment regarding Google.\n",
       "    *   Many articles highlight Google's strong position in AI, cloud computing, and search, with positive sentiments driven by innovative AI integrations, strategic partnerships, and solid financial performance.\n",
       "    *   Several articles mention Google's investments in AI infrastructure and data centers, indicating confidence in the company's future growth.\n",
       "    *   However, some articles express concerns about increasing competition, potential market disruptions, and regulatory challenges.\n",
       "    *   There are also neutral sentiments related to Google's partnerships and collaborations with other companies.\n",
       "\n",
       "**Patterns and Correlations:**\n",
       "\n",
       "*   The recommendation trends and sentiment analysis of news suggest a generally positive outlook for Google.\n",
       "*   The stable analyst recommendations indicate confidence in Google's long-term prospects.\n",
       "*   The news articles reflect both bullish and bearish sentiments, with positive news related to AI advancements and financial performance, and negative news related to competition and market challenges.\n",
       "*   There is a correlation between positive news and analyst recommendations, as positive developments in AI and cloud computing tend to reinforce the bullish sentiment.\n",
       "*   However, negative news related to competition and market challenges may temper the bullish sentiment and lead to more cautious recommendations.\n",
       "\n",
       "In summary, Google's bullish versus bearish predictions from October 1, 2025, to November 17, 2025, show a generally positive outlook, with stable analyst recommendations and mixed sentiment in news articles. The company's strong position in AI, cloud computing, and search, as well as its strategic investments in AI infrastructure, contribute to the bullish sentiment. However, increasing competition and market challenges may temper the positive outlook and lead to more cautious recommendations.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"Compare Google's bullish versus bearish predictions from Oct 01 2025 until today. \n",
    "Include a discussion of recommendation trends, and sentiment analysis of news from the same dates. \n",
    "Discuss any patterns or correlations you find.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.174648Z",
     "iopub.status.idle": "2025-11-17T21:03:25.174929Z",
     "shell.execute_reply": "2025-11-17T21:03:25.174815Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.174803Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.refill_rpm  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add chunks embedding: 0it [00:00, ?it/s]\n",
      "Add chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The outlook for Apple (AAPL) and its peers based on recent trends and news sentiment from July 1, 2025, to November 17, 2025, is as follows:\n",
       "\n",
       "**Apple (AAPL):**\n",
       "\n",
       "*   **Recommendation Trends:** Analyst recommendations for Apple are generally positive, with a consensus of \"Buy.\" In November 2025, the recommendations were 23 Buy, 17 Hold, 2 Sell, 15 Strong Buy, and 0 Strong Sell.\n",
       "*   **News Sentiment:** News sentiment is mixed. Recent articles highlight both positive aspects, such as Warren Buffett increasing his holdings and recognition for resisting heavy investments in AI, and negative aspects, such as concerns about valuation and an antitrust lawsuit in China.\n",
       "*   **Peer Comparison:** To perform a peer comparison, I will analyze the recommendation trends and news sentiment for Apple's peers in the sub-industry.\n",
       "\n",
       "**Peers Analysis:**\n",
       "\n",
       "Based on the tool output, Apple's peers by sub-industry include: DELL, WDC, SNDK, HPE, PSTG, HPQ, NTAP, SMCI, IONQ, CMPO, and DBD.\n",
       "\n",
       "**Peer: Dell Technologies (DELL):**\n",
       "\n",
       "*   **Recommendation Trends:** Analyst recommendations for Dell are generally positive, with a consensus of \"Buy.\" In November 2025, the recommendations were 18 Buy, 6 Hold, 0 Sell, 8 Strong Buy, and 0 Strong Sell.\n",
       "*   **News Sentiment:** News sentiment is mixed. Recent articles highlight both positive aspects, such as collaboration on a high-profile project, and negative aspects, such as concerns about DRAM and NAND costs pressuring margins.\n",
       "\n",
       "**Comparison:**\n",
       "\n",
       "*   Both Apple and Dell have generally positive analyst recommendations.\n",
       "*   News sentiment for both companies is mixed, with positive and negative aspects.\n",
       "*   Based on the available information, it is difficult to make a definitive comparison between Apple and its peers without analyzing all peers.\n",
       "\n",
       "**Additional Considerations:**\n",
       "\n",
       "*   The analysis is based on limited information from the tools. A more comprehensive analysis would require additional data and research.\n",
       "*   The news sentiment is based on the tone of the articles and may not reflect the actual financial performance of the companies.\n",
       "*   Analyst recommendations are not always accurate and should be used in conjunction with other information.\n",
       "\n",
       "In summary, the outlook for Apple is mixed, with positive analyst recommendations but mixed news sentiment. A comparison with its peers suggests a similar outlook for Dell. A more comprehensive analysis would require additional data and research on all peers.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "send_message(\"\"\"How is the outlook for Apple based on trends and news sentiment from July 01 2025 until today? \n",
    "Perform the same analysis on all peers by sub-industry. Then compare Apple result to it's peers.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.175717Z",
     "iopub.status.idle": "2025-11-17T21:03:25.176102Z",
     "shell.execute_reply": "2025-11-17T21:03:25.175937Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.175916Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upsert chunks embedding: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api.refill_rpm  10\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Natural language response"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "From September 1, 2025, to November 17, 2025, Apple's stock (AAPL) experienced several fluctuations, with notable correlations to news regarding tariffs, product performance, and strategic investments.\n",
       "\n",
       "**Impact of Tariffs:**\n",
       "\n",
       "News concerning tariffs had a mixed but often significant impact on Apple's stock.\n",
       "\n",
       "*   **Positive Impact:** On October 28, 2025, news emerged that Apple had \"successfully avoided arduous tariffs through strategic U.S. investments, relocated iPhone production, [and] achieved exemptions from Chinese and Indian tariffs.\" This positive development, coupled with an investor update suggesting a strong iPhone 17 lineup, likely contributed to the significant rise in Apple's stock from October 26th to October 28th. Similarly, early September saw positive stock movement following favorable Google antitrust rulings that also hinted at a \"potential reduction in tariff concerns.\" Apple's strategic investments in rare earth materials with MP Materials and expansion of production capacity in Southeast Asia to mitigate trade risks were generally viewed with neutral to positive sentiment, contributing to a more stable or slightly upward trend.\n",
       "*   **Negative Impact:** Conversely, renewed tariff threats from President Trump on October 10, 2025, triggered a broader market selloff, causing Apple's stock to experience a \"significant stock price decline.\" This negative news directly correlated with a dip in the candlestick data around that time.\n",
       "\n",
       "**Other News and Correlations:**\n",
       "\n",
       "*   **iPhone Launches and Sales:** News related to iPhone launches and strong sales often correlated with positive stock movements. For instance, on September 22, 2025, Apple's stock \"jumped 3.2% on strong iPhone 17 preorder demand in China,\" aligning with a significant rise in the candlestick data. However, an underwhelming iPhone 17 event on September 12, 2025, where \"shares slid 3.2%,\" correlated with a noticeable drop in the stock price.\n",
       "*   **AI Development:** News about Apple's AI development and innovation had a more nuanced impact. While some articles highlighted challenges or suggested Apple was \"lagging behind competitors in AI development,\" others focused on significant investments in AI infrastructure. The stock's reaction to AI-related news was not always consistently positive or negative, indicating that investors were still evaluating Apple's long-term AI strategy.\n",
       "*   **Investor Sentiment:** Mentions of prominent investors like Warren Buffett and Peter Thiel either increasing or decreasing their stake in Apple also influenced market sentiment. For example, Peter Thiel \"significantly increased holdings\" in Apple on November 17, 2025, showing confidence in the company's future.\n",
       "\n",
       "**Candlestick and News Pattern Correlations:**\n",
       "\n",
       "*   **Early September (around 2025-09-03 to 2025-09-04):** The stock showed positive movement, with closing prices around \\$247.77-\\$247.66. This correlated with positive news about a favorable Google antitrust ruling and potential reduction in tariff concerns.\n",
       "*   **Mid-September (around 2025-09-11):** A significant drop in the closing price to \\$226.79 on September 11th aligned with news of \"plateauing device sales, minimal AI-driven innovation, slower growth, and decreased profit\" and an \"underwhelmed\" investor reaction to the iPhone 17 event.\n",
       "*   **Late September (around 2025-09-22):** The stock experienced a significant rise, with the closing price reaching \\$256.69. This correlated with multiple positive news items, including a 3.2% jump due to strong iPhone 17 preorder demand in China.\n",
       "*   **Early October (around 2025-10-10):** Despite some negative news about tariff threats, the stock saw a significant rise to \\$269.05 on October 10th. This suggests that other positive factors or strong underlying sentiment for Apple might have counteracted the broader market negativity.\n",
       "*   **Late October (around 2025-10-28):** A strong upward trend in the stock, with the closing price reaching \\$275.25, directly correlated with positive news about Apple successfully navigating tariff policies and strong iPhone 17 sales.\n",
       "\n",
       "In conclusion, Apple's stock performance during this period was clearly influenced by news, particularly concerning tariffs and product-specific announcements. Positive developments in these areas tended to drive the stock higher, while negative news could lead to declines. The broader market trends and investor sentiment also played a role in shaping the stock's movements."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api.push_default_model(\"gemini-2.5-flash\")\n",
    "send_message(\"\"\"What does the recent news say about Apple and the impact of tariffs? From 2025-09-01 up to today. \n",
    "Also locate candlestick data for the same dates. \n",
    "Discuss in detail any correlations in patterns between the candlestick and news data. Ignore duplicate news entry.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StockChat: Agents Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.177174Z",
     "iopub.status.idle": "2025-11-17T21:03:25.17762Z",
     "shell.execute_reply": "2025-11-17T21:03:25.177386Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.177367Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define parent class: retrieval-augmented generation.\n",
    "# - ChromaDB for storage and retrieval\n",
    "# - Gemini 2.0/2.5 for augmented generation\n",
    "class RetrievalAugmentedGeneration:\n",
    "    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n",
    "    config_temp = types.GenerateContentConfig(temperature=0.0)\n",
    "\n",
    "    def __init__(self, genai_client, collection_name):\n",
    "        self.client = genai_client\n",
    "        self.embed_fn = GeminiEmbedFunction(genai_client)\n",
    "        self.db = self.chroma_client.get_or_create_collection(\n",
    "            name=collection_name, \n",
    "            embedding_function=self.embed_fn, # type: ignore\n",
    "            metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def add_documents_list(self, docs: list):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n",
    "        metas=[{\"source\": doc.metadata[\"source\"]} for doc in docs]\n",
    "        content=[doc.page_content for doc in docs]\n",
    "        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate document embedding\")\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def get_documents_list(self, query: str, max_sources: int = 5000, where: Optional[dict] = None):\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        return self.stored_result(\n",
    "            self.db.query(query_texts=[query], \n",
    "                          n_results=max_sources, \n",
    "                          where=where), \n",
    "            is_query = True)\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def generate_answer(self, query: str, max_sources: int = 10, \n",
    "                        where: Optional[dict] = None, passages: Optional[list[str]] = None):\n",
    "        stored = self.get_documents_list(query, max_sources, where)\n",
    "        query_oneline = query.replace(\"\\n\", \" \")\n",
    "        prompt = f\"\"\"You're an expert writer. You understand how to interpret html and markdown. You will accept the\n",
    "        question below and answer based only on the passages. Never mention the passages in your answers. Be sure to \n",
    "        respond in concise sentences. Include all relevant background information when possible. If a passage is not \n",
    "        relevant to the answer you must ignore it. If no passage answers the question respond with: I don't know.\n",
    "\n",
    "        QUESTION: {query_oneline}\n",
    "        \n",
    "        \"\"\"\n",
    "        # Add the retrieved documents to the prompt.\n",
    "        stored_docs = [passage.docs for passage in stored]\n",
    "        for passage in stored_docs if passages is None else stored_docs + passages:\n",
    "            passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "            prompt += f\"PASSAGE: {passage_oneline}\\n\"\n",
    "        # Generate the response.\n",
    "        response = api.retriable(\n",
    "            self.client.models.generate_content,\n",
    "            model=api(Gemini.Model.GEN),\n",
    "            config=self.config_temp,\n",
    "            contents=prompt)\n",
    "        # Check for generated code and store in memory.\n",
    "        content = response.candidates[0].content\n",
    "        if len(content.parts) > 1 and content.parts[0].executable_code:\n",
    "            memory.append_code(prompt, content.parts)\n",
    "        return response\n",
    "\n",
    "    class ChromaDBResult(BaseModel): # todo: cleanup old basemodel\n",
    "        docs: str\n",
    "        dist: Optional[float] # requires query\n",
    "        meta: Optional[dict]  # requires get or query\n",
    "        store_id: str\n",
    "\n",
    "    def stored_result(self, result, is_query: bool = False) -> list[ChromaDBResult]:\n",
    "        try:\n",
    "            results = []\n",
    "            if len(result[\"documents\"]) == 0:\n",
    "                return results\n",
    "            if isinstance(result[\"documents\"][0], list):\n",
    "                for i in range(len(result[\"documents\"][0])):\n",
    "                    obj = self.ChromaDBResult(\n",
    "                        docs=result[\"documents\"][0][i],\n",
    "                        dist=result[\"distances\"][0][i] if is_query else None,\n",
    "                        meta=result[\"metadatas\"][0][i],\n",
    "                        store_id=result[\"ids\"][0][i])\n",
    "                    results.append(obj)\n",
    "            else:\n",
    "                results.append(self.ChromaDBResult(\n",
    "                    docs=result[\"documents\"][0],\n",
    "                    dist=result[\"distances\"][0] if is_query else None,\n",
    "                    meta=result[\"metadatas\"][0],\n",
    "                    store_id=result[\"ids\"][0]))\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wiki-Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.179306Z",
     "iopub.status.idle": "2025-11-17T21:03:25.179699Z",
     "shell.execute_reply": "2025-11-17T21:03:25.179573Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.179552Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define subclass: wiki-augmented generation.\n",
    "class WikiRAG(RetrievalAugmentedGeneration):\n",
    "    def __init__(self, genai_client):\n",
    "        super().__init__(genai_client, \"wikidocs\")\n",
    "            \n",
    "    def add_wiki_documents(self, title: str, wiki_chunks: list):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        result = self.get_wiki_documents(title)\n",
    "        if len(result) == 0:\n",
    "            ids = list(map(str, range(self.db.count(), self.db.count()+len(wiki_chunks))))\n",
    "            metas=[{\"title\": title, \"source\": \"add_wiki_documents\"}]*len(wiki_chunks)\n",
    "            tqdm(self.db.add(ids=ids, documents=wiki_chunks, metadatas=metas), desc=\"Generate wiki embeddings\")\n",
    "\n",
    "    def get_wiki_documents(self, title: Optional[str] = None):\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        if title is None:\n",
    "            return self.stored_result(self.db.get(where={\"source\": \"add_wiki_document\"}))\n",
    "        else:\n",
    "            return self.stored_result(self.db.get(where={\"title\": title}))\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def generate_with_wiki_passages(self, query: str, title: str, passages: list[str]):\n",
    "        return self.generate_answer(query, where={\"title\": title}, passages=passages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search-Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.182262Z",
     "iopub.status.idle": "2025-11-17T21:03:25.18278Z",
     "shell.execute_reply": "2025-11-17T21:03:25.182645Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.182629Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define subclass: search-augmented generation.\n",
    "class SearchRAG(RetrievalAugmentedGeneration):\n",
    "    def __init__(self, genai_client):\n",
    "        super().__init__(genai_client, \"searchdocs\")\n",
    "\n",
    "    def add_grounded_document(self, query: str, topic: str, result):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        chunks = result.candidates[0].grounding_metadata.grounding_chunks\n",
    "        supports = result.candidates[0].grounding_metadata.grounding_supports\n",
    "        if supports is not None: # Only add grounded documents which have supports\n",
    "            grounded_text = [f\"{s.segment.text}\" for s in supports]\n",
    "            source = [f\"{c.web.title}\" for c in chunks]\n",
    "            score = [f\"{s.confidence_scores}\" for s in supports]\n",
    "            tqdm(self.db.add(ids=str(self.db.count()),\n",
    "                             documents=json.dumps(grounded_text),\n",
    "                             metadatas=[{\"source\": \", \".join(source),\n",
    "                                         \"confidence_score\": \", \".join(score),\n",
    "                                         \"topic\": topic,\n",
    "                                         \"question\": query}]),\n",
    "                 desc=\"Generate grounding embedding\")\n",
    "\n",
    "    def get_grounding_documents(self, query: str, topic: str):\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        return self.stored_result(self.db.get(where={\"$and\": [{\"question\": query}, {\"topic\": topic}]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest-Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.185131Z",
     "iopub.status.idle": "2025-11-17T21:03:25.18571Z",
     "shell.execute_reply": "2025-11-17T21:03:25.185494Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.185412Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define subclass: rest-augmented generation.\n",
    "class RestRAG(RetrievalAugmentedGeneration):\n",
    "    exchange_codes: Optional[dict] = None\n",
    "    exchange_lists: dict = {}\n",
    "    events: dict = {}\n",
    "    holidays: dict = {}\n",
    "\n",
    "    def __init__(self, genai_client):\n",
    "        super().__init__(genai_client, \"restdocs\")\n",
    "        logging.getLogger(\"chromadb\").setLevel(logging.ERROR) # suppress warning on existing id\n",
    "        self.set_holidays(\"US\", [\"09-01-2025\",\"10-13-2025\",\"11-11-2025\",\"11-27-2025\",\"12-25-2025\"])\n",
    "        self.generated_events(\"US\")\n",
    "\n",
    "    def set_holidays(self, exchange_code: str, holidays: list):\n",
    "        self.holidays[exchange_code] = [datetime.strptime(h, \"%m-%d-%Y\").date() for h in holidays]\n",
    "\n",
    "    def get_exchange_codes(self, with_query: Optional[str] = None):\n",
    "        gen = None\n",
    "        if with_query and with_query not in self.exchange_lists.keys():\n",
    "            gen = tqdm(total=1, desc=\"Generate exchange codes with_query\")\n",
    "            data = self.get_exchanges_csv(\n",
    "                f\"\"\"What is the {with_query} exchange code? Return only the exchange codes \n",
    "                as a list in string form. Just the list string. \n",
    "                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n",
    "            self.exchange_lists[with_query] = ast.literal_eval(data.parts[-1].text)\n",
    "        elif with_query is None and self.exchange_codes is None:\n",
    "            gen = tqdm(total=1, desc=\"Generate exchange codes\")\n",
    "            data = self.get_exchanges_csv(\n",
    "                \"\"\"Give me a dictionary in string form. It must contain key:value pairs \n",
    "                mapping exchange code to name. Just the dictionary string. \n",
    "                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n",
    "            self.exchange_codes = ast.literal_eval(data.parts[-1].text.strip(\"\\\\`\"))\n",
    "        if gen:\n",
    "            gen.update(1)\n",
    "        return self.exchange_lists[with_query] if with_query else self.exchange_codes\n",
    "\n",
    "    def get_event_date(self, event_t: str, exchange_code: str, event: MarketEvent):\n",
    "        current_dt_str = datetime.now(GeneratedEvent.tz()).strftime('%c')\n",
    "        current_dt = datetime.strptime(current_dt_str, \"%a %b %d %H:%M:%S %Y\")\n",
    "        current_t_str = datetime.now(GeneratedEvent.tz()).strftime('%H:%M:%S')\n",
    "        current_t = datetime.strptime(current_t_str, \"%H:%M:%S\").time()\n",
    "        event_time = parse(event_t).time()\n",
    "        gen_datetime = None\n",
    "        if event is MarketEvent.LAST_CLOSE:\n",
    "            last_close_day = current_dt.date() - timedelta(days=0 if current_t > event_time else 1)\n",
    "            # Loop backwards to find the last valid trading day (not a weekend or holiday).\n",
    "            while last_close_day.weekday() >= 5 or last_close_day in self.holidays[exchange_code]: # 5 = Sat, 6 = Sun\n",
    "                last_close_day -= timedelta(days=1)\n",
    "            # Combine the date and time.\n",
    "            gen_datetime = datetime.combine(last_close_day, event_time)\n",
    "        else:\n",
    "            next_event_day = current_dt.date() + timedelta(days=0 if current_t < event_time else 1)\n",
    "            # Loop forward to find the next valid trading day (not a weekend or holiday).\n",
    "            while next_event_day.weekday() >= 5 or next_event_day in self.holidays[exchange_code]: # 5 = Sat, 6 = Sun\n",
    "                next_event_day += timedelta(days=1)\n",
    "            # Combine date and time.\n",
    "            gen_datetime = datetime.combine(next_event_day, event_time)\n",
    "        # Format the result as requested.\n",
    "        return gen_datetime.strftime('%a %b %d %X %Y')\n",
    "\n",
    "    def generate_event(self, exchange_code: str, event: MarketEvent):\n",
    "        if event is MarketEvent.LAST_CLOSE or event is MarketEvent.POST_CLOSE:\n",
    "            prompt = f\"\"\"What is the closing time including post_market hours.\"\"\"\n",
    "        elif event is MarketEvent.PRE_OPEN or event is MarketEvent.REG_OPEN:\n",
    "            is_pre = \"including\" if event is MarketEvent.PRE_OPEN else \"excluding\"\n",
    "            prompt = f\"\"\"What is the opening time {is_pre} pre_market hours.\"\"\"\n",
    "        elif event is MarketEvent.REG_CLOSE:\n",
    "            prompt = f\"\"\"What is the closing time excluding post_market hours.\"\"\"\n",
    "        prompt = f\"\"\"Answer based on your knowledge of exchange operating hours.\n",
    "            Do not answer in full sentences. Omit all chat and provide the answer only.\n",
    "            The fields pre_market and post_market both represent extended operating hours.\n",
    "\n",
    "            The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n",
    "            \n",
    "            Consider the {exchange_code} exchange's operating hours.\n",
    "            {prompt}\n",
    "            \n",
    "            Answer with the time in this format: '%H:%M:%S'.\n",
    "            Omit all other chat and details. Do not use sentences.\"\"\"\n",
    "        progress = tqdm(total=1, desc=f\"Generate {exchange_code}->{event}\")\n",
    "        response = self.get_exchanges_csv(prompt).candidates[0].content\n",
    "        if Gemini.Const.Stop() in f\"{response.parts[-1].text}\":\n",
    "            progress.close()\n",
    "            api.generation_fail()\n",
    "            time.sleep(api.dt_between)\n",
    "            return self.generate_event(exchange_code, event)\n",
    "        else:\n",
    "            response = self.get_event_date(response.parts[-1].text, exchange_code, event)\n",
    "            progress.update(1)\n",
    "            return response\n",
    "\n",
    "    def generated_events(self, exchange_code: str) -> GeneratedEvent:\n",
    "        # Check for an existing GeneratedEvent object having updates.\n",
    "        if exchange_code in self.events.keys() and self.events[exchange_code].has_update():\n",
    "            event_obj = self.events[exchange_code]\n",
    "            event_state = [(event_obj.pre_open, MarketEvent.PRE_OPEN),\n",
    "                           (event_obj.reg_open, MarketEvent.REG_OPEN),\n",
    "                           (event_obj.reg_close, MarketEvent.REG_CLOSE),\n",
    "                           (event_obj.post_close, MarketEvent.POST_CLOSE)]\n",
    "            # Need now in same format as generated.\n",
    "            datetime_now = parse(datetime.now(event_obj.tz()).strftime('%c'))\n",
    "            gen_ts = parse(event_obj.timestamp)\n",
    "            # Re-generate events when day changes.\n",
    "            if datetime_now.day > gen_ts.day:\n",
    "                del self.events[exchange_code]\n",
    "                return self.generated_events(exchange_code)\n",
    "            # Update changed events on trading days.\n",
    "            for e in event_state:\n",
    "                if datetime_now > parse(e[0]):\n",
    "                    event_dt = self.generate_event(exchange_code, e[1])\n",
    "                    match e[1]:\n",
    "                        case MarketEvent.PRE_OPEN:\n",
    "                            event_obj.pre_open = event_dt\n",
    "                        case MarketEvent.REG_OPEN:\n",
    "                            event_obj.reg_open = event_dt\n",
    "                        case MarketEvent.REG_CLOSE:\n",
    "                            event_obj.reg_close = event_dt\n",
    "                        case MarketEvent.POST_CLOSE:\n",
    "                            event_obj.post_close = event_dt\n",
    "            event_obj.timestamp = datetime.now(event_obj.tz()).strftime('%c')\n",
    "            self.events[exchange_code] = event_obj\n",
    "        # Generate events for an exchange code not in cache.\n",
    "        elif exchange_code not in self.events.keys():\n",
    "            self.events[exchange_code] = GeneratedEvent(\n",
    "                last_close=self.generate_event(exchange_code, MarketEvent.LAST_CLOSE),\n",
    "                pre_open=self.generate_event(exchange_code, MarketEvent.PRE_OPEN),\n",
    "                reg_open=self.generate_event(exchange_code, MarketEvent.REG_OPEN),\n",
    "                reg_close=self.generate_event(exchange_code, MarketEvent.REG_CLOSE),\n",
    "                post_close=self.generate_event(exchange_code, MarketEvent.POST_CLOSE),\n",
    "                is_holiday=datetime.now().date() in self.holidays[exchange_code])\n",
    "        return self.events[exchange_code]\n",
    "\n",
    "    def set_holiday_event(self, exchange_code: str):\n",
    "        self.generated_events(exchange_code).is_holiday = True\n",
    "\n",
    "    def last_market_close(self, exchange_code: str):\n",
    "        return self.generated_events(exchange_code).last_close\n",
    "\n",
    "    def add_api_document(self, query: str, api_response: str, topic: str, source: str = \"add_api_document\"):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        splitter = RecursiveJsonSplitter(max_chunk_size=Gemini.Const.ChunkMax())\n",
    "        docs = splitter.create_documents(texts=[api_response], convert_lists=True)\n",
    "        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n",
    "        content = [json.dumps(doc.page_content) for doc in docs]\n",
    "        metas = [{\"source\": source, \"topic\": topic}]*len(docs)\n",
    "        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate api embedding\")\n",
    "\n",
    "    def add_peers_document(self, query: str, names: list, topic: str, source: str, group: str):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        peers = {\"symbol\": topic, \"peers\": names}\n",
    "        tqdm(self.db.add(ids=str(self.db.count()),\n",
    "                         documents=[json.dumps(peers)],\n",
    "                         metadatas=[{\"source\": source, \"topic\": topic, \"group\": group}]),\n",
    "             desc=\"Generate peers embedding\")\n",
    "\n",
    "    def get_peers_document(self, query: str, topic: str, group: str):\n",
    "        return self.get_documents_list(query, where={\"$and\": [{\"group\": group}, {\"topic\": topic}]})\n",
    "\n",
    "    def add_rest_chunks(self, chunks: list, topic: str, source: str, ids: Optional[list[str]] = None,\n",
    "                        meta_opt: Optional[list[dict]] = None, is_update: bool = True):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode\n",
    "        if ids is None:\n",
    "            ids = list(map(str, range(self.db.count(), self.db.count()+len(chunks))))\n",
    "        if isinstance(chunks[0], BaseModel):\n",
    "            docs = [model.model_dump_json() for model in chunks]\n",
    "        else:\n",
    "            docs = [json.dumps(obj) for obj in chunks]\n",
    "        meta_base = {\"source\": source, \"topic\": topic}\n",
    "        if meta_opt is not None:\n",
    "            for m in meta_opt:\n",
    "                m.update(meta_base)\n",
    "        metas = [meta_base]*len(chunks) if meta_opt is None else meta_opt\n",
    "        if is_update:\n",
    "            tqdm(self.db.upsert(ids=ids, documents=docs, metadatas=metas), desc=\"Upsert chunks embedding\")\n",
    "        else:\n",
    "            tqdm(self.db.add(ids=ids, documents=docs, metadatas=metas), desc=\"Add chunks embedding\")\n",
    "\n",
    "    def get_market_status(self, exchange_code: str) -> tuple[list[VectorStoreResult], bool]: # result, has rest update\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        stored = self.stored_result(self.db.get(where={\n",
    "            \"$and\": [{\"exchange\": exchange_code}, {\"topic\": \"market_status\"}]}))\n",
    "        if len(stored) == 0:\n",
    "            return stored, True\n",
    "        # Check for a daily market status update.\n",
    "        status = json.loads(stored[0].docs)\n",
    "        gen_day = parse(self.generated_events(exchange_code).timestamp).day\n",
    "        store_day = parse(stored[0].meta['timestamp']).day\n",
    "        if status[\"holiday\"] != MarketSession.NA.value and gen_day == store_day:\n",
    "            return stored, False\n",
    "        elif gen_day > store_day:\n",
    "            return stored, True\n",
    "        # Update with generated events to avoid rest api requests.\n",
    "        status[\"session\"] = self.generated_events(exchange_code).session().value\n",
    "        status[\"isOpen\"] = self.generated_events(exchange_code).is_open()\n",
    "        stored[0].docs = json.dumps(status)\n",
    "        return stored, False\n",
    "\n",
    "    def get_basic_financials(self, query: str, topic: str, source: str = \"get_financials_1\"):\n",
    "        return self.get_documents_list(\n",
    "            query, max_sources=200, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n",
    "\n",
    "    def add_quote_document(self, query: str, quote: str, topic: str, timestamp: int, source: str):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        tqdm(self.db.add(ids=str(self.db.count()), \n",
    "                             documents=[quote], \n",
    "                             metadatas=[{\"source\": source, \"topic\": topic, \"timestamp\": timestamp}]), \n",
    "             desc=\"Generate quote embedding\")\n",
    "\n",
    "    def get_api_documents(self, query: str, topic: str, source: str = \"add_api_document\", \n",
    "                          meta_opt: Optional[list[dict]] = None):\n",
    "        where = [{\"source\": source}, {\"topic\": topic}]\n",
    "        if meta_opt is None:\n",
    "            return self.get_documents_list(query, where={\"$and\": where})\n",
    "        else:\n",
    "            for meta in meta_opt:\n",
    "                for k,v in meta.items():\n",
    "                    where.append({k: v})\n",
    "            return self.get_documents_list(query, where={\"$and\": where})\n",
    "\n",
    "    def query_api_documents(self, query: str, topic: str, source: str = \"add_api_document\"):\n",
    "        return self.generate_answer(query, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def get_exchanges_csv(self, query: str):\n",
    "        return self.generate_answer(query, max_sources=100, where={\"source\": \"exchanges.csv\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wiki Grounding Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.187109Z",
     "iopub.status.idle": "2025-11-17T21:03:25.187622Z",
     "shell.execute_reply": "2025-11-17T21:03:25.187383Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.187336Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: wiki-grounding generation.\n",
    "# - Creates new groundings by similarity to topic\n",
    "# - Retrieves existing groundings by similarity to topic\n",
    "class WikiGroundingTool:   \n",
    "    def __init__(self, genai_client):\n",
    "        self.client = genai_client\n",
    "        self.rag = WikiRAG(genai_client)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\") # suppress beta-warning\n",
    "            self.splitter = HTMLSemanticPreservingSplitter(\n",
    "                headers_to_split_on=[(\"h2\", \"Main Topic\"), (\"h3\", \"Sub Topic\")],\n",
    "                separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \"],\n",
    "                max_chunk_size=Gemini.Const.ChunkMax(),\n",
    "                chunk_overlap=50,\n",
    "                preserve_links=True,\n",
    "                preserve_images=True,\n",
    "                preserve_videos=True,\n",
    "                preserve_audio=True,\n",
    "                elements_to_preserve=[\"table\", \"ul\", \"ol\", \"code\"],\n",
    "                denylist_tags=[\"script\", \"style\", \"head\"],\n",
    "                custom_handlers={\"code\": self.code_handler},\n",
    "            )\n",
    "\n",
    "    def generate_answer(self, query: str, topic: str):\n",
    "        stored = self.rag.get_wiki_documents(topic)\n",
    "        if len(stored) > 0:\n",
    "            return self.rag.generate_with_wiki_passages(query, topic, [chunk.docs for chunk in stored]).text\n",
    "        else:\n",
    "            pages = wikipedia.search(topic + \" company\")\n",
    "            if len(pages) > 0:\n",
    "                p_topic_match = 0.80\n",
    "                for i in range(len(pages)):\n",
    "                    if tqdm(api.similarity([topic + \" company\", pages[i]]) > p_topic_match, \n",
    "                            desc= \"Score wiki search by similarity to topic\"):\n",
    "                        page_html = Gemini.get(f\"https://en.wikipedia.org/wiki/{pages[i]}\")\n",
    "                        chunks = [chunk.page_content for chunk in self.splitter.split_text(page_html)]\n",
    "                        self.rag.add_wiki_documents(topic, chunks)\n",
    "                        return self.rag.generate_with_wiki_passages(query, topic, chunks).text\n",
    "            return Gemini.Const.Stop()\n",
    "\n",
    "    def code_handler(self, element: Tag) -> str:\n",
    "        data_lang = element.get(\"data-lang\")\n",
    "        code_format = f\"<code:{data_lang}>{element.get_text()}</code>\"\n",
    "        return code_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Grounding Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.189054Z",
     "iopub.status.idle": "2025-11-17T21:03:25.189808Z",
     "shell.execute_reply": "2025-11-17T21:03:25.189596Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.18949Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: search-grounding generation.\n",
    "# - Creates new groundings by exact match to topic\n",
    "# - Retrieves existing groundings by similarity to topic\n",
    "class SearchGroundingTool:\n",
    "    config_ground = types.GenerateContentConfig(\n",
    "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    \n",
    "    def __init__(self, genai_client):\n",
    "        self.client = genai_client\n",
    "        self.rag = SearchRAG(genai_client)\n",
    "\n",
    "    def generate_answer(self, query: str, topic: str):\n",
    "        stored = self.rag.get_grounding_documents(query, topic)\n",
    "        if len(stored) > 0:\n",
    "            for i in range(len(stored)):\n",
    "                meta_q = stored[i].meta[\"question\"]\n",
    "                p_ground_match = 0.95 # This can be really high ~ 95-97%\n",
    "                if tqdm(api.similarity([query, meta_q]) > p_ground_match,\n",
    "                        desc=\"Score similarity to stored grounding\"):\n",
    "                    return ast.literal_eval(stored[i].docs)\n",
    "        return self.get_grounding(query, topic)\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def get_grounding(self, query: str, topic: str):\n",
    "        contents = [types.Content(role=\"user\", parts=[types.Part(text=query)])]\n",
    "        contents += f\"\"\"\n",
    "        You're a search assistant that provides grounded answers to questions about {topic}. You will provide only \n",
    "        results that discuss {topic}. Be brief and specific in answering and omit extra details.\n",
    "        If an answer is not possible respond with: I don't know.\"\"\"\n",
    "        response = api.retriable(self.client.models.generate_content, \n",
    "                                 model=api(Gemini.Model.GEN), \n",
    "                                 config=self.config_ground, \n",
    "                                 contents=contents)\n",
    "        if response.candidates[0].grounding_metadata.grounding_supports is not None:\n",
    "            if self.is_consistent(query, topic, response.text):\n",
    "                self.rag.add_grounded_document(query, topic, response)\n",
    "                return response.text \n",
    "        return Gemini.Const.Stop() # Empty grounding supports or not consistent in response\n",
    "\n",
    "    def is_consistent(self, query: str, topic: str, model_response: str) -> bool:\n",
    "        topic = topic.replace(\"'\", \"\")\n",
    "        id_strs = topic.split()\n",
    "        if len(id_strs) == 1:\n",
    "            matches = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", query)\n",
    "            if len(matches) > 0:\n",
    "                topic = matches[0]\n",
    "        compound_match = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", model_response)\n",
    "        model_response = model_response.replace(\"'\", \"\")\n",
    "        if len(compound_match) == 0 and topic in model_response:\n",
    "            return True # not a compound topic id and exact topic match\n",
    "        for match in compound_match:\n",
    "            if topic not in match:\n",
    "                return False\n",
    "        return True # all prefix matches contained topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest Grounding Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-17T21:03:25.191188Z",
     "iopub.status.idle": "2025-11-17T21:03:25.191644Z",
     "shell.execute_reply": "2025-11-17T21:03:25.191452Z",
     "shell.execute_reply.started": "2025-11-17T21:03:25.191433Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: rest-grounding generation.\n",
    "# - Parses the json response from rest api's\n",
    "# - Prevents concurrent http requests\n",
    "class RestGroundingTool:\n",
    "    limits = None\n",
    "\n",
    "    def __init__(self, genai_client, with_limits: bool):\n",
    "        self.client = genai_client\n",
    "        self.rag = RestRAG(genai_client)\n",
    "        if with_limits:\n",
    "            self.limits = {}\n",
    "            for rest_api in ApiLimit:\n",
    "                self.limits[rest_api.value[0]] = BlockingUrlQueue(Gemini.get, rest_api.value[1])\n",
    "\n",
    "    def get_limit(self, rest_api: ApiLimit) -> Optional[BlockingUrlQueue]:\n",
    "        return self.limits[rest_api.value[0]] if self.limits else None\n",
    "\n",
    "    def basemodel(self, data: str, schema: BaseModel, from_lambda: bool = False) -> Optional[BaseModel]:\n",
    "        try:\n",
    "            if from_lambda:\n",
    "                return schema(results=json.loads(data))\n",
    "            return schema.model_validate_json(data)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def dailycandle(self, data: str) -> Optional[DailyCandle]:\n",
    "        try:\n",
    "            candle = json.loads(data)\n",
    "            if \"from\" not in candle:\n",
    "                raise ValueError(\"not a dailycandle / missing value for date\")\n",
    "            agg = self.basemodel(data, Aggregate)\n",
    "            return DailyCandle(from_date=candle[\"from\"], \n",
    "                               status=agg.status.value, \n",
    "                               symbol=agg.symbol, \n",
    "                               open=agg.open, \n",
    "                               high=agg.high, \n",
    "                               low=agg.low, \n",
    "                               close=agg.close, \n",
    "                               volume=agg.volume, \n",
    "                               otc=agg.otc, \n",
    "                               preMarket=agg.preMarket, \n",
    "                               afterHours=agg.afterHours)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    @retry.Retry(timeout=600)\n",
    "    def try_url(self, url: str, schema: BaseModel, as_lambda: bool, with_limit: Optional[BlockingUrlQueue],\n",
    "                success_fn: Callable, *args, **kwargs):\n",
    "        try:\n",
    "            if self.limits is None:\n",
    "                data = Gemini.get(url)\n",
    "            elif with_limit:\n",
    "                data = with_limit.push(url)\n",
    "            if schema is DailyCandle:\n",
    "                model = self.dailycandle(data)\n",
    "            else:\n",
    "                model = self.basemodel(data, schema, as_lambda)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                print(f\"try_url exception: {e}\")\n",
    "                if issubclass(schema, RestResultPoly):\n",
    "                    return success_fn(*args, **kwargs, result=self.basemodel(data, RestResultPoly))\n",
    "            except Exception as not_a_result:\n",
    "                print(not_a_result)\n",
    "            return Gemini.Const.Stop()\n",
    "        else:\n",
    "            return success_fn(*args, **kwargs, model=model)\n",
    "\n",
    "    def get_symbol_matches(self, with_content, by_name: bool, model: SymbolResult):\n",
    "        matches = []\n",
    "        max_failed_match = model.count if not by_name else 3\n",
    "        p_desc_match = 0.92\n",
    "        p_symb_match = 0.95\n",
    "        if model.count > 0:\n",
    "            for obj in tqdm(model.get(), desc=\"Score similarity to query\"):\n",
    "                if max_failed_match > 0:\n",
    "                    desc = [with_content[\"q\"].upper(), obj.description.split(\"-\", -1)[0]]\n",
    "                    symb = [with_content[\"q\"].upper(), obj.symbol]\n",
    "                    if by_name and api.similarity(desc) > p_desc_match: \n",
    "                        matches.append(obj.symbol)\n",
    "                    elif not by_name and api.similarity(symb) > p_symb_match:\n",
    "                        matches.append(obj.description)\n",
    "                        max_failed_match = 0\n",
    "                    else:\n",
    "                        max_failed_match -= 1\n",
    "        if len(matches) > 0:\n",
    "            self.rag.add_api_document(with_content[\"query\"], matches, with_content[\"q\"], \"get_symbol_1\")\n",
    "            return matches\n",
    "        return Gemini.Const.Stop()\n",
    "\n",
    "    def get_quote(self, with_content, model: Quote):\n",
    "        quote = model.model_dump_json()\n",
    "        self.rag.add_quote_document(with_content[\"query\"], quote, with_content[\"symbol\"], model.t, \"get_quote_1\")\n",
    "        return quote\n",
    "\n",
    "    def parse_financials(self, with_content, model: BasicFinancials):\n",
    "        metric = list(model.metric.items())\n",
    "        chunks = []\n",
    "        # Chunk the metric data.\n",
    "        for i in range(0, len(metric), Gemini.Const.MetricBatch()):\n",
    "            batch = metric[i:i + Gemini.Const.MetricBatch()]\n",
    "            chunks.append({\"question\": with_content[\"query\"], \"answer\": batch})\n",
    "        # Chunk the series data.\n",
    "        for key in model.series.keys():\n",
    "            series = list(model.series[key].items())\n",
    "            for s in series:\n",
    "                if api.token_count(s) <= Gemini.Const.ChunkMax():\n",
    "                    chunks.append({\"question\": with_content[\"query\"], \"answer\": s})\n",
    "                else:\n",
    "                    k = s[0]\n",
    "                    v = s[1]\n",
    "                    for i in range(0, len(v), Gemini.Const.SeriesBatch()):\n",
    "                        batch = v[i:i + Gemini.Const.SeriesBatch()]\n",
    "                        chunks.append({\"question\": with_content[\"query\"], \"answer\": {k: batch}})\n",
    "        self.rag.add_rest_chunks(chunks, topic=with_content[\"symbol\"], source=\"get_financials_1\")\n",
    "        return chunks\n",
    "\n",
    "    def parse_news(self, with_content, model: NewsResultFinn):\n",
    "        if model.count > 0:\n",
    "            metas = []\n",
    "            for digest in model.get():\n",
    "                pub_date = datetime.fromtimestamp(digest.datetime, tz=GeneratedEvent.tz()).strftime(\"%Y-%m-%d\")\n",
    "                metas.append({\"publisher\": digest.source,\n",
    "                              \"published_est\": parse(pub_date).timestamp(),\n",
    "                              \"news_id\": digest.id,\n",
    "                              \"related\": digest.related})\n",
    "            self.rag.add_rest_chunks(model.get(), topic=with_content[\"symbol\"], source=\"get_news_1\",\n",
    "                                     ids=[f\"{digest.id}+news\" for digest in model.get()],\n",
    "                                     meta_opt=metas, is_update=False)\n",
    "            return [digest.summary().model_dump_json() for digest in model.get()]\n",
    "        return Gemini.Const.Stop()\n",
    "\n",
    "    def parse_news(self, with_content, model: Optional[NewsResultPoly] = None,\n",
    "                   result: Optional[RestResultPoly] = None) -> tuple[list, str]: # list of summary, next list url\n",
    "        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n",
    "            metas = []\n",
    "            for news in model.get():\n",
    "                pub_date = parse(news.published_utc).strftime(\"%Y-%m-%d\")\n",
    "                metas.append({\"publisher\": news.publisher.name,\n",
    "                              \"published_utc\": parse(pub_date).timestamp(),\n",
    "                              \"news_id\": news.id,\n",
    "                              \"related\": json.dumps(news.tickers),\n",
    "                              \"keywords\": json.dumps(news.keywords)})\n",
    "            self.rag.add_rest_chunks(model.get(), topic=with_content[\"ticker\"], source=\"get_news_2\",\n",
    "                                     ids=[news.id for news in model.get()],\n",
    "                                     meta_opt=metas, is_update=False)\n",
    "            return [news.summary().model_dump_json() for news in model.get()], model.next_url\n",
    "        elif result:\n",
    "            return result.model_dump_json()\n",
    "\n",
    "    def parse_daily_candle(self, with_content, model: Optional[DailyCandle] = None,\n",
    "                           result: Optional[RestResultPoly] = None):\n",
    "        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n",
    "            self.rag.add_rest_chunks(\n",
    "                chunks=[model],\n",
    "                topic=with_content[\"stocksTicker\"],\n",
    "                source=\"daily_candle_2\",\n",
    "                meta_opt=[{\"from_date\": model.from_date, \"adjusted\": with_content[\"adjusted\"]}])\n",
    "            return model\n",
    "        elif result:\n",
    "            return result\n",
    "\n",
    "    def parse_custom_candle(self, with_content, model: Optional[CustomCandle] = None,\n",
    "                            result: Optional[RestResultPoly] = None):\n",
    "        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n",
    "            metas = [{\n",
    "                \"timespan\": with_content[\"timespan\"],\n",
    "                \"adjusted\": with_content[\"adjusted\"],\n",
    "                \"from\": with_content[\"from\"],\n",
    "                \"to\": with_content[\"to\"]}]*model.count\n",
    "            candles = [candle.model_dump_json() for candle in model.get()]\n",
    "            self.rag.add_rest_chunks(\n",
    "                chunks=candles,\n",
    "                topic=with_content[\"stocksTicker\"],\n",
    "                source=\"custom_candle_2\",\n",
    "                meta_opt=metas)\n",
    "            return candles\n",
    "        elif result:\n",
    "            return result.model_dump_json()\n",
    "\n",
    "    def parse_overview(self, with_content, model: OverviewResult):\n",
    "        overview = [model.get().model_dump_json()]\n",
    "        self.rag.add_rest_chunks(chunks=overview, topic=with_content[\"ticker\"], source=\"ticker_overview_2\")\n",
    "        return overview\n",
    "\n",
    "    def parse_trends(self, with_content, model: TrendsResult):\n",
    "        if model.count > 0:\n",
    "            metas = [{\"period\": trend.period} for trend in model.get()]\n",
    "            trends = [trend.model_dump_json() for trend in model.get()]\n",
    "            self.rag.add_rest_chunks(trends, topic=with_content[\"symbol\"], source=\"trends_1\", meta_opt=metas)\n",
    "            return trends\n",
    "        return Gemini.Const.Stop()\n",
    "\n",
    "    def augment_market_status(self, with_id: Optional[str], model: MarketStatusResult):\n",
    "        if model.get().holiday != MarketSession.NA.value:\n",
    "            self.rag.set_holiday_event(model.get().exchange)\n",
    "        events = self.rag.generated_events(model.get().exchange)\n",
    "        model.get().session = events.session()\n",
    "        model.get().isOpen = events.is_open()\n",
    "        meta = {\"exchange\": model.get().exchange,\n",
    "                \"last_close\": events.last_close,\n",
    "                \"pre_open\": events.pre_open,\n",
    "                \"reg_open\": events.reg_open,\n",
    "                \"reg_close\": events.reg_close,\n",
    "                \"post_close\": events.post_close,\n",
    "                \"timestamp\": events.timestamp }\n",
    "        self.rag.add_rest_chunks([model.get()],\n",
    "                                 topic=\"market_status\",\n",
    "                                 source=\"get_market_status_1\",\n",
    "                                 ids=[with_id] if with_id else None,\n",
    "                                 meta_opt=[meta])\n",
    "        return model.get().model_dump_json()\n",
    "\n",
    "    def get_symbol(self, content, by_name: bool = True):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/search?q={content['q']}&exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=SymbolResult,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.get_symbol_matches,\n",
    "            with_content=content,\n",
    "            by_name=by_name)\n",
    "\n",
    "    def get_current_price(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/quote?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=Quote,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.get_quote,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_market_status(self, content, store_id: Optional[str] = None):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/market-status?exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=MarketStatusResult,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.augment_market_status,\n",
    "            with_id=store_id)\n",
    "\n",
    "    def get_peers(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/peers?symbol={content['symbol']}&grouping={content['grouping']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=PeersResult,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=lambda model: model)\n",
    "\n",
    "    def get_basic_financials(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/metric?symbol={content['symbol']}&metric={content['metric']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=BasicFinancials,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.parse_financials,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_news_simple(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/company-news?symbol={content['symbol']}&from={content['from']}&to={content['to']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=NewsResultFinn,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.parse_news,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_news_tagged(self, content):\n",
    "        next_url = f\"https://api.polygon.io/v2/reference/news?ticker={content['ticker']}&published_utc.gte={content['published_utc.gte']}&published_utc.lte={content['published_utc.lte']}&order={content['order']}&limit={content['limit']}&sort={content['sort']}&apiKey={POLYGON_API_KEY}\"\n",
    "        news = []\n",
    "        while True:\n",
    "            news_list, next_url = self.try_url(\n",
    "                next_url,\n",
    "                schema=NewsResultPoly,\n",
    "                as_lambda=False,\n",
    "                with_limit=self.get_limit(ApiLimit.POLY),\n",
    "                success_fn=self.parse_news,\n",
    "                with_content=content)\n",
    "            news += news_list\n",
    "            if next_url is None:\n",
    "                break\n",
    "            next_url += f\"&apiKey={POLYGON_API_KEY}\"\n",
    "        return news\n",
    "\n",
    "    def get_daily_candle(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://api.polygon.io/v1/open-close/{content['stocksTicker']}/{content['date']}?adjusted={content['adjusted']}&apiKey={POLYGON_API_KEY}\",\n",
    "            schema=DailyCandle,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.POLY),\n",
    "            success_fn=self.parse_daily_candle,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_custom_candle(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://api.polygon.io/v2/aggs/ticker/{content['stocksTicker']}/range/{content['multiplier']}/{content['timespan']}/{content['from']}/{content['to']}?adjusted={content['adjusted']}&sort={content['sort']}&limit={content['limit']}&apiKey={POLYGON_API_KEY}\",\n",
    "            schema=CustomCandle,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.POLY),\n",
    "            success_fn=self.parse_custom_candle,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_overview(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://api.polygon.io/v3/reference/tickers/{content['ticker']}?apiKey={POLYGON_API_KEY}\",\n",
    "            schema=OverviewResult,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.POLY),\n",
    "            success_fn=self.parse_overview,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_trends_simple(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/recommendation?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=TrendsResult,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.parse_trends,\n",
    "            with_content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ADK Web UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T22:31:15.433667Z",
     "iopub.status.busy": "2025-11-17T22:31:15.432782Z",
     "iopub.status.idle": "2025-11-17T22:31:15.44085Z",
     "shell.execute_reply": "2025-11-17T22:31:15.439836Z",
     "shell.execute_reply.started": "2025-11-17T22:31:15.433633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get the proxied URL in the Kaggle Notebooks environment.\n",
    "def get_adk_proxy_url():\n",
    "    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n",
    "    ADK_PORT = \"8000\"\n",
    "\n",
    "    servers = list(list_running_servers())\n",
    "    if not servers:\n",
    "        raise Exception(\"No running Jupyter servers found.\")\n",
    "\n",
    "    baseURL = servers[0]['base_url']\n",
    "\n",
    "    try:\n",
    "        path_parts = baseURL.split('/')\n",
    "        kernel = path_parts[2]\n",
    "        token = path_parts[3]\n",
    "    except IndexError:\n",
    "        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n",
    "\n",
    "    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n",
    "    url = f\"{PROXY_HOST}{url_prefix}\"\n",
    "\n",
    "    styled_html = f\"\"\"\n",
    "    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n",
    "        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n",
    "        </div>\n",
    "        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n",
    "            <strong> IMPORTANT:</strong> The ADK web UI is <strong>not started yet</strong>. You must wait for that to appear below.\n",
    "        </div>\n",
    "        <a href='{url}' target='_blank' style=\"\n",
    "            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n",
    "            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n",
    "            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n",
    "            Open ADK Web UI (after started appears below) \n",
    "        </a>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "    display(HTML(styled_html))\n",
    "\n",
    "    return url_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Launch the ADK Web UI.\n",
    "if not os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
    "    !adk web\n",
    "else:\n",
    "    if not os.path.isdir(\"sc2/\"):\n",
    "        !git init -b main\n",
    "        !git remote add origin https://github.com/lol-dungeonmaster/kaggle-agents-2025.git\n",
    "        !git config core.sparseCheckout true\n",
    "        !echo \"sc2/\" >> .git/info/sparse-checkout\n",
    "        !git pull origin main\n",
    "        env_key = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "        !echo \"GOOGLE_API_KEY=$env_key\" >> sc2/.env # from .venv on local runs\n",
    "    url_prefix = get_adk_proxy_url()\n",
    "    !adk web --url_prefix {url_prefix}"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7122584,
     "sourceId": 11376588,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
