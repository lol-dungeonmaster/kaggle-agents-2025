{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/oswind/stockchat-agents-edition?scriptVersionId=283096961\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-01T09:35:21.93846Z",
     "iopub.status.busy": "2025-12-01T09:35:21.93811Z",
     "iopub.status.idle": "2025-12-01T09:37:46.387777Z",
     "shell.execute_reply": "2025-12-01T09:37:46.386716Z",
     "shell.execute_reply.started": "2025-12-01T09:35:21.938433Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Setup the notebook based on running environment.\n",
    "import os\n",
    "# Optional: Enable telemetry in browser_use and chromadb.\n",
    "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"false\"\n",
    "# Check for kaggle environment.\n",
    "if os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
    "    # Kaggle Run: update the system.\n",
    "    !pip uninstall -qqy google-ai-generativelanguage pydrive2 tensorflow tensorflow-decision-forests cryptography pyOpenSSL langchain langchain-core nltk ray click google-generativeai google-cloud-translate datasets cesium bigframes plotnine mlxtend fastai spacy thinc google-colab gcsfs jupyter-kernel-gateway nltk preprocessing\n",
    "    !pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n",
    "    !pip install -qU langchain-community langchain-text-splitters wikipedia lmnr[all] google-adk google-adk[eval] google-cloud-translate\n",
    "    from kaggle_secrets import UserSecretsClient # type: ignore\n",
    "    from jupyter_server.serverapp import list_running_servers # type: ignore\n",
    "else:\n",
    "    # Mock the kaggle secrets client.\n",
    "    class UserSecretsClient:\n",
    "        @classmethod\n",
    "        def set_secret(cls, id: str, value: str):\n",
    "            os.environ[id] = value\n",
    "        @classmethod\n",
    "        def get_secret(cls, id: str):\n",
    "            try:\n",
    "                return os.environ[id]\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError: authentication token for {id} is undefined\")\n",
    "    # Local Run: update the venv.\n",
    "    %pip install -qU posthog\\<6.0.0 google-genai==1.50.0 chromadb==0.6.3 opentelemetry-proto==1.37.0\n",
    "    %pip install -qU langchain-community langchain-text-splitters wikipedia pandas google-api-core \"lmnr[all]\" browser-use ollama google-adk \"google-adk[eval]\"\n",
    "    from browser_use import Agent as BrowserAgent\n",
    "\n",
    "import ast, chromadb, json, logging, pandas, platform, pytz, re, requests, sys, threading, time, warnings, wikipedia\n",
    "from bs4 import Tag\n",
    "from chromadb import Documents, Embeddings\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.parser import parse\n",
    "from enum import Enum\n",
    "from google.adk.apps.app import App\n",
    "from google.adk.sessions import InMemorySessionService, BaseSessionService as SessionService, Session\n",
    "from google.adk.runners import Runner, Event\n",
    "from google import genai\n",
    "from google.api_core import retry, exceptions\n",
    "from google.genai.models import Models\n",
    "from google.genai import types, errors\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_text_splitters.html import HTMLSemanticPreservingSplitter\n",
    "from langchain_text_splitters.json import RecursiveJsonSplitter\n",
    "from lmnr import Laminar\n",
    "from math import inf\n",
    "from pydantic import BaseModel, field_validator\n",
    "from threading import Timer\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Callable, NewType, NamedTuple\n",
    "from wikipedia.exceptions import DisambiguationError, PageError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:37:46.390238Z",
     "iopub.status.busy": "2025-12-01T09:37:46.389422Z",
     "iopub.status.idle": "2025-12-01T09:37:46.541508Z",
     "shell.execute_reply": "2025-12-01T09:37:46.540396Z",
     "shell.execute_reply.started": "2025-12-01T09:37:46.390207Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError: authentication token for LMNR_PROJECT_API_KEY is undefined\n",
      "Skipping Laminar.initialize()\n"
     ]
    }
   ],
   "source": [
    "# Prepare the Gemini api for use.\n",
    "# Setup a retry helper for generation not run through the below api-helper.\n",
    "is_retriable = lambda e: (isinstance(e, errors.APIError) and e.code in {429, 503, 500})\n",
    "Models.generate_content = retry.Retry(predicate=is_retriable)(Models.generate_content)\n",
    "Models.embed_content = retry.Retry(predicate=is_retriable)(Models.embed_content)\n",
    "\n",
    "# Activate Laminar auto-instrumentation.\n",
    "try:\n",
    "    Laminar.initialize(project_api_key=UserSecretsClient().get_secret(\"LMNR_PROJECT_API_KEY\"))\n",
    "except:\n",
    "    print(\"Skipping Laminar.initialize()\")\n",
    "\n",
    "class GeminiModel:\n",
    "    def __init__(self, rpm: list, tpm: list, rpd: list):\n",
    "        self.rpm = rpm # requests per minute\n",
    "        self.tpm = tpm # tokens per minute in millions\n",
    "        self.rpd = rpd # requests per day\n",
    "        self.err = [0,0] # validation, api_related\n",
    "\n",
    "# A python api-helper with model fail-over/chaining/retry support.\n",
    "GeminiEmbedFunction = NewType(\"GeminiEmbedFunction\", None) # forward-decl\n",
    "class Api:\n",
    "    gen_limit_in = 1048576\n",
    "    emb_limit_in = 2048\n",
    "    gen_model = {\n",
    "        \"gemini-2.5-flash\": GeminiModel([10,1000,2000,10000],[.25,1,3,8],[250,10000,100000,inf]), # stable: 10 RPM/250K TPM/250 RPD\n",
    "        \"gemini-2.5-flash-preview-09-2025\": GeminiModel([10,1000,2000,10000],[.25,1,3,8],[250,10000,100000,inf]), # exp: 10 RPM/250K TPM/250 RPD\n",
    "        \"gemini-2.0-flash-exp\": GeminiModel([10,10,10,10],[.25,.25,.25,.25],[200,500,500,500]), # latest w/thinking: 10 RPM/250K TPM/200 RPD\n",
    "        \"gemini-2.0-flash\": GeminiModel([15,2000,10000,30000],[1,4,10,30],[200,inf,inf,inf]), # stable wo/thinking: 15 RPM/1M TPM/200 RPD\n",
    "        \"gemini-2.5-flash-lite\": GeminiModel([15,4000,10000,30000],[.25,4,10,30],[1000,inf,inf,inf]), # stable: 15 RPM/250K TPM/1K RPD\n",
    "        \"gemini-2.5-flash-lite-preview-09-2025\": GeminiModel([15,4000,10000,30000],[.25,4,10,30],[1000,inf,inf,inf]), # exp: 15 RPM/250K TPM/1K RPD\n",
    "        \"gemini-2.5-pro\": GeminiModel([5,150,1000,2000],[.125,2,5,8],[100,10000,50000,inf]), # stable: 5 RPM/250K TPM/100 RPD\n",
    "    }\n",
    "    gen_local = [\"gemma3n:e4b\",\"gemma3:12b-it-qat\"]\n",
    "    default_local = 0\n",
    "    default_model = []\n",
    "    embed_model = \"gemini-embedding-001\", GeminiModel([100,3000,5000,10000],[.03,1,5,10],[1000,inf,inf,inf]) # stable: 100 RPM/30K TPM/1000 RPD/100 per batch\n",
    "    embed_local = False\n",
    "    error_total = 0\n",
    "    min_rpm = 3\n",
    "    min_tpm = 40000\n",
    "    dt_between = 2.0\n",
    "    errored = False\n",
    "    running = False\n",
    "    dt_err = 45.0\n",
    "    dt_rpm = 60.0\n",
    "\n",
    "    @classmethod\n",
    "    def get(cls, url: str):\n",
    "        # Create a header matching the OS' tcp-stack fingerprint.\n",
    "        system_ua = None\n",
    "        match platform.system():\n",
    "            case 'Linux':\n",
    "                system_ua = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'\n",
    "            case 'Darwin':\n",
    "                system_ua = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 15_7_2) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/26.0 Safari/605.1.15'\n",
    "            case 'Windows':\n",
    "                system_ua = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36'\n",
    "        try:\n",
    "            request = requests.get(url, headers={'User-Agent': system_ua})\n",
    "            if request.status_code != requests.codes.ok:\n",
    "                print(f\"Api.get() returned status {request.status_code}\")\n",
    "            return request.text\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    class Limit(Enum):\n",
    "        FREE = 0\n",
    "        TIER_1 = 1\n",
    "        TIER_2 = 2\n",
    "        TIER_3 = 3\n",
    "    \n",
    "    class Model(Enum):\n",
    "        GEN = 1\n",
    "        EMB = 2\n",
    "        LOC = 3\n",
    "\n",
    "    class Const(Enum):\n",
    "        STOP = \"I don't know.\"\n",
    "        METRIC_BATCH = 20\n",
    "        SERIES_BATCH = 40\n",
    "        EMBED_BATCH = 100\n",
    "        CHUNK_MAX = 1500\n",
    "\n",
    "        @classmethod\n",
    "        def Stop(cls):\n",
    "            return cls.STOP.value\n",
    "\n",
    "        @classmethod\n",
    "        def MetricBatch(cls):\n",
    "            return cls.METRIC_BATCH.value\n",
    "\n",
    "        @classmethod\n",
    "        def SeriesBatch(cls):\n",
    "            return cls.SERIES_BATCH.value\n",
    "\n",
    "        @classmethod\n",
    "        def EmbedBatch(cls):\n",
    "            return cls.EMBED_BATCH.value\n",
    "\n",
    "        @classmethod\n",
    "        def ChunkMax(cls):\n",
    "            return cls.CHUNK_MAX.value\n",
    "    \n",
    "    class Env(NamedTuple): # Make init args immutable.\n",
    "        CLIENT: genai.Client\n",
    "        API_LIMIT: int\n",
    "        GEN_DEFAULT: str\n",
    "\n",
    "    def __init__(self, with_limit: Limit | int, default_model: str):\n",
    "        if default_model in self.gen_model.keys():\n",
    "            self.write_lock = threading.RLock()\n",
    "            try:\n",
    "                if isinstance(with_limit, int) and with_limit in [id.value for id in Api.Limit]:\n",
    "                    limit = with_limit\n",
    "                else:\n",
    "                    limit = with_limit.value\n",
    "            except Exception as e:\n",
    "                print(f\"Api.__init__: {with_limit} is not a valid limit\")\n",
    "            else:\n",
    "                self.args = Api.Env(\n",
    "                    genai.Client(api_key=UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")),\n",
    "                    limit, default_model)\n",
    "            self.m_id = list(self.gen_model.keys()).index(default_model)\n",
    "            self.default_model.append(default_model)\n",
    "            self.update_quota()\n",
    "            self.s_embed = GeminiEmbedFunction(self.args.CLIENT, semantic_mode = True) # type: ignore\n",
    "            logging.getLogger(\"google_genai\").setLevel(logging.WARNING) # suppress info on generate\n",
    "        else:\n",
    "            print(f\"Api.__init__: {default_model} not found in gen_model.keys()\")\n",
    "        \n",
    "\n",
    "    def __call__(self, model: Model) -> str:\n",
    "        if model == self.Model.GEN:\n",
    "            return \"models/\" + list(self.gen_model.keys())[self.m_id]\n",
    "        elif model == self.Model.LOC:\n",
    "            return self.gen_local[self.default_local]\n",
    "        else:\n",
    "            return \"models/\" + self.embed_model[0] if not self.embed_local else \"embeddinggemma:latest\"\n",
    "\n",
    "    def push_default_model(self, model_id: str):\n",
    "        if model_id in self.gen_model.keys():\n",
    "            self.write_lock.acquire()\n",
    "            self.stop_running()\n",
    "            self.default_model.append(model_id)\n",
    "            self.m_id = list(self.gen_model.keys()).index(model_id)\n",
    "            self.write_lock.release()\n",
    "        else:\n",
    "            print(f\"{model_id} not found in gen_model.keys()\")\n",
    "\n",
    "    def pop_default_model(self):\n",
    "        if len(self.default_model) > 1:\n",
    "            self.write_lock.acquire()\n",
    "            self.stop_running()\n",
    "            self.default_model.pop(-1)\n",
    "            self.m_id = list(self.gen_model.keys()).index(self.default_model[-1])\n",
    "            self.write_lock.release()\n",
    "\n",
    "    def retriable(self, retry_fn: Callable, *args, **kwargs):\n",
    "        tries = 3*len(self.gen_model.keys())\n",
    "        for attempt in range(tries):\n",
    "            try:\n",
    "                self.write_lock.acquire()\n",
    "                token_use = self.token_count(kwargs[\"contents\"])\n",
    "                if self.gen_rpm > self.min_rpm and token_use <= self.token_quota and self.token_quota > self.min_tpm:\n",
    "                    self.token_quota -= token_use\n",
    "                    self.gen_rpm -= 1\n",
    "                else:\n",
    "                    self.on_error(kwargs)\n",
    "                if not self.running and not self.errored:\n",
    "                    self.rpm_timer = Timer(self.dt_rpm, self.refill_rpm)\n",
    "                    self.rpm_timer.start()\n",
    "                    self.running = True\n",
    "                return retry_fn(*args, **kwargs)\n",
    "            except (errors.APIError, exceptions.RetryError) as api_error:\n",
    "                if isinstance(api_error, errors.APIError):\n",
    "                    is_retry = api_error.code in {429, 503, 500, 400} # code 400 when TPM exceeded\n",
    "                    if api_error.code == 400:\n",
    "                        print(f\"retriable.api_error: token limit exceeded ({token_use})\")\n",
    "                    else:\n",
    "                        print(f\"retriable.api_error({api_error.code}): {str(api_error)}\")\n",
    "                    if not is_retry or attempt == tries:\n",
    "                        raise api_error\n",
    "                self.on_error(kwargs)\n",
    "            except Exception as e:\n",
    "                print(f\"retriable.exception: {str(e)}\")\n",
    "                self.on_error(kwargs)\n",
    "            finally:\n",
    "                self.write_lock.release()\n",
    "\n",
    "    def on_error(self, kwargs):\n",
    "        self.generation_fail()\n",
    "        kwargs[\"model\"] = self(Api.Model.GEN)\n",
    "        time.sleep(self.dt_between)\n",
    "\n",
    "    def stop_running(self):\n",
    "        if self.running:\n",
    "            self.rpm_timer.cancel()\n",
    "            self.running = False\n",
    "\n",
    "    def validation_fail(self):\n",
    "        list(self.gen_model.values())[self.m_id].err[0] += 1\n",
    "        self.error_total += 1\n",
    "\n",
    "    def generation_fail(self):\n",
    "        self.stop_running()\n",
    "        self.save_error()\n",
    "        self.next_model()\n",
    "        print(\"Api.generation_fail.next_model: model is now\", list(self.gen_model.keys())[self.m_id])\n",
    "        if not self.errored:\n",
    "            self.error_timer = Timer(self.dt_err, self.zero_error)\n",
    "            self.error_timer.start()\n",
    "            self.errored = True\n",
    "\n",
    "    def save_error(self):\n",
    "        list(self.gen_model.values())[self.m_id].err[1] += 1\n",
    "        self.error_total += 1\n",
    "\n",
    "    def next_model(self):\n",
    "        self.m_id = (self.m_id+1)%len(self.gen_model.keys())\n",
    "        self.update_quota()\n",
    "\n",
    "    def refill_rpm(self):\n",
    "        self.running = False\n",
    "        self.update_quota()\n",
    "        print(\"Api.refill_rpm\", self.gen_rpm)\n",
    "\n",
    "    def zero_error(self):\n",
    "        self.errored = False\n",
    "        self.m_id = list(self.gen_model.keys()).index(self.default_model[-1])\n",
    "        self.update_quota()\n",
    "        print(\"Api.zero_error: model is now\", list(self.gen_model.keys())[self.m_id])\n",
    "\n",
    "    def update_quota(self):\n",
    "        self.gen_rpm = list(self.gen_model.values())[self.m_id].rpm[self.args.API_LIMIT]\n",
    "        self.token_quota = list(self.gen_model.values())[self.m_id].tpm[self.args.API_LIMIT]*1_000_000\n",
    "\n",
    "    def token_count(self, expr: str | list):\n",
    "        count = self.args.CLIENT.models.count_tokens(\n",
    "            model=self(Api.Model.GEN),\n",
    "            contents=json.dumps(expr) if isinstance(expr, str) else str(expr))\n",
    "        return count.total_tokens\n",
    "\n",
    "    def errors(self):\n",
    "        errors = {\"total\": self.error_total, \"by_model\": {}}\n",
    "        for m_code, m in self.gen_model.items():\n",
    "            errors[\"by_model\"].update({\n",
    "                m_code: {\n",
    "                    \"api_related\": m.err[1],\n",
    "                    \"validation\": m.err[0]\n",
    "                }})\n",
    "        return errors\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def similarity(self, content: list):\n",
    "        return self.s_embed.sts(content) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:37:46.542809Z",
     "iopub.status.busy": "2025-12-01T09:37:46.5425Z",
     "iopub.status.idle": "2025-12-01T09:37:46.553753Z",
     "shell.execute_reply": "2025-12-01T09:37:46.552713Z",
     "shell.execute_reply.started": "2025-12-01T09:37:46.54278Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the embedding function.\n",
    "api = NewType(\"api\", Api) # type: ignore (forward-decl)\n",
    "class GeminiEmbedFunction:\n",
    "    document_mode = True  # Generate embeddings for documents (T,F), or queries (F,F).\n",
    "    semantic_mode = False # Semantic text similarity mode is exclusive (F,T).\n",
    "    \n",
    "    def __init__(self, genai_client, semantic_mode: bool = False):\n",
    "        self.client = genai_client\n",
    "        if semantic_mode:\n",
    "            self.document_mode = False\n",
    "            self.semantic_mode = True\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def __embed__(self, input: Documents) -> Embeddings:\n",
    "        if self.document_mode:\n",
    "            embedding_task = \"retrieval_document\"\n",
    "        elif not self.document_mode and not self.semantic_mode:\n",
    "            embedding_task = \"retrieval_query\"\n",
    "        elif not self.document_mode and self.semantic_mode:\n",
    "            embedding_task = \"semantic_similarity\"\n",
    "        partial = self.client.models.embed_content(\n",
    "            model=api(Api.Model.EMB),\n",
    "            contents=input,\n",
    "            config=types.EmbedContentConfig(task_type=embedding_task)) # type: ignore\n",
    "        return [e.values for e in partial.embeddings]\n",
    "    \n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        try:\n",
    "            response = []\n",
    "            for i in range(0, len(input), Api.Const.EmbedBatch()):  # Gemini max-batch-size is 100.\n",
    "                response += self.__embed__(input[i:i + Api.Const.EmbedBatch()])\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"caught exception of type {type(e)}\\n{e}\")\n",
    "            raise e\n",
    "\n",
    "    def sts(self, content: list) -> float:\n",
    "        df = pandas.DataFrame(self(content), index=content)\n",
    "        score = df @ df.T\n",
    "        return score.iloc[0].iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Gemini API Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:37:46.556792Z",
     "iopub.status.busy": "2025-12-01T09:37:46.555851Z",
     "iopub.status.idle": "2025-12-01T09:37:47.06721Z",
     "shell.execute_reply": "2025-12-01T09:37:47.06567Z",
     "shell.execute_reply.started": "2025-12-01T09:37:46.556752Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the api-helper with usage limit => FREE.\n",
    "# Optional: Set limit here to one of [FREE,TIER_1,TIER_2,TIER_3]\n",
    "api = Api(with_limit=Api.Limit.FREE, default_model=\"gemini-2.5-flash\")\n",
    "# Export api environment for agent.\n",
    "os.environ[\"API_LIMIT\"]=str(api.args.API_LIMIT)\n",
    "os.environ[\"GEN_DEFAULT\"]=api.args.GEN_DEFAULT\n",
    "# Cleanup old vector_db instances.\n",
    "!rm -rf vector_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __StockChat: Agents Edition__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was during Kaggle's 5-day Generative AI course in 2025 that StockChat first existed as a simple search-connected LLM. There were two observations from that initial build. First being the need for a real-time source of grounding truth. Even with google-search data was more often incomplete. The second observation, which still exists today, is the tendency toward hallucinations in finance data. Ticker symbols can imitate the name of another company, and it also possible for the LLM to confuse a company name for a wrong symbol. This happens even when the context of the question matches the immediate discussion history and should be self-evident."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "response = chat.send_message('''What is MGM Studio's stock ticker symbol?''')\n",
    "Markdown(response.text)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "... (possibly useful content, often not)\n",
    "\n",
    "It is important not to confuse MGM Studios with MGM Resorts International, which is a separate, publicly traded hospitality and casino entertainment company with the stock ticker symbol MGM on the New York Stock Exchange (NYSE).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini is naturally chatty in a helpful way and this sometimes causes it to go off-topic. The inclusion of off-topic discussion requires that all output from the LLM be checked for topic deviations. Otherwise a backing RAG may store incorrect truths. It became a trade-off between restraining gemini output, and it's usefulness, versus unrestrained with the hallucination caveat. So google-search was not the solution, and actually it was kind-of off-putting as a source of finance chat. Thus StockChat transformed into a huge monolithic agent with access to multiple finance api's, and wikipedia/search to back it up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "send_message(\"What is MGM Studio's stock symbol?\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "MGM Studios (Metro-Goldwyn-Mayer Studios, Inc.) is a wholly-owned subsidiary of Amazon and is not publicly traded, so it does not have its own stock symbol.\n",
    "\n",
    "The stock symbol for its parent company, Amazon, is AMZN.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While big and capable, StockChat (SC1) became limited by it's single agent design.\n",
    "- There's no parallelism or asynchronous operation because parallel function calling is agent-wide. Some of the functions may have unmet dependencies when run parallel (by an LLM). In other cases the degree of parallelism is determined by whether you have paid for finance api access. As I'm building a toy I wanted to keep free-tier as an option. Effectively SC1 is a big LLM-guided loop with serial operations, and a single rest api request at a time. It makes SC1 stable at the cost of performance.\n",
    "- The lack of context management means it can handle months worth of pre-scored news data. As a synchronous operation.\n",
    "- There's a single vector store with all acquired data, requiring metadata management to compensate.\n",
    "- It has no facility to determine user interest. It's a giant cache of previously searched finance data.\n",
    "- It has no systematic evaluation except to run baseline queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these issues in mind my goal during Kaggle's 5-day Agents course was to apply Google's agentic framework to free SC1 from these limitations.\n",
    "- SC2 uses async runners while maintaining some minimal thread synchronization on shared data.\n",
    "- LLM-assisted context compaction runs at regular intervals.\n",
    "- All the sub-tools have their own vector stores.\n",
    "- A memory tool stores long-term memories with semantic meaning preserved, and tagged with date of creation.\n",
    "- A user profile expert is added to extract user attributes for long-term memory.\n",
    "- Session state keys are used to pass user interest along to other agents.\n",
    "- The ADK CLI is used to run an evaluation suite with LLM-as-judge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Kaggle the working directory for ADK runner's differs from notebook location. To work around this I use git with spare-checkout to pull in SC2's updated source. Then I setup the Kaggle runner environment and define the async runner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup working directory on Kaggle.\n",
    "if os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
    "    if not os.path.isdir(\"sc2/\"):\n",
    "        !git init -b main\n",
    "        !git remote add origin https://github.com/lol-dungeonmaster/kaggle-agents-2025.git\n",
    "        !git config core.sparseCheckout true\n",
    "        !echo \"sc2/\" >> .git/info/sparse-checkout\n",
    "        !git pull origin main\n",
    "        for api_key in [\"GOOGLE_API_KEY\",\"POLYGON_API_KEY\",\"FINNHUB_API_KEY\"]:\n",
    "            env_key = UserSecretsClient().get_secret(api_key)\n",
    "            !echo \"$api_key=$env_key\" >> sc2/.env # from .venv on local runs\n",
    "            os.environ[api_key] = UserSecretsClient().get_secret(api_key) # from .venv on local runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  [root] KeyError: authentication token for LMNR_PROJECT_API_KEY is undefined\n",
      "INFO     [root] Skipping Laminar.initialize()\n",
      "INFO     [root] sc2.__init__: the api-helper is ready\n",
      "Generate document embedding:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generate document embedding: 100%|##########| 1/1 [00:03<00:00,  3.99s/it]\n",
      "Generate document embedding: 100%|##########| 1/1 [00:04<00:00,  4.13s/it]\n",
      "INFO     [root] sc2.__init__: RestGroundingTool is ready\n",
      "INFO     [root] sc2.__init__: SearchGroundingTool is ready\n",
      "INFO     [root] sc2.__init__: WikiGroundingTool is ready\n",
      "INFO     [root] sc2.__init__: MemoryService is ready\n",
      "WARNING  [root] [EXPERIMENTAL] ReflectAndRetryToolPlugin: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  plugins=[ReflectAndRetryToolPlugin(max_retries=1)],\n",
      "WARNING  [root] [EXPERIMENTAL] EventsCompactionConfig: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  events_compaction_config=EventsCompactionConfig(\n"
     ]
    }
   ],
   "source": [
    "# Define async runner and helper functions.\n",
    "from sc2.agent import app\n",
    "from sc2.src import log\n",
    "# Logger access not possible on Kaggle to prevent hiding errors.\n",
    "# - The StderrToLog wrapper will not work as kaggle-docker makes the file-descriptor constant.\n",
    "# - Redirect basic logger output on Kaggle using print().\n",
    "if os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
    "    log_info = print\n",
    "    log_warn = print\n",
    "    log_err = print\n",
    "else:\n",
    "    log_info = log.info\n",
    "    log_warn = log.warning\n",
    "    log_err = log.error\n",
    "\n",
    "# Display the user query and response after the response is complete.\n",
    "async def on_event(e: Event, q: str):\n",
    "    try:\n",
    "        response = e.content.parts[0].text\n",
    "        if response and response != \"None\":\n",
    "            log_info(f\"USER  > {q}\")\n",
    "            log_info(f\"MODEL > {response}\\n\")\n",
    "    except Exception as err:\n",
    "        log_err(f\"on_event.exception: {str(err)}\")\n",
    "\n",
    "# Run an App with the provided BaseSessionService and user queries list.\n",
    "async def run_queries(app: App, sessions: SessionService, queries: list[str],\n",
    "                      session_id: str = \"default\", user_id: str = \"default\"):\n",
    "    runner = Runner(app=app, session_service=sessions)\n",
    "    try:\n",
    "        session = await sessions.create_session(\n",
    "            app_name=runner.app_name, user_id=user_id, session_id=session_id\n",
    "        )\n",
    "    except:\n",
    "        session = await sessions.get_session(\n",
    "            app_name=runner.app_name, user_id=user_id, session_id=session_id\n",
    "        )\n",
    "    finally:\n",
    "        log_info(f\"### Agent session: (uid={user_id}) {session_id}\\n\")\n",
    "        for query in queries:\n",
    "            await try_run(runner, session, user_id, query)\n",
    "\n",
    "# Launch a runner with the provided session and user_id then respond to query.\n",
    "# - retries on exceptions TypeError, KeyError, IndexError\n",
    "async def try_run(runner: Runner, session: Session, user_id: str, query: str):\n",
    "    try:\n",
    "        q = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "        async for response in runner.run_async(\n",
    "            user_id=user_id, session_id=session.id, new_message=q\n",
    "        ): await on_event(response, query)\n",
    "    except Exception as e:\n",
    "        q_id = \" \".join(query.split()[:4])\n",
    "        if type(e) in [TypeError, KeyError, IndexError]:\n",
    "            log_warn(f\"try_run.run_async (q={q_id}): retrying, generated {type(e).__name__}\\n\")\n",
    "            time.sleep(15.0)\n",
    "            await try_run(runner, session, user_id, query)\n",
    "        else:\n",
    "            log_warn(f\"try_run.run_async (q={q_id}): {type(e).__name__} - {str(e)}\\n\")\n",
    "\n",
    "# Check for compaction events in the provided BaseSessionService.\n",
    "# - optionally also show the llm compacted output.\n",
    "async def check_compaction(sessions: SessionService, session_id: str = \"default\", \n",
    "                           user_id: str = \"default\", show_llm: bool = False):\n",
    "    n = 0\n",
    "    for e in (await sessions.get_session(\n",
    "        app_name=app.name,\n",
    "        user_id=user_id,\n",
    "        session_id=session_id,\n",
    "    )).events:\n",
    "        if e.actions and (llm_out := e.actions.compaction):\n",
    "            n += 1\n",
    "            if show_llm:\n",
    "                log_info(f\"check_compaction.show_llm: {llm_out.compacted_content.parts[0].text}\\n\")\n",
    "    log_info(f\"check_compaction: found ({n}) compaction event\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Runner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial two-questions are used to test the agents self-awareness of tools. This was particularly problematic for the parallel `fncall_pipeline`. The goal is to have a parallel operating planner and executor of function calls. The function tool definition are tricky to access reliably when nested inside workflow agents like the ParallelAgent. In the end I exposed the planner and it's containing pipeline, then told Gemini where to look.\n",
    "\n",
    "My goal is ultimately to make SC2 a more capable assistant in addition to removing existing limits. To that end I also added a Terminology expert to make use of the built-in google-search. Meanwhile a user profile expert dynamically extracts preferences and user attributes. These two types of data are stored in long-term memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [root] ### Agent session: (uid=default) default\n",
      "\n",
      "INFO     [root] USER  > What tools do you know how to use?\n",
      "INFO     [root] MODEL > I can use the following tools:\n",
      "\n",
      "*   `sc2_memory`: An expert writer of long-term memories.\n",
      "*   `sc2_prefs`: An expert profile analyst in the field of finance, money, and stock markets.\n",
      "*   `fncall_pipeline`: A function caller with functions defined in sub-agent `sc2_fnplan`.\n",
      "*   `sc2_fnplan`: A highly intelligent FunctionTool call planner.\n",
      "*   `sc2_terms`: An expert terminologist in the field of finance, money, and stock markets.\n",
      "*   `sc2_summary`: An expert proof-reader and writer that knows HTML, JSON and Markdown.\n",
      "\n",
      "INFO     [root] USER  > Tell me what functions `fncall_pipeline` knows by checking `sc2_fnplan`.\n",
      "INFO     [root] MODEL > `fncall_pipeline` knows the following functions:\n",
      "\n",
      "*   `get_symbol_1`\n",
      "*   `get_symbols_1`\n",
      "*   `get_name_1`\n",
      "*   `get_symbol_quote_1`\n",
      "*   `get_market_status_1`\n",
      "*   `get_market_session_1`\n",
      "*   `get_company_peers_1`\n",
      "*   `get_local_datetime`\n",
      "*   `get_last_market_close`\n",
      "*   `get_exchange_codes_1`\n",
      "*   `get_exchange_code_1`\n",
      "*   `get_financials_1`\n",
      "*   `get_daily_candlestick_2`\n",
      "*   `get_custom_candlestick_2`\n",
      "*   `get_ticker_overview_2`\n",
      "*   `get_recommendation_trends_1`\n",
      "*   `get_news_with_sentiment_2`\n",
      "*   `get_wiki_grounding`\n",
      "*   `get_search_grounding`\n",
      "\n",
      "Generate memory embedding (Short Trade):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generate memory embedding (Short Trade): 100%|##########| 1/1 [00:00<00:00,  1.47it/s]\n",
      "Generate memory embedding (Short Trade): 100%|##########| 1/1 [00:00<00:00,  1.40it/s]\n",
      "INFO     [root] USER  > What is a short trade?\n",
      "INFO     [root] MODEL > A short trade, also known as short selling, is a speculative strategy where an investor sells borrowed securities with the expectation of repurchasing them at a lower price. The objective is to profit from a decrease in the security's price. If the price declines, the investor can buy the shares at a reduced cost, return them to the lender, and gain the difference. Conversely, if the price increases, the investor must buy them back at a higher price, resulting in a loss.\n",
      "\n",
      "Generate memory embedding (Gambler's ruin):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generate memory embedding (Gambler's ruin): 100%|##########| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Generate memory embedding (Gambler's ruin): 100%|##########| 1/1 [00:00<00:00,  1.20it/s]\n",
      "INFO     [root] USER  > What is gambler's ruin?\n",
      "INFO     [root] MODEL > Gambler's Ruin\n",
      "\n",
      "Gambler's ruin is a concept within probability theory. It posits that a gambler possessing a finite sum of money, engaging in a game against an opponent with an effectively infinite amount of money, will inevitably deplete their entire funds. This outcome holds true regardless of whether the game is fair or if the odds are even slightly in the gambler's favor.\n",
      "\n",
      "\n",
      "Generate memory embedding (local advisor):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generate memory embedding (local advisor): 100%|##########| 1/1 [00:00<00:00,  1.82it/s]\n",
      "Generate memory embedding (local advisor): 100%|##########| 1/1 [00:00<00:00,  1.72it/s]\n",
      "INFO     [root] USER  > My local advisor is SC at JPMorgan Chase, 212-736-2001\n",
      "INFO     [root] MODEL > I've noted that your local advisor is SC at JPMorgan Chase, phone number 212-736-2001.\n",
      "\n",
      "Generate memory embedding (User's residence):   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generate memory embedding (User's residence): 100%|##########| 1/1 [00:01<00:00,  1.62s/it]\n",
      "Generate memory embedding (User's residence): 100%|##########| 1/1 [00:01<00:00,  1.65s/it]\n",
      "INFO     [root] USER  > I live in Brooklyn, New York.\n",
      "INFO     [root] MODEL > Okay, I've noted that you live in Brooklyn, New York.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a session service and run some test queries.\n",
    "s_svc = InMemorySessionService()\n",
    "\n",
    "await run_queries(\n",
    "    app=app, sessions=s_svc,\n",
    "    queries=[\n",
    "        \"What tools do you know how to use?\",\n",
    "        \"Tell me what functions `fncall_pipeline` knows by checking `sc2_fnplan`.\",\n",
    "        \"What is a short trade?\",\n",
    "        \"What is gambler's ruin?\",\n",
    "        \"My local advisor is SC at JPMorgan Chase, 212-736-2001\",\n",
    "        \"I live in Brooklyn, New York.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Long-term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing long-term memory is as easy as creating a new `BaseSessionService`. As this Memory is a custom implementation it must be specified as a tool during user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [root] ### Agent session: (uid=default) default\n",
      "\n",
      "INFO     [root] Api.refill_rpm 10\n",
      "INFO     [root] USER  > Check memory for where I live.\n",
      "INFO     [root] MODEL > You live in Brooklyn, New York.\n",
      "\n",
      "INFO     [root] USER  > Check memory for my local advisor SCs phone number.\n",
      "INFO     [root] MODEL > SC's phone number is 212-736-2001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use long-term memory from a new session.\n",
    "s_svc2 = InMemorySessionService()\n",
    "\n",
    "await run_queries(\n",
    "    app=app, sessions=s_svc2,\n",
    "    queries=[\n",
    "        \"Check memory for where I live.\",\n",
    "        \"Check memory for my local advisor SCs phone number.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for compaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the features of SC2 that I'm looking forward to working with more is the LLM-assisted context compaction. In this implementation I've opted for zero-overlap to avoid re-summarizing past events. At this point no events are dropped from the context. The LLM is known to become confused with statement repetition, so let's avoid that complication. A delightful feature of LLM-compaction is the use of an LLM-as-judge to assess the summary quality with impartiality. It'll note neat things for you like when the tools fail completely or when parts of a user query remain unanswered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO     [root] check_compaction.show_llm: The user initiated the conversation by asking about the AI's available tools. The AI listed its tools, including `sc2_memory`, `sc2_prefs`, `fncall_pipeline`, `sc2_fnplan`, `sc2_terms`, and `sc2_summary`, along with their brief descriptions.\n",
      "\n",
      "Next, the user asked the AI to specify the functions available through `fncall_pipeline` by checking `sc2_fnplan`. The AI responded by listing 20 specific functions, predominantly related to financial data retrieval (e.g., `get_symbol_1`, `get_market_status_1`, `get_financials_1`, `get_news_with_sentiment_2`).\n",
      "\n",
      "Finally, the user asked for a definition of \"short trade.\" The AI provided a clear explanation, describing it as a speculative strategy where an investor sells borrowed securities with the expectation of repurchasing them at a lower price to profit from a price decrease.\n",
      "\n",
      "**Key information and decisions made:**\n",
      "*   The AI disclosed its capabilities in terms of tools and specific functions.\n",
      "*   The AI provided a detailed definition of a financial term requested by the user.\n",
      "\n",
      "**Unresolved questions or tasks:**\n",
      "*   There are no explicit unresolved questions or tasks at the end of this conversation segment.\n",
      "\n",
      "INFO     [root] check_compaction.show_llm: The conversation began with the user asking for a definition of \"gambler's ruin,\" which the AI successfully provided. Subsequently, the user volunteered two pieces of personal information: their local advisor (SC at JPMorgan Chase, 212-736-2001) and their residence (Brooklyn, New York). The AI acknowledged and noted both details.\n",
      "\n",
      "**Key Information & Decisions:**\n",
      "*   **Definition Provided:** The AI explained \"gambler's ruin.\"\n",
      "*   **Advisor Details Noted:** The AI recorded the user's advisor (SC, JPMorgan Chase, 212-736-2001).\n",
      "*   **Residence Noted:** The AI recorded the user's residence (Brooklyn, New York).\n",
      "\n",
      "**Unresolved Questions or Tasks:**\n",
      "There are no unresolved questions or tasks in this segment of the conversation.\n",
      "\n",
      "INFO     [root] check_compaction: found (2) compaction event\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display context compaction output.\n",
    "await check_compaction(s_svc, show_llm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation by CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SC1 evaluation didn't happen systematically. As you can see from the appendix evaluation consists of manually checking the model output, or baseline. In leveraging the ADK CLI, SC2 gains an LLM-as-judge to systematically evaluate assistant output. A rubric is applied to check response quality and related tool use. Then a hallucination test is performed to ensure the agent has stayed on-topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sysop/Documents/kaggle-agents-2025/.venv/lib/python3.12/site-packages/google/adk/evaluation/metric_evaluator_registry.py:90: UserWarning: [EXPERIMENTAL] MetricEvaluatorRegistry: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  metric_evaluator_registry = MetricEvaluatorRegistry()\n",
      "/home/sysop/Documents/kaggle-agents-2025/.venv/lib/python3.12/site-packages/google/adk/evaluation/local_eval_service.py:80: UserWarning: [EXPERIMENTAL] UserSimulatorProvider: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  user_simulator_provider: UserSimulatorProvider = UserSimulatorProvider(),\n",
      "Using evaluation criteria: criteria={'rubric_based_final_response_quality_v1': BaseCriterion(threshold=0.8, judge_model_options={'judge_model': 'gemini-2.5-flash', 'num_samples': 1}, rubrics=[{'rubric_id': 'conciseness', 'rubric_content': {'text_property': \"The agent's response is direct and to the point.\"}}, {'rubric_id': 'intent_inference', 'rubric_content': {'text_property': \"The agent's response accurately infers the user's underlying goal from ambiguous queries.\"}}]), 'rubric_based_tool_use_quality_v1': BaseCriterion(threshold=1.0, judge_model_options={'judge_model': 'gemini-2.5-flash', 'num_samples': 1}, rubrics=[{'rubric_id': 'prefs_called', 'rubric_content': {'text_property': 'The agent calls `sc2_prefs` to store profile data when required.'}}, {'rubric_id': 'memory_called_before', 'rubric_content': {'text_property': 'The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`.'}}, {'rubric_id': 'memory_called_after', 'rubric_content': {'text_property': 'The agent calls `sc2_memory` after `sc2_terms` only for new memories.'}}, {'rubric_id': 'summary_called', 'rubric_content': {'text_property': 'The agent calls `sc2_summary` last when used.'}}, {'rubric_id': 'workflow_bypass', 'rubric_content': {'text_property': 'The agent can bypass the workflow for usage related questions.'}}]), 'hallucinations_v1': BaseCriterion(threshold=0.8, judge_model_options={'judge_model': 'gemini-2.5-flash'}, evaluate_intermediate_nl_responses=True)} user_simulator_config=None\n",
      "2025-12-01 06:49:13,997 - WARNING - secret.py:13 - KeyError: authentication token for LMNR_PROJECT_API_KEY is undefined\n",
      "2025-12-01 06:49:13,998 - INFO - __init__.py:54 - Skipping Laminar.initialize()\n",
      "2025-12-01 06:49:14,229 - INFO - __init__.py:64 - sc2.__init__: the api-helper is ready\n",
      "Generate document embedding:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Generate document embedding: 100%|##########| 1/1 [00:03<00:00,  3.71s/it]\n",
      "Generate document embedding: 100%|##########| 1/1 [00:03<00:00,  3.80s/it]\n",
      "2025-12-01 06:49:18,839 - INFO - __init__.py:72 - sc2.__init__: RestGroundingTool is ready\n",
      "2025-12-01 06:49:18,840 - INFO - __init__.py:74 - sc2.__init__: SearchGroundingTool is ready\n",
      "2025-12-01 06:49:18,841 - INFO - __init__.py:76 - sc2.__init__: WikiGroundingTool is ready\n",
      "2025-12-01 06:49:18,842 - INFO - __init__.py:78 - sc2.__init__: MemoryService is ready\n",
      "2025-12-01 06:49:18,890 - WARNING - __init__.py:26 - [EXPERIMENTAL] ReflectAndRetryToolPlugin: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  plugins=[ReflectAndRetryToolPlugin(max_retries=1)],\n",
      "2025-12-01 06:49:18,939 - WARNING - __init__.py:26 - [EXPERIMENTAL] EventsCompactionConfig: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  events_compaction_config=EventsCompactionConfig(\n",
      "2025-12-01 06:49:18,939 - WARNING - __init__.py:26 - [EXPERIMENTAL] UserSimulatorProvider: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  user_simulator_provider = UserSimulatorProvider(\n",
      "2025-12-01 06:49:18,940 - WARNING - __init__.py:26 - [EXPERIMENTAL] LocalEvalService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  eval_service = LocalEvalService(\n",
      "2025-12-01 06:49:18,941 - WARNING - __init__.py:26 - [EXPERIMENTAL] StaticUserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  return StaticUserSimulator(static_conversation=eval_case.conversation)\n",
      "2025-12-01 06:49:18,942 - WARNING - __init__.py:26 - [EXPERIMENTAL] UserSimulator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n",
      "2025-12-01 06:49:20,706 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:20,804 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:21,234 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:21,335 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:22,239 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:22,288 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:23,182 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:25,574 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:25,576 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:25,577 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:36,695 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:38,488 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:39,862 - WARNING - types.py:6334 - Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "2025-12-01 06:49:46,575 - WARNING - __init__.py:26 - [EXPERIMENTAL] RubricBasedFinalResponseQualityV1Evaluator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  return self._registry[eval_metric.metric_name][0](eval_metric=eval_metric)\n",
      "2025-12-01 06:49:46,577 - WARNING - __init__.py:26 - [EXPERIMENTAL] RubricBasedEvaluator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n",
      "2025-12-01 06:49:46,580 - WARNING - __init__.py:26 - [EXPERIMENTAL] LlmAsJudge: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n",
      "2025-12-01 06:49:51,285 - WARNING - __init__.py:26 - [EXPERIMENTAL] RubricBasedToolUseV1Evaluator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  return self._registry[eval_metric.metric_name][0](eval_metric=eval_metric)\n",
      "2025-12-01 06:49:51,288 - WARNING - __init__.py:26 - [EXPERIMENTAL] RubricBasedEvaluator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n",
      "INFO     [root] Api.refill_rpm 10\n",
      "2025-12-01 06:50:07,623 - WARNING - __init__.py:26 - [EXPERIMENTAL] HallucinationsV1Evaluator: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  return self._registry[eval_metric.metric_name][0](eval_metric=eval_metric)\n",
      "2025-12-01 06:50:16,247 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /home/sysop/Documents/kaggle-agents-2025/sc2/.adk/eval_history/sc2_sc2_eval_suite_1764589816.2472925.evalset_result.json\n",
      "2025-12-01 06:50:18,639 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /home/sysop/Documents/kaggle-agents-2025/sc2/.adk/eval_history/sc2_sc2_eval_suite_1764589818.6387215.evalset_result.json\n",
      "2025-12-01 06:50:20,395 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /home/sysop/Documents/kaggle-agents-2025/sc2/.adk/eval_history/sc2_sc2_eval_suite_1764589820.395301.evalset_result.json\n",
      "2025-12-01 06:50:24,276 - INFO - api.py:225 - Api.refill_rpm 10\n",
      "2025-12-01 06:50:29,980 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /home/sysop/Documents/kaggle-agents-2025/sc2/.adk/eval_history/sc2_sc2_eval_suite_1764589829.9797585.evalset_result.json\n",
      "2025-12-01 06:50:39,274 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /home/sysop/Documents/kaggle-agents-2025/sc2/.adk/eval_history/sc2_sc2_eval_suite_1764589839.2740445.evalset_result.json\n",
      "2025-12-01 06:50:40,440 - INFO - local_eval_set_results_manager.py:62 - Writing eval result to file: /home/sysop/Documents/kaggle-agents-2025/sc2/.adk/eval_history/sc2_sc2_eval_suite_1764589840.4402955.evalset_result.json\n",
      "*********************************************************************\n",
      "Eval Run Summary\n",
      "sc2_eval_suite:\n",
      "  Tests passed: 6\n",
      "  Tests failed: 0\n",
      "********************************************************************\n",
      "Eval Set Id: sc2_eval_suite\n",
      "Eval Id: create_memory_2\n",
      "Overall Eval Status: PASSED\n",
      "---------------------------------------------------------------------\n",
      "Metric: rubric_based_final_response_quality_v1, Status: PASSED, Score: 1.0, Threshold: 0.8\n",
      "Rubric Scores:\n",
      "Rubric: The agent's response is direct and to the point., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent's response accurately infers the user's underlying goal from ambiguous queries., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "---------------------------------------------------------------------\n",
      "Metric: rubric_based_tool_use_quality_v1, Status: PASSED, Score: 1.0, Threshold: 1.0\n",
      "Rubric Scores:\n",
      "Rubric: The agent calls `sc2_prefs` to store profile data when required., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_memory` after `sc2_terms` only for new memories., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_summary` last when used., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent can bypass the workflow for usage related questions., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "---------------------------------------------------------------------\n",
      "Metric: hallucinations_v1, Status: PASSED, Score: 1.0, Threshold: 0.8\n",
      "---------------------------------------------------------------------\n",
      "Invocation Details:\n",
      "+----+-------------------------+------------------------+---------------------------+-----------------------+---------------------------+------------------------------------------+------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------+------------------------+\n",
      "|    | prompt                  | expected_response      | actual_response           | expected_tool_calls   | actual_tool_calls         | rubric_based_final_response_quality_v1   | Rubric: The agent's response is direct and to the point.   | Rubric: The agent's response accurately infers the user's underlying goal from ambiguous queries.   | rubric_based_tool_use_quality_v1   | Rubric: The agent calls `sc2_prefs` to store profile data when required.   | Rubric: The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`.   | Rubric: The agent calls `sc2_memory` after `sc2_terms` only for new memories.   | Rubric: The agent calls `sc2_summary` last when used.   | Rubric: The agent can bypass the workflow for usage related questions.   | hallucinations_v1      |\n",
      "+====+=========================+========================+===========================+=======================+===========================+==========================================+============================================================+=====================================================================================================+====================================+============================================================================+=================================================================================+=================================================================================+=========================================================+==========================================================================+========================+\n",
      "|  0 | I live in Brooklyn, New | I have saved where you | It's great to know that   |                       | id='adk-0a21d28d-e189-43f | Status: PASSED, Score:                   | Reasoning: The final                                       | Reasoning: The user's                                                                               | Status: PASSED, Score:             | Reasoning: The user                                                        | Reasoning: The agent did                                                        | Reasoning: The agent did                                                        | Reasoning: The agent did                                | Reasoning: The user's                                                    | Status: PASSED, Score: |\n",
      "|    | York.                   | live in memory.        | you live in Brooklyn, New |                       | 9-a917- 179ac463535c'     | 1.0                                      | answer directly addresses                                  | query \"I live in                                                                                    | 1.0                                | provided profile                                                           | not call `sc2_memory`,                                                          | not call `sc2_memory` or                                                        | not call `sc2_summary` in                               | prompt (\"I live in                                                       | 1.0                    |\n",
      "|    |                         |                        | York! I've saved this     |                       | args={'request': 'The     |                                          | the user's input by                                        | Brooklyn, New York\" is a                                                                            |                                    | information (\"I live in                                                    | `sc2_terms`, or                                                                 | `sc2_terms` in its                                                              | its response., Score: 1.0                               | Brooklyn, New York\") is                                                  |                        |\n",
      "|    |                         |                        | information to your       |                       | user lives in Brooklyn,   |                                          | acknowledging the                                          | direct statement of fact                                                                            |                                    | Brooklyn, New York\"), and                                                  | `fncall_pipeline` in its                                                        | response, so the                                                                |                                                         | not a usage- related                                                     |                        |\n",
      "|    |                         |                        | profile. If you have any  |                       | New York.'}               |                                          | information, stating it                                    | and is not ambiguous. The                                                                           |                                    | the agent correctly used                                                   | response, so the                                                                | condition for this                                                              |                                                         | question. Therefore, this                                                |                        |\n",
      "|    |                         |                        | questions about finance,  |                       | name='sc2_prefs'          |                                          | has been saved, and                                        | agent correctly                                                                                     |                                    | the `sc2_prefs` tool to                                                    | condition for this                                                              | ordering property was not                                                       |                                                         | property is not                                                          |                        |\n",
      "|    |                         |                        | money, or the stock       |                       |                           |                                          | offering further                                           | identified this as                                                                                  |                                    | process and store this                                                     | ordering property was not                                                       | met., Score: 1.0                                                                |                                                         | applicable to the current                                                |                        |\n",
      "|    |                         |                        | market, feel free to ask. |                       |                           |                                          | assistance, without any                                    | \"profile data\" as per the                                                                           |                                    | information, as indicated                                                  | met., Score: 1.0                                                                |                                                                                 |                                                         | interaction., Score: 1.0                                                 |                        |\n",
      "|    |                         |                        |                           |                       |                           |                                          | unnecessary information                                    | developer instructions                                                                              |                                    | by the tool call                                                           |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                         |                        |                           |                       |                           |                                          | or digression. This is a                                   | and used the appropriate                                                                            |                                    | `sc2_prefs(request='The                                                    |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                         |                        |                           |                       |                           |                                          | direct and appropriate                                     | `sc2_prefs` tool to store                                                                           |                                    | user lives in Brooklyn,                                                    |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                         |                        |                           |                       |                           |                                          | response given the user's                                  | it, successfully                                                                                    |                                    | New York.')` and the                                                       |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                         |                        |                           |                       |                           |                                          | statement., Score: 1.0                                     | fulfilling the implicit                                                                             |                                    | tool's description as a                                                    |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                         |                        |                           |                       |                           |                                          |                                                            | goal of saving this                                                                                 |                                    | profile analyst., Score:                                                   |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                         |                        |                           |                       |                           |                                          |                                                            | information., Score: 1.0                                                                            |                                    | 1.0                                                                        |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "+----+-------------------------+------------------------+---------------------------+-----------------------+---------------------------+------------------------------------------+------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------+------------------------+\n",
      "\n",
      "\n",
      "\n",
      "********************************************************************\n",
      "Eval Set Id: sc2_eval_suite\n",
      "Eval Id: term_discovery_1\n",
      "Overall Eval Status: PASSED\n",
      "---------------------------------------------------------------------\n",
      "Metric: rubric_based_final_response_quality_v1, Status: PASSED, Score: 1.0, Threshold: 0.8\n",
      "Rubric Scores:\n",
      "Rubric: The agent's response is direct and to the point., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent's response accurately infers the user's underlying goal from ambiguous queries., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "---------------------------------------------------------------------\n",
      "Metric: rubric_based_tool_use_quality_v1, Status: PASSED, Score: 1.0, Threshold: 1.0\n",
      "Rubric Scores:\n",
      "Rubric: The agent calls `sc2_prefs` to store profile data when required., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_memory` after `sc2_terms` only for new memories., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_summary` last when used., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent can bypass the workflow for usage related questions., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "---------------------------------------------------------------------\n",
      "Metric: hallucinations_v1, Status: PASSED, Score: 1.0, Threshold: 0.8\n",
      "---------------------------------------------------------------------\n",
      "Invocation Details:\n",
      "+----+------------------------+---------------------------+---------------------------+-----------------------+---------------------------+------------------------------------------+------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------+------------------------+\n",
      "|    | prompt                 | expected_response         | actual_response           | expected_tool_calls   | actual_tool_calls         | rubric_based_final_response_quality_v1   | Rubric: The agent's response is direct and to the point.   | Rubric: The agent's response accurately infers the user's underlying goal from ambiguous queries.   | rubric_based_tool_use_quality_v1   | Rubric: The agent calls `sc2_prefs` to store profile data when required.   | Rubric: The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`.   | Rubric: The agent calls `sc2_memory` after `sc2_terms` only for new memories.   | Rubric: The agent calls `sc2_summary` last when used.   | Rubric: The agent can bypass the workflow for usage related questions.   | hallucinations_v1      |\n",
      "+====+========================+===========================+===========================+=======================+===========================+==========================================+============================================================+=====================================================================================================+====================================+============================================================================+=================================================================================+=================================================================================+=========================================================+==========================================================================+========================+\n",
      "|  0 | What is a short trade? | A short trade, also known | A short trade, also known |                       | id='adk-06b2c5a6-06c7-47e | Status: PASSED, Score:                   | Reasoning: The user asked                                  | Reasoning: The user's                                                                               | Status: PASSED, Score:             | Reasoning: The agent did                                                   | Reasoning: The agent                                                            | Reasoning: The tool                                                             | Reasoning: `sc2_summary`                                | Reasoning: The user                                                      | Status: PASSED, Score: |\n",
      "|    |                        | as short- selling or      | as short selling or       |                       | 6-8d26- f53c99aec3f9'     | 1.0                                      | for a definition of a                                      | query \"What is a short                                                                              | 1.0                                | not call `sc2_prefs`. The                                                  | called `sc2_memory` at                                                          | `sc2_terms` was not                                                             | was called at step 1,                                   | prompt \"What is a short                                                  | 1.0                    |\n",
      "|    |                        | going-short is an         | shorting, is a            |                       | args={'request': 'What is |                                          | \"short trade.\" The                                         | trade?\" is a direct and                                                                             |                                    | user's prompt, \"What is a                                                  | step 0. Neither                                                                 | called in the response.                                                         | which is the last step in                               | trade?\" is not a usage-                                                  |                        |\n",
      "|    |                        | investment strategy where | speculative trading       |                       | a short trade?'}          |                                          | agent's final answer                                       | unambiguous question                                                                                |                                    | short trade?\", is a                                                        | `sc2_terms` nor                                                                 | Therefore, the condition                                                        | the sequence of tool                                    | related question. The                                                    |                        |\n",
      "|    |                        | an investor anticipates a | strategy. In this         |                       | name='sc2_memory' id='a d |                                          | directly provides this                                     | asking for a definition.                                                                            |                                    | request for information                                                    | `fncall_pipeline` were                                                          | of `sc2_memory` being                                                           | calls (the only other                                   | agent correctly did not                                                  |                        |\n",
      "|    |                        | decline in the price of   | strategy, an investor     |                       | k-5ad53614-23dc-46a6-820c |                                          | definition without any                                     | Therefore, the condition                                                                            |                                    | and does not require                                                       | called in the response,                                                         | called *after*                                                                  | call was `sc2_memory` at                                | bypass the workflow,                                                     |                        |\n",
      "|    |                        | an asset, typically a     | sells borrowed securities |                       | -3210edbb95e1'            |                                          | extraneous information,                                    | for this property to be                                                                             |                                    | storing profile data.                                                      | thus `sc2_memory`                                                               | `sc2_terms` is not                                                              | step 0)., Score: 1.0                                    | using `sc2_memory` and                                                   |                        |\n",
      "|    |                        | stock.                    | with the expectation of   |                       | args={'request': \"A short |                                          | conversational filler, or                                  | applicable (an ambiguous                                                                            |                                    | Therefore, the tool was                                                    | implicitly occurs before                                                        | applicable., Score: 1.0                                                         |                                                         | `sc2_summary` to provide                                                 |                        |\n",
      "|    |                        |                           | buying them back later at |                       | trade, also known as      |                                          | unnecessary preamble. The                                  | query) is not met.,                                                                                 |                                    | not required and                                                           | them., Score: 1.0                                                               |                                                                                 |                                                         | an answer, which aligns                                                  |                        |\n",
      "|    |                        |                           | a lower price, aiming to  |                       | short selling or          |                                          | information provided is                                    | Score: 1.0                                                                                          |                                    | correctly not called.,                                                     |                                                                                 |                                                                                 |                                                         | with the property's                                                      |                        |\n",
      "|    |                        |                           | profit from a decline in  |                       | shorting, is a            |                                          | relevant and concise.,                                     |                                                                                                     |                                    | Score: 1.0                                                                 |                                                                                 |                                                                                 |                                                         | implication that it *can*                                                |                        |\n",
      "|    |                        |                           | the security's price. If  |                       | speculative trading       |                                          | Score: 1.0                                                 |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         | bypass for usage                                                         |                        |\n",
      "|    |                        |                           | the price of the security |                       | strategy where an         |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         | questions, but                                                           |                        |\n",
      "|    |                        |                           | falls, the investor buys  |                       | investor sells borrowed   |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         | *shouldn't* for others.,                                                 |                        |\n",
      "|    |                        |                           | the shares back at a      |                       | securities with the       |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         | Score: 1.0                                                               |                        |\n",
      "|    |                        |                           | lower price, returns them |                       | expectation of buying     |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           | to the lender, and keeps  |                       | them back later at a      |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           | the difference as profit. |                       | lower price. The goal is  |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           | However, if the price of  |                       | to profit from a decline  |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           | the security rises, the   |                       | in the security's price.  |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           | investor must buy them    |                       | If the price falls, the   |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           | back at a higher price,   |                       | investor buys the shares  |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           | which results in a loss.  |                       | back at a lower price,    |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           |                           |                       | returns them to the       |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           |                           |                       | lender, and keeps the     |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           |                           |                       | difference as profit.     |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           |                           |                       | Conversely, if the price  |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           |                           |                       | rises, the investor must  |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           |                           |                       | buy them back at a higher |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           |                           |                       | price, resulting in a     |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           |                           |                       | loss.\"}                   |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                        |                           |                           |                       | name='sc2_summary'        |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "+----+------------------------+---------------------------+---------------------------+-----------------------+---------------------------+------------------------------------------+------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------+------------------------+\n",
      "\n",
      "\n",
      "\n",
      "********************************************************************\n",
      "Eval Set Id: sc2_eval_suite\n",
      "Eval Id: term_discovery_2\n",
      "Overall Eval Status: PASSED\n",
      "---------------------------------------------------------------------\n",
      "Metric: rubric_based_final_response_quality_v1, Status: PASSED, Score: 1.0, Threshold: 0.8\n",
      "Rubric Scores:\n",
      "Rubric: The agent's response is direct and to the point., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent's response accurately infers the user's underlying goal from ambiguous queries., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "---------------------------------------------------------------------\n",
      "Metric: rubric_based_tool_use_quality_v1, Status: PASSED, Score: 1.0, Threshold: 1.0\n",
      "Rubric Scores:\n",
      "Rubric: The agent calls `sc2_prefs` to store profile data when required., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_memory` after `sc2_terms` only for new memories., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_summary` last when used., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent can bypass the workflow for usage related questions., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "---------------------------------------------------------------------\n",
      "Metric: hallucinations_v1, Status: PASSED, Score: 1.0, Threshold: 0.8\n",
      "---------------------------------------------------------------------\n",
      "Invocation Details:\n",
      "+----+-------------------------+---------------------------+---------------------------+-----------------------+---------------------------+------------------------------------------+------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------+------------------------+\n",
      "|    | prompt                  | expected_response         | actual_response           | expected_tool_calls   | actual_tool_calls         | rubric_based_final_response_quality_v1   | Rubric: The agent's response is direct and to the point.   | Rubric: The agent's response accurately infers the user's underlying goal from ambiguous queries.   | rubric_based_tool_use_quality_v1   | Rubric: The agent calls `sc2_prefs` to store profile data when required.   | Rubric: The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`.   | Rubric: The agent calls `sc2_memory` after `sc2_terms` only for new memories.   | Rubric: The agent calls `sc2_summary` last when used.   | Rubric: The agent can bypass the workflow for usage related questions.   | hallucinations_v1      |\n",
      "+====+=========================+===========================+===========================+=======================+===========================+==========================================+============================================================+=====================================================================================================+====================================+============================================================================+=================================================================================+=================================================================================+=========================================================+==========================================================================+========================+\n",
      "|  0 | What is gambler's ruin? | Gambler's Ruin is a       | Gambler's Ruin is a       |                       | id='adk-63f4407e-52fc-455 | Status: PASSED, Score:                   | Reasoning: The final                                       | Reasoning: The user's                                                                               | Status: PASSED, Score:             | Reasoning: The agent did                                                   | Reasoning: The agent                                                            | Reasoning: The tool                                                             | Reasoning: The agent                                    | Reasoning: The user                                                      | Status: PASSED, Score: |\n",
      "|    |                         | concept in probability    | concept in probability    |                       | f-9d59- 628f36394236'     | 1.0                                      | answer directly addresses                                  | query \"What is gambler's                                                                            | 1.0                                | not call `sc2_prefs`. The                                                  | called `sc2_memory` as                                                          | `sc2_terms` was not                                                             | called `sc2_summary` at                                 | prompt \"What is gambler's                                                | 1.0                    |\n",
      "|    |                         | theory. It describes a    | theory. It posits that a  |                       | args={'request': \"What is |                                          | the user's question by                                     | ruin?\" is not an                                                                                    |                                    | user prompt \"What is                                                       | the first step (step 0).                                                        | called by the agent.                                                            | step 1, which is the last                               | ruin?\" is a factual                                                      |                        |\n",
      "|    |                         | scenario where a gambler, | gambler possessing a      |                       | gambler's ruin?\"}         |                                          | providing a clear                                          | ambiguous query; it is a                                                                            |                                    | gambler's ruin?\" does not                                                  | The tools `sc2_terms` and                                                       | Since `sc2_terms` was not                                                       | step in the                                             | question, not a usage-                                                   |                        |\n",
      "|    |                         | beginning with a finite   | finite sum of money,      |                       | name='sc2_memory'         |                                          | definition of \"gambler's                                   | direct question asking                                                                              |                                    | require the storage of                                                     | `fncall_pipeline` were                                                          | called, the condition for                                                       | `tool_calls_and_response`                               | related question. The                                                    |                        |\n",
      "|    |                         | sum of money, will        | engaged in a game against |                       | id='adk- bf19929c-3381-4a |                                          | ruin\" without any                                          | for a definition.                                                                                   |                                    | profile data, so the                                                       | not called at all in the                                                        | `sc2_memory` to be called                                                       | sequence., Score: 1.0                                   | agent correctly executed                                                 |                        |\n",
      "|    |                         | inevitably lose all of    | an opponent with an       |                       | b1-80b6-62b327127e4d'     |                                          | extraneous conversational                                  | Therefore, the condition                                                                            |                                    | `sc2_prefs` tool was not                                                   | response. Therefore,                                                            | *after* `sc2_terms` did                                                         |                                                         | a workflow for a factual                                                 |                        |\n",
      "|    |                         | their funds.              | infinite amount of        |                       | args={'request':          |                                          | elements or irrelevant                                     | for evaluating inference                                                                            |                                    | required to be called.,                                                    | `sc2_memory` was called                                                         | not occur, and thus the                                                         |                                                         | query rather than                                                        |                        |\n",
      "|    |                         |                           | capital, will inevitably  |                       | \"Gambler's ruin is a      |                                          | information., Score: 1.0                                   | from *ambiguous* queries                                                                            |                                    | Score: 1.0                                                                 | before either of them.,                                                         | constraint \"only for new                                                        |                                                         | bypassing it, which                                                      |                        |\n",
      "|    |                         |                           | deplete their entire      |                       | concept in probability    |                                          |                                                            | is not applicable. The                                                                              |                                    |                                                                            | Score: 1.0                                                                      | memories\" was not                                                               |                                                         | demonstrates its ability                                                 |                        |\n",
      "|    |                         |                           | fortune. This outcome is  |                       | theory. It states that a  |                                          |                                                            | agent accurately inferred                                                                           |                                    |                                                                            |                                                                                 | violated., Score: 1.0                                                           |                                                         | to discern when to apply                                                 |                        |\n",
      "|    |                         |                           | irrespective of whether   |                       | gambler with a finite     |                                          |                                                            | the explicit goal of the                                                                            |                                    |                                                                            |                                                                                 |                                                                                 |                                                         | its standard workflow                                                    |                        |\n",
      "|    |                         |                           | the game is fair or even  |                       | amount of money, playing  |                                          |                                                            | user, which was to get a                                                                            |                                    |                                                                            |                                                                                 |                                                                                 |                                                         | versus when a bypass (for                                                |                        |\n",
      "|    |                         |                           | if it offers a slight     |                       | against an opponent with  |                                          |                                                            | definition. Since the                                                                               |                                    |                                                                            |                                                                                 |                                                                                 |                                                         | usage questions) might be                                                |                        |\n",
      "|    |                         |                           | advantage to the gambler. |                       | an infinite amount of     |                                          |                                                            | property's specific                                                                                 |                                    |                                                                            |                                                                                 |                                                                                 |                                                         | appropriate., Score: 1.0                                                 |                        |\n",
      "|    |                         |                           |                           |                       | money, will eventually    |                                          |                                                            | condition (ambiguous                                                                                |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                         |                           |                           |                       | lose all of their money.  |                                          |                                                            | queries) was not met, the                                                                           |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                         |                           |                           |                       | This outcome occurs even  |                                          |                                                            | property is considered                                                                              |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                         |                           |                           |                       | in a fair game or a game  |                                          |                                                            | fulfilled., Score: 1.0                                                                              |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                         |                           |                           |                       | biased in the gambler's   |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                         |                           |                           |                       | favor.\"}                  |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                         |                           |                           |                       | name='sc2_summary'        |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "+----+-------------------------+---------------------------+---------------------------+-----------------------+---------------------------+------------------------------------------+------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------+------------------------+\n",
      "\n",
      "\n",
      "\n",
      "********************************************************************\n",
      "Eval Set Id: sc2_eval_suite\n",
      "Eval Id: function_aware\n",
      "Overall Eval Status: PASSED\n",
      "---------------------------------------------------------------------\n",
      "Metric: rubric_based_final_response_quality_v1, Status: PASSED, Score: 1.0, Threshold: 0.8\n",
      "Rubric Scores:\n",
      "Rubric: The agent's response is direct and to the point., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent's response accurately infers the user's underlying goal from ambiguous queries., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "---------------------------------------------------------------------\n",
      "Metric: rubric_based_tool_use_quality_v1, Status: PASSED, Score: 1.0, Threshold: 1.0\n",
      "Rubric Scores:\n",
      "Rubric: The agent calls `sc2_prefs` to store profile data when required., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_memory` after `sc2_terms` only for new memories., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_summary` last when used., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent can bypass the workflow for usage related questions., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "---------------------------------------------------------------------\n",
      "Metric: hallucinations_v1, Status: PASSED, Score: 1.0, Threshold: 0.8\n",
      "---------------------------------------------------------------------\n",
      "Invocation Details:\n",
      "+----+---------------------------+---------------------------+---------------------------+-----------------------+---------------------------+------------------------------------------+------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------+------------------------+\n",
      "|    | prompt                    | expected_response         | actual_response           | expected_tool_calls   | actual_tool_calls         | rubric_based_final_response_quality_v1   | Rubric: The agent's response is direct and to the point.   | Rubric: The agent's response accurately infers the user's underlying goal from ambiguous queries.   | rubric_based_tool_use_quality_v1   | Rubric: The agent calls `sc2_prefs` to store profile data when required.   | Rubric: The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`.   | Rubric: The agent calls `sc2_memory` after `sc2_terms` only for new memories.   | Rubric: The agent calls `sc2_summary` last when used.   | Rubric: The agent can bypass the workflow for usage related questions.   | hallucinations_v1      |\n",
      "+====+===========================+===========================+===========================+=======================+===========================+==========================================+============================================================+=====================================================================================================+====================================+============================================================================+=================================================================================+=================================================================================+=========================================================+==========================================================================+========================+\n",
      "|  0 | Tell me what functions    | `fncall_pipeline` knows   | `fncall_pipeline` can     |                       | id='adk-66d3704a-e420-4cf | Status: PASSED, Score:                   | Reasoning: The final                                       | Reasoning: The user's                                                                               | Status: PASSED, Score:             | Reasoning: The agent's                                                     | Reasoning: The agent did                                                        | Reasoning: The agent did                                                        | Reasoning: The agent did                                | Reasoning: The user's                                                    | Status: PASSED, Score: |\n",
      "|    | `fncall_pipeline` knows   | the following functions:  | access the following      |                       | e-85ac- 2529f03068f3'     | 1.0                                      | answer directly provides                                   | query is direct and                                                                                 | 1.0                                | response does not include                                                  | not call `sc2_memory`,                                                          | not call `sc2_memory` or                                                        | not call `sc2_summary` in                               | prompt is a direct usage-                                                | 1.0                    |\n",
      "|    | by checking `sc2_fnplan`. | get_symbol_1,             | functions:  *             |                       | args={'request': 'List    |                                          | the requested list of                                      | unambiguous, explicitly                                                                             |                                    | a call to `sc2_prefs`.                                                     | `sc2_terms`, or                                                                 | `sc2_terms` in its                                                              | its response. Since                                     | related question about                                                   |                        |\n",
      "|    |                           | get_symbols_1,            | `get_symbol_1` *          |                       | all functions defined     |                                          | functions without                                          | asking for a list of                                                                                |                                    | The user's prompt is a                                                     | `fncall_pipeline` in its                                                        | response, nor did the                                                           | `sc2_summary` was not                                   | tool functionality. The                                                  |                        |\n",
      "|    |                           | get_name_1,               | `get_symbols_1` *         |                       | within sc2_fnplan'}       |                                          | additional text or                                         | functions and specifying                                                                            |                                    | question about tool                                                        | response. Since the                                                             | user's prompt involve new                                                       | used, the condition of                                  | agent responded by                                                       |                        |\n",
      "|    |                           | get_symbol_quote_1,       | `get_name_1` *            |                       | name='sc2_fnplan'         |                                          | conversational fluff,                                      | the tool to check                                                                                   |                                    | functionality and does                                                     | premise for the ordering                                                        | memories. Therefore, the                                                        | the property is not met,                                | directly invoking the                                                    |                        |\n",
      "|    |                           | get_market_status_1,      | `get_symbol_quote_1` *    |                       |                           |                                          | making it direct and to                                    | (`sc2_fnplan`).                                                                                     |                                    | not require storing                                                        | condition is not met, the                                                       | property is not                                                                 | and thus it is not                                      | specified tool,                                                          |                        |\n",
      "|    |                           | get_market_session_1,     | `get_market_status_1` *   |                       |                           |                                          | the point., Score: 1.0                                     | Therefore, there was no                                                                             |                                    | profile data. Thus,                                                        | property is not                                                                 | applicable., Score: 1.0                                                         | applicable., Score: 1.0                                 | `sc2_fnplan`, without                                                    |                        |\n",
      "|    |                           | get_company_peers_1,      | `get_market_session_1` *  |                       |                           |                                          |                                                            | need for the agent to                                                                               |                                    | `sc2_prefs` was not                                                        | applicable in a violating                                                       |                                                                                 |                                                         | engaging in any                                                          |                        |\n",
      "|    |                           | get_local_datetime,       | `get_company_peers_1` *   |                       |                           |                                          |                                                            | infer an underlying goal                                                                            |                                    | called when it was not                                                     | sense., Score: 1.0                                                              |                                                                                 |                                                         | extraneous steps that                                                    |                        |\n",
      "|    |                           | get_last_market_close,    | `get_local_datetime` *    |                       |                           |                                          |                                                            | from an ambiguous query.,                                                                           |                                    | required, fulfilling the                                                   |                                                                                 |                                                                                 |                                                         | might be part of a                                                       |                        |\n",
      "|    |                           | get_exchange_codes_1,     | `get_last_market_close` * |                       |                           |                                          |                                                            | Score: 1.0                                                                                          |                                    | property., Score: 1.0                                                      |                                                                                 |                                                                                 |                                                         | broader workflow, thus                                                   |                        |\n",
      "|    |                           | get_exchange_code_1,      | `get_exchange_codes_1` *  |                       |                           |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         | demonstrating its ability                                                |                        |\n",
      "|    |                           | get_financials_1,         | `get_exchange_code_1` *   |                       |                           |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         | to bypass such a workflow                                                |                        |\n",
      "|    |                           | get_daily_candlestick_2,  | `get_financials_1` *      |                       |                           |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         | for direct usage                                                         |                        |\n",
      "|    |                           | get_custom_candlestick_2, | `get_daily_candlestick_2` |                       |                           |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         | inquiries., Score: 1.0                                                   |                        |\n",
      "|    |                           | get_ticker_overview_2, ge | * `get_custom_candlestick |                       |                           |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           | t_recommendation_trends_1 | _2` *                     |                       |                           |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           | , get_news_with_sentiment | `get_ticker_overview_2` * |                       |                           |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           | _2, get_wiki_grounding,   | `get_recommendation_trend |                       |                           |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           | get_search_grounding.     | s_1` * `get_news_with_sen |                       |                           |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           |                           | timent_2` *               |                       |                           |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           |                           | `get_wiki_grounding` *    |                       |                           |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           |                           | `get_search_grounding`    |                       |                           |                                          |                                                            |                                                                                                     |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "+----+---------------------------+---------------------------+---------------------------+-----------------------+---------------------------+------------------------------------------+------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------+------------------------+\n",
      "\n",
      "\n",
      "\n",
      "********************************************************************\n",
      "Eval Set Id: sc2_eval_suite\n",
      "Eval Id: tool_aware\n",
      "Overall Eval Status: PASSED\n",
      "---------------------------------------------------------------------\n",
      "Metric: rubric_based_final_response_quality_v1, Status: PASSED, Score: 1.0, Threshold: 0.8\n",
      "Rubric Scores:\n",
      "Rubric: The agent's response is direct and to the point., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent's response accurately infers the user's underlying goal from ambiguous queries., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "---------------------------------------------------------------------\n",
      "Metric: rubric_based_tool_use_quality_v1, Status: PASSED, Score: 1.0, Threshold: 1.0\n",
      "Rubric Scores:\n",
      "Rubric: The agent calls `sc2_prefs` to store profile data when required., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_memory` after `sc2_terms` only for new memories., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_summary` last when used., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent can bypass the workflow for usage related questions., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "---------------------------------------------------------------------\n",
      "Metric: hallucinations_v1, Status: PASSED, Score: 1.0, Threshold: 0.8\n",
      "---------------------------------------------------------------------\n",
      "Invocation Details:\n",
      "+----+------------------------+-------------------------+-----------------------+-----------------------+---------------------+------------------------------------------+------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------+------------------------+\n",
      "|    | prompt                 | expected_response       | actual_response       | expected_tool_calls   | actual_tool_calls   | rubric_based_final_response_quality_v1   | Rubric: The agent's response is direct and to the point.   | Rubric: The agent's response accurately infers the user's underlying goal from ambiguous queries.   | rubric_based_tool_use_quality_v1   | Rubric: The agent calls `sc2_prefs` to store profile data when required.   | Rubric: The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`.   | Rubric: The agent calls `sc2_memory` after `sc2_terms` only for new memories.   | Rubric: The agent calls `sc2_summary` last when used.   | Rubric: The agent can bypass the workflow for usage related questions.   | hallucinations_v1      |\n",
      "+====+========================+=========================+=======================+=======================+=====================+==========================================+============================================================+=====================================================================================================+====================================+============================================================================+=================================================================================+=================================================================================+=========================================================+==========================================================================+========================+\n",
      "|  0 | What tools do you know | I can use the following | I know how to use the |                       |                     | Status: PASSED, Score:                   | Reasoning: The agent's                                     | Reasoning: The user's                                                                               | Status: PASSED, Score:             | Reasoning: The user's                                                      | Reasoning: The agent did                                                        | Reasoning: The agent did                                                        | Reasoning: The agent did                                | Reasoning: The user's                                                    | Status: PASSED, Score: |\n",
      "|    | how to use?            | tools: sc2_memory,      | following tools:      |                       |                     | 1.0                                      | response directly answers                                  | query \"What tools do you                                                                            | 1.0                                | prompt was a question                                                      | not make any tool calls.                                                        | not make any tool calls.                                                        | not make any tool calls,                                | prompt was a usage-                                                      | 1.0                    |\n",
      "|    |                        | sc2_prefs,              | `sc2_memory`,         |                       |                     |                                          | the user's question by                                     | know how to use?\" is a                                                                              |                                    | about the agent's                                                          | Therefore, the condition                                                        | Therefore, the condition                                                        | which means `sc2_summary`                               | related question. The                                                    |                        |\n",
      "|    |                        | fncall_pipeline,        | `sc2_prefs`,          |                       |                     |                                          | listing the tools it                                       | direct and unambiguous                                                                              |                                    | capabilities, not a                                                        | of calling `sc2_memory`                                                         | of calling `sc2_memory`                                                         | was not used. Therefore,                                | agent's response, \"No                                                    |                        |\n",
      "|    |                        | sc2_fnplan, sc2_terms,  | `fncall_pipeline`,    |                       |                     |                                          | knows how to use, without                                  | question. There is no                                                                               |                                    | request to store profile                                                   | before `sc2_terms` or                                                           | after `sc2_terms` is not                                                        | the condition that it is                                | intermediate steps were                                                  |                        |\n",
      "|    |                        | sc2_summary.            | `sc2_fnplan`,         |                       |                     |                                          | any additional                                             | underlying goal to infer                                                                            |                                    | data. Therefore, calling                                                   | `fncall_pipeline` is not                                                        | applicable as neither of                                                        | called last \"when used\"                                 | taken,\" indicates that it                                                |                        |\n",
      "|    |                        |                         | `sc2_terms`, and      |                       |                     |                                          | elaboration or                                             | beyond directly answering                                                                           |                                    | `sc2_prefs` was not                                                        | applicable as none of                                                           | these tools were used.,                                                         | is satisfied as it was                                  | bypassed any complex                                                     |                        |\n",
      "|    |                        |                         | `sc2_summary`.        |                       |                     |                                          | unnecessary information.,                                  | the question. Therefore,                                                                            |                                    | required. The agent did                                                    | these tools were used.,                                                         | Score: 1.0                                                                      | not used at all., Score:                                | workflow that might                                                      |                        |\n",
      "|    |                        |                         |                       |                       |                     |                                          | Score: 1.0                                                 | the condition for this                                                                              |                                    | not call any tools, which                                                  | Score: 1.0                                                                      |                                                                                 | 1.0                                                     | involve tool calls or                                                    |                        |\n",
      "|    |                        |                         |                       |                       |                     |                                          |                                                            | property (an ambiguous                                                                              |                                    | aligns with not calling                                                    |                                                                                 |                                                                                 |                                                         | planning, directly                                                       |                        |\n",
      "|    |                        |                         |                       |                       |                     |                                          |                                                            | query) was not met.,                                                                                |                                    | `sc2_prefs` when not                                                       |                                                                                 |                                                                                 |                                                         | addressing the nature of                                                 |                        |\n",
      "|    |                        |                         |                       |                       |                     |                                          |                                                            | Score: 1.0                                                                                          |                                    | required., Score: 1.0                                                      |                                                                                 |                                                                                 |                                                         | the question., Score: 1.0                                                |                        |\n",
      "+----+------------------------+-------------------------+-----------------------+-----------------------+---------------------+------------------------------------------+------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------+------------------------+\n",
      "\n",
      "\n",
      "\n",
      "********************************************************************\n",
      "Eval Set Id: sc2_eval_suite\n",
      "Eval Id: create_memory_1\n",
      "Overall Eval Status: PASSED\n",
      "---------------------------------------------------------------------\n",
      "Metric: rubric_based_final_response_quality_v1, Status: PASSED, Score: 1.0, Threshold: 0.8\n",
      "Rubric Scores:\n",
      "Rubric: The agent's response is direct and to the point., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent's response accurately infers the user's underlying goal from ambiguous queries., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "---------------------------------------------------------------------\n",
      "Metric: rubric_based_tool_use_quality_v1, Status: PASSED, Score: 1.0, Threshold: 1.0\n",
      "Rubric Scores:\n",
      "Rubric: The agent calls `sc2_prefs` to store profile data when required., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_memory` after `sc2_terms` only for new memories., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent calls `sc2_summary` last when used., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "Rubric: The agent can bypass the workflow for usage related questions., Score: 1.0, Reasoning: This is an aggregated score derived from individual entries. Please refer to individual entries in each invocation for actual rationale from the model.\n",
      "---------------------------------------------------------------------\n",
      "Metric: hallucinations_v1, Status: PASSED, Score: 1.0, Threshold: 0.8\n",
      "---------------------------------------------------------------------\n",
      "Invocation Details:\n",
      "+----+---------------------------+--------------------------+---------------------------+-----------------------+---------------------------+------------------------------------------+------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------+------------------------+\n",
      "|    | prompt                    | expected_response        | actual_response           | expected_tool_calls   | actual_tool_calls         | rubric_based_final_response_quality_v1   | Rubric: The agent's response is direct and to the point.   | Rubric: The agent's response accurately infers the user's underlying goal from ambiguous queries.   | rubric_based_tool_use_quality_v1   | Rubric: The agent calls `sc2_prefs` to store profile data when required.   | Rubric: The agent calls `sc2_memory` before `sc2_terms` or `fncall_pipeline`.   | Rubric: The agent calls `sc2_memory` after `sc2_terms` only for new memories.   | Rubric: The agent calls `sc2_summary` last when used.   | Rubric: The agent can bypass the workflow for usage related questions.   | hallucinations_v1      |\n",
      "+====+===========================+==========================+===========================+=======================+===========================+==========================================+============================================================+=====================================================================================================+====================================+============================================================================+=================================================================================+=================================================================================+=========================================================+==========================================================================+========================+\n",
      "|  0 | My local advisor is SC at | I have stored your local | I already know that the   |                       | id='adk-9aaffd5a-287d-48d | Status: PASSED, Score:                   | Reasoning: The final                                       | Reasoning: The user's                                                                               | Status: PASSED, Score:             | Reasoning: The user                                                        | Reasoning: The agent's                                                          | Reasoning: The agent's                                                          | Reasoning: The agent's                                  | Reasoning: The user                                                      | Status: PASSED, Score: |\n",
      "|    | JPMorgan Chase,           | advisor's information.   | local advisor is SC at    |                       | a-9a62- 4e346e31cb20'     | 1.0                                      | answer directly addresses                                  | query is a clear                                                                                    | 1.0                                | prompt contained profile                                                   | response did not include                                                        | response did not include                                                        | response did not include                                | prompt was not a \"usage                                                  | 1.0                    |\n",
      "|    | 212-736-2001.             |                          | JPMorgan Chase, and their |                       | args={'request': 'My      |                                          | the user's statement                                       | statement of profile                                                                                |                                    | data (advisor name,                                                        | calls to `sc2_memory`,                                                          | calls to `sc2_memory` or                                                        | a call to `sc2_summary`.                                | related question,\" so                                                    |                        |\n",
      "|    |                           |                          | phone number is           |                       | local advisor is SC at    |                                          | without any extraneous                                     | data, not an ambiguous                                                                              |                                    | company, phone number),                                                    | `sc2_terms`, or                                                                 | `sc2_terms`. Therefore,                                                         | Therefore, the property                                 | this property is not                                                     |                        |\n",
      "|    |                           |                          | 212-736-2001.             |                       | JPMorgan Chase,           |                                          | information or                                             | query. The agent                                                                                    |                                    | and the agent                                                              | `fncall_pipeline`.                                                              | the property is not                                                             | is not applicable.,                                     | applicable to the current                                                |                        |\n",
      "|    |                           |                          |                           |                       | 212-736-2001.'}           |                                          | conversational filler. It                                  | correctly inferred the                                                                              |                                    | appropriately called                                                       | Therefore, the property                                                         | applicable., Score: 1.0                                                         | Score: 1.0                                              | interaction., Score: 1.0                                                 |                        |\n",
      "|    |                           |                          |                           |                       | name='sc2_prefs'          |                                          | confirms the information                                   | user's goal was to                                                                                  |                                    | `sc2_prefs` to handle                                                      | is not applicable.,                                                             |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           |                          |                           |                       |                           |                                          | provided by the user.,                                     | provide profile data, as                                                                            |                                    | this information., Score:                                                  | Score: 1.0                                                                      |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           |                          |                           |                       |                           |                                          | Score: 1.0                                                 | evidenced by its use of                                                                             |                                    | 1.0                                                                        |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           |                          |                           |                       |                           |                                          |                                                            | the `sc2_prefs` tool,                                                                               |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           |                          |                           |                       |                           |                                          |                                                            | which is designed for                                                                               |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           |                          |                           |                       |                           |                                          |                                                            | storing profile data                                                                                |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           |                          |                           |                       |                           |                                          |                                                            | according to the                                                                                    |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           |                          |                           |                       |                           |                                          |                                                            | instructions. The                                                                                   |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           |                          |                           |                       |                           |                                          |                                                            | response then confirms                                                                              |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "|    |                           |                          |                           |                       |                           |                                          |                                                            | the data., Score: 1.0                                                                               |                                    |                                                                            |                                                                                 |                                                                                 |                                                         |                                                                          |                        |\n",
      "+----+---------------------------+--------------------------+---------------------------+-----------------------+---------------------------+------------------------------------------+------------------------------------------------------------+-----------------------------------------------------------------------------------------------------+------------------------------------+----------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------------------------------+---------------------------------------------------------+--------------------------------------------------------------------------+------------------------+\n",
      "\n",
      "\n",
      "\n",
      "2025-12-01 06:50:40,922 - ERROR - base_events.py:1821 - Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7b392c0e12b0>\n",
      "2025-12-01 06:50:40,922 - ERROR - base_events.py:1821 - Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x7b392aed7410>, 163304.64493107), (<aiohttp.client_proto.ResponseHandler object at 0x7b392aed7230>, 163307.551887757), (<aiohttp.client_proto.ResponseHandler object at 0x7b392aed7890>, 163311.3517091)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x7b392c0e1370>\n",
      "2025-12-01 06:50:40,924 - ERROR - base_events.py:1821 - Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7b392a7ae420>\n",
      "2025-12-01 06:50:40,924 - ERROR - base_events.py:1821 - Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x7b392aed7050>, 163304.441401676)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x7b392a7aca70>\n",
      "2025-12-01 06:50:40,925 - ERROR - base_events.py:1821 - Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7b3929b58c20>\n",
      "2025-12-01 06:50:40,925 - ERROR - base_events.py:1821 - Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x7b392aed7d70>, 163300.374662593), (<aiohttp.client_proto.ResponseHandler object at 0x7b392a760170>, 163301.411946312)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x7b3929b58b60>\n",
      "2025-12-01 06:50:40,927 - ERROR - base_events.py:1821 - Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x7b392a778f50>\n",
      "2025-12-01 06:50:40,927 - ERROR - base_events.py:1821 - Unclosed connector\n",
      "connections: ['deque([(<aiohttp.client_proto.ResponseHandler object at 0x7b392aed7ef0>, 163299.872841362), (<aiohttp.client_proto.ResponseHandler object at 0x7b392a761130>, 163300.01212217), (<aiohttp.client_proto.ResponseHandler object at 0x7b392a760a10>, 163300.013835746), (<aiohttp.client_proto.ResponseHandler object at 0x7b392a760770>, 163301.746375534)])']\n",
      "connector: <aiohttp.connector.TCPConnector object at 0x7b392a778e90>\n"
     ]
    }
   ],
   "source": [
    "!adk eval sc2 sc2/eval/test_cases.json --config_file_path=sc2/eval/config.json --print_detailed_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In applying Google's ADK to SC1, the result is a more capable SC2 which is ready to grow beyond it's first edition roots. Unresolved issues from SC1 remain. Parallelism will enable large work loads, like a stack of news requiring analysis, or background processes to drive self-improvement. This will enable a better user experience when locally running models are later employed to scale further. With the addition of agentic capabilities StockChat has room to grow again.\n",
    "\n",
    "__I hope you'll stick around to see how far the project gets! Thanks for taking the time to check out my notebook!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Appendix__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini Baseline Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:37:47.068787Z",
     "iopub.status.busy": "2025-12-01T09:37:47.068482Z",
     "iopub.status.idle": "2025-12-01T09:37:55.509204Z",
     "shell.execute_reply": "2025-12-01T09:37:55.508285Z",
     "shell.execute_reply.started": "2025-12-01T09:37:47.068759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is an accurate retelling of events. \n",
    "config_with_search = types.GenerateContentConfig(\n",
    "    tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "chat = api.args.CLIENT.chats.create(\n",
    "    model=api(Api.Model.GEN),\n",
    "    config=config_with_search,\n",
    "    history=[]) # Ignoring the part about dark elves, and tengwar.\n",
    "\n",
    "response = chat.send_message('Do you know anything about the stock market?')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:37:55.511122Z",
     "iopub.status.busy": "2025-12-01T09:37:55.510223Z",
     "iopub.status.idle": "2025-12-01T09:38:05.175474Z",
     "shell.execute_reply": "2025-12-01T09:38:05.174372Z",
     "shell.execute_reply.started": "2025-12-01T09:37:55.511088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "response = chat.send_message('I have an interest in AMZN stock')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:05.176966Z",
     "iopub.status.busy": "2025-12-01T09:38:05.17662Z",
     "iopub.status.idle": "2025-12-01T09:38:20.367294Z",
     "shell.execute_reply": "2025-12-01T09:38:20.36637Z",
     "shell.execute_reply.started": "2025-12-01T09:38:05.176936Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "response = chat.send_message('''Tell me about AMZN current share price, short-term trends, and bullish versus bearish predictions''')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:20.368522Z",
     "iopub.status.busy": "2025-12-01T09:38:20.368261Z",
     "iopub.status.idle": "2025-12-01T09:38:24.396265Z",
     "shell.execute_reply": "2025-12-01T09:38:24.395283Z",
     "shell.execute_reply.started": "2025-12-01T09:38:20.3685Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "response = chat.send_message('''What is mgm studio's stock ticker symbol?''')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:24.397509Z",
     "iopub.status.busy": "2025-12-01T09:38:24.397251Z",
     "iopub.status.idle": "2025-12-01T09:38:27.856846Z",
     "shell.execute_reply": "2025-12-01T09:38:27.855899Z",
     "shell.execute_reply.started": "2025-12-01T09:38:24.397488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "response = chat.send_message('''What was the last open,close,high,low data for AMZN again?''')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:27.860629Z",
     "iopub.status.busy": "2025-12-01T09:38:27.860289Z",
     "iopub.status.idle": "2025-12-01T09:38:35.834892Z",
     "shell.execute_reply": "2025-12-01T09:38:35.834067Z",
     "shell.execute_reply.started": "2025-12-01T09:38:27.860607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "response = chat.send_message('''What is AMZN open,close,high,low data for the past month? \n",
    "Present the data with multiple columns for display in markdown.''')\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previously on Kaggle: StockChat 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation BaseModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:35.836154Z",
     "iopub.status.busy": "2025-12-01T09:38:35.83581Z",
     "iopub.status.idle": "2025-12-01T09:38:35.926167Z",
     "shell.execute_reply": "2025-12-01T09:38:35.925145Z",
     "shell.execute_reply.started": "2025-12-01T09:38:35.836125Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Validation BaseModels in pydantic schema.\n",
    "class RestStatus(Enum):\n",
    "    OK = \"OK\"\n",
    "    DELAY = \"DELAYED\"\n",
    "    NONE = \"NOT_FOUND\"\n",
    "    AUTH = \"NOT_AUTHORIZED\"\n",
    "\n",
    "class StopGeneration(BaseModel):\n",
    "    result: str = Api.Const.Stop()\n",
    "\n",
    "class RestResultPoly(BaseModel):\n",
    "    request_id: Optional[str] = None\n",
    "    count: Optional[int] = None\n",
    "    next_url: Optional[str] = None\n",
    "    status: RestStatus  \n",
    "\n",
    "class MarketSession(Enum):\n",
    "    PRE = \"pre-market\"\n",
    "    REG = \"regular\"\n",
    "    POST = \"post-market\"\n",
    "    CLOSED = \"closed\"\n",
    "    NA = \"not applicable\"\n",
    "\n",
    "class MarketEvent(Enum):\n",
    "    PRE_OPEN = 0\n",
    "    REG_OPEN = 1\n",
    "    REG_CLOSE = 2\n",
    "    POST_CLOSE = 3\n",
    "    LAST_CLOSE = 4\n",
    "\n",
    "class AssetClass(Enum):\n",
    "    STOCKS = \"stocks\"\n",
    "    OPTION = \"options\"\n",
    "    CRYPTO = \"crypto\"\n",
    "    FOREX = \"fx\"\n",
    "    INDEX = \"indices\"\n",
    "    OTC = \"otc\"\n",
    "\n",
    "class SymbolType(Enum):\n",
    "    COMMON = \"Common Stock\"\n",
    "    ETP = \"ETP\"\n",
    "    ADR = \"ADR\"\n",
    "    REIT = \"REIT\"\n",
    "    DELISTED = \"\"\n",
    "    CEF = \"Closed-End Fund\"\n",
    "    UNIT = \"Unit\"\n",
    "    RIGHT = \"Right\"\n",
    "    EQUITY = \"Equity WRT\"\n",
    "    GDR = \"GDR\"\n",
    "    PREF = \"Preference\"\n",
    "    CDI = \"CDI\"\n",
    "    NVDR = \"NVDR\"\n",
    "    REG = \"NY Reg Shrs\"\n",
    "    MLP = \"MLP\"\n",
    "    MUTUAL = \"Mutual Fund\"\n",
    "\n",
    "class Locale(Enum):\n",
    "    US = \"us\"\n",
    "    GLOBAL = \"global\"\n",
    "\n",
    "class Sentiment(Enum):\n",
    "    V_POS = \"very positive\"\n",
    "    POSITIVE = \"positive\"\n",
    "    NEUTRAL_P = \"neutral/positive\"\n",
    "    NEUTRAL_SP = \"neutral/slightly positive\"\n",
    "    NEUTRAL = \"neutral\"\n",
    "    NEUTRAL_SN = \"neutral/slightly negative\"\n",
    "    NEUTRAL_N = \"neutral/negative\"\n",
    "    MIXED = \"mixed\"\n",
    "    NEGATIVE = \"negative\"\n",
    "    V_NEG = \"very negative\"\n",
    "\n",
    "class Trend(Enum):\n",
    "    S_BUY = \"strong-buy\"\n",
    "    BUY = \"buy\"\n",
    "    HOLD = \"hold\"\n",
    "    SELL = \"sell\"\n",
    "    S_SELL = \"strong-sell\"\n",
    "\n",
    "class MarketCondition(Enum):\n",
    "    BULL = \"bullish\"\n",
    "    BULLN = \"cautiously bullish\"\n",
    "    HOLD = \"hold\"\n",
    "    BEARN = \"cautiously bearish\"\n",
    "    BEAR = \"bearish\"\n",
    "\n",
    "class GeneratedEvent(BaseModel):\n",
    "    last_close: str\n",
    "    pre_open: str\n",
    "    reg_open: str\n",
    "    reg_close: str\n",
    "    post_close: str\n",
    "    timestamp: Optional[str] = None\n",
    "    is_holiday: Optional[bool] = None\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        if self.timestamp is None:\n",
    "            self.timestamp = datetime.now(self.tz()).strftime('%c')\n",
    "        if self.is_holiday is None:\n",
    "            self.is_holiday = False\n",
    "\n",
    "    def session(self, with_date: Optional[str] = None) -> MarketSession:\n",
    "        if with_date is None:\n",
    "            with_date = datetime.now(self.tz()).strftime('%c')\n",
    "        compare = parse(with_date)\n",
    "        if self.is_holiday or compare.weekday() > 4: # weekend\n",
    "            return MarketSession.CLOSED\n",
    "        events = [parse(event).time() for event in [self.pre_open,self.reg_open,self.reg_close,self.post_close]]\n",
    "        if compare.time() < events[0]:\n",
    "            return MarketSession.CLOSED\n",
    "        else:\n",
    "            session = MarketSession.NA\n",
    "            if compare.time() >= events[0]:\n",
    "                session = MarketSession.PRE\n",
    "            if compare.time() >= events[1]:\n",
    "                session = MarketSession.REG\n",
    "            if compare.time() >= events[2]:\n",
    "                session = MarketSession.POST\n",
    "            if compare.time() >= events[3]:\n",
    "                session = MarketSession.CLOSED\n",
    "        return session\n",
    "\n",
    "    def is_open(self) -> bool:\n",
    "        return self.session() != MarketSession.CLOSED\n",
    "\n",
    "    def has_update(self) -> bool:\n",
    "        datetime_now = datetime.now(self.tz())\n",
    "        self_ts = parse(self.timestamp)\n",
    "        # Re-generate events for a new day.\n",
    "        if datetime_now.day > self_ts.day:\n",
    "            return True\n",
    "        # No updates on holidays or when generated after post_close.\n",
    "        if self.is_holiday or self_ts.time() >= parse(self.post_close).time():\n",
    "            return False\n",
    "        # Compare current time to generated event times.\n",
    "        for event in [self.pre_open,self.reg_open,self.reg_close]:\n",
    "            if datetime_now.time() > parse(event).time():\n",
    "                return True\n",
    "        # Current time is before pre_open.\n",
    "        return False\n",
    "\n",
    "    @classmethod\n",
    "    def tz(cls):\n",
    "        return pytz.timezone('US/Eastern') # Exchanges data is in eastern time.\n",
    "    \n",
    "    @classmethod\n",
    "    def apply_fix(cls, value, fix: datetime) -> tuple[str, datetime]:\n",
    "        api.validation_fail()\n",
    "        value = fix.strftime('%c')\n",
    "        return value, fix\n",
    "    \n",
    "    @field_validator(\"last_close\")\n",
    "    def valid_close(cls, value):\n",
    "        date_gen = parse(value) # Generated close is in eastern time and tzinfo naive.\n",
    "        date_now = parse(datetime.now(cls.tz()).strftime('%c')) # Need now in same format as generated.\n",
    "        # Soft-pass: when actual session is closed after post-market\n",
    "        if date_now.day == date_gen.day+1 and date_now.weekday() <= 4:\n",
    "            date_fix = date_gen.replace(day=date_now.day)\n",
    "            if date_fix.timestamp() < date_now.timestamp():\n",
    "                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use today's close\n",
    "        # Soft-pass: when actual session is open post-market\n",
    "        if date_now.day == date_gen.day and date_now.timestamp() < date_gen.timestamp():\n",
    "            if date_now.weekday() > 0:\n",
    "                date_fix = date_gen.replace(day=date_now.day-1)\n",
    "            else:\n",
    "                date_fix = date_gen.replace(day=date_now.day-3)\n",
    "            if date_now.timestamp() > date_fix.timestamp():\n",
    "                value, date_gen = cls.apply_fix(value, date_fix) # soft-pass: use previous close\n",
    "        if date_now.weekday() == 0 or date_now.weekday() == 1 and date_gen.weekday() <= 4: # 0=monday, 4=friday\n",
    "            return value # pass: generated thurs/friday on a monday/tues\n",
    "        elif date_now.weekday() > 0 and date_now.weekday() <= 4 and date_gen.weekday() <= date_now.weekday()-1:\n",
    "            return value # pass: generated yesterday/prior on a tues-fri\n",
    "        elif date_now.weekday() > 4 and date_gen.weekday() <= 4:\n",
    "            return value # pass: generated thurs/friday on a weekend\n",
    "        elif date_now.day == date_gen.day and date_now.timestamp() > date_gen.timestamp():\n",
    "            return value # pass: generated today after closed\n",
    "        elif date_now.timestamp() < date_gen.timestamp():\n",
    "            raise ValueError(\"last close cannot be a future value\")\n",
    "        else:\n",
    "            raise ValueError(\"generated invalid last close\")\n",
    "        api.validation_fail()\n",
    "\n",
    "class VectorStoreResult(BaseModel):\n",
    "    docs: str\n",
    "    dist: Optional[float] # requires query\n",
    "    meta: Optional[dict]  # requires get or query\n",
    "    store_id: str\n",
    "\n",
    "class Aggregate(RestResultPoly):\n",
    "    symbol: str\n",
    "    open: float\n",
    "    high: float\n",
    "    low: float\n",
    "    close: float\n",
    "    volume: int\n",
    "    otc: Optional[bool] = None\n",
    "    preMarket: Optional[float] = None\n",
    "    afterHours: Optional[float] = None\n",
    "\n",
    "class DailyCandle(Aggregate):\n",
    "    from_date: str\n",
    "\n",
    "class AggregateWindow(BaseModel):\n",
    "    o: float\n",
    "    h: float\n",
    "    l: float\n",
    "    c: float\n",
    "    v: int # traded volume\n",
    "    n: Optional[int] = None # transaction count\n",
    "    vw: Optional[float] = None # volume weighted average price\n",
    "    otc: Optional[bool] = None\n",
    "    t: int\n",
    "\n",
    "    @field_validator(\"t\")\n",
    "    def valid_t(cls, value):\n",
    "        if not value > 0:\n",
    "            raise ValueError(\"invalid timestamp\")\n",
    "        if len(str(value)) == 13:\n",
    "            return int(value/1000)\n",
    "        return value\n",
    "\n",
    "class CustomCandle(RestResultPoly): \n",
    "    ticker: str\n",
    "    adjusted: bool\n",
    "    queryCount: int\n",
    "    resultsCount: int\n",
    "    results: list[AggregateWindow]\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[AggregateWindow]:\n",
    "        return self.results\n",
    "    \n",
    "class MarketStatus(BaseModel):\n",
    "    exchange: str\n",
    "    holiday: Optional[str] = None\n",
    "    isOpen: bool\n",
    "    session: Optional[MarketSession] = None\n",
    "    t: int\n",
    "    timezone: str\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        if self.session is None:\n",
    "            self.session = MarketSession.CLOSED\n",
    "        if self.holiday is None:\n",
    "            self.holiday = MarketSession.NA.value\n",
    "\n",
    "class MarketStatusResult(BaseModel):\n",
    "    results: MarketStatus\n",
    "\n",
    "    def get(self) -> MarketStatus:\n",
    "        return self.results\n",
    "\n",
    "class Symbol(BaseModel):\n",
    "    description: str\n",
    "    displaySymbol: str\n",
    "    symbol: str\n",
    "    type: SymbolType\n",
    "\n",
    "class SymbolResult(BaseModel):\n",
    "    count: int\n",
    "    result: list[Symbol]\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.result)\n",
    "\n",
    "    def get(self) -> list[Symbol]:\n",
    "        return self.result\n",
    "\n",
    "class Quote(BaseModel):\n",
    "    c: float\n",
    "    d: float\n",
    "    dp: float\n",
    "    h: float\n",
    "    l: float\n",
    "    o: float\n",
    "    pc: float\n",
    "    t: int\n",
    "\n",
    "    @field_validator(\"t\")\n",
    "    def valid_t(cls, value):\n",
    "        if not value > 0:\n",
    "            raise ValueError(\"invalid timestamp\")\n",
    "        return value\n",
    "\n",
    "class PeersResult(BaseModel):\n",
    "    results: list[str]\n",
    "    count: Optional[int] = None\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[str]:\n",
    "        return self.results\n",
    "\n",
    "class BasicFinancials(BaseModel):\n",
    "    metric: dict\n",
    "    metricType: str\n",
    "    series: dict\n",
    "    symbol: str\n",
    "\n",
    "class Insight(BaseModel):\n",
    "    sentiment: Sentiment|MarketCondition\n",
    "    sentiment_reasoning: str\n",
    "    ticker: str\n",
    "\n",
    "class Publisher(BaseModel):\n",
    "    favicon_url: Optional[str]\n",
    "    homepage_url: str\n",
    "    logo_url: str\n",
    "    name: str\n",
    "\n",
    "class NewsSummary(BaseModel):\n",
    "    title: str\n",
    "    summary: Optional[str]\n",
    "    insights: Optional[list[Insight]]\n",
    "    published_utc: str\n",
    "\n",
    "class NewsTypePoly(BaseModel):\n",
    "    amp_url: Optional[str] = None\n",
    "    article_url: str\n",
    "    title: str\n",
    "    author: str\n",
    "    description: Optional[str] = None\n",
    "    id: str\n",
    "    image_url: Optional[str] = None\n",
    "    insights: Optional[list[Insight]] = None\n",
    "    keywords: Optional[list[str]] = None\n",
    "    published_utc: str\n",
    "    publisher: Publisher\n",
    "    tickers: list[str]\n",
    "\n",
    "    def summary(self):\n",
    "        return NewsSummary(title=self.title,\n",
    "                           summary=self.description,\n",
    "                           insights=self.insights,\n",
    "                           published_utc=self.published_utc)\n",
    "\n",
    "class NewsResultPoly(RestResultPoly):\n",
    "    results: list[NewsTypePoly]\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[NewsTypePoly]:\n",
    "        return self.results\n",
    "\n",
    "class NewsTypeFinn(BaseModel):\n",
    "    category: str\n",
    "    datetime: int\n",
    "    headline: str\n",
    "    id: int\n",
    "    image: str\n",
    "    related: str # symbol\n",
    "    source: str\n",
    "    summary: str\n",
    "    url: str\n",
    "\n",
    "    def summary(self):\n",
    "        return NewsSummary(title=self.headline,\n",
    "                           summary=self.summary,\n",
    "                           insights=None,\n",
    "                           published_utc=self.datetime)\n",
    "\n",
    "class NewsResultFinn(BaseModel):\n",
    "    results: list[NewsTypeFinn]\n",
    "    count: Optional[int] = None\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[NewsTypeFinn]:\n",
    "        return self.results\n",
    "\n",
    "class NewsTypeGenerated(BaseModel):\n",
    "    title: str\n",
    "    summary: str\n",
    "    insights: list[Insight]\n",
    "    keywords: list[str]\n",
    "    source: Publisher\n",
    "    published_utc: str\n",
    "    tickers: list[str]\n",
    "    url: str\n",
    "\n",
    "    def summary(self):\n",
    "        return NewsSummary(title=self.title,\n",
    "                           summary=self.summary,\n",
    "                           insights=self.insights,\n",
    "                           published_utc=self.published_utc)\n",
    "\n",
    "class TickerOverview(BaseModel):\n",
    "    ticker: str\n",
    "    name: str\n",
    "    market: AssetClass\n",
    "    locale: Locale\n",
    "    primary_exchange: Optional[str] = None\n",
    "    active: bool\n",
    "    currency_name: str\n",
    "    cik: Optional[str] = None\n",
    "    composite_figi: Optional[str] = None\n",
    "    share_class_figi: Optional[str] = None\n",
    "    market_cap: Optional[int|float] = None\n",
    "    phone_number: Optional[str] = None\n",
    "    address: Optional[dict] = None\n",
    "    description: Optional[str] = None\n",
    "    sic_code: Optional[str] = None\n",
    "    sic_description: Optional[str] = None\n",
    "    ticker_root: Optional[str] = None\n",
    "    homepage_url: Optional[str] = None\n",
    "    total_employees: Optional[int] = None\n",
    "    list_date: Optional[str] = None\n",
    "    branding: Optional[dict] = None\n",
    "    share_class_shares_outstanding: Optional[int] = None\n",
    "    weighted_shares_outstanding: Optional[int] = None\n",
    "    round_lot: Optional[int] = None\n",
    "\n",
    "class OverviewResult(RestResultPoly):\n",
    "    results: TickerOverview\n",
    "\n",
    "    def get(self) -> TickerOverview:\n",
    "        return self.results\n",
    "\n",
    "class RecommendationTrend(BaseModel):\n",
    "    buy: int\n",
    "    hold: int\n",
    "    period: str\n",
    "    sell: int\n",
    "    strongBuy: int\n",
    "    strongSell: int\n",
    "    symbol: str\n",
    "\n",
    "class TrendsResult(BaseModel):\n",
    "    results: list[RecommendationTrend]\n",
    "    count: Optional[int] = None\n",
    "\n",
    "    def model_post_init(self, *args, **kwargs) -> None:\n",
    "        self.count = len(self.results)\n",
    "\n",
    "    def get(self) -> list[RecommendationTrend]:\n",
    "        return self.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:35.92737Z",
     "iopub.status.busy": "2025-12-01T09:38:35.927092Z",
     "iopub.status.idle": "2025-12-01T09:38:35.937924Z",
     "shell.execute_reply": "2025-12-01T09:38:35.936754Z",
     "shell.execute_reply.started": "2025-12-01T09:38:35.927342Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# A contents-memory object.\n",
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.system = f\"\"\"Give a concise, and detailed summary. Use information that you learn from the API responses.\n",
    "        Use your tools and function calls according to the rules. Convert any all-upper case identifiers\n",
    "        to proper case in your response. Convert any abbreviated or shortened identifiers to their full forms.\n",
    "        Convert timestamps according to the rules before including them. Think step by step.\n",
    "        \"\"\"\n",
    "        self.revery = {}\n",
    "        self.contents = []\n",
    "        self.prompt = None\n",
    "        self.summary = None\n",
    "        self.response = None\n",
    "    \n",
    "    def set_prompt(self, prompt):\n",
    "        self.prompt = f\"\"\"\n",
    "        The current date and time is: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n",
    "        \n",
    "        {prompt}\n",
    "        \"\"\"\n",
    "        self.contents = [types.Content(role=\"user\", parts=[types.Part(text=self.prompt)])]\n",
    "\n",
    "    def set_reason(self, step):\n",
    "        # Append the model's reasoning part.\n",
    "        self.contents.append(types.Content(role=\"model\", parts=[types.Part(thought=True,text=step)]))\n",
    "\n",
    "    def append_code(self, prompt, code_response_parts):\n",
    "        subroutine_content = [types.Content(role=\"user\", parts=[types.Part(text=prompt)]),\n",
    "                              types.Content(role=\"model\", parts=code_response_parts)]\n",
    "        # Append the model's generated code and execution result.\n",
    "        self.revery[datetime.now(GeneratedEvent.tz()).strftime('%c')] = { \n",
    "            \"contents\": subroutine_content\n",
    "        }\n",
    "\n",
    "    def update_contents(self, function_call, api_response_part):\n",
    "        # Append the model's function call part.\n",
    "        self.contents.append(types.Content(role=\"model\", parts=[types.Part(function_call=function_call)])) \n",
    "        # Append the api response part.\n",
    "        self.contents.append(types.Content(role=\"user\", parts=[api_response_part]))\n",
    "\n",
    "    def set_summary(self, summary):\n",
    "        self.summary = summary\n",
    "        self.contents.append(types.Content(role=\"model\", parts=[types.Part(text=summary)]))\n",
    "        self.revery[datetime.now(GeneratedEvent.tz()).strftime('%c')] = {\n",
    "            \"prompt\": self.prompt, \n",
    "            \"summary\": self.summary, \n",
    "            \"contents\": self.contents\n",
    "        }\n",
    "        self.contents = []\n",
    "\n",
    "memory = Memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:35.93916Z",
     "iopub.status.busy": "2025-12-01T09:38:35.938911Z",
     "iopub.status.idle": "2025-12-01T09:38:36.865466Z",
     "shell.execute_reply": "2025-12-01T09:38:36.864385Z",
     "shell.execute_reply.started": "2025-12-01T09:38:35.93914Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: retrieval-augmented generation.\n",
    "# - using Chroma and text-embedding-004 for storage and retrieval\n",
    "# - using gemini-2.0-flash for augmented generation\n",
    "class RetrievalAugmentedGenerator:\n",
    "    chroma_client = chromadb.PersistentClient(path=\"vector_db\")\n",
    "    config_temp = types.GenerateContentConfig(temperature=0.0)\n",
    "    exchange_codes: Optional[dict] = None\n",
    "    exchange_lists: dict = {}\n",
    "    events: dict = {}\n",
    "    holidays: dict = {}\n",
    "\n",
    "    def __init__(self, genai_client, collection_name):\n",
    "        self.client = genai_client\n",
    "        self.embed_fn = GeminiEmbedFunction(genai_client)\n",
    "        self.db = self.chroma_client.get_or_create_collection(\n",
    "            name=collection_name, \n",
    "            embedding_function=self.embed_fn,  # type: ignore\n",
    "            metadata={\"hnsw:space\": \"cosine\"})\n",
    "        logging.getLogger(\"chromadb\").setLevel(logging.ERROR) # suppress warning on existing id\n",
    "        self.set_holidays(\"US\", [\"09-01-2025\",\"10-13-2025\",\"11-11-2025\",\"11-27-2025\",\"12-25-2025\"])\n",
    "        #self.generated_events(\"US\")\n",
    "\n",
    "    def set_holidays(self, exchange_code: str, holidays: list):\n",
    "        self.holidays[exchange_code] = [datetime.strptime(h, \"%m-%d-%Y\").date() for h in holidays]\n",
    "\n",
    "    def get_exchange_codes(self, with_query: Optional[str] = None):\n",
    "        gen = None\n",
    "        if with_query and with_query not in self.exchange_lists.keys():\n",
    "            gen = tqdm(total=1, desc=\"Generate exchange codes with_query\")\n",
    "            data = self.get_exchanges_csv(\n",
    "                f\"\"\"What is the {with_query} exchange code? Return only the exchange codes \n",
    "                as a list in string form. Just the list string. \n",
    "                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n",
    "            self.exchange_lists[with_query] = ast.literal_eval(data.parts[-1].text)\n",
    "        elif with_query is None and self.exchange_codes is None:\n",
    "            gen = tqdm(total=1, desc=\"Generate exchange codes\")\n",
    "            data = self.get_exchanges_csv(\n",
    "                \"\"\"Give me a dictionary in string form. It must contain key:value pairs \n",
    "                mapping exchange code to name. Just the dictionary string. \n",
    "                Omit all other information or details. Do not chat or use sentences.\"\"\").candidates[0].content\n",
    "            self.exchange_codes = ast.literal_eval(data.parts[-1].text.strip(\"\\\\`\"))\n",
    "        if gen:\n",
    "            gen.update(1)\n",
    "        return self.exchange_lists[with_query] if with_query else self.exchange_codes\n",
    "\n",
    "    def get_event_date(self, event_t: str, exchange_code: str, event: MarketEvent):\n",
    "        current_dt_str = datetime.now(GeneratedEvent.tz()).strftime('%c')\n",
    "        current_dt = datetime.strptime(current_dt_str, \"%a %b %d %H:%M:%S %Y\")\n",
    "        current_t_str = datetime.now(GeneratedEvent.tz()).strftime('%H:%M:%S')\n",
    "        current_t = datetime.strptime(current_t_str, \"%H:%M:%S\").time()\n",
    "        event_time = parse(event_t).time()\n",
    "        gen_datetime = None\n",
    "        if event is MarketEvent.LAST_CLOSE:\n",
    "            last_close_day = current_dt.date() - timedelta(days=0 if current_t > event_time else 1)\n",
    "            # Loop backwards to find the last valid trading day (not a weekend or holiday).\n",
    "            while last_close_day.weekday() >= 5 or last_close_day in self.holidays[exchange_code]: # 5 = Sat, 6 = Sun\n",
    "                last_close_day -= timedelta(days=1)\n",
    "            # Combine the date and time.\n",
    "            gen_datetime = datetime.combine(last_close_day, event_time)\n",
    "        else:\n",
    "            next_event_day = current_dt.date() + timedelta(days=0 if current_t < event_time else 1)\n",
    "            # Loop forward to find the next valid trading day (not a weekend or holiday).\n",
    "            while next_event_day.weekday() >= 5 or next_event_day in self.holidays[exchange_code]: # 5 = Sat, 6 = Sun\n",
    "                next_event_day += timedelta(days=1)\n",
    "            # Combine date and time.\n",
    "            gen_datetime = datetime.combine(next_event_day, event_time)\n",
    "        # Format the result as requested.\n",
    "        return gen_datetime.strftime('%a %b %d %X %Y')\n",
    "\n",
    "    def generate_event(self, exchange_code: str, event: MarketEvent):\n",
    "        if event is MarketEvent.LAST_CLOSE or event is MarketEvent.POST_CLOSE:\n",
    "            prompt = f\"\"\"What is the closing time including post_market hours.\"\"\"\n",
    "        elif event is MarketEvent.PRE_OPEN or event is MarketEvent.REG_OPEN:\n",
    "            is_pre = \"including\" if event is MarketEvent.PRE_OPEN else \"excluding\"\n",
    "            prompt = f\"\"\"What is the opening time {is_pre} pre_market hours.\"\"\"\n",
    "        elif event is MarketEvent.REG_CLOSE:\n",
    "            prompt = f\"\"\"What is the closing time excluding post_market hours.\"\"\"\n",
    "        prompt = f\"\"\"Answer based on your knowledge of exchange operating hours.\n",
    "            Do not answer in full sentences. Omit all chat and provide the answer only.\n",
    "            The fields pre_market and post_market both represent extended operating hours.\n",
    "\n",
    "            The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n",
    "            \n",
    "            Consider the {exchange_code} exchange's operating hours.\n",
    "            {prompt}\n",
    "            \n",
    "            Answer with the time in this format: '%H:%M:%S'.\n",
    "            Omit all other chat and details. Do not use sentences.\"\"\"\n",
    "        progress = tqdm(total=1, desc=f\"Generate {exchange_code}->{event}\")\n",
    "        response = self.get_exchanges_csv(prompt).candidates[0].content\n",
    "        try:\n",
    "            if Api.Const.Stop() in f\"{response.parts[-1].text}\":\n",
    "                self.generate_event_failed(progress, exchange_code, event)\n",
    "            else:\n",
    "                response = self.get_event_date(response.parts[-1].text, exchange_code, event)\n",
    "                progress.update(1)\n",
    "                return response\n",
    "        except Exception as e:\n",
    "            self.generate_event_failed(progress, exchange_code, event)\n",
    "\n",
    "    def generate_event_failed(self, progress: tqdm, exchange_code: str, event: MarketEvent):\n",
    "        progress.close()\n",
    "        api.generation_fail()\n",
    "        time.sleep(api.dt_between)\n",
    "        return self.generate_event(exchange_code, event)\n",
    "\n",
    "    def generated_events(self, exchange_code: str) -> GeneratedEvent:\n",
    "        # Check for an existing GeneratedEvent object having updates.\n",
    "        if exchange_code in self.events.keys() and self.events[exchange_code].has_update():\n",
    "            event_obj = self.events[exchange_code]\n",
    "            event_state = [(event_obj.pre_open, MarketEvent.PRE_OPEN),\n",
    "                           (event_obj.reg_open, MarketEvent.REG_OPEN),\n",
    "                           (event_obj.reg_close, MarketEvent.REG_CLOSE),\n",
    "                           (event_obj.post_close, MarketEvent.POST_CLOSE)]\n",
    "            # Need now in same format as generated.\n",
    "            datetime_now = parse(datetime.now(event_obj.tz()).strftime('%c'))\n",
    "            gen_ts = parse(event_obj.timestamp)\n",
    "            # Re-generate events when day changes.\n",
    "            if datetime_now.day > gen_ts.day:\n",
    "                del self.events[exchange_code]\n",
    "                return self.generated_events(exchange_code)\n",
    "            # Update changed events on trading days.\n",
    "            for e in event_state:\n",
    "                if datetime_now > parse(e[0]):\n",
    "                    event_dt = self.generate_event(exchange_code, e[1])\n",
    "                    match e[1]:\n",
    "                        case MarketEvent.PRE_OPEN:\n",
    "                            event_obj.pre_open = event_dt\n",
    "                        case MarketEvent.REG_OPEN:\n",
    "                            event_obj.reg_open = event_dt\n",
    "                        case MarketEvent.REG_CLOSE:\n",
    "                            event_obj.reg_close = event_dt\n",
    "                        case MarketEvent.POST_CLOSE:\n",
    "                            event_obj.post_close = event_dt\n",
    "            event_obj.timestamp = datetime.now(event_obj.tz()).strftime('%c')\n",
    "            self.events[exchange_code] = event_obj\n",
    "        # Generate events for an exchange code not in cache.\n",
    "        elif exchange_code not in self.events.keys():\n",
    "            self.events[exchange_code] = GeneratedEvent(\n",
    "                last_close=self.generate_event(exchange_code, MarketEvent.LAST_CLOSE),\n",
    "                pre_open=self.generate_event(exchange_code, MarketEvent.PRE_OPEN),\n",
    "                reg_open=self.generate_event(exchange_code, MarketEvent.REG_OPEN),\n",
    "                reg_close=self.generate_event(exchange_code, MarketEvent.REG_CLOSE),\n",
    "                post_close=self.generate_event(exchange_code, MarketEvent.POST_CLOSE),\n",
    "                is_holiday=datetime.now().date() in self.holidays[exchange_code])\n",
    "        return self.events[exchange_code]\n",
    "\n",
    "    def set_holiday_event(self, exchange_code: str):\n",
    "        self.generated_events(exchange_code).is_holiday = True\n",
    "\n",
    "    def last_market_close(self, exchange_code: str):\n",
    "        return self.generated_events(exchange_code).last_close\n",
    "\n",
    "    def add_documents_list(self, docs: list):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n",
    "        metas=[{\"source\": doc.metadata[\"source\"]} for doc in docs]\n",
    "        content=[doc.page_content for doc in docs]\n",
    "        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate document embedding\")\n",
    "\n",
    "    def add_api_document(self, query: str, api_response: str, topic: str, source: str = \"add_api_document\"):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        splitter = RecursiveJsonSplitter(max_chunk_size=Api.Const.ChunkMax())\n",
    "        docs = splitter.create_documents(texts=[api_response], convert_lists=True)\n",
    "        ids = list(map(str, range(self.db.count(), self.db.count()+len(docs))))\n",
    "        content = [json.dumps(doc.page_content) for doc in docs]\n",
    "        metas = [{\"source\": source, \"topic\": topic}]*len(docs)\n",
    "        tqdm(self.db.add(ids=ids, documents=content, metadatas=metas), desc=\"Generate api embedding\")\n",
    "\n",
    "    def add_peers_document(self, query: str, names: list, topic: str, source: str, group: str):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        peers = {\"symbol\": topic, \"peers\": names}\n",
    "        tqdm(self.db.add(ids=str(self.db.count()),\n",
    "                         documents=[json.dumps(peers)],\n",
    "                         metadatas=[{\"source\": source, \"topic\": topic, \"group\": group}]),\n",
    "             desc=\"Generate peers embedding\")\n",
    "\n",
    "    def get_peers_document(self, query: str, topic: str, group: str):\n",
    "        return self.get_documents_list(query, where={\"$and\": [{\"group\": group}, {\"topic\": topic}]})\n",
    "\n",
    "    def add_rest_chunks(self, chunks: list, topic: str, source: str, ids: Optional[list[str]] = None,\n",
    "                        meta_opt: Optional[list[dict]] = None, is_update: bool = True):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode\n",
    "        if ids is None:\n",
    "            ids = list(map(str, range(self.db.count(), self.db.count()+len(chunks))))\n",
    "        if isinstance(chunks[0], BaseModel):\n",
    "            docs = [model.model_dump_json() for model in chunks]\n",
    "        else:\n",
    "            docs = [json.dumps(obj) for obj in chunks]\n",
    "        meta_base = {\"source\": source, \"topic\": topic}\n",
    "        if meta_opt is not None:\n",
    "            for m in meta_opt:\n",
    "                m.update(meta_base)\n",
    "        metas = [meta_base]*len(chunks) if meta_opt is None else meta_opt\n",
    "        if is_update:\n",
    "            tqdm(self.db.upsert(ids=ids, documents=docs, metadatas=metas), desc=\"Upsert chunks embedding\")\n",
    "        else:\n",
    "            tqdm(self.db.add(ids=ids, documents=docs, metadatas=metas), desc=\"Add chunks embedding\")\n",
    "\n",
    "    def get_market_status(self, exchange_code: str) -> tuple[list[VectorStoreResult], bool]: # result, has rest update\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        stored = self.stored_result(self.db.get(where={\n",
    "            \"$and\": [{\"exchange\": exchange_code}, {\"topic\": \"market_status\"}]}))\n",
    "        if len(stored) == 0:\n",
    "            return stored, True\n",
    "        # Check for a daily market status update.\n",
    "        status = json.loads(stored[0].docs)\n",
    "        gen_day = parse(self.generated_events(exchange_code).timestamp).day\n",
    "        store_day = parse(stored[0].meta['timestamp']).day\n",
    "        if status[\"holiday\"] != MarketSession.NA.value and gen_day == store_day:\n",
    "            return stored, False\n",
    "        elif gen_day > store_day:\n",
    "            return stored, True\n",
    "        # Update with generated events to avoid rest api requests.\n",
    "        status[\"session\"] = self.generated_events(exchange_code).session().value\n",
    "        status[\"isOpen\"] = self.generated_events(exchange_code).is_open()\n",
    "        stored[0].docs = json.dumps(status)\n",
    "        return stored, False\n",
    "\n",
    "    def get_basic_financials(self, query: str, topic: str, source: str = \"get_financials_1\"):\n",
    "        return self.get_documents_list(\n",
    "            query, max_sources=200, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n",
    "\n",
    "    def add_quote_document(self, query: str, quote: str, topic: str, timestamp: int, source: str):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        tqdm(self.db.add(ids=str(self.db.count()), \n",
    "                             documents=[quote], \n",
    "                             metadatas=[{\"source\": source, \"topic\": topic, \"timestamp\": timestamp}]), \n",
    "             desc=\"Generate quote embedding\")\n",
    "\n",
    "    def get_api_documents(self, query: str, topic: str, source: str = \"add_api_document\", \n",
    "                          meta_opt: Optional[list[dict]] = None):\n",
    "        where = [{\"source\": source}, {\"topic\": topic}]\n",
    "        if meta_opt is None:\n",
    "            return self.get_documents_list(query, where={\"$and\": where})\n",
    "        else:\n",
    "            for meta in meta_opt:\n",
    "                for k,v in meta.items():\n",
    "                    where.append({k: v})\n",
    "            return self.get_documents_list(query, where={\"$and\": where})\n",
    "\n",
    "    def query_api_documents(self, query: str, topic: str, source: str = \"add_api_document\"):\n",
    "        return self.generate_answer(query, where={\"$and\": [{\"source\": source}, {\"topic\": topic}]})\n",
    "\n",
    "    def add_grounded_document(self, query: str, topic: str, result):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        chunks = result.candidates[0].grounding_metadata.grounding_chunks\n",
    "        supports = result.candidates[0].grounding_metadata.grounding_supports\n",
    "        if supports is not None: # Only add grounded documents which have supports\n",
    "            grounded_text = [f\"{s.segment.text}\" for s in supports]\n",
    "            source = [f\"{c.web.title}\" for c in chunks]\n",
    "            score = [f\"{s.confidence_scores}\" for s in supports]\n",
    "            tqdm(self.db.add(ids=str(self.db.count()),\n",
    "                             documents=json.dumps(grounded_text),\n",
    "                             metadatas=[{\"source\": \", \".join(source),\n",
    "                                         \"confidence_score\": \", \".join(score),\n",
    "                                         \"topic\": topic,\n",
    "                                         \"question\": query}]),\n",
    "                 desc=\"Generate grounding embedding\")\n",
    "\n",
    "    def get_grounding_documents(self, query: str, topic: str):\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        return self.stored_result(self.db.get(where={\"$and\": [{\"question\": query}, {\"topic\": topic}]}))\n",
    "            \n",
    "    def add_wiki_documents(self, title: str, wiki_chunks: list):\n",
    "        self.embed_fn.document_mode = True # Switch to document mode.\n",
    "        result = self.get_wiki_documents(title)\n",
    "        if len(result) == 0:\n",
    "            ids = list(map(str, range(self.db.count(), self.db.count()+len(wiki_chunks))))\n",
    "            metas=[{\"title\": title, \"source\": \"add_wiki_documents\"}]*len(wiki_chunks)\n",
    "            tqdm(self.db.add(ids=ids, documents=wiki_chunks, metadatas=metas), desc=\"Generate wiki embeddings\")\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def generate_with_wiki_passages(self, query: str, title: str, passages: list[str]):\n",
    "        return self.generate_answer(query, where={\"title\": title}, passages=passages)\n",
    "    \n",
    "    def get_wiki_documents(self, title: Optional[str] = None):\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        if title is None:\n",
    "            return self.stored_result(self.db.get(where={\"source\": \"add_wiki_document\"}))\n",
    "        else:\n",
    "            return self.stored_result(self.db.get(where={\"title\": title}))\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def get_documents_list(self, query: str, max_sources: int = 5000, where: Optional[dict] = None):\n",
    "        self.embed_fn.document_mode = False # Switch to query mode.\n",
    "        return self.stored_result(\n",
    "            self.db.query(query_texts=[query], \n",
    "                          n_results=max_sources, \n",
    "                          where=where), \n",
    "            is_query = True)\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def get_exchanges_csv(self, query: str):\n",
    "        return self.generate_answer(query, max_sources=100, where={\"source\": \"exchanges.csv\"})\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def generate_answer(self, query: str, max_sources: int = 10, \n",
    "                        where: Optional[dict] = None, passages: Optional[list[str]] = None):\n",
    "        stored = self.get_documents_list(query, max_sources, where)\n",
    "        query_oneline = query.replace(\"\\n\", \" \")\n",
    "        prompt = f\"\"\"You're an expert writer. You understand how to interpret html and markdown. You will accept the\n",
    "        question below and answer based only on the passages. Never mention the passages in your answers. Be sure to \n",
    "        respond in concise sentences. Include all relevant background information when possible. If a passage is not \n",
    "        relevant to the answer you must ignore it. If no passage answers the question respond with: I don't know.\n",
    "\n",
    "        QUESTION: {query_oneline}\n",
    "        \n",
    "        \"\"\"\n",
    "        # Add the retrieved documents to the prompt.\n",
    "        stored_docs = [passage.docs for passage in stored]\n",
    "        for passage in stored_docs if passages is None else stored_docs + passages:\n",
    "            passage_oneline = passage.replace(\"\\n\", \" \")\n",
    "            prompt += f\"PASSAGE: {passage_oneline}\\n\"\n",
    "        # Generate the response.\n",
    "        response = api.retriable(\n",
    "            self.client.models.generate_content,\n",
    "            model=api(Api.Model.GEN),\n",
    "            config=self.config_temp,\n",
    "            contents=prompt)\n",
    "        # Check for generated code and store in memory.\n",
    "        content = response.candidates[0].content\n",
    "        if len(content.parts) > 1 and content.parts[0].executable_code:\n",
    "            memory.append_code(prompt, content.parts)\n",
    "        return response\n",
    "\n",
    "    def stored_result(self, result, is_query: bool = False) -> list[VectorStoreResult]:\n",
    "        try:\n",
    "            results = []\n",
    "            if len(result[\"documents\"]) == 0:\n",
    "                return results\n",
    "            if isinstance(result[\"documents\"][0], list):\n",
    "                for i in range(len(result[\"documents\"][0])):\n",
    "                    obj = VectorStoreResult(docs=result[\"documents\"][0][i],\n",
    "                                            dist=result[\"distances\"][0][i] if is_query else None,\n",
    "                                            meta=result[\"metadatas\"][0][i],\n",
    "                                            store_id=result[\"ids\"][0][i])\n",
    "                    results.append(obj)\n",
    "            else:\n",
    "                results.append(\n",
    "                    VectorStoreResult(docs=result[\"documents\"][0],\n",
    "                                      dist=result[\"distances\"][0] if is_query else None,\n",
    "                                      meta=result[\"metadatas\"][0],\n",
    "                                      store_id=result[\"ids\"][0]))\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiki Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:36.866933Z",
     "iopub.status.busy": "2025-12-01T09:38:36.866551Z",
     "iopub.status.idle": "2025-12-01T09:38:36.878151Z",
     "shell.execute_reply": "2025-12-01T09:38:36.877191Z",
     "shell.execute_reply.started": "2025-12-01T09:38:36.866902Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: wiki-grounding generation.\n",
    "# - using gemini-2.0-flash for response generation\n",
    "# - using a RAG-implementation to store groundings\n",
    "# - create new groundings by similarity to topic\n",
    "# - retrieve existing groundings by similarity to topic\n",
    "class WikiGroundingGenerator:   \n",
    "    def __init__(self, genai_client, rag_impl):\n",
    "        self.client = genai_client\n",
    "        self.rag = rag_impl\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\") # suppress beta-warning\n",
    "            self.splitter = HTMLSemanticPreservingSplitter(\n",
    "                headers_to_split_on=[(\"h2\", \"Main Topic\"), (\"h3\", \"Sub Topic\")],\n",
    "                separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \"],\n",
    "                max_chunk_size=Api.Const.ChunkMax(),\n",
    "                chunk_overlap=50,\n",
    "                preserve_links=True,\n",
    "                preserve_images=True,\n",
    "                preserve_videos=True,\n",
    "                preserve_audio=True,\n",
    "                elements_to_preserve=[\"table\", \"ul\", \"ol\", \"code\"],\n",
    "                denylist_tags=[\"script\", \"style\", \"head\"],\n",
    "                custom_handlers={\"code\": self.code_handler},\n",
    "            )\n",
    "\n",
    "    def generate_answer(self, query: str, topic: str):\n",
    "        stored = self.rag.get_wiki_documents(topic)\n",
    "        if len(stored) > 0:\n",
    "            return self.rag.generate_with_wiki_passages(query, topic, [chunk.docs for chunk in stored]).text\n",
    "        else:\n",
    "            pages = wikipedia.search(topic + \" company\")\n",
    "            if len(pages) > 0:\n",
    "                p_topic_match = 0.80\n",
    "                for i in range(len(pages)):\n",
    "                    if tqdm(api.similarity([topic + \" company\", pages[i]]) > p_topic_match, \n",
    "                            desc= \"Score wiki search by similarity to topic\"):\n",
    "                        page_html = Api.get(f\"https://en.wikipedia.org/wiki/{pages[i]}\")\n",
    "                        chunks = [chunk.page_content for chunk in self.splitter.split_text(page_html)]\n",
    "                        self.rag.add_wiki_documents(topic, chunks)\n",
    "                        return self.rag.generate_with_wiki_passages(query, topic, chunks).text\n",
    "            return Api.Const.Stop()\n",
    "\n",
    "    def code_handler(self, element: Tag) -> str:\n",
    "        data_lang = element.get(\"data-lang\")\n",
    "        code_format = f\"<code:{data_lang}>{element.get_text()}</code>\"\n",
    "        return code_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:36.879393Z",
     "iopub.status.busy": "2025-12-01T09:38:36.879095Z",
     "iopub.status.idle": "2025-12-01T09:38:36.907264Z",
     "shell.execute_reply": "2025-12-01T09:38:36.905975Z",
     "shell.execute_reply.started": "2025-12-01T09:38:36.879373Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: search-grounding generation.\n",
    "# - using gemini-2.0-flash with GoogleSearch tool for response generation\n",
    "# - using a RAG-implementation to store groundings\n",
    "# - create new groundings by exact match to topic\n",
    "# - retrieve existing groundings by similarity to topic\n",
    "class SearchGroundingGenerator:\n",
    "    config_ground = types.GenerateContentConfig(\n",
    "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    \n",
    "    def __init__(self, genai_client, rag_impl):\n",
    "        self.client = genai_client\n",
    "        self.rag = rag_impl\n",
    "\n",
    "    def generate_answer(self, query: str, topic: str):\n",
    "        stored = self.rag.get_grounding_documents(query, topic)\n",
    "        if len(stored) > 0:\n",
    "            for i in range(len(stored)):\n",
    "                meta_q = stored[i].meta[\"question\"]\n",
    "                p_ground_match = 0.95 # This can be really high ~ 95-97%\n",
    "                if tqdm(api.similarity([query, meta_q]) > p_ground_match,\n",
    "                        desc=\"Score similarity to stored grounding\"):\n",
    "                    return ast.literal_eval(stored[i].docs)\n",
    "        return self.get_grounding(query, topic)\n",
    "\n",
    "    @retry.Retry(\n",
    "        predicate=is_retriable,\n",
    "        initial=2.0,\n",
    "        maximum=64.0,\n",
    "        multiplier=2.0,\n",
    "        timeout=600,\n",
    "    )\n",
    "    def get_grounding(self, query: str, topic: str):\n",
    "        contents = [types.Content(role=\"user\", parts=[types.Part(text=query)])]\n",
    "        contents += f\"\"\"\n",
    "        You're a search assistant that provides answers to questions about {topic}.\n",
    "        Do not discuss alternative topics of interest. Do not discuss similar topics.\n",
    "        You will provide answers that discuss only {topic}. \n",
    "        You may discuss the owner or parent of {topic} when no other answer is possible.\n",
    "        Otherwise respond with: I don't know.\"\"\"\n",
    "        response = api.retriable(self.client.models.generate_content, \n",
    "                                 model=api(Api.Model.GEN), \n",
    "                                 config=self.config_ground, \n",
    "                                 contents=contents)\n",
    "        if response.candidates[0].grounding_metadata.grounding_supports is not None:\n",
    "            if self.is_consistent(query, topic, response.text):\n",
    "                self.rag.add_grounded_document(query, topic, response)\n",
    "                return response.text \n",
    "        return Api.Const.Stop() # Empty grounding supports or not consistent in response\n",
    "\n",
    "    def is_consistent(self, query: str, topic: str, model_response: str) -> bool:\n",
    "        topic = topic.replace(\"'\", \"\")\n",
    "        id_strs = topic.split()\n",
    "        if len(id_strs) == 1:\n",
    "            matches = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", query)\n",
    "            if len(matches) > 0:\n",
    "                topic = matches[0]\n",
    "        compound_match = re.findall(rf\"{id_strs[0]}[\\s,.]+\\S+\", model_response)\n",
    "        model_response = model_response.replace(\"'\", \"\")\n",
    "        if len(compound_match) == 0 and topic in model_response:\n",
    "            return True # not a compound topic id and exact topic match\n",
    "        for match in compound_match:\n",
    "            if topic not in match:\n",
    "                return False\n",
    "        return True # all prefix matches contained topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rest Grounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:36.908675Z",
     "iopub.status.busy": "2025-12-01T09:38:36.908331Z",
     "iopub.status.idle": "2025-12-01T09:38:36.930145Z",
     "shell.execute_reply": "2025-12-01T09:38:36.929102Z",
     "shell.execute_reply.started": "2025-12-01T09:38:36.90865Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Rest api-helpers to manage request-per-minute limits.\n",
    "# - define an entry for each endpoint limit\n",
    "# - init rest tool with limits to create blocking queues\n",
    "# - apply a limit to requests with rest_tool.try_url\n",
    "class ApiLimit(Enum):\n",
    "    FINN = \"finnhub.io\",50\n",
    "    POLY = \"polygon.io\",4 # (id_url,rpm)\n",
    "\n",
    "class BlockingUrlQueue:\n",
    "    on_cooldown = False\n",
    "    cooldown = None\n",
    "    cooldown_start = None\n",
    "    \n",
    "    def __init__(self, rest_fn: Callable, per_minute: int):\n",
    "        self.per_minute_max = per_minute\n",
    "        self.quota = per_minute\n",
    "        self.rest_fn = rest_fn\n",
    "\n",
    "    def push(self, rest_url: str):\n",
    "        if not self.on_cooldown:\n",
    "            self.cooldown = Timer(60, self.reset_quota)\n",
    "            self.cooldown.start()\n",
    "            self.cooldown_start = time.time()\n",
    "            self.on_cooldown = True\n",
    "        if self.quota > 0:\n",
    "            self.quota -= 1\n",
    "            time.sleep(0.034) # ~30 requests per second\n",
    "            return self.rest_fn(rest_url)\n",
    "        else:\n",
    "            print(f\"limited {self.per_minute_max}/min, waiting {self.limit_expiry()}s\")\n",
    "            time.sleep(max(self.limit_expiry(),0.5))\n",
    "            return self.push(rest_url)\n",
    "\n",
    "    def reset_quota(self):\n",
    "        self.quota = self.per_minute_max\n",
    "        self.on_cooldown = False\n",
    "        self.cooldown_start = None\n",
    "\n",
    "    def limit_expiry(self):\n",
    "        if self.cooldown_start:\n",
    "            return max(60-(time.time()-self.cooldown_start),0)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:36.931802Z",
     "iopub.status.busy": "2025-12-01T09:38:36.931444Z",
     "iopub.status.idle": "2025-12-01T09:38:36.983056Z",
     "shell.execute_reply": "2025-12-01T09:38:36.981844Z",
     "shell.execute_reply.started": "2025-12-01T09:38:36.931773Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define tool: rest-grounding generation.\n",
    "# - using gemini-2.0-flash for response generation\n",
    "# - using a RAG-implementation to store groundings\n",
    "# - reduce long-context by chunked pre-processing\n",
    "class RestGroundingGenerator:    \n",
    "    limits = None\n",
    "\n",
    "    def __init__(self, rag_impl, with_limits: bool):\n",
    "        self.rag = rag_impl\n",
    "        if with_limits:\n",
    "            self.limits = {}\n",
    "            for rest_api in ApiLimit:\n",
    "                self.limits[rest_api.value[0]] = BlockingUrlQueue(Api.get, rest_api.value[1])\n",
    "\n",
    "    def get_limit(self, rest_api: ApiLimit) -> Optional[BlockingUrlQueue]:\n",
    "        return self.limits[rest_api.value[0]] if self.limits else None\n",
    "\n",
    "    def basemodel(self, data: str, schema: BaseModel, from_lambda: bool = False) -> Optional[BaseModel]:\n",
    "        try:\n",
    "            if from_lambda:\n",
    "                return schema(results=json.loads(data))\n",
    "            return schema.model_validate_json(data)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    def dailycandle(self, data: str) -> Optional[DailyCandle]:\n",
    "        try:\n",
    "            candle = json.loads(data)\n",
    "            if \"from\" not in candle:\n",
    "                raise ValueError(\"not a dailycandle / missing value for date\")\n",
    "            agg = self.basemodel(data, Aggregate)\n",
    "            return DailyCandle(from_date=candle[\"from\"], \n",
    "                               status=agg.status.value, \n",
    "                               symbol=agg.symbol, \n",
    "                               open=agg.open, \n",
    "                               high=agg.high, \n",
    "                               low=agg.low, \n",
    "                               close=agg.close, \n",
    "                               volume=agg.volume, \n",
    "                               otc=agg.otc, \n",
    "                               preMarket=agg.preMarket, \n",
    "                               afterHours=agg.afterHours)\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "\n",
    "    @retry.Retry(timeout=600)\n",
    "    def try_url(self, url: str, schema: BaseModel, as_lambda: bool, with_limit: Optional[BlockingUrlQueue],\n",
    "                success_fn: Callable, *args, **kwargs):\n",
    "        try:\n",
    "            if self.limits is None:\n",
    "                data = Api.get(url)\n",
    "            elif with_limit:\n",
    "                data = with_limit.push(url)\n",
    "            if schema is DailyCandle:\n",
    "                model = self.dailycandle(data)\n",
    "            else:\n",
    "                model = self.basemodel(data, schema, as_lambda)\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                print(f\"try_url exception: {e}\")\n",
    "                if issubclass(schema, RestResultPoly):\n",
    "                    return success_fn(*args, **kwargs, result=self.basemodel(data, RestResultPoly))\n",
    "            except Exception as not_a_result:\n",
    "                print(not_a_result)\n",
    "            return StopGeneration()\n",
    "        else:\n",
    "            return success_fn(*args, **kwargs, model=model)\n",
    "\n",
    "    def get_symbol_matches(self, with_content, by_name: bool, model: SymbolResult):\n",
    "        matches = []\n",
    "        max_failed_match = model.count if not by_name else 3\n",
    "        p_desc_match = 0.92\n",
    "        p_symb_match = 0.95\n",
    "        if model.count > 0:\n",
    "            for obj in tqdm(model.get(), desc=\"Score similarity to query\"):\n",
    "                if max_failed_match > 0:\n",
    "                    desc = [with_content[\"q\"].upper(), obj.description.split(\"-\", -1)[0]]\n",
    "                    symb = [with_content[\"q\"].upper(), obj.symbol]\n",
    "                    if by_name and api.similarity(desc) > p_desc_match: \n",
    "                        matches.append(obj.symbol)\n",
    "                    elif not by_name and api.similarity(symb) > p_symb_match:\n",
    "                        matches.append(obj.description)\n",
    "                        max_failed_match = 0\n",
    "                    else:\n",
    "                        max_failed_match -= 1\n",
    "        if len(matches) > 0:\n",
    "            self.rag.add_api_document(with_content[\"query\"], matches, with_content[\"q\"], \"get_symbol_1\")\n",
    "            return matches\n",
    "        return Api.Const.Stop()\n",
    "\n",
    "    def get_quote(self, with_content, model: Quote):\n",
    "        quote = model.model_dump_json()\n",
    "        self.rag.add_quote_document(with_content[\"query\"], quote, with_content[\"symbol\"], model.t, \"get_quote_1\")\n",
    "        return quote\n",
    "\n",
    "    def parse_financials(self, with_content, model: BasicFinancials):\n",
    "        metric = list(model.metric.items())\n",
    "        chunks = []\n",
    "        # Chunk the metric data.\n",
    "        for i in range(0, len(metric), Api.Const.MetricBatch()):\n",
    "            batch = metric[i:i + Api.Const.MetricBatch()]\n",
    "            chunks.append({\"question\": with_content[\"query\"], \"answer\": batch})\n",
    "        # Chunk the series data.\n",
    "        for key in model.series.keys():\n",
    "            series = list(model.series[key].items())\n",
    "            for s in series:\n",
    "                if api.token_count(s) <= Api.Const.ChunkMax():\n",
    "                    chunks.append({\"question\": with_content[\"query\"], \"answer\": s})\n",
    "                else:\n",
    "                    k = s[0]\n",
    "                    v = s[1]\n",
    "                    for i in range(0, len(v), Api.Const.SeriesBatch()):\n",
    "                        batch = v[i:i + Api.Const.SeriesBatch()]\n",
    "                        chunks.append({\"question\": with_content[\"query\"], \"answer\": {k: batch}})\n",
    "        self.rag.add_rest_chunks(chunks, topic=with_content[\"symbol\"], source=\"get_financials_1\")\n",
    "        return chunks\n",
    "\n",
    "    def parse_news(self, with_content, model: NewsResultFinn):\n",
    "        if model.count > 0:\n",
    "            metas = []\n",
    "            for digest in model.get():\n",
    "                pub_date = datetime.fromtimestamp(digest.datetime, tz=GeneratedEvent.tz()).strftime(\"%Y-%m-%d\")\n",
    "                metas.append({\"publisher\": digest.source,\n",
    "                              \"published_est\": parse(pub_date).timestamp(),\n",
    "                              \"news_id\": digest.id,\n",
    "                              \"related\": digest.related})\n",
    "            self.rag.add_rest_chunks(model.get(), topic=with_content[\"symbol\"], source=\"get_news_1\",\n",
    "                                     ids=[f\"{digest.id}+news\" for digest in model.get()],\n",
    "                                     meta_opt=metas, is_update=False)\n",
    "            return [digest.summary().model_dump_json() for digest in model.get()]\n",
    "        return Api.Const.Stop()\n",
    "\n",
    "    def parse_news(self, with_content, model: Optional[NewsResultPoly] = None,\n",
    "                   result: Optional[RestResultPoly] = None) -> tuple[list, str]: # list of summary, next list url\n",
    "        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n",
    "            metas = []\n",
    "            for news in model.get():\n",
    "                pub_date = parse(news.published_utc).strftime(\"%Y-%m-%d\")\n",
    "                metas.append({\"publisher\": news.publisher.name,\n",
    "                              \"published_utc\": parse(pub_date).timestamp(),\n",
    "                              \"news_id\": news.id,\n",
    "                              \"related\": json.dumps(news.tickers),\n",
    "                              \"keywords\": json.dumps(news.keywords)})\n",
    "            self.rag.add_rest_chunks(model.get(), topic=with_content[\"ticker\"], source=\"get_news_2\",\n",
    "                                     ids=[news.id for news in model.get()],\n",
    "                                     meta_opt=metas, is_update=False)\n",
    "            return [news.summary().model_dump_json() for news in model.get()], model.next_url\n",
    "        elif result:\n",
    "            return result.model_dump_json()\n",
    "\n",
    "    def parse_daily_candle(self, with_content, model: Optional[DailyCandle] = None,\n",
    "                           result: Optional[RestResultPoly] = None):\n",
    "        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n",
    "            self.rag.add_rest_chunks(\n",
    "                chunks=[model],\n",
    "                topic=with_content[\"stocksTicker\"],\n",
    "                source=\"daily_candle_2\",\n",
    "                meta_opt=[{\"from_date\": model.from_date, \"adjusted\": with_content[\"adjusted\"]}])\n",
    "            return model\n",
    "        elif result:\n",
    "            return result\n",
    "\n",
    "    def parse_custom_candle(self, with_content, model: Optional[CustomCandle] = None,\n",
    "                            result: Optional[RestResultPoly] = None):\n",
    "        if model and model.status in [RestStatus.OK, RestStatus.DELAY]:\n",
    "            metas = [{\n",
    "                \"timespan\": with_content[\"timespan\"],\n",
    "                \"adjusted\": with_content[\"adjusted\"],\n",
    "                \"from\": with_content[\"from\"],\n",
    "                \"to\": with_content[\"to\"]}]*model.count\n",
    "            candles = [candle.model_dump_json() for candle in model.get()]\n",
    "            self.rag.add_rest_chunks(\n",
    "                chunks=candles,\n",
    "                topic=with_content[\"stocksTicker\"],\n",
    "                source=\"custom_candle_2\",\n",
    "                meta_opt=metas)\n",
    "            return candles\n",
    "        elif result:\n",
    "            return result.model_dump_json()\n",
    "\n",
    "    def parse_overview(self, with_content, model: OverviewResult):\n",
    "        overview = [model.get().model_dump_json()]\n",
    "        self.rag.add_rest_chunks(chunks=overview, topic=with_content[\"ticker\"], source=\"ticker_overview_2\")\n",
    "        return overview\n",
    "\n",
    "    def parse_trends(self, with_content, model: TrendsResult):\n",
    "        if model.count > 0:\n",
    "            metas = [{\"period\": trend.period} for trend in model.get()]\n",
    "            trends = [trend.model_dump_json() for trend in model.get()]\n",
    "            self.rag.add_rest_chunks(trends, topic=with_content[\"symbol\"], source=\"trends_1\", meta_opt=metas)\n",
    "            return trends\n",
    "        return Api.Const.Stop()\n",
    "\n",
    "    def augment_market_status(self, with_id: Optional[str], model: MarketStatusResult):\n",
    "        if model.get().holiday != MarketSession.NA.value:\n",
    "            self.rag.set_holiday_event(model.get().exchange)\n",
    "        events = self.rag.generated_events(model.get().exchange)\n",
    "        model.get().session = events.session()\n",
    "        model.get().isOpen = events.is_open()\n",
    "        meta = {\"exchange\": model.get().exchange,\n",
    "                \"last_close\": events.last_close,\n",
    "                \"pre_open\": events.pre_open,\n",
    "                \"reg_open\": events.reg_open,\n",
    "                \"reg_close\": events.reg_close,\n",
    "                \"post_close\": events.post_close,\n",
    "                \"timestamp\": events.timestamp }\n",
    "        self.rag.add_rest_chunks([model.get()],\n",
    "                                 topic=\"market_status\",\n",
    "                                 source=\"get_market_status_1\",\n",
    "                                 ids=[with_id] if with_id else None,\n",
    "                                 meta_opt=[meta])\n",
    "        return model.get().model_dump_json()\n",
    "\n",
    "    def get_symbol(self, content, by_name: bool = True):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/search?q={content['q']}&exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=SymbolResult,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.get_symbol_matches,\n",
    "            with_content=content,\n",
    "            by_name=by_name)\n",
    "\n",
    "    def get_current_price(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/quote?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=Quote,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.get_quote,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_market_status(self, content, store_id: Optional[str] = None):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/market-status?exchange={content['exchange']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=MarketStatusResult,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.augment_market_status,\n",
    "            with_id=store_id)\n",
    "\n",
    "    def get_peers(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/peers?symbol={content['symbol']}&grouping={content['grouping']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=PeersResult,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=lambda model: model)\n",
    "\n",
    "    def get_basic_financials(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/metric?symbol={content['symbol']}&metric={content['metric']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=BasicFinancials,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.parse_financials,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_news_simple(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/company-news?symbol={content['symbol']}&from={content['from']}&to={content['to']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=NewsResultFinn,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.parse_news,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_news_tagged(self, content):\n",
    "        next_url = f\"https://api.polygon.io/v2/reference/news?ticker={content['ticker']}&published_utc.gte={content['published_utc.gte']}&published_utc.lte={content['published_utc.lte']}&order={content['order']}&limit={content['limit']}&sort={content['sort']}&apiKey={POLYGON_API_KEY}\"\n",
    "        news = []\n",
    "        while True:\n",
    "            news_list, next_url = self.try_url(\n",
    "                next_url,\n",
    "                schema=NewsResultPoly,\n",
    "                as_lambda=False,\n",
    "                with_limit=self.get_limit(ApiLimit.POLY),\n",
    "                success_fn=self.parse_news,\n",
    "                with_content=content)\n",
    "            news += news_list\n",
    "            if next_url is None:\n",
    "                break\n",
    "            next_url += f\"&apiKey={POLYGON_API_KEY}\"\n",
    "        return news\n",
    "\n",
    "    def get_daily_candle(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://api.polygon.io/v1/open-close/{content['stocksTicker']}/{content['date']}?adjusted={content['adjusted']}&apiKey={POLYGON_API_KEY}\",\n",
    "            schema=DailyCandle,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.POLY),\n",
    "            success_fn=self.parse_daily_candle,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_custom_candle(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://api.polygon.io/v2/aggs/ticker/{content['stocksTicker']}/range/{content['multiplier']}/{content['timespan']}/{content['from']}/{content['to']}?adjusted={content['adjusted']}&sort={content['sort']}&limit={content['limit']}&apiKey={POLYGON_API_KEY}\",\n",
    "            schema=CustomCandle,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.POLY),\n",
    "            success_fn=self.parse_custom_candle,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_overview(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://api.polygon.io/v3/reference/tickers/{content['ticker']}?apiKey={POLYGON_API_KEY}\",\n",
    "            schema=OverviewResult,\n",
    "            as_lambda=False,\n",
    "            with_limit=self.get_limit(ApiLimit.POLY),\n",
    "            success_fn=self.parse_overview,\n",
    "            with_content=content)\n",
    "\n",
    "    def get_trends_simple(self, content):\n",
    "        return self.try_url(\n",
    "            f\"https://finnhub.io/api/v1/stock/recommendation?symbol={content['symbol']}&token={FINNHUB_API_KEY}\",\n",
    "            schema=TrendsResult,\n",
    "            as_lambda=True,\n",
    "            with_limit=self.get_limit(ApiLimit.FINN),\n",
    "            success_fn=self.parse_trends,\n",
    "            with_content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callable Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:36.984934Z",
     "iopub.status.busy": "2025-12-01T09:38:36.984594Z",
     "iopub.status.idle": "2025-12-01T09:38:37.044463Z",
     "shell.execute_reply": "2025-12-01T09:38:37.042878Z",
     "shell.execute_reply.started": "2025-12-01T09:38:36.984905Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Callable functions in openapi schema.\n",
    "decl_get_symbol_1 = types.FunctionDeclaration(\n",
    "    name=\"get_symbol_1\",\n",
    "    description=\"\"\"Search for the stock ticker symbol of a given company, security, isin or cusip. Each ticker\n",
    "                   entry provides a description, symbol, and asset type. If this doesn't help you should try \n",
    "                   calling get_wiki_tool_response next.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"A ticker symbol to search for.\"\"\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"q\", \"exchange\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_symbols_1 = types.FunctionDeclaration(\n",
    "    name=\"get_symbols_1\",\n",
    "    description=\"\"\"List all supported symbols and tickers. The results are filtered by exchange code.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter the results.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"exchange\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_name_1 = types.FunctionDeclaration(\n",
    "    name=\"get_name_1\",\n",
    "    description=\"\"\"Search for the name associated with a stock ticker or symbol's company, security, isin or cusip. \n",
    "    Each ticker entry provides a description, matching symbol, and asset type.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The symbol or ticker to search for.\"\"\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            },\n",
    "            \"company\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The company you're searching for.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"q\", \"exchange\", \"query\", \"company\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_symbol_quote_1 = types.FunctionDeclaration(\n",
    "    name=\"get_symbol_quote_1\",\n",
    "    description=\"\"\"Search for the current price or quote of a stock ticker or symbol. The response is\n",
    "                   provided in json format. Each response contains the following key-value pairs:\n",
    "                   \n",
    "                   c: Current price,\n",
    "                   d: Change,\n",
    "                  dp: Percent change,\n",
    "                   h: High price of the day,\n",
    "                   l: Low price of the day,\n",
    "                   o: Open price of the day,\n",
    "                  pc: Previous close price,\n",
    "                   t: Epoch timestamp of price in seconds.\n",
    "\n",
    "                   Parse the response and respond according to this information.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The stock ticker symbol for a company, security, isin, or cusip.\" \n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The exchange code used to filter quotes. This must always be 'US'.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"query\", \"exchange\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_local_datetime = types.FunctionDeclaration(\n",
    "    name=\"get_local_datetime\",\n",
    "    description=\"\"\"Converts an array of timestamps from epoch time to the local timezone format. The result is an array\n",
    "                   of date and time in locale appropriate format. Suitable for use in a locale appropriate response.\n",
    "                   Treat this function as a vector function. Always prefer to batch timestamps for conversion. Use this\n",
    "                   function to format date and time in your responses.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"t\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"\"\"An array of timestamps in seconds since epoch to be converted. The order of\n",
    "                                  timestamps matches the order of conversion.\"\"\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"integer\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"t\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_market_status_1 = types.FunctionDeclaration(\n",
    "    name=\"get_market_status_1\",\n",
    "    description=\"\"\"Get the current market status of global exchanges. Includes whether exchanges are open or closed.  \n",
    "                   Also includes holiday details if applicable. The response is provided in json format. Each response \n",
    "                   contains the following key-value pairs:\n",
    "\n",
    "                   exchange: Exchange code,\n",
    "                   timezone: Timezone of the exchange,\n",
    "                    holiday: Holiday event name, or null if it's not a holiday,\n",
    "                     isOpen: Whether the market is open at the moment,\n",
    "                          t: Epoch timestamp of status in seconds (Eastern Time),\n",
    "                    session: The market session can be 1 of the following values: \n",
    "                    \n",
    "                    pre-market,regular,post-market when open, or null if closed.\n",
    "                    \n",
    "                    Parse the response and respond according to this information.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"exchange\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_market_session_1 = types.FunctionDeclaration(\n",
    "    name=\"get_market_session_1\",\n",
    "    description=\"Get the current market session of global exchanges.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"exchange\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_company_peers_1 = types.FunctionDeclaration(\n",
    "    name=\"get_company_peers_1\",\n",
    "    description=\"\"\"Search for a company's peers. Returns a list of peers operating in the same country and in the same\n",
    "                   sector, industry, or subIndustry. Each response contains the following key-value pairs: \n",
    "                   \n",
    "                   symbol: The company's stock ticker symbol, \n",
    "                   peers: A list containing the peers.\n",
    "                   \n",
    "                   Each peers entry contains the following key-value pairs:\n",
    "                   \n",
    "                   symbol: The peer company's stock ticker symbol, \n",
    "                   name: The peer company's name.\n",
    "                   \n",
    "                   Parse the response and respond according to this information.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The stock ticker symbol of a company to obtain peers.\"\n",
    "            },\n",
    "            \"grouping\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"This parameter may be one of the following values: sector, industry, subIndustry.\n",
    "                                  Always use subIndustry unless told otherwise.\"\"\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"grouping\", \"exchange\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_exchange_codes_1 = types.FunctionDeclaration(\n",
    "    name=\"get_exchange_codes_1\",\n",
    "    description=\"\"\"Get a dictionary mapping all supported exchange codes to their names.\"\"\"\n",
    ")\n",
    "\n",
    "decl_get_exchange_code_1 = types.FunctionDeclaration(\n",
    "    name=\"get_exchange_code_1\",\n",
    "    description=\"\"\"Search for the exchange code to use when filtering by exchange. The result will be one or\n",
    "                   more exchange codes provided as a comma-separated string value.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Specifies which exchange code to search for.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"q\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_financials_1 = types.FunctionDeclaration(\n",
    "    name=\"get_financials_1\",\n",
    "    description=\"\"\"Get company basic financials such as margin, P/E ratio, 52-week high/low, etc. Parse the response for \n",
    "                   key-value pairs in json format and interpret their meaning as stock market financial indicators.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol for a company.\"\n",
    "            },\n",
    "            \"metric\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"It must always be declared as the value 'all'\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"metric\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_daily_candlestick_2 = types.FunctionDeclaration(\n",
    "    name=\"get_daily_candlestick_2\",\n",
    "    description=\"\"\"Get a historical daily stock ticker candlestick / aggregate bar (OHLC). \n",
    "                   Includes historical daily open, high, low, and close prices. Also includes historical daily trade\n",
    "                   volume and pre-market/after-hours trade prices. It provides the last trading days' data after \n",
    "                   11:59PM Eastern Time.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"stocksTicker\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The stock ticker symbol of a company to search for.\",\n",
    "            },\n",
    "            \"date\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"The date of the requested candlestick in format YYYY-MM-DD.\"\"\"\n",
    "            },\n",
    "            \"adjusted\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n",
    "                                  Use true unless told otherwise.\"\"\"\n",
    "            },\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"stocksTicker\", \"date\", \"adjusted\", \"exchange\", \"query\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "decl_get_company_news_1 = types.FunctionDeclaration(\n",
    "    name=\"get_company_news_1\",\n",
    "    description=\"Retrieve the most recent news articles related to a specified ticker.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol for a company.\",\n",
    "            },\n",
    "            \"from\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be older than the parameter 'to'.\"\"\"\n",
    "            },\n",
    "            \"to\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD. It must be more recent than the parameter 'from'. The\n",
    "                                  default value is today's date.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"from\", \"to\", \"query\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "decl_get_custom_candlestick_2 = types.FunctionDeclaration(\n",
    "    name=\"get_custom_candlestick_2\",\n",
    "    description=\"\"\"Get a historical stock ticker candlestick / aggregate bar (OHLC) over a custom date range and \n",
    "                   time interval in Eastern Time. Includes historical open, high, low, and close prices. Also \n",
    "                   includes historical daily trade volume and pre-market/after-hours trade prices. It includes \n",
    "                   the last trading days' data after 11:59PM Eastern Time.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"stocksTicker\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The stock ticker symbol of a company to search for.\",\n",
    "            },\n",
    "            \"multiplier\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"This must be included and equal to 1 unless told otherwise.\"\n",
    "            },\n",
    "            \"timespan\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The size of the candlestick's time window. This is allowed to be one of the following:\n",
    "                                  second, minute, hour, day, week, month, quarter, or year. The default value is day.\"\"\"\n",
    "            },\n",
    "            \"from\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'to'.\"\"\"\n",
    "            },\n",
    "            \"to\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'from'. The \n",
    "                                  default is one weekday before get_last_market_close.\n",
    "                                  Replace more recent dates with the default.\"\"\"\n",
    "            },\n",
    "            \"adjusted\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"May be true or false. Indicates if the results should be adjusted for splits.\n",
    "                                  Use true unless told otherwise.\"\"\"\n",
    "            },\n",
    "            \"sort\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"This must be included. May be one of asc or desc. asc will sort by timestmap in \n",
    "                                  ascending order. desc will sort by timestamp in descending order.\"\"\"\n",
    "            },\n",
    "            \"limit\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"\"\"Set the number of base aggregates used to create this candlestick. This must be 5000 \n",
    "                                  unless told to limit base aggregates to something else.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"stocksTicker\", \"multiplier\", \"timespan\", \"from\", \"to\", \"adjusted\", \"sort\", \"limit\", \"query\"]\n",
    "    },\n",
    ")\n",
    "\n",
    "decl_get_last_market_close = types.FunctionDeclaration(\n",
    "    name=\"get_last_market_close\",\n",
    "    description=\"\"\"Get the last market close of the specified exchange in Eastern Time. The response has already\n",
    "                   been converted by get_local_datetime so this step should be skipped.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"exchange\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The exchange code used to filter results. When not specified the default exchange \n",
    "                                  code you should use is 'US' for the US exchanges. A dictionary mapping all supported \n",
    "                                  exchange codes to their names be retrieved by calling get_exchange_codes_1. \n",
    "                                  Search for an exchange code to use by calling get_exchange_code_1, specifying the\n",
    "                                  exchange code to search for.\"\"\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"exchange\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_ticker_overview_2 = types.FunctionDeclaration(\n",
    "    name=\"get_ticker_overview_2\",\n",
    "    description=\"\"\"Retrieve comprehensive details for a single ticker symbol. It's a deep look into a companys \n",
    "    fundamental attributes, including its primary exchange, standardized identifiers (CIK, composite FIGI, \n",
    "    share class FIGI), market capitalization, industry classification, and key dates. Also includes branding assets in\n",
    "    the form of icons and logos.\n",
    "    \"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"ticker\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol of a company.\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"ticker\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_recommendation_trends_1 = types.FunctionDeclaration(\n",
    "    name=\"get_recommendation_trends_1\",\n",
    "    description=\"\"\"Get the latest analyst recommendation trends for a company.\n",
    "                The data includes the latest recommendations as well as historical\n",
    "                recommendation data for each month. The data is classified according\n",
    "                to these categories: strongBuy, buy, hold, sell, and strongSell.\n",
    "                The date of a recommendation indicated by the value of 'period'.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol for a company.\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_news_with_sentiment_2 = types.FunctionDeclaration(\n",
    "    name=\"get_news_with_sentiment_2\",\n",
    "    description=\"\"\"Retrieve the most recent news articles related to a specified ticker. Each article includes \n",
    "                   comprehensive coverage. Including a summary, publisher information, article metadata, \n",
    "                   and sentiment analysis.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"ticker\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Stock ticker symbol for a company.\"\n",
    "            },\n",
    "            \"published_utc.gte\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD must be older than the parameter 'published_utc.lte'. \n",
    "                                  The default value is one-month ago from today's date.\"\"\"\n",
    "            },\n",
    "            \"published_utc.lte\": {\n",
    "                \"type\": \"string\",\n",
    "                \"format\": \"date-time\",\n",
    "                \"description\": \"\"\"A date in format YYYY-MM-DD must be more recent than the parameter 'published_utc.gte'.\n",
    "                                  The default is one weekday prior to get_last_market_close (excluding weekends).\n",
    "                                  Replace more recent dates with the default.\"\"\"\n",
    "            },\n",
    "            \"order\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"Must be desc for descending order, or asc for ascending order.\n",
    "                                  When order is not specified the default is descending order.\n",
    "                                  Ordering will be based on the parameter 'sort'.\"\"\"\n",
    "            },\n",
    "            \"limit\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"\"\"This must be included and equal to 1000 unless told otherwise.\"\"\"\n",
    "            },\n",
    "            \"sort\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"\"\"The sort field used for ordering. This value must\n",
    "                                  always be published_utc.\"\"\"\n",
    "            },\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question you're attempting to answer.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"limit\", \"ticker\", \"published_utc.gte\", \"published_utc.lte\", \"order\", \"sort\", \"query\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_rag_tool_response = types.FunctionDeclaration(\n",
    "    name=\"get_rag_tool_response\",\n",
    "    description=\"\"\"A database containing useful financial information. Always check here for answers first.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"A question needing an answer. Asked as a simple string.\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_wiki_tool_response = types.FunctionDeclaration(\n",
    "    name=\"get_wiki_tool_response\",\n",
    "    description=\"\"\"Answers questions that still have unknown answers. Retrieve a wiki page related to a company, \n",
    "                   product, or service. Each web page includes detailed company information, financial indicators, \n",
    "                   tickers, symbols, history, and products and services.\"\"\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question's company or product. Just the name and no other details.\"\n",
    "            },\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The complete, unaltered, query string.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"id\", \"q\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "decl_get_search_tool_response = types.FunctionDeclaration(\n",
    "    name=\"get_search_tool_response\",\n",
    "    description=\"Answers questions that still have unknown answers. Use it after checking all your other tools.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"q\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question needing an answer. Asked as a simple string.\"\n",
    "            },\n",
    "            \"id\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The question's company or product. In one word. Just the name and no other details.\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"q\", \"id\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:37.046725Z",
     "iopub.status.busy": "2025-12-01T09:38:37.046398Z",
     "iopub.status.idle": "2025-12-01T09:38:37.265392Z",
     "shell.execute_reply": "2025-12-01T09:38:37.264589Z",
     "shell.execute_reply.started": "2025-12-01T09:38:37.046695Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import the finance api secret keys.\n",
    "\n",
    "POLYGON_API_KEY = UserSecretsClient().get_secret(\"POLYGON_API_KEY\")\n",
    "FINNHUB_API_KEY = UserSecretsClient().get_secret(\"FINNHUB_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:37.266594Z",
     "iopub.status.busy": "2025-12-01T09:38:37.266369Z",
     "iopub.status.idle": "2025-12-01T09:38:38.529142Z",
     "shell.execute_reply": "2025-12-01T09:38:38.528181Z",
     "shell.execute_reply.started": "2025-12-01T09:38:37.266575Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Instantiate tools and load the exchange data from source csv.\n",
    "# - Identifies exchanges by a 1-2 letter code which can be used to filter response data.\n",
    "# - Also maps the exchange code to exchange details.\n",
    "try:\n",
    "    df = pandas.read_csv(\"/kaggle/input/exchanges/exchanges_src.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    df = pandas.read_csv(\"exchanges_src.csv\") # local run\n",
    "df = df.drop([\"close_date\"], axis=1).fillna(\"\")\n",
    "df.to_csv(\"exchanges.csv\", index=False)\n",
    "exchanges = CSVLoader(file_path=\"exchanges.csv\", encoding=\"utf-8\", csv_args={\"delimiter\": \",\"}).load()\n",
    "\n",
    "# Prepare a RAG tool for use and add the exchange data.\n",
    "tool_rag = RetrievalAugmentedGenerator(api.args.CLIENT, \"finance\")\n",
    "tool_rag.add_documents_list(exchanges)\n",
    "\n",
    "# Prepare a the grounding tools for use.\n",
    "tool_wiki = WikiGroundingGenerator(api.args.CLIENT, tool_rag)\n",
    "tool_ground = SearchGroundingGenerator(api.args.CLIENT, tool_rag)\n",
    "tool_rest = RestGroundingGenerator(tool_rag, with_limits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Calling Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:38.530378Z",
     "iopub.status.busy": "2025-12-01T09:38:38.530074Z",
     "iopub.status.idle": "2025-12-01T09:38:38.563906Z",
     "shell.execute_reply": "2025-12-01T09:38:38.562676Z",
     "shell.execute_reply.started": "2025-12-01T09:38:38.530351Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Implement the callable functions and function handler.\n",
    "\n",
    "def ask_rag_tool(content):\n",
    "    return tool_rag.generate_answer(content[\"question\"]).text\n",
    "\n",
    "def ask_wiki_tool(content):\n",
    "    return tool_wiki.generate_answer(content[\"q\"], content[\"id\"])\n",
    "\n",
    "def ask_search_tool(content):\n",
    "    return tool_ground.generate_answer(content[\"q\"], content[\"id\"])\n",
    "\n",
    "def get_exchange_codes_1(content):\n",
    "    return tool_rag.get_exchange_codes()\n",
    "\n",
    "def get_exchange_code_1(content):\n",
    "    return tool_rag.get_exchange_codes(with_query=content)\n",
    "    \n",
    "def last_market_close(content):\n",
    "    return tool_rag.last_market_close(content[\"exchange\"])\n",
    "    \n",
    "def get_symbol_1(content, by_name: bool = True):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"q\"], \"get_symbol_1\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_symbol(content, by_name)\n",
    "    return json.loads(stored[0].docs)\n",
    "\n",
    "def get_symbols_1(content):\n",
    "    return None # todo\n",
    "\n",
    "def get_name_1(content):\n",
    "    return get_symbol_1(content, by_name = False)\n",
    "\n",
    "def get_quote_1(content):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_quote_1\")\n",
    "    if tool_rag.generated_events(content[\"exchange\"]).is_open():\n",
    "        return get_current_price_1(content)\n",
    "    elif len(stored) > 0:\n",
    "        last_close = parse(tool_rag.last_market_close(content[\"exchange\"])).timestamp()\n",
    "        for quote in stored:\n",
    "            if quote.meta[\"timestamp\"] >= last_close:\n",
    "                return [quote.docs for quote in stored]\n",
    "    return get_current_price_1(content)\n",
    "\n",
    "def get_current_price_1(content):\n",
    "    return tool_rest.get_current_price(content)\n",
    "\n",
    "def get_market_status_1(content):\n",
    "    stored, has_update = tool_rag.get_market_status(content['exchange'])\n",
    "    if has_update:\n",
    "        with_id = stored[0].store_id if len(stored) > 0 else None\n",
    "        return tool_rest.get_market_status(content, with_id)\n",
    "    return stored[0].docs\n",
    "\n",
    "def get_session_1(content):\n",
    "    return json.loads(get_market_status_1(content))[\"session\"]\n",
    "\n",
    "def get_peers_1(content):\n",
    "    stored = tool_rag.get_peers_document(content[\"query\"], content[\"symbol\"], content['grouping'])\n",
    "    if len(stored) == 0:\n",
    "        peers = tool_rest.get_peers(content)\n",
    "        if peers.count > 0:\n",
    "            names = []\n",
    "            for peer in peers.get():\n",
    "                if peer == content[\"symbol\"]:\n",
    "                    continue # skip including the query symbol in peers\n",
    "                name = get_name_1(dict(q=peer, exchange=content[\"exchange\"], query=content[\"query\"]))\n",
    "                if name != Api.Const.Stop():\n",
    "                    data = {\"symbol\": peer, \"name\": name}\n",
    "                    names.append(data)\n",
    "            tool_rag.add_peers_document(content[\"query\"], names, content[\"symbol\"], \"get_peers_1\", content['grouping'])\n",
    "            return names\n",
    "        return Api.Const.Stop()\n",
    "    return json.loads(stored[0].docs)[\"peers\"]\n",
    "\n",
    "def local_datetime(content):\n",
    "    local_t = []\n",
    "    for timestamp in content[\"t\"]:\n",
    "        local_t.append(local_date_from_epoch(timestamp))\n",
    "    return local_t\n",
    "\n",
    "def local_date_from_epoch(timestamp):\n",
    "    if len(str(timestamp)) == 13:\n",
    "        return datetime.fromtimestamp(timestamp/1000, tz=GeneratedEvent.tz()).strftime('%c')\n",
    "    else:\n",
    "        return datetime.fromtimestamp(timestamp, tz=GeneratedEvent.tz()).strftime('%c')\n",
    "\n",
    "def get_financials_1(content):\n",
    "    stored = tool_rag.get_basic_financials(content[\"query\"], content[\"symbol\"], \"get_financials_1\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_basic_financials(content)\n",
    "    return [chunk.docs for chunk in stored]\n",
    "\n",
    "def get_news_1(content):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"get_news_1\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_news_simple(content)\n",
    "    return [NewsTypeFinn.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n",
    "\n",
    "def get_daily_candle_2(content):\n",
    "    stored = tool_rag.get_api_documents(\n",
    "        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"daily_candle_2\", \n",
    "        meta_opt=[{\"from_date\": content[\"date\"], \"adjusted\": content[\"adjusted\"]}])\n",
    "    if len(stored) == 0:\n",
    "        candle = tool_rest.get_daily_candle(content)\n",
    "        # Attempt to recover from choosing a holiday.\n",
    "        candle_date = parse(content[\"date\"])\n",
    "        if candle.status is RestStatus.NONE and candle_date.weekday() == 0 or candle_date.weekday() == 4:\n",
    "            if candle_date.weekday() == 0: # index 0 is monday, index 4 is friday\n",
    "                content[\"date\"] = candle_date.replace(day=candle_date.day-3).strftime(\"%Y-%m-%d\")\n",
    "            else:\n",
    "                content[\"date\"] = candle_date.replace(day=candle_date.day-1).strftime(\"%Y-%m-%d\")\n",
    "            return get_daily_candle_2(content)\n",
    "        return candle.model_dump_json()\n",
    "    return [json.loads(candle.docs) for candle in stored]\n",
    "\n",
    "def get_custom_candle_2(content):\n",
    "    stored = tool_rag.get_api_documents(\n",
    "        query=content[\"query\"], topic=content[\"stocksTicker\"], source=\"custom_candle_2\", \n",
    "        meta_opt=[{\n",
    "            \"timespan\": content[\"timespan\"],\n",
    "            \"adjusted\": content[\"adjusted\"],\n",
    "            \"from\": content[\"from\"],\n",
    "            \"to\": content[\"to\"]}])\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_custom_candle(content)\n",
    "    return [json.loads(candle.docs) for candle in stored]\n",
    "\n",
    "def get_overview_2(content):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"ticker\"], \"ticker_overview_2\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_overview(content)\n",
    "    return json.loads(stored[0].docs)\n",
    "\n",
    "def get_trends_1(content):\n",
    "    stored = tool_rag.get_api_documents(content[\"query\"], content[\"symbol\"], \"trends_1\")\n",
    "    if len(stored) == 0:\n",
    "        return tool_rest.get_trends_simple(content)\n",
    "    return [json.loads(trend.docs) for trend in stored]\n",
    "\n",
    "def get_news_2(content):\n",
    "    timestamp_from = parse(content[\"published_utc.gte\"]).timestamp()\n",
    "    timestamp_to = parse(content[\"published_utc.lte\"]).timestamp()\n",
    "    news_from = tool_rag.get_api_documents(\n",
    "        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_from}])\n",
    "    news_to = tool_rag.get_api_documents(\n",
    "        content[\"query\"], content[\"ticker\"], \"get_news_2\", [{\"published_utc\": timestamp_to}])\n",
    "    if len(news_from) > 0 and len(news_to) > 0:\n",
    "        stored = tool_rag.get_api_documents(\n",
    "            content[\"query\"], content[\"ticker\"], \"get_news_2\",\n",
    "            [{\"published_utc\": {\"$gte\": timestamp_from}},\n",
    "             {\"published_utc\": {\"$lte\": timestamp_to}}])\n",
    "        return [NewsTypePoly.model_validate_json(news.docs).summary().model_dump_json() for news in stored]\n",
    "    return tool_rest.get_news_tagged(content)\n",
    "        \n",
    "finance_tool = types.Tool(\n",
    "    function_declarations=[\n",
    "        decl_get_symbol_1,\n",
    "        decl_get_symbols_1,\n",
    "        decl_get_name_1,\n",
    "        decl_get_symbol_quote_1,\n",
    "        decl_get_market_status_1,\n",
    "        decl_get_market_session_1,\n",
    "        decl_get_company_peers_1,\n",
    "        decl_get_local_datetime,\n",
    "        decl_get_last_market_close,\n",
    "        decl_get_exchange_codes_1,\n",
    "        decl_get_exchange_code_1,\n",
    "        decl_get_financials_1,\n",
    "        decl_get_daily_candlestick_2,\n",
    "        decl_get_custom_candlestick_2,\n",
    "        decl_get_ticker_overview_2,\n",
    "        decl_get_recommendation_trends_1,\n",
    "        decl_get_news_with_sentiment_2,\n",
    "        decl_get_rag_tool_response,\n",
    "        decl_get_wiki_tool_response,\n",
    "        decl_get_search_tool_response\n",
    "    ]\n",
    ")\n",
    "\n",
    "function_handler = {\n",
    "    \"get_symbol_1\": get_symbol_1,\n",
    "    \"get_symbols_1\": get_symbols_1,\n",
    "    \"get_name_1\": get_name_1,\n",
    "    \"get_symbol_quote_1\": get_quote_1,\n",
    "    \"get_market_status_1\": get_market_status_1,\n",
    "    \"get_market_session_1\": get_session_1,\n",
    "    \"get_company_peers_1\": get_peers_1,\n",
    "    \"get_local_datetime\": local_datetime,\n",
    "    \"get_last_market_close\": last_market_close,\n",
    "    \"get_exchange_codes_1\": get_exchange_codes_1,\n",
    "    \"get_exchange_code_1\": get_exchange_code_1,\n",
    "    \"get_financials_1\": get_financials_1,\n",
    "    \"get_daily_candlestick_2\": get_daily_candle_2,\n",
    "    \"get_custom_candlestick_2\": get_custom_candle_2,\n",
    "    \"get_ticker_overview_2\": get_overview_2,\n",
    "    \"get_recommendation_trends_1\": get_trends_1,\n",
    "    \"get_news_with_sentiment_2\": get_news_2,\n",
    "    \"get_rag_tool_response\": ask_rag_tool,\n",
    "    \"get_wiki_tool_response\": ask_wiki_tool,\n",
    "    \"get_search_tool_response\": ask_search_tool\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:38.56542Z",
     "iopub.status.busy": "2025-12-01T09:38:38.565023Z",
     "iopub.status.idle": "2025-12-01T09:38:38.590351Z",
     "shell.execute_reply": "2025-12-01T09:38:38.589087Z",
     "shell.execute_reply.started": "2025-12-01T09:38:38.565396Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Implement the function calling expert.\n",
    "# Define the system prompt.\n",
    "instruction = f\"\"\"You are a helpful and informative bot that answers finance and stock market questions. \n",
    "Only answer the question asked and do not change topic. While the answer is still\n",
    "unknown you must follow these rules for predicting function call order:\n",
    "\n",
    "RULE#1: Always consult your other functions before get_search_tool_response.\n",
    "RULE#2: Always consult get_wiki_tool_response before get_search_tool_response.\n",
    "RULE#3: Always consult get_search_tool_response last.\n",
    "RULE#4: Always convert timestamps with get_local_datetime and use the converted date/time in your response.\n",
    "RULE#5: Always incorporate as much useful information from tools and functions in your response.\"\"\"\n",
    "\n",
    "def get_response():\n",
    "    # Enable system prompt, function calling and minimum-randomness.\n",
    "    config_fncall = types.GenerateContentConfig(\n",
    "        system_instruction=instruction,\n",
    "        tools=[finance_tool],\n",
    "        temperature=0.0\n",
    "    )\n",
    "    memory.response = api.retriable(\n",
    "        api.args.CLIENT.models.generate_content,\n",
    "        model=api(Api.Model.GEN),\n",
    "        config=config_fncall,\n",
    "        contents=memory.contents)\n",
    "\n",
    "def retry_last_send():\n",
    "    api.generation_fail()\n",
    "    time.sleep(api.dt_between)\n",
    "    get_response()\n",
    "\n",
    "@retry.Retry(\n",
    "    predicate=is_retriable,\n",
    "    initial=2.0,\n",
    "    maximum=64.0,\n",
    "    multiplier=2.0,\n",
    "    timeout=600,\n",
    ")\n",
    "def send_message(prompt):\n",
    "    #display(Markdown(\"#### Prompt\"))\n",
    "    #print(prompt, \"\\n\")\n",
    "    memory.set_prompt(prompt)\n",
    "    # Handle cases with multiple chained function calls.\n",
    "    function_calling_in_process = True\n",
    "    # Send the initial user prompt and function declarations.\n",
    "    get_response()\n",
    "    while function_calling_in_process:\n",
    "        try:\n",
    "            response_parts = memory.response.candidates[0].content.parts\n",
    "            # A summary response never includes function calls.\n",
    "            if not any(part.function_call for part in response_parts):\n",
    "                memory.set_summary(\"\\n\".join(e.text for e in response_parts))\n",
    "                function_calling_in_process = False\n",
    "                break # The function calling chain is complete.\n",
    "            else:\n",
    "                # A part can be a function call or reasoning-step.\n",
    "                for part in response_parts:\n",
    "                    if function_call := part.function_call:\n",
    "                        # Extract the function call.\n",
    "                        fn_name = function_call.name\n",
    "                        #display(Markdown(\"#### Predicted function name\"))\n",
    "                        #print(fn_name, \"\\n\")\n",
    "                        # Extract the function call arguments.\n",
    "                        fn_args = {key: value for key, value in function_call.args.items()}\n",
    "                        #display(Markdown(\"#### Predicted function arguments\"))\n",
    "                        #print(fn_args, \"\\n\")\n",
    "                        # Call the predicted function.\n",
    "                        print(\"send_message: get function response\")\n",
    "                        api_response = function_handler[fn_name](fn_args)[:20000] # Stay within the input token limit\n",
    "                        #display(Markdown(\"#### API response\"))\n",
    "                        #print(api_response[:500], \"...\", \"\\n\")\n",
    "                        # Create an API response part.\n",
    "                        api_response_part = types.Part.from_function_response(\n",
    "                            name=fn_name,\n",
    "                            response={\"content\": api_response},\n",
    "                        )\n",
    "                        memory.update_contents(function_call, api_response_part)\n",
    "                    else:\n",
    "                        #display(Markdown(\"#### Natural language reasoning step\"))\n",
    "                        #print(part.text)\n",
    "                        memory.set_reason(part.text)\n",
    "                print(\"send_message: updating state\")\n",
    "                get_response() # Send the updated prompt.\n",
    "                print(\"send_message: got a response\")\n",
    "        except Exception as e:\n",
    "            if isinstance(response_parts, list):\n",
    "                print(\"send_message: generated wrong function arguments\")\n",
    "            retry_last_send()\n",
    "            \n",
    "    # Show the final natural language summary.\n",
    "    display(Markdown(\"#### Natural language response\"))\n",
    "    display(Markdown(memory.summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Baseline Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:38:38.592358Z",
     "iopub.status.busy": "2025-12-01T09:38:38.591569Z",
     "iopub.status.idle": "2025-12-01T09:39:02.665455Z",
     "shell.execute_reply": "2025-12-01T09:39:02.664509Z",
     "shell.execute_reply.started": "2025-12-01T09:38:38.592332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "response = tool_rag.get_exchanges_csv(\n",
    "    \"\"\"Give me a dictionary in string form. It must contain key:value pairs mapping \n",
    "    exchange code to name. Just the dictionary string in pretty form.\"\"\")\n",
    "print(response.candidates[0].content.parts[-1].text)\n",
    "\n",
    "response = tool_rag.get_exchanges_csv(\n",
    "    \"\"\"What is the Germany exchange code? Return only the exchange codes as a simple \n",
    "    comma separated value that I can copy.\"\"\")\n",
    "print(response.candidates[0].content.parts[-1].text, \"\\n\")\n",
    "\n",
    "response = tool_rag.get_exchanges_csv(\"What are the Germany exchanges and thier corresponding exchange codes?\")\n",
    "print(response.text, \"\\n\")\n",
    "\n",
    "response = tool_rag.generate_answer(\"What are Google's stock ticker symbols?\")\n",
    "print(response.text, \"\\n\")\n",
    "\n",
    "response = tool_rag.generate_answer(\"What is Facebook's stock ticker symbol?\")\n",
    "print(response.text, \"\\n\")\n",
    "\n",
    "response = tool_rag.get_exchanges_csv(\"What are the US exchange operating hours?\")\n",
    "print(response.text, \"\\n\")\n",
    "\n",
    "response = tool_rag.get_exchanges_csv(\n",
    "    f\"\"\"Answer based on your knowledge of exchange operating hours.\n",
    "    Do not answer in full sentences. Omit all chat and provide the answer only.\n",
    "    The fields pre_market and post_market both represent extended operating hours.\n",
    "\n",
    "    The current date and time: {datetime.now(GeneratedEvent.tz()).strftime('%c')}\n",
    "\n",
    "    Weekdays are: Mon, Tue, Wed, Thu, Fri.\n",
    "    On weekdays all exchanges open after pre-market and regular hours.\n",
    "    On weekdays all exchanges close after regular and post-market hours.\n",
    "    \n",
    "    Weekends are: Sat, Sun.\n",
    "    Always exclude weekends from exchange operating hours.\n",
    "    A list of holidays in date format mm-dd-yyyy: {tool_rag.holidays[\"US\"]}\n",
    "    Always exclude holidays from exchange operating hours.\n",
    "    When the answer is a holiday use the prior weekday for close.\n",
    "    When the answer is a holiday use the next weekday for open.\n",
    "    \n",
    "    Consider the US exchange's operating hours.\n",
    "    Provide the most recent weekday's close including post_market hours.\n",
    "    \n",
    "    Answer with a date that uses this format: '%a %b %d %X %Y'.\"\"\")\n",
    "print(response.candidates[0].content.parts[-1].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SC1 Baseline Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:39:02.667131Z",
     "iopub.status.busy": "2025-12-01T09:39:02.666714Z",
     "iopub.status.idle": "2025-12-01T09:40:01.671247Z",
     "shell.execute_reply": "2025-12-01T09:40:01.670306Z",
     "shell.execute_reply.started": "2025-12-01T09:39:02.667108Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Wait 59s for rate-limits to reset on FREE-tier.\n",
    "if api.args.API_LIMIT is Api.Limit.FREE.value:\n",
    "    print(\"Gemini API limit is FREE. Waiting 59s...\")\n",
    "    time.sleep(59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:40:01.672421Z",
     "iopub.status.busy": "2025-12-01T09:40:01.672149Z",
     "iopub.status.idle": "2025-12-01T09:50:27.139495Z",
     "shell.execute_reply": "2025-12-01T09:50:27.138624Z",
     "shell.execute_reply.started": "2025-12-01T09:40:01.672401Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"What is the current session for US exchanges?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:50:27.141129Z",
     "iopub.status.busy": "2025-12-01T09:50:27.140509Z",
     "iopub.status.idle": "2025-12-01T09:50:30.743848Z",
     "shell.execute_reply": "2025-12-01T09:50:30.742851Z",
     "shell.execute_reply.started": "2025-12-01T09:50:27.141098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"What is the US market status?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:50:30.745435Z",
     "iopub.status.busy": "2025-12-01T09:50:30.745152Z",
     "iopub.status.idle": "2025-12-01T09:50:32.103219Z",
     "shell.execute_reply": "2025-12-01T09:50:32.10224Z",
     "shell.execute_reply.started": "2025-12-01T09:50:30.745413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"When was the last US market close?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:50:32.108507Z",
     "iopub.status.busy": "2025-12-01T09:50:32.108202Z",
     "iopub.status.idle": "2025-12-01T09:50:34.936982Z",
     "shell.execute_reply": "2025-12-01T09:50:34.936176Z",
     "shell.execute_reply.started": "2025-12-01T09:50:32.108485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"What is Apple's stock ticker?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:50:34.938082Z",
     "iopub.status.busy": "2025-12-01T09:50:34.937778Z",
     "iopub.status.idle": "2025-12-01T09:50:40.869314Z",
     "shell.execute_reply": "2025-12-01T09:50:40.86848Z",
     "shell.execute_reply.started": "2025-12-01T09:50:34.93806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"What is the current price of Amazon stock? Display the result as a json string in markdown.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:50:40.870681Z",
     "iopub.status.busy": "2025-12-01T09:50:40.870394Z",
     "iopub.status.idle": "2025-12-01T09:51:12.966723Z",
     "shell.execute_reply": "2025-12-01T09:51:12.966017Z",
     "shell.execute_reply.started": "2025-12-01T09:50:40.870656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"\"\"Show me Apple's basic financials and help me understand key performance metrics. \n",
    "How has the stock performed?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:51:12.967914Z",
     "iopub.status.busy": "2025-12-01T09:51:12.967585Z",
     "iopub.status.idle": "2025-12-01T09:51:19.10145Z",
     "shell.execute_reply": "2025-12-01T09:51:19.100587Z",
     "shell.execute_reply.started": "2025-12-01T09:51:12.967887Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"I need Apple's daily candlestick from 2025-05-05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:51:19.102661Z",
     "iopub.status.busy": "2025-12-01T09:51:19.102353Z",
     "iopub.status.idle": "2025-12-01T09:51:30.085114Z",
     "shell.execute_reply": "2025-12-01T09:51:30.083891Z",
     "shell.execute_reply.started": "2025-12-01T09:51:19.102633Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"Tell me who are Apple's peers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:51:30.086366Z",
     "iopub.status.busy": "2025-12-01T09:51:30.086069Z",
     "iopub.status.idle": "2025-12-01T10:01:50.212716Z",
     "shell.execute_reply": "2025-12-01T10:01:50.211877Z",
     "shell.execute_reply.started": "2025-12-01T09:51:30.086339Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"Tell me who are Amazon's peers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:01:50.213934Z",
     "iopub.status.busy": "2025-12-01T10:01:50.213671Z",
     "iopub.status.idle": "2025-12-01T10:02:13.190687Z",
     "shell.execute_reply": "2025-12-01T10:02:13.189906Z",
     "shell.execute_reply.started": "2025-12-01T10:01:50.213913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"\"\"Locate Apple's stock ticker, then download recommendation trends of all Apple's peers by sub-industry, \n",
    "and then finally compare them.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:02:13.191973Z",
     "iopub.status.busy": "2025-12-01T10:02:13.191687Z",
     "iopub.status.idle": "2025-12-01T10:02:31.505884Z",
     "shell.execute_reply": "2025-12-01T10:02:31.505059Z",
     "shell.execute_reply.started": "2025-12-01T10:02:13.191951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"\"\"Tell me Amazon's current share price and provide candlestick data for the past month. \n",
    "Sort the data in descending order by date. Format the prices consistently as currency. \n",
    "Round prices to two decimal places. \n",
    "Present the data with multiple columns for display in markdown. \n",
    "Discuss and provide details about any patterns you notice in the price data. \n",
    "Correlate recent patterns with news over the same date range.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:02:31.507048Z",
     "iopub.status.busy": "2025-12-01T10:02:31.50677Z",
     "iopub.status.idle": "2025-12-01T10:02:35.674241Z",
     "shell.execute_reply": "2025-12-01T10:02:35.673221Z",
     "shell.execute_reply.started": "2025-12-01T10:02:31.507028Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"What is Apple's ticker overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:02:35.675526Z",
     "iopub.status.busy": "2025-12-01T10:02:35.675251Z",
     "iopub.status.idle": "2025-12-01T10:03:06.185343Z",
     "shell.execute_reply": "2025-12-01T10:03:06.184215Z",
     "shell.execute_reply.started": "2025-12-01T10:02:35.675505Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"What is Google's stock ticker symbol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:03:06.186601Z",
     "iopub.status.busy": "2025-12-01T10:03:06.186343Z",
     "iopub.status.idle": "2025-12-01T10:03:21.329079Z",
     "shell.execute_reply": "2025-12-01T10:03:21.328009Z",
     "shell.execute_reply.started": "2025-12-01T10:03:06.186581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"What is MGM Studio's stock symbol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:03:21.330314Z",
     "iopub.status.busy": "2025-12-01T10:03:21.329903Z",
     "iopub.status.idle": "2025-12-01T10:03:30.249651Z",
     "shell.execute_reply": "2025-12-01T10:03:30.248672Z",
     "shell.execute_reply.started": "2025-12-01T10:03:21.33029Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"What is MGM Studio's owner company stock symbol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:03:30.252399Z",
     "iopub.status.busy": "2025-12-01T10:03:30.25052Z",
     "iopub.status.idle": "2025-12-01T10:03:38.252751Z",
     "shell.execute_reply": "2025-12-01T10:03:38.2519Z",
     "shell.execute_reply.started": "2025-12-01T10:03:30.252373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"What is Facebook's stock ticker symbol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:03:38.254164Z",
     "iopub.status.busy": "2025-12-01T10:03:38.253799Z",
     "iopub.status.idle": "2025-12-01T10:04:47.16415Z",
     "shell.execute_reply": "2025-12-01T10:04:47.163215Z",
     "shell.execute_reply.started": "2025-12-01T10:03:38.254137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"\"\"Compare Amazon's bullish versus bearish predictions from Oct 01 2025 until today. \n",
    "Include a discussion of recommendation trends, and sentiment analysis of news from the same dates. \n",
    "Discuss any patterns or correlations you find.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:04:47.165337Z",
     "iopub.status.busy": "2025-12-01T10:04:47.165067Z",
     "iopub.status.idle": "2025-12-01T10:05:31.899404Z",
     "shell.execute_reply": "2025-12-01T10:05:31.898486Z",
     "shell.execute_reply.started": "2025-12-01T10:04:47.16531Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"\"\"Compare Google's bullish versus bearish predictions from Oct 01 2025 until today. \n",
    "Include a discussion of recommendation trends, and sentiment analysis of news from the same dates. \n",
    "Discuss any patterns or correlations you find.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:05:31.900755Z",
     "iopub.status.busy": "2025-12-01T10:05:31.900458Z",
     "iopub.status.idle": "2025-12-01T10:19:10.932752Z",
     "shell.execute_reply": "2025-12-01T10:19:10.931852Z",
     "shell.execute_reply.started": "2025-12-01T10:05:31.900732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"\"\"How is the outlook for Apple based on trends and news sentiment from July 01 2025 until today? \n",
    "Perform the same analysis on all peers by sub-industry. Then compare Apple result to it's peers.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:19:10.934219Z",
     "iopub.status.busy": "2025-12-01T10:19:10.933726Z",
     "iopub.status.idle": "2025-12-01T10:20:42.262769Z",
     "shell.execute_reply": "2025-12-01T10:20:42.26176Z",
     "shell.execute_reply.started": "2025-12-01T10:19:10.934198Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "send_message(\"\"\"What does the recent news say about Apple and the impact of tariffs? From 2025-09-01 up to today. \n",
    "Also locate candlestick data for the same dates. \n",
    "Discuss in detail any correlations in patterns between the candlestick and news data. Ignore duplicate news entry.\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7122584,
     "sourceId": 11376588,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
